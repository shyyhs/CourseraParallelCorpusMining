This course is called Communication Strategies for a Virtual Age.
So this is the School of Continuing Studies.
Do you like almonds?
There's a little almond part of your brain that's responsible for whether or not you get bored.
What if I told you that your belly button is the secret to being confident?
My personal experience or what the world says?
These are the questions we are going to answer in Communication Strategies for a Virtual Age.
We designed this course to challenge your thinking.
And at every stage, we are going to teach you the science behind soft skills.
We're going to teach you the biology and the neurology.
Because knowledge without application is useless.
because we're going to show you how to apply communication strategies in person with somebody.
But at the same time, we're going to show you how to take those same strategies and apply them virtually, on a teleconference, on a video conference, over email.
We're going to challenge your ideas of what a virtual team is.
And is it better to actually speak in person?
We're going to give you some tools to become better at communication, public speaking, presenting, creating slides and pitch decks.
We're going to show you strategies to pitch, an entirely new way to elevator pitch.
How to make meetings that people actually want to go to.
What is active listening?
Is there a way you can actually physically practice it?
What we're going to do, is we're going to make you Batman.
For each one of those topics, we're going to give you a series of tools so you have a utility belt.
Can you learn to play basketball by watching TV?
So I go to my bike and I try to fix the flat tire and I totally mess it up, and it doesn't work.
I had to take it to someone to fix it for me.
Why?
Because you can't learn by watching, you can only learn by doing.
In this course as much as possible we will be trying to make you do things.
Analyze something, respond to something, change to something, find something and bring it back.
In the first module is an overview of some ideas in virtual communication and some ideas for communication in general to set up the other modules.
Module two is about presenting and speaking both in person and virtually.
Module three is about negotiation and persuasion.
Module four is pitching and selling.
In the fifth module we are going to be giving you tactics to make meetings more interesting, effective and maybe fun.
So for example, active listening, how to have difficult conversations, how to answer questions effectively.
There are three quizzes and three peer reviews.
So whether it's in a quiz or whether it's in a peer review, the markers, the reviewers are going to be given very specific criteria on how to mark you and listening for specific elements.
Let me give you an example.
Suppose we present you with a scenario on personality types, a one would be you not even referencing personality types, just talking with your opinion.
So it's a sliding scale.
As much as possible because it's communication we've tried to avoid giving you yes or no answers and more nuance in your answers.
I love science.
We've also taken ideas from police interrogation, improv comedy, professional wrestling, busking, poker analysis and trying to take key elements and apply them to communication.
And that's why it's really important that you check out the resources and the readings.
Again the big underlining theme is that you can't learn by watching you have to learn by doing.
Now if you have a PhD or you know someone who has a PhD, you will know that they are very skeptical people, very analytical and that's good.
When I first started we would always spend a bunch of time debating the merits of a given idea.
But here's something that was really funny, at the end of the workshops no matter how much someone disagreed with me, no matter how skeptical they were, by the end they were convinced.
Why?
Because you can't learn by just watching, by reading, you have to do it for yourself.
I'm going to introduce some ideas that will make you skeptical.
I am going to introduce some ideas that you may disagree with, not like and that's okay.
But before you make your final decision, try it for yourself.
Because that's the only way to learn.
So, dear learner, good luck, enjoy, get stressed and see you at the end.
Hi, everybody, welcome.
This is it, lesson one of the course.
Thank you all so much for joining us.
Because the thing you have to remember about this course is I'm not teaching you rules.
There's no one way to do anything, but I am going to teach you tools so that in any situation, you're like Batman.
More formal, I got these three things.
Less formal, I got these three things.
Oh only audio, I got these three things.
You'll have tools for every situation.
But before we get into those tools, we have to identify the three traps most people fall into when they're communicating.
Now, the important thing to realize here is not that these traps exists, but you need to ask yourself which one do you fall into?
Have you ever been really, really bored in a meeting?
When was the last time someone was talking to you with slides, and all you thought yourself is, oh!
I'm just going to do this later.
I'll ask for the slides, I'll look at it later.
Why?
Usually, it's because they fall into one of those three traps.
In the following videos, we are going to discuss those three traps.
But, before you get to those videos, go into the resources section of this first lesson and look at the examples we've shown you.
When it's done, ask yourself, do you fall into those same traps?
Because this will build the foundation for the whole course.
Because if we can avoid these traps not just virtually, but in person, then we can become master communicators.
It's speaking using words and phrases that you wouldn't normally use when you're talking to a friend, when you're talking to someone one-on-one.
Think about it.
Versus saying, "We need to know why people are coming into our stores, and what they're buying when they're in our stores." And then we got to ask them why.
Or, if I go back to the first trap, avoiding third person, it's saying, "You know what?
I realized when I was waiting in line at Starbucks, almost everybody paid with their app.
Which one would make more of an impact on you?
Now I know what.
And let me answer that question in two ways.
Really?
Why not do this?
Start with the formal language, but end with a sentence or two that's talking like a human being.
So with this trap, we don't have to avoid it completely.
We want to try and avoid it as much as we can, or we want to fall into it, but have a little ladder of normal communication of me talking to my friend to get myself out of the trap.
So before you move onto the next video and see what the third trap is, we want you to go into the resources section.
One of them falls into the trap of formalized language, the other does not.
And I want you to ask yourself two questions.
And number two, who would you rather learn from?
So the third trap and this is the biggest one and the hardest to get over.
Too many details when we're speaking.
And you're talking and you're talking.
And as you keep talking, you realize, I don't really know how to finish my point.
And I just keep going and going and then finally it's just kind of like, so that's pretty much everything that I wanted to say for that part of the thing.
Does anyone have any questions or anything?
So when we think about, when we communicate whether it is in video, whether it is via email, whether it is in person, we have to ask ourselves this question.
The answer is yes.
Ask yourself where is the trend going?
The answer is let's talk for two minutes.
When we're on a video chat, when we're trying to sell a point, when we're trying to explain a situation, we think giving you all the details is the most important thing.
Giving you as much information as possible, so that you can absorb it all, so you can make the best decision.
But when do you absorb details?
That's why you say things like can you just send me a summary?
Could you send me the slide?
I just need to see some of the details later.
So we think that by giving more information, by overloading people with details and information, we are enhancing our communication.
But actually, we're hurting it.
So what do people want?
So when we're communicating, whether it's in a teleconference or whether it's in person, what do people want?
How do we avoid falling into the trap of too many details?
So, at the end of your discussion, you want someone to be like, you know what, I need to know more about this.
Can you just send me all the details please?
I really want to know more.
And number two, instead of lots of details, instead of a list of information, they want a picture.
So think of this concept.
Instead of lots of details or list of information, one vivid detail.
Let me give you an example.
And it was really nice and it was a really small island.
And when you went there was like no beaches.
You had to drive to get to the beaches, and it was kind of hard to get to.
And the sand was like all perfect white color.
What if I just said this?
Imagine the perfect beach for a vacation.
That's where I used to work.
You've assumed it's nice and hot.
You've pictured a beautiful beach with sand and looking out onto it.
That is the difference between details and vivid detail.
So how do we avoid too many details?
Speaking in pictures, instead of a list of information, one vivid detail.
If you do that, if you manage to build that muscle, you'll never fall into that trap again.
Now at the end of this video, go into the extra resources.
Now if you're like me, the second you see a long article, you say to yourself, I'm going to read that later.
In this lesson, we're going to address the two major misconceptions between virtual and in-person communication.
Now, I'm not going to tell you one is better than the other.
If you're like me, you're probably thinking, well, there's pros and cons to both.
So, if you were going to ask people, is it easier to communicate in-person or is it easier to communicate virtually through email, through chat, through video conference?
What do you think they would say?
They would say, it's always easier to communicate in person.
Number one, most communication is nonverbal, and you need to see the person to pick up on their body language, their tone.
This feeding off each other is a thing that promotes creativity, it's a thing that promotes people interacting with one another and it creates relationships.
Yes, most communication is nonverbal.
But have you ever mistaken someone's body language?
What happens if you don't connect personality-wise when you meet someone?
Are you more likely to resist their ideas?
That's something that is much rare in virtual communication.
Yes, you can feed off each other's ideas for sure, but then you fall into the trap of group think.
In an email exchange, it is much easier to voice your concerns or voice your questions than in a 10-person meeting, where you're the only person that isn't loving that idea.
How often have you been in a meeting, and you can tell no one wants to do something, but we still do it.
Because the boss is so passionate about that idea.
Because of that energy exchange, it is much easier in in-person communication to fall into group think.
So, which is better?
I don't know.
The truth is, both have pros and cons.
But is there a way we can apply this knowledge?
The answer is yes, by using a bow tie.
We'll get to that after we talk about the second myth.
The second myth is that, it's easier to feel like you're part of a team, part of an organization, part of a tribe in-person than virtually.
What if you walk into an organization where everyone knows each other well except you, first day on the job syndrome.
How much stronger is that feeling of not feeling part of the tribe in-person than if you're on a virtual team?
Let me give you an example.
Many, many years ago, I worked as a waiter in this big hotel.
The hotel had been around since the early 80s.
I started working there in the late 90s.
About 85 percent of the people I worked with had been there since day one of the hotel.
It took me months and months to get acceptance from everyone.
Is everyone always at the tribe, at the same time or some people out, hunter-gathering?
Virtually, no one's out hunter-gathering, because everyone always has their phone or their laptop with them.
So virtually, you can instantly start communicating with all the members of the tribe.
These communities that are huge, international, across the world bridge languages, and none of them have ever met.
That being said, if I truly want to trust, I have to see someone.
I do.
Personally.
How do you really know someone without even knowing what they look like, without being able to read their expressions?
So, how can we get the best of both worlds with the bow tie?
How often have you ended or tried to cut the conversation short by saying, "Could you just maybe send me an email we'll talk back and forth like that?" Let's be real.
How often have you been like, "I do not want to have this conversation.
" Virtual communication is a beautiful edition, and the way the trend is going, if we make the majority of our communication virtual, each side of the bow tie, we're going to be good communicators.
So now, we understand the three major traps in communication that apply both virtually and in person.
But one thing we haven't done is identify, what do we mean when we say virtual communication?
So by the end of this lesson, you will understand the three major types of virtual teams and how you make people feel like a strong part of that team, irrespective of which one it is.
So here are the three types of virtual teams that we will be discussing.
Number one, a team where everyone is in one location except for one person.
And number three, and here is the most common.
Where you all work in the same location but still talk virtually.
That is the biggest, most misunderstood, and often forgotten virtual team.
That could be a team where everyone's here, but the manager is somewhere else.
It could be a sales team that is responsible for a region, but the manager of that team is somewhere else.
It could be a virtual assistant helping out an organization with some filing work or dictation work.
She works in the woods, but she works with a very, very large law firm in downtown Montreal.
So that is one virtual team.
Another friend of mine was a sales rep for rather large medical devices, and she was responsible for the West Coast of North America.
Each one had a different region of North America, and their manager was in one of those locations.
So this team almost never met.
They knew each other for years, but they were almost never in person.
And that is the most common type of virtual team.
What's the point of this lesson?
How do you reward someone where the whole team is in one place except for them?
How you can you use that same thing to reward when no one is in the same place?
How do you reward someone in the exact same way when you're all in the same place?
because right now, you're thinking of three different ways to reward, and you're saying, well, what do you mean by reward?
Someone does a good job.
And the answer is very simple, and here's the main learning.
We are in a virtual age, but we are still human beings.
And the one way you can reward, irrespective of what your virtual team that you work on, is recognition, virtual recognition.
When you want to recognize someone, it's great to go one-on-one and say, you did a great job today.
Because recognition in front of your peers is the thing that'll really make people loyal.
it's a thing that will work irrespective of which virtual team you work on.
So how does that apply to communication?
Let me give you a little story.
I used to work on a sales team, and the manager of the sales team was in a virtual location.
Half of our team was in-person, and the other half we saw only occasionally, so they were virtual as well.
We would have bi-monthly meetings, so we always had virtual conversations, and they were almost always by audio, so phone conferences.
And the reason was some of us were so remote that we didn't have really good internet access, but we all had good phone access.
And the manager would start off every single meeting by recognizing one person in that group, and we all felt like such a part of a team.
So the key to strong virtual teams, irrespective of which one it is, is recognition in front of your peers.
I feel I can drink, like some beer, it's like my favorite thing in the world to drink.
And notice, if I was doing a presentation about beer, and you saw all of this.
As you are trying to figure out all the different things, you're looking at the four different pictures, you're reading the four different titles, you're not listening to me.
But while I'm talking about water, you're trying to process all the information this slide, by the time I move into the next point, you're already behind.
And you're trying to figure out what I'm talking about next, what part of the slide you should be looking at.
All over sudden there's too many details that's going to be too complex, area 47 shuts down and you stop listening.
It's got a picture, it's very simple words, the lazy rule is in effect, but what are we missing?
There's a gentleman named Brian Medina who wrote a book called Brain Rules, and he talked about how the brain processes information.
And he talked about the picture superiority effect, and when you think about it it makes sense, and you know it.
Leaves, bark, leaves, bark, eyes, leaves, what?
We've talked about that concept already, that's the evolution behind it.
One picture that activates area 47 and engages you, you can process in a second, but now you have to listen to me to find out if you're right or not.
So you looked at that whole slide as a whole, and even though you probably knew I was going to ask you about it, you're probably trying to focus on it, but we absorb very little.
Here is how Heineken is going to succeed in the North American market.
You pretty much got the two strategies, but you don't have any of the details which means you process those images like this, and now you have to listen to me to find out if you're right.
You probably got all that information like this, because both the superior picture superiority effect and the lazy rule were engaged.
And the best part about it, is I don't need to see you for it to work, which means I can use it in all my communication.
This is the person that every time you ask them about something you sent them, the paper, the email they've never read it, but they say things like, "You know what, I remember looking at it, I just didn't get a chance to really go in depth I'll get back to you soon as I can." Usually, they're decision-maker, and they take forever to make the decision but you needed that decision yesterday.
How do you communicate with them?
Before we get to how do you communicate with them, we have to ask ourselves, what are they thinking and what do they want?
What do they need?
The underlining thing that they need is to feel understood, not understanding what they're saying but understanding their situation.
If you've ever had this person in your work environment, they're always saying things like this, "You know what, I've been really overwhelmed, I saw the email, I haven't gotten to it yet.
Why are they saying things like, "You know what, it's just been really crazy here this time of year." It's because it's important for them to feel like you understand their situation, and this is the hardest thing to keep in your head.
Because a lot of times you're like, no you haven't been.
That's what you're thinking.
Can we talk on Tuesday afternoon that gives you a little more time?" "Hey thanks so much I appreciate it." "Yeah let's do Tuesday afternoon." Then you'd say, "2 P.M?" So what you're doing is at every stage of your response you're showing empathy and asking them for their opinion on something, their point of view.
Now suppose it's not about getting a meeting, suppose it's about getting a decision.
So the empathy is things like this, I know it's super busy but there were three criteria that I've identified for you, A, B, or C and I want to get your opinion on what do you think is the best one?
I haven't had a chance to really think about them all but I promise I'm going to get to it as soon as possible, awesome.
They'll say something like, "At a glance, but I haven't really committed to it yet." By the way I'm doing this because this is how we communicate by email.
We'll talk next week, but I'm going to start focusing on A if that's okay with you but still not forgetting B and C.
What do think about that?
But you're giving them those quick little summaries and asking for their point of view, communicates your busy, I just want you to guide me in the right direction.
That's going to make him feel like you really understand their situation, and more importantly, it makes them feel smart, intelligent, like their opinion matters and that is how you communicate with an uninformed person.
It's the kind of person that you can recognize in two ways, way number 1, if you see them constantly working alone, working extra, working over lunch, but always alone.
And the second way you recognize them is they are the person that always wants feedback.
They love feedback, tell me, is there anything I could do better, what could I achieve more?
People who are driven by achievement are wiling to take moderate risk, they are willing to try new things, they are not going to take a chance because they want to achieve.
So they're not afraid to take chances, it just has to seem a little risky, how can we use this to our advantage?
You approach them like this, everyone thinks this is going to take two weeks, I think we can do it in one, right away, you're addressing their underlying motivation.
The goal is 5%, do you think you could do 7?
Because if you give them this slightly unreasonable challenge, a little bit of an extra thing, that's going to address their underlying motivation.
So if you're on the teleconference you can ask them, listen Sarah, I know that for the region, your part of the quota is 10% increase in sales.
What do you mean by more?
Yes, I think I can do that.
Great, so we'll all check back and we'll give us a progress report in maybe a month, Sarah sound good?
We can also communicate strategically, so we address people's underlining motivations.
But how do we figure that out?
And in this video, we are going to break down the three major types of questions, how you use them, why you use them, and what you get out of them.
The three types of questions are closed-ended questions, yes or no, this or that, black or white.
Why do you want to work from home?
Why you want to go to a vegetarian restaurant?
That is the fundamental difference and here is why it's important, because where we might disagree in positional bargaining, we might be able to find agreement in principled bargaining.
What if you sent a message and the message said something like this, hey, I know that you wanted to get some more money because you feel like you're doing a lot of work for the organization right now.
Chances are what are they going to say?
Suppose there's an open window, and you and I are working in an office together.
You open the window, because you want some fresh air, it's very stuffy in here.
Yes, but it's really stuffy in here, we need some fresh air.
What if we started talking and said, okay, well why do you want the window open so bad?
Because I can't breathe in here.
Okay, well, I'm freezing.
Yes, I know it's like when we open the window it gets super cold.
Like could we open the door?
Then we go back to lesson three, with a strategic question, we make it an nudge.
If you're still stuffy, maybe we open the window a crack and I move away from it?
You are on a regional team, everyone is in different time zones, but we're all selling the same thing, and you have someone that really wants to have a meeting.
And everyone doesn't want to, because of the time zones, because they're busy and then we have this big email chain back and forth of people saying, well, do we have to have this meeting?
What's the point of the meeting?
Well, I think it's important to have a meeting, shouldn't we talk about things?
Shouldn't we communicate?
Is something going on in your region that you need help with?
Chances are, if someone is insisting on having a meeting or really wants to meet, it's because they have something underlining they need to get out to everybody.
So suppose you say that, and the person is like, yes, I actually think I found a new way to increase sales.
Also, there was someone else in our organizational group that wanted that panel to include a bunch of animation actors, and they really really wanted to have a meeting.
We're spending all this time, well if we can't meet here, how about here?
Then I went and I sent him an email, one on one and I said, hey, just out of curiosity, why do we want to have this meeting so bad?
Then as I was like, well because you've been talking to all the actors and you were afraid that the actors are going to be the ones that disagree, do you want to chat with the actors and then I'll talk to the Ubisoft people?
He went over to the actors, I went to the Ubisoft people and I said, we have a slight concern, we're afraid that we might disagree with each other, overlap or contradict one another.
What do you all think?
I sent it over to the other person, he sent it to the actors and the actor is like, oh great that we can talk about these four things then.
And before we were done, we didn't need to have a meeting and we had a more solid idea of what the panel was going to discuss, and that was just for me sending one email saying, why are we having this meeting?
Instead of finding out and trying to figure out the position, we try to figure out the underlying principle behind the position.
So, just like when you look at a menu you're, ''Ooh, that sounds interesting, ooh.'' It gets you interested, curious, excited to find out more, to get to the main course.
How?
Is how you do it differently.
What?
So, you can say, ''I'm a project manager,'' ''I'm a teacher." Saw a lots of people.
Why are you a project manager?
Amongst your friends, what do they come to you for?
Amongst people at work, what do they come to you for?
Are you the person that solves IT problems?
What do people come to you for?
The second one, what do you want to be known for?
With this new idea you have for your current job, what do you want to be known for?
This one should be easy, just think about the last time you complained about work to a friend.
Your underlining the thing that you do and the reason you do it, why?
Take a few minutes right now, answer those questions and write down, ''Discover Your Why.'' I am someone that believes that.
So, you're probably sitting there going, ''oh, that's a great theoretical idea, '' but let's see it in action.
If you're like me, the first thing that pops into you is, what does that mean?
Or you go like, ''okay, I think I get it but,'' which means that you're thinking about it, that you're curious, that you saw that appetizer that makes you excited about eating in this restaurant.
Now at the time when he wanted to start Starbucks, no one believed the idea would work, because you could buy coffee everywhere for super cheap.
When you have said this term, ''we should catch up soon,'' ''yeah, let's go for a coffee.'' Where's the first place you think of, a convenient Starbucks close to both of us.
So, it's not the basket of french fries, it's the basket of french fries cooked in a different way with different things in it.
Why do people come to you?
You could say something like, people come to me to solve their IT problem.
Why you though?
Why not first ask their friend next to them?
Why not go to the IT expert?
Why do they wait six months before they talk to you, or why do they not wait at all to see you?
I'm someone that believes that I can teach anyone to be a good programmer in the way anyone can learn how to say Allah, to second language.
That's your 'Why?' How?
"Well, I don't just fix problems, I show people how to fix their own problems" That's a 'How' It's how you get to your 'Why', it has to be 100 percent related.
What is the unique way you problem solve?
What is the unique way you do anything that no one else does?
So, your 'Why?' "I'm someone that believes" Your 'How?' is literally the sentence, "I do that by..", "I'm someone that believes, Blank, "I do that by.." Blank.
How do you create a place that fosters community and human connection?
Well, they do that by not only just selling really good coffee and coffee products, but also by creating an in-store experience that makes people feel welcome and comfortable.
Think about it like this; If you need to get some work done, and you don't want to be at home and you don't want to be at work, where do you go?
That is an in-store experience that makes you feel welcome, that is the 'How, ' and that's just as exciting and interesting, as a 'Why'.
Can I send you an email?
In the case of Starbucks, want to buy some coffee?
Want to come to Starbucks?
The 'What' is just a simple action that you want the listener to take, and that is how you move from an elevator to an advertiser.
You order the steak, delicious.
The stuff you don't always eat, but if they weren't on the plate, something would be missing.
Why?
Why are the veggies an essential part of the meal, even though you don't always consume them?
There's 50 people who can do your job, why you?
Now if you think back to the appetizer, do you remember how one of the rules of a good action, of a good what, was a time constraint?
If decision-making is made both through feeling and through information, what's a scarier feeling?
This will never end or I can see the end.
Sometimes you do this with veggies.
Now before we end this lesson, there's a lot of you out there that probably have a question in your head.
All these examples we've been using, it's all about pitching ourselves for money or for some product.
What if I don't want to pitch anything?
Why?
You want to present a solution, and the way you're going to do it like no one else can.
How much do we have to invest?
"Am I going to feel comfortable having lunch and strategy sessions with this person?" The human element, the veggies, can apply to every presentation as well.
"Here's a report from our last quarter's sales." Is part of that presentation not also going to be, "What do we do now?
What am I going to do about these numbers I've just shown you?
What should we do?" So even though we use the pitch example, these elements can apply to any time you have to do a formal presentation.
So, it's now onto the last part of dessert, and that is how we talk about numbers.
What I'd like to do is give you three tools to help you talk about numbers in a way that's going to be fun, that's going to be colorful, that's going to make your meal go from just good to memorable.
Sometimes we relate a number were like, it's going to grow by 20 percent, it has a thousand this, and people will be like, "Okay.
Because an impactful number should be like, "Oh," you should see reaction because it should speak to both the logical and emotional parts of your brain.
Then Apple came out and just said this, a thousand songs in your pocket.
Because if you're like me you're like, "Oh, a thousand songs?" This is back in the day.
Now, it's probably like what, a hundred thousand songs?
So, what does that mean?
Well, another way to think about it is numbers need to be in context.
So, this is Adidas 1998 to 2000, they experience a 90 percent increase in sales.
All of a sudden, if you're an investor in Adidas, you went from thinking like, "That's awesome" to like, "Oh, what are we doing wrong?" Because a number compared to another number again, talks to both the logical and the emotional part of my brain.
It causes me to think about the next decision differently, when we put them against each other and here's the last little rule.
So, here we have some financials from Apple, around 2012, 2013 and I've tried to make it so that the numbers pop out a little bit, right?
Suppose you're at home on your computer and you're talking to your laptop because everyone else is on a virtual meeting, we're on a virtual meeting, and you start going into these numbers.
Think about what you did, you saw the first red numbers thing, you saw the first red letter first you're like, "Okay, okay" and then, you started looking at the other stuff to figure out what those numbers meant.
So, what can I do about it?
Suppose I can't do any of those things, I have to show you the slide because someone insisted on it.
Before I show you the slide, I tell you the story of what these numbers mean.
So what do these numbers mean?
At the end of the day, this whole graph, it's only telling us one thing, our distribution is terrible.
Remember, we're not teaching you rules, the one way to do things because there is no one right way.
We're teaching you tools, so the next time you do a presentation, you can go back like, do I have our schema?
Am I comparing this number against something?
Is this number telling me a story?
So, what is computer architecture?
So what do we mean by physics here?
Well, physics is, we have in the world we have particles and they bounce around, they interact, we have photons bouncing around in the world, and we need somehow translate what humans want to do into what the physics can do.
And one of the problems with this is, this is a really big gap.
So how do you, go from application directly to physics?
You have physics bouncing around the world.
You have mechanical systems.
And without some level of abstraction, it's very hard to go from the application directly to the physics.
Now, in the broader sense, what computer architecture is trying to do is it's trying to come up with the abstraction and the implementation layers.
That are needed to be able to bridge this gap.
So, we're gonna put a bunch of different layers in here.
And by making smaller abstraction layers and smaller layers, we're going to be able to solve subsets of these problems and not have to change everything here in the middle, just one.
Let's say the physics changes or the application changes a little bit, we'll be able to reuse a lot of the work that we've done along the way.
I wanted to point out that in the natural world, it's pretty challenging to directly jump from application to physics, but there's a few examples.
So one example I wanted to bring up actually is the compass.
The compass is a nifty little device that directly takes physics and gets pushed up into an application.
But there's very few other examples.
I think book is a okay example of this but otherwise people build lots of abstraction layers in between here.
And one other thing I wanted to point out here is that we're trying to efficiently use manufacturing technologies.
So what I mean by that is, when physics changes, or we move to smaller transistors, or we move from, let's say, silicon to gallium arsenide or some other implementation technology, that changes the bottom layer here, but we want to still be able to reuse a lot of the other work that we've done over the years.
So, let's take a look at the abstractions in modern day computing systems.
So, what do I mean by devices?
We have transistors, and we can build different types of transistors.
Mosfets, BJTs, we can build other, other types of FETs, and we start to build circuits, bigger circuits out of this, and out of those we go and build gates.
And then we start to get into what this course is about, which is different types of architecture.
So there's microarchitecture, which is how you do you go and actually build a specific implementation of a chip.
And then we get into operating systems and virtual machines, Programming languages, and algorithms.
And then finally we get to the algorithm the application programmer sitting on top.
So in this course, in computer architecture, we're only gonna be focusing in this three middle layers here, instruction set architecture, or what I will sometimes refer to as big A computer architecture.
Microarchitecture, or, sometimes what people call organization, of computing systems.
And, register transfer language and we'll, we'll also overlap a little bit into the, the abstraction layers above and below here.
So, we'll talk a little bit about some operating system concerns and virtual machine concerns.
And we'll talk a little bit about how the tran-, the technology and the gates influences the computing system.
So one important point here about computer architecture is it's constantly changing because different constraints and different applications are changing.
So, people have new applications that they come up with.
They come up with ways, or people come up with different applications.
I now want to have a smart phone.
And this pushes down different requirements and these different requirements actually suggest how to change the architecture.
If you, for instance want to do a lot of video processing that can actually influence your computer architecture so you add specialized instructions to do video processing.
And a lot times new, new technologies make new architecture possible.
So, what do I mean by that?
Well, lets say all of sudden, you get a big bump in transistors, you get twice as many transistors.
And, what's, the interesting thing here, is that, computer architecture is not done in a vacuum.
So, computer architecture actually provides feedback up and down this abstraction layer stack.
So, it will give feedback, and it will actually influence the research directions that technology looks at.
But that might take a few years.
So let's talk a little bit more about what this class is about, but we'll, we'll do it by way of a little bit of history.
It was first moved in Princeton in 1952, it was actually started in the late'40's and took them a couple years to get, to get working.
And one of the interesting things here is that this machine is actually built out of vacuum tubes.
Well, before we had transistors we had little glass tubes that actually looked like light bulbs, and inside of those there were switches that could be switched.
So, very similar idea to what our transistor can do, but, instead you had a evacuated glass tube, and you had a little transmitter, it was a cathode ray tube.
And then you had a gate that could open and close inside of this.
So people were building computers long before transistors, and people were thinking about computer architecture long before transistors.
And people were even thinking about computer architecture and these sorts of technologies even before vacuum tubes.
So there was electromechanical systems, a good example of this actually was originally in phone systems.
They had these cool electromechanical switches.
What that's actually doing is, it's sending pulses which are turning a mechanical, a little mechanical arm inside of a relay system, and people built computers out of those electro-mechanical relays.
So you can have switches that turn, change switches, similar sorts of ideas to transistors.
And even before that people had looked at building mechanical systems.
And now of days we, of course, have transistors.
So, it was computing then, in the fifties and if we fast forward to today, we have lot, computers look very different.
In this figure here, ya know, this thing was the size of a room.
It's a, sort of normal-sized room, but, still sort of room sized.
But today we have lots of different applications.
So, we have computing, let's say, in small systems.
So we have a little sensor network-, networks, and little sensor nodes distributed.
We have mobile audio players and iPods.
So, the influence of this technology, computer architecture, has been very, very broad.
We have GPS's, which are little computers that can basically fit on your wrist these days and tell you exactly where you are.
E books, tablets, set-top boxes and the list goes on and on and on.
And what, what, I want to get across here is that computer architecture has a very rich history.
So we're not studying something which no one cares about anymore.
People are sitting there sort of ready to get the next generation computer architecture.
People, and, and it used to be you know, you want your faster desktop computer.
They want to enable voice recognition on the go.
They want to be able to, in scientific applications, they want to build a model, some health system that's really complex, that you weren't able to do before.
So, it continues on and on.
It is very relevant today, and it has a very rich history.
In this course we're gonna talk a little bit about the history, we'll mostly focus on the technology.
This class, we're gonna Touch on history a little bit, but more focused on the, on the technology considerations.
So here's a chart that's from Hennessy and Patterson's Computer Architecture, or A Quantitative Approach, and what this graph is trying to show is, is something very fundamental to computer architecture, and it's what's been driving our industry.
So what we see here is we see different processor designs plotted on a log plot.
So this is ten, 100, 1000.
This is a log plot and it says performance versus years.
So, we've seen computing going up exponentially faster.
And this is a, a really fundamental to driving what's been going on in our industry and why computer architecture is so important.
And I do want to say that, you know, this exponential increase is, comes from two things.
What I mean that is the, lower down layers and the implementation technology, like the transistor technologies.
And some of it is from having better and better computer architecture.
A lot of times what happens if you look at this graph is what's happening is you're getting more transistors, but those transistors are not necessarily exponentially faster.
So, what computer architects have to do is we need to figure out how to take buckets and buckets of more transistors and turn them into more performance.
And that's what this is many times called is it's called Moore's Law.
If you've heard that term before, what it is, is we're trying, Moore's, Gordon Moore said that every eighteen months to two years, you're going to get twice as many transistors which, you can have for the same amount of dollars.
People sort of transformed that now into meaning your computer's gonna get twice as fast every year.
That's not what, Gordon Moore originally actually said.
He said he can get twice as many transistors for a certain amount of dollars.
And people have also sometimes taken this to mean that you get twice as many transistors on a chip every year.
It's not quite what he said, but close enough approximation.
But if you go farther back into the past, you can actually plot other technologies, like vacuum tube technologies, and relay based technologies.
And it also fits on this, this graph relatively well.
And it's sort of still on this exponentially increasing curve.
Okay, so let's look at, there's two inflection points in this graph that we wanna look at.
First one's right here, you can see that the slope changes a little bit.
Well, what, what happened here?
This was the introduction of reduced instruction set computers, or risk computers.
So we got a little bit of a, a crank up there when people came out with the first risk.
So, what, what happened here?
Well, sequential performance, so this is the performance of a single program; was getting faster exponentially.
I like to use 2005 as the number but somewhere between 2003 and 2007, sequential processor performance started to, to really have a, a problem.
But overall performance of your processor, still continuous to go up today.
And what happened is we had to move to multi-core processors or multiple cores on a single chip.
Cuz it would be very harmful to computer architecture and computing industry if all of a sudden our computers stopped getting faster, no one would be buying new computer chips.
My name is Dimitri, and I'm happy to see you are interested in competitive data science.
Data science is all about machine learning applications.
And in data science, like everywhere else, people are looking for the very best solutions to their problems.
They're looking for the models that have the best predictive capabilities, the models that make as few mistakes as possible.
And the competition for one becomes an essential way to find such solutions.
Competing for the prize, participants push through the limits, come up with novel ideas.
Companies organize data science competitions to get top quality models for not so high price.
And for data scientists, competitions become a truly unique opportunity to learn, well, and of course win a prize.
This course is a chance for you to catch up on the trends in competitive data science and learn what we, competition addicts and at the same time, lecturers of this course, have already learned while competing.
In this course, we will go through competition solving process step by step and tell you about exploratory data analysis, basic and advanced feature generation and preprocessing, various model validation techniques.
We've put together all our experience and created this course for you.
We've also designed quizzes and programming assignments to let you apply your newly acquired skills.
Moreover, as a final project, you will have an opportunity to compete with other students and participate in a special competition, hosted on the world's largest platform for data science challenges called Kaggle.
And the Bertrand paradox basically tells us that in a model with seemingly fairly reasonable assumptions we get a result that just doesn't make a lot of sense.
So we have the assumptions that you've got prices, and product differentiation and so on and the result we got was that friends make no profits.
So what we're going to do in this video is we're going to adjust the model assumptions to see if we can get closer to reality starting from this, from this model.
So let's just recap what the assumptions were.
These companies compete in prices and they have identical products that they're selling.
So let's take this model and then let's try to remove these assumptions one by one and see what the result might be.
Okay, the easiest one is that maybe firms do not have identical products.
Right, so in reality, consumers will have different tastes and products will be differentiated.
So each seller might well produce a different flavor of ice cream.
Simply speaking, if one of the products charges is slightly lower priced than the other but the other is, the other sells strawberry, strawberry ice cream and I sell vanilla ice cream, the fans of strawberry ice cream aren't going to care that much about tiny price differences.
So remember I said that there's just a single day on which the two sellers get together and they sell ice cream.
In reality, you have repetitions that are infinite or at least indefinite.
So every summer season the sellers set their prices.
They go to the beach, meet one day, they meet the next day and they meet the day after.
There's a possibility that from tomorrow onwards this summer is going to be over so there's an element of uncertainty here.
So this is something where we looked at in week two.
Another assumption is that we had complete market transparency.
So what does that mean?
It means that every consumer knows the prices of both, of both the sellers.
Is that reasonable?
Well, in reality, there's often imperfect market transparency.
So some consumers will simply only know the price of one seller.
So, in reality, if we think about this, there are costs for consumers associated with switching sellers.
So if you have 10 ice creams, if you bought 10 ice creams or nine ice creams, you get the 10th one for free.
It's another possibility.
What is that going to do?
In reality firms will have limited capacity.
And that means that there is no incentive to induce a price war over the complete demand because you're simply not going to be able to satisfy this demand.
And so what is interesting is that these are all characteristics of the market but firms can actually try to actively influence these aspects to try and avoid the Bertrand trap.
They might be able to agree on prices implicitly or explicitly.
They might play the game repeatedly to make sure that there is no end point.
You might increase switching costs so that's going to make it more difficult for rivals to steal your customers.
And it might simply be a possible strategy to differentiate your product.
So in the last two videos we've looked at the Bertrand paradox.
Economic theory will tell us that firms who sell the same product to the market will end up in a perfectly competitive situation and make zero profits.
In reality, however, we see that there are some aspects that will lower the competitive pressure and enable firms to make positive profits.
Firms do not have to take these aspects as given but they can actually try to actively influence them in their favor.
One aspect that we only touched upon but that's of particular importance is product differentiation.
So we'll have a closer look at this in the next couple of videos.
And the Bertrand paradox basically tells us that in a model with seemingly fairly reasonable assumptions we get a result that just doesn't make a lot of sense.
So we have the assumptions that you've got prices, and product differentiation and so on and the result we got was that friends make no profits.
So what we're going to do in this video is we're going to adjust the model assumptions to see if we can get closer to reality starting from this, from this model.
So let's just recap what the assumptions were.
These companies compete in prices and they have identical products that they're selling.
So let's take this model and then let's try to remove these assumptions one by one and see what the result might be.
Okay, the easiest one is that maybe firms do not have identical products.
Right, so in reality, consumers will have different tastes and products will be differentiated.
So each seller might well produce a different flavor of ice cream.
Simply speaking, if one of the products charges is slightly lower priced than the other but the other is, the other sells strawberry, strawberry ice cream and I sell vanilla ice cream, the fans of strawberry ice cream aren't going to care that much about tiny price differences.
So remember I said that there's just a single day on which the two sellers get together and they sell ice cream.
In reality, you have repetitions that are infinite or at least indefinite.
So every summer season the sellers set their prices.
They go to the beach, meet one day, they meet the next day and they meet the day after.
There's a possibility that from tomorrow onwards this summer is going to be over so there's an element of uncertainty here.
So this is something where we looked at in week two.
Another assumption is that we had complete market transparency.
So what does that mean?
It means that every consumer knows the prices of both, of both the sellers.
Is that reasonable?
Well, in reality, there's often imperfect market transparency.
So some consumers will simply only know the price of one seller.
So, in reality, if we think about this, there are costs for consumers associated with switching sellers.
So if you have 10 ice creams, if you bought 10 ice creams or nine ice creams, you get the 10th one for free.
It's another possibility.
What is that going to do?
In reality firms will have limited capacity.
And that means that there is no incentive to induce a price war over the complete demand because you're simply not going to be able to satisfy this demand.
And so what is interesting is that these are all characteristics of the market but firms can actually try to actively influence these aspects to try and avoid the Bertrand trap.
They might be able to agree on prices implicitly or explicitly.
They might play the game repeatedly to make sure that there is no end point.
You might increase switching costs so that's going to make it more difficult for rivals to steal your customers.
And it might simply be a possible strategy to differentiate your product.
So in the last two videos we've looked at the Bertrand paradox.
Economic theory will tell us that firms who sell the same product to the market will end up in a perfectly competitive situation and make zero profits.
In reality, however, we see that there are some aspects that will lower the competitive pressure and enable firms to make positive profits.
Firms do not have to take these aspects as given but they can actually try to actively influence them in their favor.
One aspect that we only touched upon but that's of particular importance is product differentiation.
So we'll have a closer look at this in the next couple of videos.
Wander through the darkness, erasing all the light.
>> Okay stop there we have, we have another issue here which is really closely related to the thing we've been talking about which is the relationship between notes and syllables.
Here instead of talking about notes and syllables, the other responsibility that a songwriter has about phrasing and preserving the natural shape of the language, is here we have wander through the darkness, that's told the musical phrase, right?
>> Erasing all the lines, that's another musical phrase, right?
>> Okay, now with the road map that the melody is laying out is saying, idea, idea, idea.
And what the grammar is saying is, wander through the darkness one idea.
Erasing all the lines of the border and the boundaries they defined, second thing.
And so your grammar is saying, I have two independent ideas.
And yet your music now is saying, oh, hold it, let's take that second idea and slice it into two pieces and separate them, and put them each behind their own fence though they're longing to embrace.
And so you have two choices here.
Number 1, you can create one long musical phrase, wander through the darkness, erasing all the lines of the boundaries, and you can do that.
So I want you to sing it the way you've got it now first, then I want to make a little change.
>> Oh, by the way, wander through the darkness not wander through the darkness.
Anyway, try again.
>> Okay so now what I want you to do, is simply substitute for the word of, I want you to substitute all.
All the borders and the boundaries they define.
>> Wander through the darkness, erasing all the lies of the borders and the boundaries they define.
>> Wander through the darkness, erasing all the lights, all the borders and the boundaries they define.
Leave behind a trail, that paints your picture in the sky.
Your hiding in a big rain cloud, painting silently but no one stops to see you.
Leave behind a trail that paints your picture in the sky.
Hello, and a warm welcome to everyone of you from around the world.
This is week one of Computational Neuroscience, and I'm your instructor, Rajesh Rao.
Let's begin our computational adventures with a picture.
You've probably seen a picture like this before.
Physicists tell us that this is the universe that we live in.
But I think they're mistaken.
This is the universe that we really live in.
This three pound mass of tissue inside our skull is what allows us to perceive the world, and indeed the universe.
This amazing machine is what enables us to think, feel, act and be human.
This is what is enabling me to speak these words right now and allowing you to listen.
And when the lecture gets boring which hopefully won't happen too often, you can thank the same triple organ for enabling you to skip forward a few slides or maybe doze off in the chair that you're sitting in.
In this course we'll try to unravel some of this mystery and understand the brain using computational models.
In this course, we will cover three types of computational models.
The first kind are descriptive models.
So in this case we're interested in quantifying how neurons respond to external stimuli, and what we get here is something called a neural encoding model.
Which quantitatively describes how every different neuron responds to external stimuli.
The counterpart to encoding is decoding.
So in this case we're interested in extracting information from neurons that have been recorded from the brain and then using this information for controlling something like a prosthetic hand for example.
So this problem of decoding is extremely important in the field of brain computer interfacing and neural prosthetics.
So in this case we are interested in simulating the behavior of a single neuron or a network of neurons on a computer.
So you might have heard about the Human Brain Project, which is being led by Henry Markram in Europe.
And that project is an example of a computer simulation of an extremely large network of neurons in the extreme case perhaps the entire brain on a computer.
The last type of models that they look at are called interpretive or normative models.
So in this case we're interested in understanding why brain circuits operate in the way that they do.
In other words we're interested in extracting some computational principles that underlie the function of a particular brain circuit.
So we'll look at examples of all of these three types of models in the coming weeks.
Here are the two recommended textbooks for this course.
They're not required but they might be useful if you need additional information besides what's covered in the lecture videos and the lecture slides.
The first one is Theoretical Neuroscience.
This is standard textbook in the field, and it's a book written by Peter Dayan and Larry Abbott, two leading researchers in computational neuroscience.
The other textbook is called Tutorial on Neural Systems Modelling, and it's by another leading researcher in the field, Thomas Anastasio.
And this book also comes with a math lab code that you might find useful as you're exploring concepts and computations you are assigned.
So let's end with some of the goals of the course.
Well, at the end of the course you should be able to first of all, quantitatively describe what a biological neuron or network of neurons is doing given some experimental data that perhaps you got from your neuroscientist friend.
Secondly, you would like to be able to simulate on a computer the behavior of neurons or the networks or neurons.
And finally, you should be able to at the end of the course formulate computational principle that would help explain the operation of certain neurons or networks in the brain.
So are you ready?
Hi, in this short video, we will solve a code problem together.
The problem itself is quite elementary.
So the main purpose of this video is to show you the general pipeline of solving code problems in this class.
The problem is called A plus B.
In this problem, we are given two digits on the standard input and our goal is to output their sum on the standard output.
You can see two sample tests here on the page.
For example, if the input for your program consists of the integers 3 and 2, then your program should output 5.
If, on the other hand, the input consists of two integers 7 and 9, then your program is supposed to output 16, of course.
The next section consists of three Starter files.
Which in this particular case are actually solutions, not just starter files.
So the files are for programming languages Python, Java, and C++.
Finally the last section contains an instruction consisting of four steps on how to solve this problem.
So let's go through these four steps together.
The first step is to download one of the starter files.
Now the file is here and let's take a look inside.
So, this is a very simple solution which, first, creates three variables.
Then it reads a and b from the standard input.
Then it computes the sum.
And then finally it outputs the sum on the standard output.
So to run this program we first need to compile it.
So this is the second step of our instruction.
For this we highly recommend to use the same compiler flags that are shown on this page.
This will ensure that your program behaves in the same way on the testing system and on your local machine.
So in this case let's just copy the flags and use it to compile our program.
So this produced an executable file a.out and we can now run it.
Let's give this program for example 2 and 3.
So the output is 5.
9 and 4, the output is 13 as expected.
And now the next step is to actually submit this solution to this problem.
Let's go to my submission tab.
So after a while, the testing system shows that our solution passed all the tests, which is quite satisfactory.
To illustrate it one more time, let me repeat the whole procedure quickly for the Python programming language.
So we first download the starter Python file.
Let's take a look at what is inside.
So the program is again very simple as expected.
So we just take a and be from the standard input and we output the sum of a and b.
Now we need to run this program for this you might want to go to this available programming languages page.
Again just to check how we run Python scripts so we just use Python, Python 3.
So let's do this.
For example 4, 4 and the output is 8 which is as expected.
So let's just go ahead and submit this solution.
So you go to the my submission tab, you press the Create Submission button and then you replace this file by APlusB.py.
So when the file is uploaded, you finally press the Submit button.
So in a few seconds, this solution will be accepted by the testing system.
Well this wasn't very challenging, right?
In the next video we will see a much more interesting example of a computational problem.
We will submit this solution to a testing system to figure out that it is buggy actually.
So we will fix this bug, submit it again, to find out that our solution is slow.
We will get a time limit exceeded feedback message from the testing system.
Meaning that for large data sets it works in more than one second, for example.
So this will require us to come up with a much, more faster solution.
We will implement it, submit it to the system, again, to find out that it is still buggy.
We will use stress testing to locate the bug, to fix it, and to finally submit a correct solution to the system which will pass all the tests.
Hello everybody, welcome back to the data structure and algorithms specialization.
Here I just want to give you a brief heads up, about what we're going to be talking about in the next two lectures.
So, in the next two lectures, we're going to dive right in.
We're going to look into a couple of algorithms problems, in particular we're going to talk about algorithms for computing Fibonacci numbers And algorithms for computing greatest common divisors.
Now these might be, feel a little bit weird for the very first algorithms that we're going to talk to in a class.
They're kind of number theoretic and numerical, and they won't actually be that similar to what we'll be talking about in the rest of the class.
So you might wonder why we're looking at them, and what you should be paying attention to.
And that's really what I want to talk to you today about.
In particular, these two topics were chosen, because they were the clearest examples we could think of for why algorithms are critically important.
Why coming up with a good algorithm is really so important on so many problems.
And in particular, both of these problems have the following very interesting properties.
To begin with, both of these problems have a pretty straightforward algorithm.
One where you sort of take the definition of the problem that you're trying to solve.
You sort of take the words that you have, and you sort of interpret them as an algorithm.
And more or less immediately you have some code, and it works.
And it computes the things that you want it to compute.
Unfortunately, in both cases, these very straightforward algorithms are far, far too slow.
You end up with algorithms that take thousands of years to run, even on very modest inputs.
And this is not acceptable for practical purposes, you don't have millenia to wait for your computation to finish.
And so you need something better, and it turns out in both of this cases there is something better.
There is going to be a slightly more complicated algorithm, something that maybe requires one or two bright ideas to get it to work.
This slightly more complicated algorithm, works fine and is actually incredibly fast.
You can handle sort of any reasonable instance of these problems in the blink of an eye.
And so, the whole point of this is to really show with these very concrete examples, that at least in these instances, and in many others that we'll see throughout the course, finding the right algorithm can make all the difference in the world.
It's the difference between having an algorithm that takes more time than you will have in your life to finish, and an algorithm that is done before you even knew it started.
And so really this is what you should be paying attention to.
Why it is so, so important that we find good algorithms.
Hi, I'm Michael Levin and together we will study Greedy Algorithms.
They are some of the simplest algorithms that exist and they usually seem a pretty natural way to try solving a problem.
We will start with a few examples of problems that can be solved by greedy algorithms, just to illustrate how they work.
And our very first problem is a problem about largest number.
So imagine this situation.
But instead of negotiating your salary with you, he will give you a few pieces of paper with digits written on them.
Given a few digits, to arrange them in the largest possible number.
So what do you think will be the correct answer to this problem?
And of course, the correct answer is 997531.
And it's pretty obvious that you should arrange numbers from the largest to the smallest, from left to right.
But let's look at how the greedy algorithm does that.
So, the Greedy Strategy is start with a list of digits then find the maximum digit in the list.
Append it to the number and remove it from the list.
And then repeat this process until there are no digits left in the list.
So on the next step we will find the largest digit, which is again 9.
We'll append it to the number to the right and remove it from the list.
Then we will find 7 as the largest digit appended to the right and remove it from the list.
And then we get the correct answer, 997531.
And in the next video, we will design an algorithm to find the minimum number of refuels during a long journey by car.
We will see similarities between these two problems, largest number problem and car refueling problem.
And we will define how greedy algorithms work in general.
So in this video, we'll get our first sense of what it's actually like to analyze an algorithm.
And we'll do that by first of all reviewing a famous sorting algorithm, namely the Merge Sort algorithm.
And then giving a really fairly mathematically precise upper bound on exactly how many operations the Merge Sort algorithm requires to correctly sort an input array.
So I feel like I should begin with a bit of an apology.
Here we are in 2012, a very futuristic sounding date.
So, what justification do I have for beginning, you know, a modern class in algorithms with such an old example?
One, I haven't even put down on the slide, which is like a number of the algorithms we'll see, "Merge Sort" as an oldie but a goodie.
So it's over 60, or maybe even 70 years old.
But it's still used all the time in practice, because this really is one of the methods of choice for sorting.
The standard sorting algorithm in the number of programming libraries.
So that's the first reason.
But there's a number of others as well that I want to be explicit about.
So first of all, throughout these online courses, we'll see a number of general algorithm design paradigms ways of solving problems that cut across different application domains.
And the first one we're going to focus on is called the Divide-and-Conquer algorithm design paradigm.
So in Divide-and-Conquer, the idea is, you take a problem, and break it down into smaller sub problems which you then solve recursively, ...
And Merge Sort is still today's the, perhaps the, most transparent application of the Divide-and-Conquer paradigm, ...
As for its benefits, so for example, you're probably all aware of the sorting problem.
Probably you know some number of sorting algorithms perhaps including Merge Sort itself.
so for example, three other sorting algorithms that you may know about, but that I'm not going to discuss here.
If you don't know them, I encourage you to look them up in a text book or look them up on the web.
Let's start with three sorting algorithms which are perhaps simpler, first of all is "Selection Sort".
So this is where you do a number of passes through the way repeatedly, identifying the minimum of the elements that you haven't looked at yet, ...
so you're basically a linear number of passes each time doing a minimum computation.
There's "Insertion Sort", which is still useful in certain cases in practice as we will discuss, but again it's generally not as good as Merge Sort, ...
So after ten loops of Insertion Sort, you'll have the invariant that whatever the first ten elements of the array are going to be in sorted order, ...
Finally, some of you may know about "Bubble Sort", which is where you identify adjacent pairs of elements which are out of order, ...
and then you do repeated swaps until in the end the array is completely sorted.
Again I just say this to jog your memory, these are simpler sorts than Merge Sort, ...
but all of them are worse in the sense that they're lack in performance in general, which scales with N^2, ...
and the input array has N elements, so they all have, in some sense, quadratic running time.
But if we use this non-trivial Divide-and-Conquer approach, or non-obvious approach, we'll get a, as we'll see, a much better running time than this quadratic dependence on the input.
Okay?
So we'll get a win, first sorting in Divide-and-Conquer, and Merge Sort is the algorithm that realizes that benefit.
So the second reason that I wanna start out by talking about the Merge Sort algorithm, is to help you calibrate your preparation.
I think the discussion we're about to have will give you a good signal for whether you're background's at about the right level, of the audience that I'm thinking about for this course.
So in particular, when I describe the Merge Sort algorithm, you'll notice that I'm not going to describe in a level of detail that you can just translate it line by line into a working program in some programming language.
So hopefully, I don't know, it may not be easy the analysis of Merge Sort discussion.
because as the course moves on, we're going to be discussing algorithms and analysis which are a bit more complicated than the one we're about to do with Merge Sort.
So in other words, I think that this would be a good warm-up for what's to come.
Now another reason I want to discuss Merge Sort is that our analysis of it will naturally segment discussion of how we analyze the algorithms in this course and in general.
So we're going to expose a couple of assumptions in our analysis, we're focus on worst case behavior, ...
and then we'll also expose our focus on so called "Asymptotic Analysis", which meaning will be much more concerned with the rate of growth on an algorithms performance than on things like low-order terms or on small changes in the constant factors.
So this is a way of tying up the total number of operations that are executed by an algorithm.
And as we'll see a little bit later, this Recursion-Tree method generalizes greatly.
And it will allow us to analyze lots of different recursive algorithms, lots of different Divide-and-Conquer algorithms, including the integer multiplication algorithm that we discussed in an earlier segment.
So what is the computational problem that Merge Sort is meant to solve?
But let me tell you a little bit about it anyways, just so that we're all on the same page.
An array of N numbers in arbitrary order, and the goal of course is to produce output array where the numbers are in sorted order, let's say, from smallest to largest.
Okay so, for example, we could consider the following input array, and then the goal would be to produce the following output array.
You'll notice that here in input array, it had eight elements, all of them were distinct, it was the different integers, between 1 and 8.
Now the sorting problem really isn't any harder if you have duplicates, in fact it can even be easier, ...
but to keep the discussion as simple as possible let's just, among friends, go ahead and assume that they're distinct, for the purpose of this lecture.
And I'll leave it as an exercise which I encourage you to do, which is to think about how the Merge Sort algorithm implementation and analysis would be different, if at all, if there were ties, okay?
Go ahead and make the distinct assumption for simplicity from here on out.
Okay, so before I write down any pseudo code for Merge Sort, let me just show you how the algorithm works using a picture, ...
and I think it'll be pretty clear what the code would be, even just given a single example.
So the Merge Sort algorithm is a recursive algorithm, and again, that means that a program which calls itself and it calls itself on smaller sub problems of the same form, okay?
So the Merge Sort is its purpose in life is to sort the given input array.
So it's going to spawn, or call itself on smaller arrays.
And this is gonna be a canonical Divide-and-Conquer application, where we simply take the input array, we split it in half, we solve the left half recursively, we solve the right half recursively, and then we combine the results.
So let's look at that in the picture.
So the first recursive call gets the first four elements, the left half of the array, namely 5, 4, 1, 8.
And, of course, the other recursive call is gonna get the rest of the elements, 7, 2, 6, 3.
You can imagine these has been copied into new arrays before they're given to the recursive calls.
Now, by the magic of recursion, or by induction if you like, the recursive calls will do their task.
So from our first recursive call, we receive the output, 1, 4, 5, 8, and from the second recursive call, we received the sorted output, 2, 3, 6, 7.
So now, all the remains to complete the Merge Sort is to take the two results of our recursive calls, these two sorted elements of length-4, and combine them to produce the final output, namely the sorted array of all eight of the input numbers.
And hopefully you are already are thinking about how you might actually implement this merge in a computationally efficient way.
And I will tell you exactly how the merge is done.
In effect, you just walk pointers down each of the two sort of sub-arrays, copying over, populating the output array in the sorted order.
But I will give you some more details in just a slide or two.
Split it in half, solve recursively, and then have some slick merging procedure to combine the two results into a sorted output.
Okay, so let's move on, and actually discuss the pseudo-code for the merge sort algorithm.
First, let me just tell you the pseudo-code, leaving aside exactly how the merging subroutine is implemented.
And thus, high levels should be very simple and clear at this point.
Again, as I promised, this isn't something you would directly translate into code, although it's pretty close.
Well, first of all, there's, , you know, in any recursive algorithm, you gotta have some base cases.
You gotta have this idea that when the input's sufficient.
Really small you don't do any recursion, you just return some trivial answer.
Okay, so to be clear, I haven't written down the base cases.
Although of course you would if you were actually implementing, a merge short.
Some of you, make a note of that.
That's something that would really depend somewhat on what, on the programming language, so that's exactly what I want to avoid.
I really want to talk about the concepts which transcend any particular programming language implementation.
So that's why I'm going to describe algorithms at this level okay.
Alright, so the hard part relatively speaking, that is.
The left half and the right half.
How do we combine them into one?
And in English, I already told you on the last slide.
The idea is you just populate the output array in a sorted order, by traversing pointers or just traversing through the two, sorted sub-arrays in parallel.
So let's look at that in some more detail.
Okay, so here is the pseudo-code for the merge step.
And then, I'm gonna use a and b to denote the results of the two recursive calls, okay?
So, the first recursive call has given us array a, which contains the left half of the input array in sorted order.
Similarly, b contains the right half of the input array, again, in sorted order.
So, as I said, we're gonna need to traverse the two, sorted sub-arrays, a and b, in parallel.
We're going to do a single pass of the output array copying it in an increasing order.
Always taking the smallest from the union of the two sorted sub arrays.
The minimum element that you haven't yet looked at in A and B has to be at the front of one or the two lists right so for example at the very beginning of the algorithm where is the minimum element over all.
Well, which ever of the two arrays it lands in -- A or B -- it has to be the smallest one there okay.
So the smallest element over all is either the smallest element A or it's the smallest element B.
So you just check both places, the smaller one is the smallest you copy it over and you repeat.
That's it.
So the purpose of K is just to traverse the output array from left to right.
Currently looking at position I, and the first array of position J and the second array.
So if the, if, the entry in the i position of A is smaller, we copy that one over.
Of course, we have to increment i.
We probe one deeper into the list A, and symmeterically for the case where the current position in B has the smaller element.
Now again, I'm being a little bit sloppy, so that we can focus on the forest, and not sort of, And not get bogged down with the trees.
Because you have additional checks for when i or j reaches the end of the array, at which point you copy over all the remaining elements into C.
This again, is just the same thing that we wrote on the last slide, okay?
Now, so that's the Merge Sort algorithm.
Now let's get to the meaty part of this lecture, which is, okay, so merge sort produces a sorted array.
What makes it, if anything, better than much simpler non divide and conquer algorithms, like say, insertion sort?
Other words, what is the running time of the merge sort algorithm?
Now I'm not gonna give you a completely precise definition, definition of what I mean by running time and there's good reason for that, as we'll discuss shortly.
But intuitively, you should think of the running time of an algorithm, you should imagine that you're just running the algorithm in a debugger.
Then, every time you press enter, you advance with one line of the program through the debugger.
And then basically, the running time is just a number of operations executed, the number of lines of code executed.
So the question is, how many times you have to hit enter on the debugger before the, program finally terminates.
So we're interested in how many such, lines of code get executed for Merge Short when an input array has n numbers.
So let's start with a more modest school.
Rather than thinking about the number of operations executed by Merge Sort, which is this crazy recursive algorithm, which is calling itself over and over and over again.
That seems like it should be an easier place to start.
So let me remind you, the pseudo code of the merge subroutine, here it is.
So let's just go and count up how many operations that are gonna get used.
So there's the initialization step.
So let's say that I'm gonna charge us one operation for each of these two initializations.
Here or here.
So for each of these N iterations of the four loop we're gonna do four operations.
So putting it all together, what do we have is the running time for merge.
So the upshot is that the running time of the merge subroutine, given an array of M numbers, is at most four M plus two.
So a couple of comments.
In the previous slide we were thinking about an input size of N.
See I've changed the name of the variable to M.
That's gonna be convenient once we think about merge sort, which is recursing on smaller sub-problems.
But it's exactly the same thing and, and whatever.
The second thing is, there's some ambiguity in exactly how we counted lines of code on the previous slide.
The number of lines of code executed are not gonna matter, and we'll see why shortly.
So, amongst friends, let's just agree, let's call it 4M plus two operations from merge, to execute on array on exactly M entries.
So, let me abuse our friendship now a little bit further with an, an inequality which is true, but extremely sloppy.
But I promise it'll make our lives just easier in some future calculations.
Okay, you have to admit it's true, 6MO is at least 4M plus two.
Okay.
Now I don't expect anyone to be impressed with this rather crude upper bound, the number of lines of code that the merge subroutine needs to finish, to execute.
The key question you recall was how many lines of code does merge sort require to correctly sort the input array, not just this subroutine.
So the number of recursive calls, the number of things we have to analyze, is blowing up exponentially as we think about various levels of the recursion.
Now, if there's one thing we have going for us, it's that every time we make a recursive call.
So there's some kind of tension between on the one hand explosion of sub problems, a proliferation of sub problems and the fact that successive subproblems only have to solve smaller and smaller subproblems.
And resolute resolving these two forces is what's going to drive our analysis of Merge Short.
So, the good news is, is I'll be able to show you a complete analysis of exactly how many lines of code Merge Sort takes.
And I'll be able to give you, and, in fact, a very precise upper bound.
So the claim is that Merge Short never needs than more than six times N.
In the simpler sorting methods that we briefly discussed like insertion sort, selection sort, and bubble sort, I claimed that their performance was governed by the quadratic function of the input size.
That is they need a constant times in the squared number of operations to sort an input array of length N.
Merge sort by contrast needs at most a constant times N times log N, not N squared but N times log N lines of code to correctly sort an input array.
So to get a feel for what kind of win this is let me just remind you for those of you who are rusty, or for whatever reason have lived in fear of a logarithm, just exactly what the logarithm is.
So you have the X axis, where you have N, which is going from one up to infinity.
Okay, and let's contrast this with a logarithm.
So the log of n, log base 2 of n is, you type the number N into your calculator, okay?
And then you keep repeating dividing by two and you count how many times you divide by two until you get a number that drops below one okay.
So the point is you already see this if a log of a 1000 roughly is something like ten then the logarithm is much, much smaller than the input.
So F(n) being log base 2 of n.
And I encourage you to do this, perhaps a little bit more precisely on the computer or a graphing calculator, at home.
But log is running much, much, much slower than the identity function.
So, in this video, we'll graduate beyond the domain of just vanilla binary search trees, like we've been talking about before, and we'll start talking about balanced binary search trees.
These are the search trees you'd really want to use when you want to have real time guarantees on your operation time.
Cuz they're search trees which are guaranteed to stay balanced, which means the height is guaranteed to stay logarithmic, which means all of the operations search trees support that we know and love, will also be a logarithmic in the number of keys that they're storing.
So, let's just quickly recap.
What is the basic structure tree property?
It should be the case that at every single node of your search tree, if you go to the left, you'll only see keys that are smaller than where you started and if you go to the right you only see keys that are bigger than where you started.
And a really important observation, which is that, given a set of keys, there's going to be lot and lots of legitimate, valid, binary search trees with those keys.
So, we've been having these running examples where the keys one, two, three, four, five.
On the other hand, you can also have these crazy chains, basically devolved to link lists where the heights for, and elements could be as high as N - 1.
So, in general, you could have an exponential difference in the height.
It can be as small, in the best case, as logarithmic and as big, in the worst case, as linear.
So, this obviously motivates search trees that have the additional property that you never have to worry about their height.
You know they're going to be well balanced.
You're never worried about them having this really lousy linear height.
Remember, why it's so important to have a small height?
It's because the running time of all of the operations of search trees depends on the height.
You want to do search, you want to insertions, you want to find predecessors or whatever, the height is going to be what governs the running time of all those properties.
But it's got to be logarithmic, lets make sure it stays logarithmic all the time, even as we do insertions and deletions.
If we can do that, then we get a very rich collection of supported operations all running in logarithmic time.
There are many, many, many different balanced search trees.
They're not super, most of them are not super different from each other.
I'm going to talk about one of the more popular ones which are called Red Black Trees.
These were not the first balanced binary search tree data structures, that honor belongs to AVL trees, which again are not very different from red black trees, though the invariants are slightly different.
So, they're sometimes called self-adjusting trees for that reason.
And it's super simple, but they still have kind of amazing guarantees.
And then finally, going beyond the, just the binary tree paradigm many of you might want to look up examples of B trees or also B+ trees.
Here what the idea is, in a given node you're going to have not just one key but many keys and from a node, you have multiple branches that you can take depending where you're searching for falls with respect to the multiple keys that are at that node.
The motivation in a database context for going beyond the binary paradigm, is to have a better match up with the memory hierarchy.
So, that's also very important, although a little bit out of the scope here.
That said, what we discuss about red-black trees, much of the intuition will translate to all of these other balance tree data structures, if you ever find yourself in a position where you need to learn more about them.
And so, what I'm going to focus on in this video is, first of all, what the invariants are, and then how the invariants guarantee that the height will be logarithmic.
Time permitting, at some point, there will be optional videos more about the guts, more about the implementations of red black trees namely how do you maintain these invariants under insertions and deletions.
That's quite a bit more complicated, so that's appropriate for, for optional material.
But understanding what the invariants are and what role they play in controlling the height is very accessible, and it's something I think every programmer should know.
You might be wondering, you know, why red black?
Well, I asked my colleague, Leo Guibas about that a few years ago.
And he told me that when he and Professor Sedgewick were writing up this article the journals were, just had access to a certain kind of new printing technology that allowed very limited color in the printed copies of the journals.
And so, they were eager to use it, and so they named the data structure red black, so they could have these nice red and black pictures in the journal article.
So, that's the rather idiosyncratic reason why these data structures got the name that they did, red black trees.
So, secondly we're going to maintain the invariant that the roots of the search tree is always black, it can never be red.
So, with the superficial pair of invariants out of the way, let's go to the two main ones.
By which, I mean, if you have a red node in the search tree, then its children must be black.
If you think about for a second, you realize this also implies that if a notice red, and it has a parent, then that parent has to be a black node.
So, in that sense, there are no two red nodes in a row anywhere in the tree.
And the final invariant which is also rather severe is that every path you might take from a root to a null pointer, passes through exactly the same number of black nodes.
So, what happens in an unsuccessful search, you start at the root depending on whether you need to go smaller or bigger, you go left or right respectably.
You keep going left right as appropriate until eventually you hit a null pointer.
So, I want you to think about the process that which you start at the root and then, eventually, fall off the end of the tree.
In doing so, you traverse some number of nodes.
Some of those nodes will be black some of those nodes will be red.
And I want you to keep track of the number of black nodes and the constraints that a red black tree, by definition, must satisfy, is that no matter what path you take through the tree starting from the root terminating at a null pointer, the number of black nodes traversed, has to be exactly the same.
Let's move on to some examples.
And this is meant to, kind of, whet your appetite for the idea that red black trees must be pretty balanced.
They have to have height, basically logarithmic.
So, remember, what's the most unbalanced search tree?
So, the claim is, even a chain with three nodes can not be a red black tree.
So, maybe, with the key values one, two and three.
So, the question that we're asking is, is there a way to color the node, these three nodes, red and black so that all four of the invariants are satisfied.
So, we need to color each red or black.
So, we can either make two red, three black, two black, three red, or both two and three black.
And all of the cases are the same.
Just to give one example, suppose that we colored the node two, red, and one and three are black.
It says, really on any unsuccessful search, you pass through the same number of black nodes.
And so, one unsuccessful search would be, you search for zero.
And if you search for a zero, you go to the root, you immediately go left to hit a null pointer.
So, you see exactly one black node.
On the other hand, suppose you searched for four, then you'd start at the root, and you'd go right, and you go to two, you'd go right, and you go to three, you'd go right again, and only then will you get a null pointer.
And on that, unsuccessful search, you'd encounter two black nodes, both the one and the three.
I'll leave that for you to check, that no matter how you try to code two and three red or black, you're going to break one of the invariants.
If at most one is red, you'd break the fourth invariant.
So, that's a non-example of a red-black tree.
So, let's look at an example of a red-black tree.
One, a search tree where you can actually color the nodes red or black so that all four invariants are maintained.
So, one search tree which is very easy to make red black is a perfectly balanced one.
So, for example, let's consider this three nodes search tree has the keys three, five, and seven and let's suppose the five is the root.
It's asking can we color theses three nodes some combination of red and black so that all four of the invariants are satisfied?
If you think about it a little bit, you realize, yeah, you can definitely color these nodes red or black to make and satisfy for the invariants.
In particular, suppose we color all three of the nodes, black.
And, if you think about it, we've satisfied invariant four because this tree is perfectly balanced.
No matter what you unsuccessfully search for, you're going to encounter two black nodes.
If you search for, say, one, you're going to encounter three and five.
If you search for, say, six, you're going to encounter five and seven.
So, all root null paths have exactly two black nodes and variant number four is also satisfied.
But, of course, the whole point of having a binary search tree data structure is you want to be dynamic.
You want to accommodate insertions and deletions.
Every time you have an insertion or a deletion into a red black tree, you get a new node.
Let's say, an insertion, you get a new node, you have to color it something.
And now, all of a sudden, you got to worry about breaking one of these four invariants.
So, let me just show you some easy cases where you can accommodate insertions without too much work.
Time permitting we will include some optional videos with the notion of rotations which do more fundamental restructuring of search trees so that they can maintain the four invariants, and stay nearly perfectly balanced.
So, if we have this red black tree where everything's black, and we insert, say, six, that's going to get inserted down here.
Now, if we try to color it black, it's no longer going to be a red black tree.
But the way we can fix it is instead of coloring the six black, we color it red.
And now, this six is basically invisible to invariant number four.
So, all four invariants are satisfied once you insert the six and color it red.
If we then insert, say, an eight, we can pull exactly the same trick, we can call it an eight red.
Again, it doesn't participate in invariant four at all so we haven't broken it.
Moreover, we still don't have two reds in a row, so we haven't broken invariant number three either.
So, this is yet another red black tree.
In fact, this is not the unique way to color the nodes of this search tree, so that it satisfies all four of the invariants.
Clearly, the first three invariants are all satisfied.
But also, in pushing the red upward, consolidating the red at six and eight, and putting it at seven instead, we haven't changed the number of black nodes on any given path.
So, all paths still have equal number of black nodes and invariant four remains satisfied.
As I said, I've shown you here only simple examples, where you don't have to do much work on an insertion to retain the red black properties.
In general, if you keep inserting more and more stuff and certainly if you do the deletions, you have to work much harder to maintain those four invariants.
So, what's the point of these seemingly arbitrary four invariants of a red black tree?
Well, the whole point is that if you satisfy these four invariants in your search tree, then your height is going to be small.
And because your height's going to be small, all your operations are going to be fast.
So, let me give you a proof that if a search tree satisfies the four invariants, then it has super small height.
And what's clear about this proof is it's very obvious the role played by this invariants three and four.
Essentially, what the invariants guarantee is that, a red black tree has to look like a perfectly balanced tree with at most a sort of factor two inflation.
So, let's see exactly what I mean.
So, let's begin with an observation.
Forget about the colors for a moment, and just think about the structure of binary trees.
Suppose we have a tree where if you start from the root, and no matter how it is you navigate left and right, child pointers until you terminate in a null pointer.
If that hypothesis is satisfied, then if you think about it, the top of this tree has to be totally filled in.
So, let me draw a picture here of the case of k = three.
So, if no matter how you go from the root to a null pointer, you have to see at least three nodes along the way.
So, you have to have the root.
If, in fact, you were missing some nodes in any of these top k levels.
So, what's the point is, the point is this gives us a lower bound on the population of a search tree as a function of the lengths of its root null paths.
So, let's now combine that with a red black tree invariant to see why red black trees have to have small height.
So again, to recap where we got to on the previous slide.
So, let's rewrite this a little bit and let's actually say, instead of having a lower bound on N in terms of k, let's have an upper bound on k in terms of N.
So, the length of every root null path, the minimum length of every root null path is bounded above by log base two of quantity N + 1.
This is just adding one to both sides and taking the logarithm base two.
So, what does this buy us?
Well, now, let's start thinking about red black trees.
So now, red black tree with N nodes.
What does this say?
This says that the number of nodes, forget about red or black, just the number of nodes on some root null path has to be the most log base two of N + 1.
In the best case, all of those are black.
Maybe some of them are red, but in the, in, the maximum case, all of them are black.
This is an even weaker statement than what we just proved.
Now, let's, now let's apply the two knockout punches of our two invariants.
It's telling us that if we look at a path in our red black tree, we go from the root, we think about, let's say, that's an unsuccessful search, we go down to a null pointer.
It says, if we think of the red nodes as invisible, if we don't count them in our tally, then we're only going to see log, basically a logarithmic number of nodes.
But when we care about the height of the red black tree, of course, we care about all of the nodes, the red nodes and the black nodes.
So, so far we know, that if we only count black nodes then we're good, We only have log base two of N + 1 nodes that we need to count.
It says, well actually, black nodes are a majority of nodes in the tree.
So, if we know the number of black nodes is small, then because you can't have two reds in a row, the number of total nodes on the path is at most twice as large.
In the worst case, you have a black route, then red, then black, then red, then black, then red, then black, et cetera.
At the worst case, the number of red nodes is equal to the number of black nodes, which doubles the length of the path once you start counting the red nodes as well.
And this is exactly what it means for a tree to have a logarithmic depth.
So, this, in fact, proves the claim, if the search trees satisfies the invariants one through four, in particular if there's no two reds in a row and all root null paths have an equal number of black nodes, then, knowing nothing else about this search tree, it's got to be almost balanced.
It's perfectly balanced up to a factor of two.
Clearly that's exactly what you want from this data structure.
But for the poor soul who has to actually implement this data structure, the hard work is maintaining these invariants even as the data structure changes.
Remember, the point here is to be dynamic, to accommodate insertions and deletions.
And searches and deletions can disrupt these four invariants and then one has to actually change the code to make sure they're satisfied again, so that the tree stays balanced, has low height, even under arbitrary sequences of insertions and deletions.
It can be done, without significantly slowing down any of the operations.
It's pretty tricky, takes some nice ideas.
There's a couple well-known algorithms textbooks that cover those details.
Or if you look at open source and limitations of balanced search trees, you can look at code that does that implementations.
But, because it can be done in a practical way and because Red Black Tree supports such an original array of operations, that's why you will find them used in a number practical applications.
Well, we're almost done with our discussion of symmetric encryption.
There are just a couple of odds and ends that I'd like to discuss before we move on to the next topic.
So the first thing I'd like to mention is how we derive many keys from one key.
Well, imagine we have a certain source key that's generated by one of, a number of methods.
Imagine the source key is generated by a hardware random number generator or perhaps is generated by a key exchange protocol which we're going to discuss later.
But now, as we said, in many cases, we actually need many keys to secure a session, not just one single source key.
For example, if you remember, in TLS there were unidirectional keys and we needed keys in each direction.
And in fact, in each direction, we needed multiple keys.
And I want to talk a little bit about how KDF's are constructed.
So first of all, suppose we have a secure PRF, that happens to have key space K.
In this case, the source key is, in fact, a uniform random key for the secure PRF F.
And we can use it directly to generate keys, all the keys that we need to secure the session.
So in this case, the KDF is really simple.
And then what it will do is it will basically evaluate the PRF on zero.
Then it will evaluate the PRF on two, up until L.
So, if you need unidirectional keys you would generate, you know, one key in each direction where each key might include an encryption key and a MAC key.
And so, you would basically generate as many bits as you need and then finally cut off the output at the time when you've generated enough keys to secure your session.
Okay so this is a fairly straight forward mechanism it's basically using the secure PRF as a pseudo random generator.
And the only question is what is its context string.
Well, I'll tell you that the context string is basically a unique string that identifies the application.
So in fact you might have multiple applications on the same system that's trying to establish multiple secure keys.
Maybe you have SSH running as one process, you have a web server running as another process, IPsec as a third process and all three need to have secret keys generated.
And this context variable basically tries to separate the three of them.
So, let me ask you, more precisely, what do you think the purpose of this context variable is?
I just want you to remember that, even though this is actually fairly straightforward, and we discussed this before, the context string is actually important, and it does need to be specific to the application, so that each application gets its own session keys, even if multiple applications happen to sample the same SK.
The next question is, what do we do if the source key actually isn't uniform?
If the source key is not a uniform key for the pseudo random function then we can no longer assume that the output of the pseudo random function is indistinguishable from random.
In fact, if we just use the KDF that we just described then the output might not look random to the adversary and then he might be able to anticipate some of the session keys that we'll be using and thereby break the session.
So then we have a problem.
Now why would this source key not be uniform?
Well there are many reasons why this happened.
For example if you use a key exchange protocol, it so happens typically that key exchange protocols will generate a high entropy key.
So it's not going to be a uniform string.
It will be uniform in some subset of a larger set, And we'll see examples of that as soon as we talk about key exchange protocols.
And so KDFs have to kind of accommodate for the fact that key exchange protocols actually don't generate uniform bit strings.
The other problem is, that, in fact, the hardware random number generator you're using might actually produce biased outputs.
And so all we want to assume is that it generates a high entropy string, but one that might be biased.
In which case, we have to somehow clean this bias.
This is called the extract-then-expand paradigm, where the first step of the KDF is to extract a pseudo random key from the actual source key.
So in a picture you can think about it like this.
This is the horizontal line and the vertical axis is basically the probability of each one of these values, and you can see that this is a kind of a bumpy function which would say that the source key is not uniformly distributed in the key space.
What we do in this case is we use what's called an extractor.
So an extractor is something that takes a bumpy distribution and makes it into a uniform distribution over the key space.
In our case we're actually just gonna be using what are called computational extractors, namely extractors that don't necessarily produce uniform distribution at the end but they generated distribution that's indistinguishable from uniform.
Now extractors typically take as input something called a salt, and a salt just like in a salad, it kind of adds flavor to things, what it does is basically kind of jumbles things around, so that no matter what the input distribution is, the output distribution is still going to be indistinguishable from random.
So a salt basically, what is it?
It's a non-secret string, so it's publicly known.
It doesn't matter if the adversary knows what the salt is, and it's fixed forever.
The only point is that when you chose it, you chose one at random.
And then the hope is that the funny distribution that you're trying to extract from kinda doesn't inherently depends on the salt that you chose and hence as a result using your salt, you will actually get a distribution that looks indistinguishable from random.
In some sense the salt is only there to defend against adversarially bad distributions that might mess up our extractor.
Okay, so now that we have extracted a pseudo random key.
Now, we might as well just use it in a KDF that we just saw using a secure pseudo random function to expand the key into as many bits as we need to actually secure the session.
The first one is we extract a pseudo-random key, and then once we have a pseudo-random key we already know how to extend it into as many keys as we need using a pseudo-random function.
So the standardized way of doing this is called HKDF.
This is a KDF, a key derivation function that's built from HMAC.
And here HMAC is used both as the PRF for expanding and an extractor for extracting the initial pseudo-random key.
So let me explain how this works.
So in the extract step, we're gonna use our salt which you remember is a public value just happened to be generated at random at the beginning of time.
So we're kind of using a public value as a key.
And nevertheless, one can argue that HMAC has extraction properties, such that, when we apply HMAC, the resulting key is going to look indistinguishable from random, assuming that the source key actually has enough entropy to it.
And now that we have the pseudo random key we're simply going to use HMAC as a PRF to generate a session key of you know as many bits as we need for the session keys.
Okay.
So that basically concludes our discussion of HKDF.
And I just want you to remember that, once you obtain a source key, either from hardware or from a key exchange protocol, the way you convert it into session keys is not by using that sample directly.
You would never use a source key directly as a session key in a protocol.
And the KDF would give you all the keys and output that you need, for, the randomness, for the random keys to be used in your protocol.
And a typical KDF to use is HKDF, which is actually getting quite a bit of traction out there.
Okay.
The last topic I wanna talk about in this segment is, how do you extract keys from passwords.
The problem here is that passwords have relatively low entropy.
In fact, we're gonna talk about passwords later on in the course when we talk about user authentication.
And so, I'm not gonna say too much here.
I'll just say passwords generally have very little entropy estimated on the order of twenty bits of entropy, say.
And as a result, there is simply not enough entropy to generate session keys out of a password.
And yet we still need to do it very frequently.
We still need to derive encryption keys and MACs and so on out of passwords, so the question is how to do it.
The first thing is, you know, for this kind of purpose, don't use HKDF.
What will happen is that the derived keys will actually be vulnerable to something called a dictionary attack, which we're gonna talk about much later in the course when we talk about user authentication.
So, the way PBKDFs defend against this low entropy problem that results in a dictionary attack is by two means.
First of all, as before they use a salt, a public, random value that's fixed forever.
But in addition, they also use what's called a slow hash function.
And let me describe kind of the standard approach to deriving keys from passwords.
This is called PKCS#5, and in particular, the version I'll describe is what's called PBKDF1.
All you would do, you know, you would call a function, you know, derived key from password.
You would give the password in as input, and you would get a key as output.
But you should be aware of course that this key is not going to have high entropy so in fact it will be guessable.
What these PBKDFs try to do is make the guessing problem as hard as possible.
Okay.
So the way they work, first of all, is, as we said, they basically hash, the concatenation of the password and the salt.
And then the hash itself is designed to be a very slow hash function.
And the way we build a slow hash function is by taking one particular hash function, say, SHA-256, and we iterate it many, many times, C times.
So you can imagine 1000 times, perhaps even a million times.
And what do I mean by iterating it?
So, well, we take the password and the salt.
And we put them inside of one input to the hash function.
And then we apply the hash function, oops, let me write it like this.
And then we apply the hash function and we get an output, and then we apply the hash function again and we get another output.
And we do this again and again and again maybe a thousand times or a million times depending on how fast your processors are and then finally we get the final output that we actually output as, as the key output of this key derivation function.
Now what is the point here?
Iterating a function 10,000 times or even a million times is going to take very little time on a modern CPU, and as a result, it doesn't really affect the user's experience.
The user types in his password, it gets hashed a million times and then it gets output.
And maybe that could even take, you know a tenth of a second and the user wouldn't even notice it.
However the attacker, all he can do is he can try all the passwords in the dictionary, because we know people tend to pick passwords in dictionaries, and so he could just try them one by one, remember the SALT is public, so he knows what the SALT is.
And so he can just try this hash one by one.
However because the hash function is slow, each attempt is gonna take him a tenth of second.
So if he needs to run through a dictionary, you know, with, with a 200 billion passwords in it, because the hash function is slow, this is gonna take quite awhile.
And by doing that, we slow down the dictionary attack, and we make it harder for the attacker to get our session keys.
Not impossible, just harder.
That's all this is trying to do.
Okay, so this is basically what I wanted to say about password based KDFs.
As I said, this is not something you would build yourself.
And you would just call the appropriate function to convert a password into a key, and then use the resulting key.
Okay, in the next segment, we're gonna see how to use symmetric encryption in a way that allows us to search on the cipher texts.
We're going to concentrate on programming and problem solving in the context of real applications, and our focus is going to be on two things, Algorithms which are methods for solving problems and data structures which store the information associated in problem, with a problem and go hand in hand with algorithms.
We'll consider a number of data structures and algorithms that are basic to all the methods we consider including stacks, queues, bags and priority queues.
And then some advanced algorithms that make use of the basic algorithms that we developed earlier in the course.
So, why should one study algorithms?
Well, their input, impact is very broad and far-reaching.
From the internet to biology to, commercial computing, computer graphics, security, multimedia, social networks, and scientific applications, algorithms are all around us.
They're used for movies and video games, for particle collision simulation, they're used to study the genome, and all manner of other applications.
So, that's one important reason to study algorithms, their impact is broad and far-reaching.
Algorithms are also interesting to study, because they, they have ancient roots.
Now the first algorithm we studied goes back to 300 B.C., dating at least to Euclid.
The concept of an algorithm was formalized actually here at Princeton, by Church and Turing, in the 1930s.
But most algorithms that we consider, were discovered in recent decades.
In fact, some were discovered by undergraduates in a course, course like this.
And there's plenty of other algorithms waiting to be discovered by students like you.
The main reason that people study algorithms, is to be able to solve problems that it could not otherwise be addressed.
For example, in the first lecture, we're going to talk about the network connectivity problem, where the problem is, given a large set of items that are connected together pairwise is there a way to get from one to another with a path through the connections.
In this case the answer is that there is such a path.
Algorithms are very interesting objects to study.
Another quote from Francis Sullivan, says, "The great algorithms are the poetry of computation." Just like verse, they can be terse, elusive, dense, and even mysterious.
But once unlocked, they cast a brilliant new light on some aspect of computing.
Another reason many people study algorithms and I suspect many of you, is it's necessary to understand good algorithms, efficient algorithms, a good data structures in order to be a proficient programmer.
Bad programmers worry about the code, good programmers worry about data structures, and their relationships.
And, I might add, the algorithms that process them.
Niklaus Wirth, another pioneer in computer science, wrote a famous book called Algorithms + Data Structures = Programs.
Another reason nowadays to study algorithms is that, they have become a common language for understanding, nature.
Algorithms are computational models, and algorithmic models are replacing mathematical models in scientific inquiry.
In the twentieth century, math, scientists developed mathematical models to try to understand natural phenomenon.
It soon became clear that those mathematical models were difficult to solve.
It was difficult to create solutions, to be able to test hypotheses against natural phenomenon.
So, more and more and more now a days people are developing computational models, where they attempt to simulate what might be happening in nature in order to try to better understand it.
Algorithms play an extremely important role in this process.
And we'll see some examples of this in this course.
Another important reason is that if you know effect, how to effectively use algorithms and data structures you're going to have a much better chance at interviewing for a job in the technology industry then if you don't.
So, here's a bunch of reasons that I just went through for studying algorithms.
Their impact's broad and far-reaching, they have old roots and present new opportunities, they allow us to solve problems that could not otherwise be addressed, you can use them for intellectual stimulation to become a proficient programmer.
They might unlock the secrets of life in the universe, and they're good for fun and profit.
Well, there's plenty of good reasons to study other things, but I'll submit there's no good reason not to study algorithims.
So, for this course we have two resources that I want to talk about and make sure that people are familiar with before entering into the content.
This is a publishing model that Kevin Wayne and I developed and have been using for many years, and we think it's a very effective way to support the, kinds of lectures that we're going to be giving in this course.
Down at the bottom, and it's optional for this course, we have a text book.
It's a traditional, text book that extensively covers the topics in the course, in fact many more topics than we can present in lecture.
And then supporting that textbook, is free online material that we call the book site.
You can go to books, the book site to see the lecture slides.
But more important, there's code, there's exercises, tere's a great deal of information there.
In fact, maybe ten times what's in the book, including a summary of the content.
So, during this course you'll be referring to the book site frequently while working online.
We're assuming that people who take this course know how to program, and know the basics of loops, arrays, functions.
They have some exposure to object oriented programming and recursion.
We use the Java language, but we don't dwell on details of Java, we mostly use it as an expository language.
If you want to review the material that we think is prerequisite for the material in this course, you can do a quick review by looking at sections 1.1 and 1.2 of the book.
If you want an in depth review, we have a full text book called, An Introduction to Programming in Java: An Interdisciplinary Approach.
There is a book site and text book as well.
But, the bottom line is, you should be able t o program, and the quick exercise to get ready is, to write a java program on your computer perhaps using a programming model, as described on the book site.
We will provide much more detail information on that as we get into the assignments.
You can use your own programming environment if your comfortable with one or you download ours.
We have instructions on the web on how to do that.
Today, we're going to talk about the union find problem.
The subtext of today's lecture really is to go through the steps that we'll follow over and over again to develop a useful algorithm.
The first step is to model the problem.
Try to understand, basically, what are the main elements of the problem that need to be solved.
Then we'll find some algorithm to solve the problem.
In many cases, the first algorithm we come up with would be fast enough and maybe it fits in memory and, we'll go ahead and use it, and be off and running.
But in many other cases maybe it's not fast enough, or there's not enough memory.
So, what we do is try to figure out why, find a way to address whatever's causing that problem, find a new algorithm and iterate until we're satisfied.
This is the scientific approach to designing and analyzing algorithms, where we build mathematical models to try and understand what's going on, and then we do experiments to validate those models and help us improve things.
So, first we'll talk about the dynamic connectivity problem, the model of the problem for union find.
So, here's the idea.
Doesn't really matter what they are.
We're going to use the numbers, zero through N to model our objects.
And then, we have the idea of a connection between two objects.
And, we'll, postulate that there's going to be a command that says, connect two objects.
Given two objects, provide a connection between them.
And then key part of the problem is find query or the connected query, which just asks, is there a path connecting the two objects.
So for example, in this set of ten objects, we performed already, a bunch of union commands, connecting four and three, three and eight, six and five, nine and four, two and one.
And now we might have a connected query that says, is zero connect ed to seven?
Well, in this case, there is no connection, so we say no.
We are going to say yes, even no we don't have a direct connection between eight and nine.
There is a path from eight to three to four to nine.
So, that's our problem, to be able to officially support these two commands for given set of objects.
Seven and two creates a connection between seven and two.
And that's a redundant connection.
And now, if we ask is zero connected to seven we're going to answer yes.
So that's our problem, intermix union, commands and connected queries and we need to be able to officially support those commands for a large number of objects.
So, here's a much bigger example.
And you can see that we're going to need efficient algorithms for this.
First of all, you can see we're going to need a computer for this.
It would take quite, quite some time for a human to figure out whether there's a connection.
In this case there is a connection.
Now, the algorithms that we're looking at today are not going to actually give the path connecting the two objects.
In part two of the course, we'll consider algorithms that explicitly find paths.
They're not as efficient as union find because they have more work to do.
Now, applications of these, these algorithms involve objects of all types.
That's a very convenient initial starting point for our programs because we can use integers as an index into an array then, and then quickly access information relevant to each object.
And it also just supresses a lot of details that are not relevant to union find.
Now, the connections, well, we need, a few abstract properties that these connections have to satisfy.
And they're all quite natural and intuitive.
So we assume that is connected to is an equivalence relation.
That is, every object's connected to itself, it's symmetric.
If P's connected to Q, then Q's connected to P, and it's transitive.
If P's connected to Q, and Q's connected to R, then P's connected to R.
Now these properties are very intuitive.
But it's worthwhile to state them explicitly and make sure that our algorithms maintain them.
When we have an equivalence relation a set of objects and connections divide into subsets called connected components.
One consisting of just object zero, second one objects one, four and five.
And third one the other four objects.
And these components have the property that if any two objects in them are connected and there is no object outside that is connected to those objects, that's connected components.
Our algorithms will gain efficiency by maintaining connected components and using that knowledge to efficiently answer the query that's, that they're presented with.
Okay, so to implement the operations, we have to find query and the union command.
The find is going to have to check if two objects are in the same component and the union command is going to have to replace components containing two objects with their union.
So, for example, if we have these components, and we get the command to union connect, two and five.
All of that leads up to, in a programming world to specifying, a data type which is simply specification of the methods that we are want to going to implement in order to solve this problem.
So you know, typical Java model, what we will do is create a class called UF that contains two methods, one to implement union, the other one to implement connected, which returns a boolean.
The constructor, takes SR unit, the number of objects, so that it can build data structure based on the number of objects.
So, and we have to, bear in mind, as we're building our logarithms, that both the number of objects can be huge, but also, the number of operations.
We can have a, a very large number, of union and connected, operations and our algorithms are going to have to be efficient, under those conditions.
One of the practices that will follow often in this course is to check our API design before getting too far into dealing with the problem, by building a client that is going to use the data type that we develop.
So, for this example, we've got a client that, Will read information from standard input.
First, an integer which is the number of objects that are going to be processed.
And then a series of pairs of object names.
And what the client does is it, it'll, first it'll read the integer from standard input, and create a, a UF object.
And then as long as standard input is not empty, it's going to read two integers from the input.
If they are connected it'll ignore.
So, that's our test client and that's a fine test client to make sure that any implementation does what we expect that it will.
We've described the operations we want to implement all the way down to code and we have client code that we're going to have to be able to service with our
Now we'll look at our first implementation of an algorithm for solving the dynamic connectivity problem, called Quick-find.
This is a so called eager algorithm, for solving kind activity problem.
The data structure that we're going to use to support the algorithm is simply an integer array indexed by object.
The interpretation is the two objects, P and Q are connected if and only if, their entries in the array are the same.
So for example in this example with our ten objects the idea array that describes the situation after seven connections is illustrated in the middle of the slide.
And three, four, eight, and nine all have entry eight.
So that representation is, shows that they're connected.
We just check the array entries to see if they're equal.
Check if P and Q have the same ID.
So, six and one have different IDs.
One has ID one, six has ID zero.
They're not in the same connected component.
Union is more difficult in order to merge the components, containing two given objects.
We have to change all the entries, whose ID is equal to one of them to the other one.
And arbitrarily we choose to change the ones that are the same as P to the ones that are same as Q.
So if we're going to union six and one, then we have to change entries zero, five, and six.
Everybody in the same connected component as six.
From zero to one.
And this is, as we'll see, this is a bit of a problem when we have a huge number of objects, because there's a lot of values that can change.
But still, it's easy to implement, so that'll be our starting point.
So we'll start with a, a demo of how this works.
So, initially, we set up the ID array, with each entry, equal to its index.
They're in their own connected component.
Now, when we get a union operation.
Then we're going to change, all entries, whose ID is equal to the first ID to the second one.
So in this case, we'll change the, connect three and four means that we need to change the four to a three.
And we'll continue to do a few more so you'll get an idea of how it works.
So three and eight now so to connect three and eight now three and four have to be connected to eight.
So both of those entries have to change to eight.
Okay?
So now, what about six and five?
So again, we change the first one to match the second one.
So to connect six and five, we change the six to a five.
What about nine and four?
So, now we have to change the, to connect nine and four, we have to change, 9's entry to be the same as 4's.
So now we have three, four, eight, and nine.
All have entries eight.
They're all on the same connected component.
Two and one means that we connect two and one by changing the 2201.
Eight and nine are already connected.
They have the same, entries in the idea array.
And five and zero have different entries.
They're not connected, so we'd return false, in that case, not connected.
And then, if we want to connect five and zero.
Then, as usual we'll connect, the entry corresponding to both five and six to zero.
And union, six and one so there is three entries that have to get changed.
All those zeros have to get changed to ones.
Now next we'll look at the code for implementating that.
Okay, with this concrete demo in mind then moving to coding up this algorithim is pretty straight forward.
Although it's an interesting programming exercise that a lot of us would get wrong the first time.
That's the data structure that's going to support this implementation.
The constructor has to create the array and then go through and set the value corresponding to each index I to I.
That's the easy one .
This is the Quick-find algorithm.
So it simply takes its two arguments, P and Q, and checks whether their ID entries are equal, and returns that value.
The more complicated operation implement is a union.
And there, we find first the ID corresponding with the first argument, and then the ID corresponding to the second argument.
And then we go through the whole array, and looking for the entries whose IDs are equal to the ID of the first argument, and set those to the ID of the second argument.
That's a pretty straightforward implementation.
And I mentioned that a lot of us would get us wrong.
As we saw when doing the implementation, both the initialized and union operations involved the for-loop that go through the entire array.
So they have to touch in a constant proportional to n times after touching array entry.
Find Operation is quick, it's just to a constant number of times check array entries.
And this is problematic because the union operation is too expensive.
In particular if you just have N union commands on N objects which is not unreasonable.
And one of the themes that we'll go through over and over in this course is that quadratic time is much to slow.
And we can't accept quadratic time algorithms for large problems.
The reason is they don't scale.
As computers get faster and bigger, quadratic algorithms actually get slower.
Now, let's just talk roughly about what I mean by that.
A very rough standard, say for now, is that people have computers that can run billions of operations per second, and they have billions of entries in main memory.
So, that means that you could touch everything in the main memory in about a second.
That's kind of an amazing fact that this rough standard is really held for 50 or 60 years.
The computers get bigger but they get faster so to touch everything in the memory is going to take a few seconds.
Now it's true when computers only have a few thousand words of memory and it's true now that they have billions or more.
So let's accept that as what computers are like.
Now, that means is that, with that huge memory, we can address huge problems.
So we could have, billions of objects, and hope to do billions of union commands on them.
And, but the problem with that quick find algorithm is that, that would take ten^18th operations, or, say array axises or touching memory.
And if you do the math, that works out to 30 some years of computer time.
Obviously, not practical to address such a problem on today's computer.
And, and the reason is, and the problem is that quadratic algorithms don't scale with technology.
You might have a new computer that's ten times as fast but you could address a problem that's ten times as big.
And with a quadratic algorithm when you do that.
That's the kind of situation we're going to try to avoid by developing more efficient algorithms for solving problems like this.
All right so QuickFind is too slow for huge problems.
So, how are we going to do better?
Our first attempt is an alternative called, Quick-union.
This is so called lazy approach to algorithm design where we try to avoid doing work until we have to.
It uses the same data structure or array ID with size M but now it has a different interpretation.
We are going to think of that array as representing a set of trees that's called a forest as depicted at right.
So, each entry in the array is going to contain a reference to its parent in the tree.
Now each entry in the array has associated with it a root.
Elements that are all by themselves in just, in their own connected component, point to themselves, so one points to itself but also nine points to itself.
It's the root of the tree, containing two, four and three.
So that's the root of three is nine, going up that root.
Now, once we can calculate these roots, then we can implement the find operation just by checking whether the two items that we're supposed to check with are connective where they have the same root.
That's equivalent to saying, are they in the same connective component?
So that's some work, going to find the roots of each item but the union operation is very easy.
All we do is set the ID of P's route to the ID of Q's route.
Let's make P's tree point to Q.
So in this case, we would change the entry of nine to be six to merge three and five.
The components containing three and five.
And with just changing one value in the array we get the two large components emerged together.
Because a union operation only involves changing one entry in the array.
So let's look at the Implementation, a demo of that one in operation first.
So again we, we start out the same way but now the idea array entry really means that every one of these things is a little tree where the one node each everyone pointing to itself.
It's the root of it's own tree so now if we have to put four and three in the same component, then all we do is we take the root, of the component containing the first item and make that a child of the root of the component, component containing the second item.
In this case we just make four as parent three.
So again, we take the first item and make it a child of the root of the tree containing the second item.
So now three, four, and eight are in the same component.
Six and five six goes below five.
Now if we get our, our eight and nine connected, we just checked that they have the same root and they both have the same root eight and so they're connected.
Five and four 4's root is eight.
Five and zero.
Five goes to be a child of zero.
Six and one.
6's route is zero 1's its own route, so zero becomes a child of one.
Each one of these union operations just involves changing one entry in the array.
And finally, seven and three.
So seven's root is one, three's root is eight, one becomes a child of eight.
Okay and now we have one connected component with all the items together.
Alright, so now let's look at the code for implementing Quick-union.
The constructor is the same as the other one.
We create the array and then set each element to be it's own root.
So starting at any node, you just follow ID equals ID of I until they're equal and then you're at a root and that's a private method that we can use to implement the find operation or the connected operation.
You just find the root of P and the root of Q and if you check if they're equal.
And then the union operation is simply find the two roots I and then set the idea the first one could be the second one.
There's this one wild loop that we have to worry about a little bit.
But that's a quick and elegant implementation of code to solve the dynamic connectivity problem called Quick-union.
So now we're going to have to look at can this code be effective for large problems?
Well unfortunately Quick-union is faster but it's also too slow.
And the defect for Quick-union is that the trees can get too tall.
Which would mean that the find operation would be too expensive.
Of each object just pointing to next and then to do a find operation for object at the bottom would involve going all the way through the tree.
Costing involving in the ray axises just to do the find operation and that's going to be too slow if you have a lot of operations.
Okay.
So, we've looked at the quick union and quick find algorithms.
Both of which are easy to implement.
So, how are we going to do better?
That's what we'll look at next.
A very effective improvement, it's called weighting.
And it might have occurred to you while we are looking at these algorithms.
The idea is to when implementing the quick union algorithm take steps to avoid having tall trees.
If you've got a large tree and a small tree to combine together what you want to try to do is avoid putting the large tree lower, that's going to lead to long tall trees.
And there's a relatively easy way to do that.
So, we, we avoid this first situation here where we put the larger tree lower.
In the weighted algorithm, we always put the smaller tree lower.
How we, let's see how we implement that.
Let's see a demo first.
Okay, so again start out in our normal starting position, where everybody's in their own tree.
And for when there's only two items to link it, it works, works the same way as before.
So, six and five doesn't matter, whichever one goes down doesn't matter.
Nine and four, so now, nine is the small one four is the big one.
Two and one, five and zero.
So now, five and zero five is in the bigger tree so zero goes below.
Seven and two, two is in the bigger tree so seven goes below.
Six and one they're in equal size trees.
And seven and three, three is in the smaller tree so it goes below.
So, the weighted algorithm always makes sure that the smaller tree goes below.
And again, we wind up with a single tree representing all the objects.
But this time, we h ave some guarantee that no item is too far from the root and we'll talk about that explicitly in a second.
So, here's an example that shows the effect of doing the weighted quick union where we always put the smaller tree down below for the same set of union commands.
This is with a hundred sites and 88 union operations.
You can see in the top the big tree has some trees, some nodes, a fair distance from the root.
In the bottom, for the weighted algorithm all the nodes are within distance four from the root.
The average distance to the root is much, much lower.
Let's look at the Java implementation and then we'll look in more detail at, at that quantitative information.
Find implementation is identical to for quick union, you're just checking whether the roots are equal.
For the union implementation, we're going to modify the code to check the sizes.
And link the root of the smaller tree to the root of the larger tree in each case.
And then after changing the id link, we also change the size array.
If we make id, i a child of j, then we have to increment the size of j's tree by the size of i's tree.
Or if we do the other way around, then we have to increment the size of i's tree by the size of j's tree.
So, that's the full code in white for implementing quick union.
So, not very much code but much, much better performance.
In fact we can analyze the running time mathematically and show that defined operation, it takes time proportional to how far down the trees are in the node in the tree, the nodes are in the tree, but we can show that it's guaranteed that the depth of any node in the tree is at most the logarithm to the base two of N.
And, and, so for, if N is a thousand, that's going to be ten, if N is a million that's twenty, if N is a billion that's 30.
It's a very small number compared to N.
So, let's look at the proof of that.
We do some mathematical proofs in, in this course when they're critical such as this one.
And why is it true that the depth of any node x is, at most, log base two of N?
Well, the key to understanding that is to, take a look at exactly when does the depth of any node increase?
The x's depth will increase by one, when its tree, T1 in this diagram, is merged into some other tree, T2 in this diagram.
Well, at that point we said we only do that if the size of T2 was bigger than the or equal to size of T1.
So, when the depth of x increases, the size of its tree at least doubles.
So, that's the key because that means that the size of the tree containing x can double at most log N times because if you start with one and double log N times, you get N and there's only N nodes in the tree.
So, that's a sketch of a proof that the depth of any node x is at most log base two of N.
And that has profound impact on the performance of this algorithm.
But now, both the union and the connected or find operation takes time proportional to log base two of N.
And that is an algorithm that scales.
If N grows from a million to a billion, that cost goes from twenty to 30, which is quite not acceptable.
Now, this was very easy to implement and, and we could stop but usually, what happens in the design of algorithms is now that we understand what it is that gains performance, we take a look and see, well, could we improve it even further.
And in this case, it's very easy to improve it much, much more.
And that's the idea of path compression.
And this idea is that, well, when we're trying to find the root of the tree containing a, a given node.
We're touching all the nodes on the path from that node to the root.
So when we're looking, we're trying to find the root of, of P.
After we find it, we might as well just go back and make every node on that path just point to the root.
And the reason would be, no reason not to do that.
We had one line of code to flatten the tree, amazingly.
Actually to make a one liner code, we use a, a simple variant where we make every other node in the path point to its grandparent on the way up the tree.
Now, that's not quite as good as totally flattening actually in practice that it actually is just about as good.
So, with one line of code, we can keep the trees almost completely flat.
And what was proved by Hopcroft Ulman and Tarjan was that if you have N objects, any sequence of M union and find operations will touch the array at most a c (N + M lg star N) times.
And now, lg N is kind of a funny function.
It's the number of times you have to take the log of N to get one.
And the way to think, it's called the iterated log function.
And another point about this is it so close to being linear that is t ime proportional to N instead of time proportional to N times the slowly growing function in N.
Is there a simple algorithm that is linear?
And people, looked for a long time for that, and actually it works out to be the case that we can prove that there is no such algorithm.
And it's important for us to know that theory and that will help us decide how to choose which algorithms we're going to use in practice, and where to concentrate our effort in trying to find better algorithms.
It's amazing fact that was eventually proved by Friedman and Sachs, that there is no linear time algorithm for the union find problem.
So, that's our summary for algorithms for solving the dynamic connectivity problem.
With using weighted quick union and with path compression, we can solve problems that could not otherwise be addressed.
For example, if you have a billion operations and a billion objects I said before it might take thirty years.
We can do it in six seconds.
Now, and what's most important to recognize about this is that its the algorithm design that enables the solution to the problem.
A faster computer wouldn't help much.
Welcome to the Johns Hopkins Data Science Track.
I'm incredibly excited to tell you a little bit about the track and about where you're going to be going over the next nine months.
My name is Jeff Leek, and I'm a professor in the Johns Hopkins Bloomberg School of Public Health.
I thought I'd lead off this introductory video with a quote by one of my favorite US Presidents, Teddy Roosevelt.
It's not the person who points out how the person who's actually doing things is doing them wrong or messing up.
It's the person who's actually trying to get things done, even when there are obstacles in the way.
And a lot of data science right now is being able to push through a lot of the difficulties that you have when you're dealing with either large or messy data.
It includes collecting the data clean them up and then building new announced techniques that exploring new information about that data.
And so, all of those steps are a little bit complicated and sometimes it opens you to criticism when you're trying to do something new and interesting.
And so I wanted to lead with a quote that said it's important to strive the valiantly do these sorts of things, even if you're going to take some criticism.
So the key challenge in data science is actually really nicely summed up in this quote by Dan Myer.
He says, ask yourselves, what problem you, have you ever solved, ever, that was worth solving, where you knew all of the given information in advance?
Where you didn't have a surplus of information and have to filter some of it out, or you didn't have insufficient information and have to go find some?
You're either in a situation where you really don't have enough data to answer the question that you're interested in, and you have to go out and try to search for it, find it on the web, or find it in other places.
Or you're in a situation where you are overwhelmed with a surplus of data and you have to filter out all of the irrelevant information to try to narrow in on your question.
And you'll notice that I said question in both of those cases.
And I think this goes to the heart of our philosophy about data science.
We're interested in answering questions with data.
And that actually makes it more challenging, because sometimes, you can answer a question with some data but you might not be able to answer your question with some data.
So this track is about refocusing on answering the question that you're interested in solving with the data that you have.
So we are all faculty in the Johns Hopkins Blumberg School of Public Health in the Biostatistics Department.
And you could say that we all do data intensive statistics in biology and medicine.
Brian Caffo works on the statistics of brain, analyzing brain imaging data.
And I work on the statistics of analyzing genomics data.
And Roger Peng works on the statistics of analyzing fine particulate matter.
All of us work on problems where the data aren't always clean and nice and easy to handle.
All of us work on problems where the questions that we want to answer are complicated and you have to break them down into parts.
And all of us, sort of, work on questions where we're very passionate about trying to get the right answer so that we can help people in human health.
But the techniques that you're going to be learning about are not exclusive to biology and medicine.
That's just one area where there's been a recent upsurge in the amount of data that's available.
So why data science?
Why should you take this program?
This is a cover of The Economist now.
It's a little bit old I guess ancient history from a couple of years ago.
It's much easier to store.
And there's so many free computing tools out there right now, that you can actually do something with this entire data deluge that's sort of assaulting all different areas of science and business.
So the other thing is that you've probably heard the term big data.
And so we'll hear a little bit more about what we think about big data throughout the course of this particular course, the Data Scientist's Toolbox.
But big data is, sort of a new frontier in the sense that, we have data in areas that we didn't used to have that data.
We didn't have access to information about GPS coordinates from cars from everybody in the entire world.
It wasn't possible to sequence everybody's genome.
And now that's all possible.
So we have access to this data and it allows us to answer questions we never could before.
So, it's an incredibly exciting time, and you're somebody who can get in there and use that data to answer those questions.
So why statistical data science?
You'll notice that we're, all of your instructors are biostatistics professors and so this will, this data science track will obviously have a little bit of a statistical bend.
I think that that's appropriate given that statistics is the science of learning from data.
So, data is very, very, it's very rare that you'll get a data set where all of the answers are really clear, and there's no uncertainty.
In any case where there is uncertainty, that's where statistics comes and plays a role.
So, this is a again, a little bit older New York Times article now, but it talks about how the key word for a lot of graduates to open the door for a lot of jobs, is to learn about statistics.
So why are you lucky?
He got into building a internet company at the time when there was this explosive growth in internet usage and it just opened the door for the opportunity to build something amazing and huge and wonderful.
And sort of, that's the right, that's what the time is right now for data.
It sort of there's an explosive growth of data in every possible area you can imagine.
You're also lucky because tools and competitions and websites have all been developed around the idea of helping to learn about data, but also getting involved in projects that have super high profile results.
So, one example is the Heritage Health Prize, which I'm showing you a picture of here.
The Heritage Health Prize was a $3 million contest for people who could analyze data and come up with a better predictor of who would be admitted to a hospital in another year.
So you can see that's a huge amount of money that's being invested in these ideas of algorithm development and data science of prediction.
So it gives you an exciting opportunity to get involved in projects that, sort of, weren't happening five or ten years ago.
This course track will focus almost exclusively on the use of the R programming language.
And so I thought it was appropriate to talk a little bit about why we like R so much.
So we like R obviously, because we all use it.
But it's also sort of increasingly the most commonly used language for data science.
There are other languages that are also very useful.
And we won't be talking about them a lot in this course but they're obviously good complements to the R programming language.
Like, Python, in this class we'll be focusing on R because it has a broad range of packages that allow you to go from the rawest of raw files, all the way to interactive reports and documents and web apps that you can share with your collaborators.
It has one of the best development environments of any programming language, in our studio.
It also has an amazing ecosystem of developers.
And what I mean by that is there are a lot of people that are developing our packages.
And they're also available to get in touch with on mailing lists or by email or on stack overflow.
And so it's really possible to learn about the cutting edge of packages that are being developed.
There also very easy to install and play nicely together, which is a, a feature that doesn't always happen in a lot of the languages that are used for data science.
So the next thing I thought I would mention is, who is a data scientist?
And I thought I'd mention that some people that I think are data scientists, that might not, either label themselves that way or have other people label them that way.
So the first is Daryl Morey, who'd the general manager of the Houston Rockets basketball team in the US.
So he uses data to analyze basketball players and transactions and making trades.
And so I would consider him to be a data scientist Because he's a person who uses data to answer questions about basketball.
So, she used to be the Chief, Data Scientist at Bentley, and now she's at Accel Partners.
And so, she uses data to answer all sorts of questions about mining the web, and understanding that way that humans interact with each other through social media.
So, again she might not label herself a data scientist, but I think the way that she uses data, is a evocative of the sort of ideas, that we would like to convey in this data sciences track.
If you're taking this course, you probably know who Daphne Koller is.
She's the CEO of Coursera.
But she's also another person who's using all the data they're collecting through Coursera to better, to improve the way that we do educational delivery and educational assessment at this huge scale that Coursera is providing.
And finally, Nate Silver is one of the most famous data scientists, or statisticians in the world today.
So he used a large amount of totally free public data to make predictions about who would win elections in the United States, and was remarkably accurate.
So our goal is to teach you about a bunch different skills that will be useful for you as a data scientist.
So, this is a Venn Diagram and some statisticians and data scientists don't like Venn Diagrams but I'm going to get, show you one anyway.
And so, this Venn Diagram has Data Science at the, sort of, the center of this Venn diagram that intersects several different skills.
So, if you look right here there's data science and it involves three different components.
And so our data science track will focus a little bit on each of these, but it will primarily focus on math and statistics knowledge and hacking skills.
And so math and statistics knowledge sort of speaks for itself.
We're going to teach you a little bit about math and a little bit about statistics.
But hacking skills also has another component to it which is the ability to go out and answer questions for yourself.
One key component of a data scientist job right now is that most of the answers aren't already outlined in the textbook.
This is all new stuff that's happening.
So what are the major skills of being a data scientist is being to go to Google, and go to Stack Overflow, and go to one of the other sites and look up what you need to learn and figure out what answers you know and what answers you don't know, and then figuring out how you can use the information you have to answer the question that you'd like to answer.
That might be the reason you're taking this course track.
And so you can see this is a plot of listings are for data science jobs over time and of course it's exploding.
And we'll talk a little bit about why you shouldn't extrapolate, necessarily, from your data forever, but it does suggest that data science is a hot area that's growing and I think obviously we're very excited about it and hope you're excited about it too.
So this course, Data Scientist's Toolbox, will continue with lectures on the following three things.
First, we're going to introduce you to the course track.
Then we're going to tell you a little bit about getting the tools that you need to get set up and get installed, hopefully get you over that hump.
And then we're going to give you the basic background on data science sort of writ large, so that you'll be ready to jump into any of the individual classes and really take off.
Looking forward to seeing you in the rest of the class.
In week two of course, we're going to be covering a bunch of software that you're going to install that will constitute the data scientist's toolbox, as we described it for this course's track.
So the first question you might ask yourself is, what software do you need?
Well to know what, software you need, you have to know what exactly a data scientist is going to do.
So, in this course sequence we're going to talk about all the different components of being a data scientist.
Determining if that data is even accessible, a lot of times the ideal dataset isn't even available.
Then ways that you can go out and actually obtain the data whether it's from a database, or from a website, cleaning the data up so that it can be processed and analyzed.
Performing some sort of exploratory analysis, including making plots and clusterings so you can identify patterns that you didn't know about before hand in the data set.
Performing statistical prediction or modeling to try to, build a sort of an intuition about what's going to happen in the next sample you might take.
Then synthesizing them and writing them up in reproducible ways that can be shared with other people.
Finally, we're going to talk about distributing results through things like interacting graphics, also through right ups and presentations, and finally through interactive apps built on top of R.
So the main workhorse of data science in terms of this data science track is the R programming language.
And it's widely supported by a large group of developers.
Who can contribute new packages all the time that can improve and extend the functionality of R.
We'll be installing this in the second week of the class.
We'll do most of our coding in RStudio.
RStudio is an Integrated Development Environment, an IDE for R.
It's actually one of the best IDE's I think for many other languages as well in terms of data science.
The R IDE is free as well just like the language R, and so we will be downloading this IDE and setting it up again the second week of class.
The interface looks something like this.
And we'll talk a lot more about this in the second week and later on in the rest of the class.
So this is a new .R file that's going to contain some code that we're going to be writing in.
So we can write that code, here in the file at the prompt and then down here, you see a console.
See plots you recently made, the packages that you have loaded, or help files for specific functions that you might be interested in.
There are a lot of other really nice functions that come with Rstudio, and we'll be talking about those more throughout the class.
The primary type of file that we'll be interacting with, for the most part in this class, is an R script.
So, an R script is a file with the extension .R, and so it's just a, actually a text file.
Except the text file contains bits of R code, so here it's you can see a comment.
So this isn't actually executed but R you could include that so that people can understand what's happening in the code.
And then there're things like functions and so forth which we'll be talking about a lot more when we're coding.
If this seems intimidating to look at this function right now you should worry about it when you get through R programming.
You'll be a wizard and be able to do things much more complicated than this.
The other thing that we'll be using is R markdown documents.
In other words, they can be rerun and produce the exact same numbers that you got when you did your analysis.
So this is a file with an extension ,RMD and this .RMD file has a very structured format of text file.
And so we'll talk a lot more about what that format is later but you could take this structured file and you can knit it to html with this button here.
And you actually create an html file that will actually be formatted very nicely.
So for example, what you type in text looks like this, and it turns into a nice bulleted list in HTML, once you knit HTML.
And we'll talk a lot more about how that file works later in the class.
We're going to talk about how we are going to do distributed version control with Github and Git.
Or you can share and contribute to other projects, so that you can get your name out there in the data science community.
We're going to running most of the commands from the shell or from the command line interface.
So, there's a brief tour of all the tools that we're going to be using in this class.
This lecture is about getting help.
This lecture applies both to this cla-, this course that you're taking right now, the Data Scientist Toolbox.
So, keep in mind that in a standard class you may have taken in a class of 30 or 100 people, you would raise your hand and ask a question.
But in a class like this in a massive online open class there could be up to a 100,000 people taking the class.
And what you're going to do instead is post your questions to the message board.
And then hopefully, your fellow students will upload them if they're good questions.
And you instructor will try to respond to as many as possible, but probably more often than that your peers or community TAs will be responding.
And so, there are three of us that are teaching these nine classes and we are going to try to put in as much as we can to answer your questions.
And so relying on your fellow peers and your community TAs, we found is a great way to get involved.
We've also learned that the community that's built around the message boards and the massive online open courses is amazing.
And it's a, probably the best learning part of the entire experience.
And so hopefully, you'll get involved and you'll be an active participant in those message boards.
It's very clear that the fastest answer is often the one that you find for yourself.
So to try to answer your questions yourself, you should try to look it up on Google or look it up on Stack Overflow.
If you ask a question that's very simple to Google, you'll often a get response that says Google it or read the documentation.
Which is not the easiest way to get the answer that you're going for.
An important part of being an active participant in a community environment here is to, if you figure out an answer to a question is to post it to the message board.
It's almost a sure bet that there's a lot of other people that are struggling with the same thing.
And so, they'll really appreciate it if you take the time to post the message board the way that you figured out how to solve that problem.
So, I thought I'd mention just a few important R functions that will help you to find answers for some of the questions you might have.
So, when you have an R function, we'll talk a little bit more about R more later in the class.
So, one example is that you can type like this.
And if you use help.search, you might not even necessarily have to get the function name exactly right.
It'll still search through, through the help files and try to find things for you.
And then, if you want to get the arguments for a function, you can use the function, you can use, the, command args, like this.
Args of rnorm and that'll tell you the function arguments.
These functions are very useful if your goal is to try to figure out how r is working for a particular function.
But it might not be so useful, if you want to understand the sort of underlying concepts involved in those functions.
So another thing is you might want to do is actually look a little bit deeper into the code.
So if you wanted to do that you can actually just type the function name without any brackets and it will actually reproduce the entire code for you.
Then what I end up getting out on the R console is actually this right here.
You could also see this link here to a reference card with a lot of helpful R functions.
So, an important point that you'll run into a lot in this class is how to ask an R question.
And so there are a few different components of it that you should keep in mind.
First is, you will want to outline what are the steps that you have executed in order to create this problem.
So, if you ran three functions in order you should reproduce what those three functions are.
And then you should say what you expect the output to be.
And then what you saw instead.
So I expected it to give me the answer to this question and instead, it gave me an error.
And so a really important thing to keep in mind is that R packages and R and all of these other tools that we're going to be telling you about are going to be evolving over time.
And so it's really important that you tell the version of the product that you're using.
So, the version of the package, the version of R that you're using and then what operating system you're working on.
When you're asking a data analysis question, there's a similar set of things that you need to re, re, report.
So first is what is the question you are trying to answer.
And then, what steps or tools do you use to answer it?
This may be a combination of R tools and outside tools and maybe some intuition.
And then, you again, you report what you expected to see.
I expected to be able to tell the relationship between them and what do I see instead?
I see oh, I don't know, I see some crazy scatter plot and I don't know what that means.
And so important thing to think, keep in mind here too is what other solutions you might have thought about.
So sometimes you run through three or four different things to try to get the right answer.
And so, if you're report what you try or the different things you try, there when people try to answer your question, they can go directly to something you haven't tried.
So an important point of asking questions in highly massive class like this is to make sure that you're very specific in the titles of the questions that you're using on the message forum.
I can't fit a linear model.
Then you're not exactly giving a lot of detail as what exactly your problem is or how it can be addressed?
So, a better question to ask is, sort of saying, okay, I have this function and it's happening in that version of R 2.15.
And is only being produced when I have a large data set and here's the software that I'm using.
I'm using Mac OS X 10.6.3.
And even better question is to use a title that's a little bit more succinct.
So, here you lead off again, the function that you're asking about, you say okay, I'm asking about R 2.15 and again it's on this operating system.
And then I very succinctly describe seg fault on large data frame.
So by focusing on the very specific details, it means people can jump very quickly to the answers that you might need.
So there's similar sorts of questions, specific details you would want to give when asking questions about data analysis problems.
So, in general, the more specific you are the faster your answer will come.
So there's some etiquette that we would like to encourage in terms of using these forums.
Or in, in just using help sites in general not necessarily the ones in these forums.
What's the question you're trying to answer?
Try to provide the minimum amount of information.
If you, you provide way to much information it's very hard for people to filter through and figure out what their real problem is.
Being polite never hurt anybody and will often get your answer more quickly.
It's the polite thing to do, post that you found on the course website so that people can search it and find that answer as well.
But it's very easy to overwhelm the inboxes of your instructors or community TAs if you all start sending emails simultaneously.
When there's a typo in the assignment, please report it on the forums and we will address it as fast as we possibly can.
Some things that you shouldn't necessarily do are immediately assume you found a bug in a major program.
So, saying you found a bug in R and that's why things aren't working.
So begging other people to do your work for you.
Please don't post homework questions on mailing lists or on the course forums.
If you post the questions or the answers on the forums it, it sort of takes away from the experience of everybody else.
Please don't e-mail a lot of different lists all simultaneously.
Try to figure out what the right mailing list is and only e-mail that.
And then, you don't want to ask general data analysis questions on R forums.
So try to keep those who are R course forums, where hopefully there'll be a big group of interested people all trying to answer the same questions.
So the transfer of these slides go to Roger Payne who's another instructor in the course track.
That's a link to his video on YouTube and it was inspired by Eric Raymond's lecture, How to ask questions the smart way.
Alright.
Now that we've seen efficient implementations of algorithms that can solve the unifying problem for huge problem instances let's look to see how that might be applied.
There's a huge number of applications of Union-find.
We talked about dynamic connectivity in networks there's many other examples in our computational infrastructure.
Down at the bottom is one of those important one is in image processing for understanding how to label areas in images.
We'll see later Kruskal's minimum spanning tree algorithm, which is a graph processing algorithm which uses Union-find as a subroutine.
There's algorithms in physics for understanding physical phenomenon that we'll look at an example and many others on this list.
So, the one we're going to talk about now is called percolation.
That's a model for many physical systems I'll give an abstract model and then just talk briefly about how it applies to physical systems.
So let's think of an n by n grid of squares that we call sites.
That's white in the diagram with probably P or blocked, that's black of the diagram with probability one - P and we define a system to, we say that a system is percolated if the top and the bottom are connected by open sites.
So the system at the left, you can find a way to get from the top to the bottom through white squares, but the system to the right does not percolate, there's no way to get from the top to the bottom through white squares.
So, that's a model for many systems.
You can think of for electricity.
And so if there's a conductor from top to bottom then the thing conducts electricity.
Or, you could think of it as, as water flowing through a porous substance of some kind.
Where a vacant side is just empty and a block side has got some material, and either the water flows through from top to bottom, or not.
Or you could think of a social network where it's people connected and either there's a c onnection between two people or not and these are a way not to get from one group of people to another communicating through that social network.
That's just a few examples of the percolation model.
So if we, we are talking abouta randomized model where the sites are vacant with the given probability.
Probability that a site is vacant is low as on the left, two examples on the left in this diagram, it's not going to percolate.
If the probability is high and there is a lot of open sides, it definitely is going to percolate.
There would be lots of ways to get from the top to the bottom.
But in the middle, when it's medium, it's questionable whether it percolates or not.
So the scientific question, or the, mathematical question from this model is, how do we know, whether it's going to percolate or not?
In this problem and in many similar problems, there's what's called a phase transition.
And actually, the threshold between when it percolates and when it doesn't percolate is very sharp.
And actually there is a value as N gets large that if you're less than that value it almost certainly will not percolate, if you're greater it almost certainly will.
This is an example of a mathematical model where the problem is, is very well articulated.
What's that threshold value but, nobody knows the solution to that mathematical problem.
The only solution we have comes from a computational model, where we run simulations to try and determine the value of that probability.
So what we're going to run is called a so called Monte Carlo simulation.
Where we initialize the whole grid to be block ed all black and then we randomly fill in open sites.
And every time we add an open site, we check to see if it makes the system percolate.
And we keep going until we get to a point where the system percolates.
And we can show that the vacancy percentage at the time that it percolates is an estimate of this threshold value.
So what we want to do is run this experiment millions of times, which we can do in a computer, as long as we can, efficiently do the calculation of does it percolate or not.
That's a Monte Carlo simulation, a computational problem that gives us a solution to this, scientifc problem where, mathematical problems nobody knows how to solve yet.
So, let's, look in a little bit more detail of how we're going to use our dynam-, dynamic connectivity model to do this.
So, it's clear that, we'll create an object corresponding to each site.
And we'll give'em a name, from zero to N^2-1 as indicated here.
And then we'll connect them together.
So the percolation model on the left corresponds to the, connection model on the right, according to what we've been doing.
Now, you might say, well, what we want to do is, connect, check whether any site in the bottom row is connected to any site in the top row, and use union find for that.
Problem with that is, that would be a brute force algorithm.
Instead, what we do is create a virtual site on the top and on the bottom.
And then, when we want to know whether this system percolates, we just check whether the virtual top site is connected to the virtual bottom site.
So how do we model opening a new site?
Well to open a site we just connect it to all it's adjacent open sites.
So that's a few calls to Union but that's easy to implement.
And that's where we get the result that, by running enough simulations for a big-enough n, that this, percolation threshold is about .592746.
With this fast algorithm we can get an accurate answer to the scientific question.
If we use a slow Union-find algorithm we won't be able to run it for very big problems and we won't get a very accurate answer.
So in summary, we took an important problem.
The, the dynamic connectivity problem.
We modeled the problem to try to understand precisely what kinds of data structures and algorithms we'd need to solve it.
We saw a few easy algorithms for solving the problem, and quickly saw that they were inadequate for addressing huge problems.
And then left us with, applications that, could not be solved without these efficient algorithms.
For algorithm design where we try to develop mathematical models that help us understand the properties of the algorithms that we're developing.
And then we test those models through experimentation enabling us to improve algorithms iterating, developing better algorithms and more refined models until we get what we need to solve the practical problems that we have of interest.
That's going to be the overall architecture for studying algorithms that we're going to use throughout the course.
This is a brief follow-up video to getting help and it's about finding answers.
The reason why there are two videos about this is because it's such a critical skill in data science.
And the reason why it's one of the three fundamental skill is because almost of none of the knowledge that you will need is already sort of set in standardized text books.
It's often scattered in a bunch of different places and you have to be able to sort of synthesize it or find the information that you need about.
Whether it's about which data set you need to be using, or the statistical analysis you need to be doing, or the R Package that you need to be using.
All of this is sort of scattered around, and you have to be willing to do a little bit of hard work and elbow grease to find it yourself.
Obviously we'll tell you as much as we can in lectures, but we're necessarily limited by the amount of time that we can lecture every week, and so it's important to be able to find that information yourself.
So key, some key characteristics packers are that they're willing to go out and find the answers on their own even if it takes a little bit of time or a little bit of effort.
They're knowledgeable about where to find those answers whether its Google, or stack over glow, or cat.
They're unintimidated by new data types or packages.
And so a key characteristic I would say the way to summarize it up is being alive but relentless here.
Going after the answer and you just trying to find it But you're very polite while doing it.
And so Google knows this too.
In their hiring practices they're looking for these sort of characteristics.
So an important question is where to look for, for different types of questions.
So for our programming you might want to go straight to the the archive of the class forums.
Where the class you're taking will focus on very specific questions or functions.
And there'll be a large group of interested people.
You could read the manual or help files like I showed you in the getting help lecture.
That's actually one of the best ways to do it.
That's even better if you've got a person that you know that already is a bit of a data scientist.
They can often help you out.
And then you can post to the class forums and try to get your answers.
You can also post to forums outside of the class.
The R Mailing List or Stackoverflow, if you have R questions.
For data analysis or statistics type questions, you want to go to start again with the class forums, and then go to the web or to friends.
And then there's another outside forum called CrossValidated where you can ask these types of questions.
So forget HUB, they have a lot of tutorials and nice information that you can use to get answers there.
So an important point to know is that Googling data science questions isn't always the easiest thing in the world.
So, the best place to start with if you have a pretty general question is often in the forums.
And if people can direct you to where you should be searching outside of the forums.
Keep in mind that Stackoverflow with the tag R is a really good place to get information about R.
And, so, you have to use this tag because if you just use the letter R, it obviously is, sometimes, a little bit hard to search for.
You can also try the R mailing list for software questions or CrossValidated for more general questions.
Usually what I've found is that if I'm going to work in Google, searching Google, I use usually type something like the data type and then data analysis or I type the data type and then the R package.
Another thing to keep in mind is that data analysis or data science is often called something different depending on what kind of data you are looking at, so for example medical data it might be called biostatistics.
For data in computer vision it might be machine learning or natural language processing for data from text and so on.
And so, you can often find that out by posting to forums and people will let you know what the right word to be googling is.
And it was inspired by Eric Raymond's How to Ask Questions the Right Way.
This is the first in a series of overview lectures that tell'll you about the other courses in the Data Science course track.
I'm going to start off with R programming, which is another one of the most fundamental classes in our Data Science track.
R is the language that we're going to be using for most of the data analysis and data science that we're going to be doing on the computer science end.
How to write functions, to do things to that data, how to debug them and then a little bit about simulation and optimization.
So now I'm just going to show you a couple of examples of the sorts of things that you'll learn in that class.
So for example you'll learn about the readLines function for reading text from a file.
So in this case what we're going to be doing is we're going to be reading lines actually from the website of the Johns Hopkins Bloomberg School of Public Health.
So this is the website right there.
And so what we do is we go to that website and then we use the readLine func, readLines function to read the text from that site.
And then we look at that text and you can actually see the HTML code, and it's actually been sucked into R that you can then use to analyze the website.
Another thing that you'll be learning about is how to figure out when there's something wrong with your function.
So, you'll be writing lots of functions in this class.
And so, one thing that you want to know is when they aren't working, why aren't they working?
And so this is a slide that comes from one of those about how do you figure out, what were you expecting, and what did you get?
And how do you reproduce the problems so that you can figure out how that function works?
And so the lapply function takes a particular kind of argument.
And a list in this case, and applies a function to all the elements of that list and returns something back to you.
But you don't actually have to access to that.
You can actually just use the R function.
So this will cover everything from sort of the basics, to more complicated functions like lapply.
This is the Getting and Cleaning Data course overview.
This is actually one of the more unique classes in our data science track, but I think its sort of one of the most fundamental components of being a data scientist.
Which is being able to go out and get data from whatever source it's in and whatever form it's in, and turning it into a clean processed data set, that then you can use to answer questions.
Reading in data from a very large number of different sources, merging it together, reshaping it, summarizing it, and then finding some data resources that you can use to augment the data that you already have.
So here are a couple of different things that you might learn about.
So, for example, how to connect to a MySQL database, a MySQL database, from R.
So there might be one cloud that contains reviews and one cloud that ca, contains solutions, say from a peer assessment, and you want to combine them together.
And so, you can use commands in R to merge those data sets together.
And then, talking about, sort of, raw versus processed data.
So talking about, what are the data that come to you in their rawest possible form, the original source of the data versus the processed data.
The data that's ready for analysis, ready to be used by people that has happened after you've merged it, and sort, subsetted it, and transformed it into the nice tidy data set that people can use.
So that's getting data.
This is a review of exploratory data analysis, which is the next course in the course sequence.
Exploratory data analysis course will cover the principles of how do you create analytic graphics, graphics that allow you to analyze data.
It'll talk about exploratory graphs, how you explore the data and get in, create enough graphs to sort of figure out the structure of what's going on.
It will talk about the plotting systems in R.
So it'l talk about base plotting, lattice plotting and then ggplot2 which is a popular newer platform.
It'll talk about hierarchical clustering, K-means clustering and a little about dimension reduction.
These are all techniques that you can use to get in and explore data as a first pass.
So, for example, it will talk about how to use ggplot2 package to make plots like this, sort of, sort of pretty smooth scatter plots that allow you to like understand the relationship between different variables.
It will talk about the principles of analytic graphics, so what are the principles that you need to create graphics that'll be useful sort of to figure out what's actually going on with the data you'll be working with.
So the idea of how do we, if we have a bunch of observations of collecting data on that, how we cluster them into relative groups that are similar to each other as a method of exploring the data and figuring out the structure of what's going on.
So this is just a couple of the ideas that will be covered in exploratory data analysis.
Statistical Inference is going to be a course that covers many of the foundational ideas that are involved with extracting generalizable information from data.
And so, the course will cover things like basic probability, likelihoods common distributions, confidence intervals, hypothesis tests, bootstrapping and power.
These are the sort of fundamental ideas that you often hear coming up when people are reporting data analysis.
So, for example, we'll talk about sort of the way that you model mathematically coin flips or proportions.
We'll also talk a little bit about how you model more continuous distributions, things like, with the normal distribution which you've probably heard about.
As a way to measure sort of the variability about a large number of different things including IQ and height and things like that.
And then we'll talk about things like bootstrapping, where you actually use the data itself to sort of create measures of variability that you can use to sort of decide how generalizable are the answers that you get from performing any particular analysis.
One of the most widely used tools for performing any sort of statistical or data science analysis is a regression model.
So the next course will be covering those regression models.
Some would say it's just one other form of just pre, creating a supervised predictive function.
But it's a little bit more than that in that it's, one of the more interpretable and easily used, tools that you can use to sort of explain you analyses.
So, this course will cover linear regression and multiple regression, ideas like confounding which we'll see a little bit in this class even, some prediction using linear models.
Scatterplots smoothing its splines, and then resampling inference, and maybe weighted regression.
So, this will cover also some ideas including ideas that you hear about often when you read articles about statistical analyses in the popular press.
So, why is it that children of tall parents tend to be tall but not as tall as their parents were?
So these sorts of fundamental ideas will be explained in the regression class.
So we'll also talk a little bit about the basic regression model, there'll be a little bit more mathematics in this class than there are in some of the other classes and sort of deriving and understanding the basic ideas behind a regression model.
We've worked hard to make it so that, basic understanding of algebra is sufficient to follow this class.
We'll also learn about multivariable regression analyses so, sometimes you want to relate one variable to another variable but you want to account for, what happens when you include other variables, adjusting your analysis.
You often hear about adjusting the analysis, and that will be covered in this class as well.
This is an overview of practical machine learning.
There are a large number of machine learning classes out there, and they are often very good.
So, the focus of this class will be primarily on hand-drawn application of machine learning in R.
So, the idea being that we'll try to focus on the R packages and the ideas that will allow you to actually take data and perform machine learning on those data.
We'll also talk a little bit conceptually about each of these prediction methods work and maybe some of the cases where there might be trouble.
So the Practical Machine Learning Content.
Predicting what the variety of different ideas like regression and trees.
We'll talk about common ideas like boosting, bagging, model blending, and a little bit about forecasting.
We'll cover basic terms, like what are true positives and false positives?
What are true negatives and false negatives, sensitivity and specificity, those sorts of things.
We'll also cover how to deal with correlated predictors by preprocessing out data that had correlated predictors.
So, this is a very more technical machine learning idea, but can be applied quite simply using the functions of a R to really improve your prediction accuracy.
I just wanted to briefly describe how to install R for a Windows machine.
So the first thing you need to do is load, launch your web browser, so I'll do that here.
And you need to go to the Comprehensive R Archive Network, or CRAN, so I'll just type that in here.
And you'll see that there is a, at the top there's three options, there's Linux a Mac and Windows.
So you can go to the Mac version here, and you want to go click on the base link here.
And the download will start, and so, depending on how fast your internet connection is, this might take a few minutes.
And you'll probably have to click on Yes for this.
And so, you can choose your language here.
There are a number of choices in terms of the translations that you can choose from.
And then you can just click through the installer, it'll kind of walk you through the various steps.
And so we'll do that right now just to see what the options are.
You have to agree to the license, which is the gener, the GNU General Public License.
There are other kind of installation setups that you can choose from.
If you know you only, you have a 32 bit machine it maybe an older machine you may, you can click on that.
By default it will install both versions so you don't have to really worry about that.
So just click through Next on this one.
So what that means is basically do you want R to kind of run in one big window with kind of different sub windows within inside of a big window, or you want it to run in kind of like separate windows.
I prefer to use the SDI mode where the, so the console will be in one window and the kind of graphics window will be a separate window.
So I'm going to click on the SDI option.
And then you can choose how you want to look at your help files.
And the Plain Text Help is well it's just plain text.
So maybe I'll just click on Plain Text just to be different.
This, generally speaking, you should not mess with, so you just click on Next.
You can create a shortcut in the Startup menu, Start menu so it's usually a good idea.
And you can usually choose the defaults here in your terms of creating a desktop icon unless your desktop is very cluttered and want to you know, avoid that.
And then it'll start installing the files on your computer.
If we can just click on Finish here.
And so I'll just close this browser here.
In this video, I'm going to to briefly show how you can install R on the Mac.
You just have to, it only takes a few steps.
So the first thing you need to do is open your web browser, and go to cran, says the comprehensive R archive network.
So you can just type in cran here, there are a number of options for you to download here for different platforms, and so we're going to download the Mac platform here.
So we go to download R for the Mac.
And you see that the latest version here, is version 3.0.3.
You want to download this package file here, so just click on this, and you'll see that the download meter will start going.
And it might take a few minutes depending on the speed of your internet connection.
Uh,and it'll guide you through all the steps you need to install R 3.0.3.
So, I'll click continue here, and this is just the description of what's going to get installed.
The software license agreement is the new general public license version 2.
So you should agree to the license, after having read it of course.
Now that's finished, I can hit close, and then it'll be in my Applications folder.
So I can just go to my Applications folder, which is right here, and there alphab, alphabetic order.
In fact the order of growth classifications are so important they've led to enormous amount of research in recent years and just talk briefly about that now.
So there is, life is a little bit more complicated than pointed out in the last example and one problem is that the inputs can cause the performance of the algorithm to vary widely.
So often we have to think about different ways of analyzing the algorithm depending on the input.
So, the running time is going to be somewhere between the best case and the worst case.
Best case is the lower bound on cost it.
If we analyze that then we can guarantee that the running time in the algorithms not going to be bigger than that.
And then in a lot of situations we might consider our input to be random.
Well we need to, someway to model, what we mean by random for the problem that we're solving but there is a lot of situations where we can do that and then we have a way to predict performance even when the input might vary widely.
So for example for 3-sum, it's kind of always the same.
With the tilde notation, the only variability in that algorithm is the number of times the counter is incremented and that's in low order terms so it doesn't need to chew up in our analysis.
For binary search it's, you might find the thing right away in which case is constant time and we can show that the average and the worst case are both lg based two(N).
There's other, in another examples that be much more variability even.
So, we have this different types of analysis depending on the input.
And but the question is, what about the actual problem that the client is trying to solve?
So we have to understand that two in order to be able to understand performance of the algorithm.
And there's two approaches that are, or successful in this.
One is to design for the worst case.
Just to make sure that your algorithm are, always runs quickly and that's definitely ideal.
Another is to, if you can't do that is to randomize and then depend on some kind of probabilistic guarantee and we'll see examples of both of these as we go through the course.
Now, those kinds of considerations, you know the idea of order of growth leads to discussion of, what's called, what I call the theory of algorithms.
And here our goals are, we have a problem to solve like solve the 3-sum problem and we want to know how difficult it is.
We want to find the best algorithm for solving that problem.
The approach that the computer scientist use for this is to try to suppress as many details as possible in the analysis.
And so just analyze the running time to or within a constant factor.
That's what order of growth is getting at and also I want to, not worry about the input model at all.
I'll give a couple of easy examples of this.
So big theta notation is just the way to describe the order of growth.
And then, there is big O notation which is upper bounds on performance.
When we say O(N^2), we mean that it's less than some constant time N^2 as N grows.
And big omega is used for lower bounds means greater than some constant time N^2 as N grows.
So, the 1-sum problem is 00 in the array.
Well, an upper bound on the difficulty of the problem is some specific algorithm.
So, for example, the brute force algorithm that looked, that looks at every array entry is a specific algorithm and it means that and that takes O(N) time.
We have to look at every, it's less than a constant time N for some constant.
And but in this case it's also easy to develop a lower bound, that's a proof that no algorithm can do better.
Well, for 1-sum you have to examine all entries in the array.
If you miss one, then that one might be zero so that means that the optimal algorithm has to have a running time at least some constant times N where we say the running time is omega of n.
Now in this case, the upper bound and the lower bound match.
So, doing the constant factor so, that's a proof that the brute force algorithm for 1-sum is optimal.
It's both omega and O(N).
For a more complicated problems it's going to be more difficult to get upper balance and lower balance and particularly upper balance and lower balance that match.
For example let's look at 3-sum.
So, upper bound for 3-sum, say our first brute force algorithm, say that the proof, was a proof that the running time of the optimal algorithm is O(N^3) but we found a better improved algorithm.
So, that's a better upper bound.
Lower bound well, we have to examine all entries cuz again, we might miss one that makes 3-sum = zero and that's a proof that the running time in the optimal algorithm is omega(N) but nobody knows higher or lower bound for 3-sum.
So there's a gap between the upper bound and the lower bound and open problems.
Is there an optimal algorithm for 3-sum?
We don't know what it is.
We don't even know if there's a algorithm whose running time is < O(N^2) or we don't know higher lower bound and linear.
So that's an example of an open problem in the theory of algorithms we don't know how difficult it is to solve the 3-sum problem.
Now, this point of view has been extremely successful in recent decades.
We have a new problem, develop some algorithm, proves some lower bound.
If there's a gap, we look for new algorithm that will lower the upper bound or we try to find a way to raise the lower bound.
Usually it's very difficult to prove non-trivial or lower bounds.
Trivial or lower bound like look at every input items is not so hard non-trivial lower bounds like for example, the proof that we're talking about for Union-find problem are much more difficult.
And in the last several decades people have learned about the computational difficulty of problems by examining steadily decreasing upper bounds so the algorithms were better worst case running times for lots and lots of important problems and plenty of optimal algorithms and plenty of gaps still remain.
It's a fascinating field of research that many people are engaged in.
Now there is a couple of caveats on this on the context to this course.
And the first one is maybe it's overly pessimistic to be focusing on the worst case.
Maybe it's not worst case data and lots of fields of engineering and science.
We don't focus on the worst case.
And since similar it's true for algorithms.
Maybe we should be focusing on understanding prope rties of the input and finding algorithms that are efficient for that input.
And the other thing is in order to really predict performance and compare algorithms we need to do a closer analysis than to within a constant factor.
And really there's so much published research in the theory of algorithms that a lot of people make the mistake of interpreting the big O results that are supposed to give improved upper bounds on the difficulty of the problem as approximate models for the running time and that's really a mistake.
So in this course, we're going to focus on approximate models by, you know making sure that we use the tilde notation and we'll try to give specific results for certain quantities of interest and the constant, any unspecified constant in the running time.
We'll have to do with properties in the machine and in the system so they will be able to use these results to predict performance and to compare algorithms.
In this video, I'm going to talk about how to install RStudio for the Mac.
It's a very simple process and only involves just a few steps.
The one thing I'll say though is that you must have R already installed before you can install RStudio.
You can go to the RStudio website, which is Rstudio.com.
And you can see down here on the lower left, there's a green button that that directs you to kind of download RStudio.
So, here there's two versions of RStudio, studio that you can download.
One is for the desktop and one is for the server down here.
Now you, we're not going to be talking about the server version at all here so, you just want to download the desktop version, so that's this button right here.
So, I'm just going to download that right now.
And, you'll see the download meter go.
Once that's finished downloading you go to the Downloads folder, and it should be the most left thing here so we're just going to click on it to install it.
And then just like any other Mac application, all you have to do to install is drag it into the Applications folder.
So, I'm going to do that right now.
So, I can just go into the Applications folder here and find RStudio.
I'll say yes, I want to open this application.
Prior to that, I was the interim lead producer at Miniclip on the mobile division, not the whole company.
But I'm now looking, as my children are getting older, to perhaps getting back into the workforce.
>> I'm a policy and public affairs professional, and over 10 years I've worked in policy lobbying in Westminster in London.
But in fact it does require a bit of preparation, listening to the lecture.
So in other words, it needs some time to be put aside.
There is never enough time.
The fact that the lectures are in video form is a very handy thing for someone like me who hasn't taken notes in a really long time, because I can repeatedly pause it and rewind it and go back over it again if I need to.
And then I create my notes in a tidy way that I keep on a different notebook.
>> Well, there's another side of Coursera that I really appreciate, and that is the peer review.
At first I was slightly skeptical, and also a bit daunted because it's an additional coursework and actually it proved really helpful for my own coursework because it helped me understand what are the sort of average standards?
And after awhile, you just start to realize that there is something as a common ground.
They helped a lot of people who had some difficulties because they didn't really have the coding background.
Rseek in the case of R helped a lot, but if it was for some other programming language, I would probably go to Stack Overflow.
The things that I'm doing right now, in my job, with what I learned is really nice and was a great experience.
>> I also learned so much that I felt clever again all of a sudden.
It was nice, it activated parts of my brain that I hadn't used in a long time.
>> Just in my household there is three of us, and all three of us have done at least one Coursera course.
So it's really changed what we do in our spare time.
This is a very brief introduction to the Git Version Control System.
So Version Control is a system that records all the changes that you've made to a file or a set o files over time so that you can, recall specific versions later.
And maybe other people will be working at the same time on a similar set of functions that you want to be able to keep track of everything that's being done to those files.
And so, Version Control means we're just going to try and save or manage all of those intermediate files.
And it's really important when you're sort of collaborating with others because, they might be using as, a different intermediate file and you might want to know how to coordinate what happened when you get to the final version.
So Git is a free and open source version of of a version control system.
It's distributed so it can handle everything from small to very large projects with speed and efficiency.
It's created by the same people who developed Linux.
It's definitely the most popular version control today compared to all the other version control systems like SVN.
Everything is stored in local repositories, or on your computer, and they're called repos and then you do most of the operations from the command line.
And so this is the link I've given you here is a, sort of a short history of how Git was developed, and how to get started.
So, the first thing that you need to do is go and get, download Git.
So, if you go to that website and download the appropriate version of the software for your operating system, that would be the right place to start.
The next thing that you do is, once it's done downloading, you open it up and you begin the installation process, so there'll be an install wizard that will take you through the steps of installing Git.
Once the installation is finished, you might want to hit the Finish button, although you may want to check uncheck the box next to review the release notes because you probably won't be interested in that at this point.
So the first thing that you want to do is open up a program called Git Bash which is the command line enr, environment for interacting with Git.
It should be loca, located in to the directory in which Git was installed or for Windows users, it will be in the Start menu now.
So, once you have Git Bash open you'll see a short welcome message followed by the name of your computer and a dollar sign on the next line.
And so the dollar sign means that it's again, the prompt like you've seen in the sort of command line interface lecture and so, it's your turn to type a command.
And so, each commit to a Git repository will be tagged with the username of the person the commit.
So what you need to do to sort of get things set up is, you need to enter your username and your e-mail.
So you type these commands where you type Git config dash global username.
And here, you're going to type in the email that you're going to be using with GitHub.
You only have to do this once when the system opens up, but you can always change it down the road if you want to use the same commands, if you want to change say your user name or the email that's associated with the Git account.
Now type the following to confirm your changes.
And, so, you should be able to see your username and your email and all of that.
So right now we're actually going to actually just exit Git Bash.
And so so you can do that with this command, just type exit and hit return.
It's dealing with Git, it's widely, widely used among scientists and does lots of neat stuff.
And so, once that's up and running we'll show you how to do some of the most important things that you need to do with the Version Control System.
This is a really brief introduction to GitHub.
Git is a version control software that allows you to control and manage the revisions of projects that you're working on locally on your computer.
And as such, it's a very useful piece of software on its own.
It allows for you to collaborate on projects together at a bigger scale.
So GitHub is a web -based hosting service for software development that uses Git revis, revision control as sort of a driving force.
And so what it allows you to do is contribute to projects online And to have your projects posted online so that other people can see them and contribute to them as well.
It also provides users with a home page that displays all of their repositories.
And the repositories that you have on GitHub are backed up on the server in case something happens to your local ca, copies.
But the real key aspect of GitHub is the social aspect and so the social aspect allows users to follow one another and to share projects and to contribute to each other's projects and so that's really the power of GitHub.
One of the things that we noticed bout GitHub is that often when you see somebody else's work You can sort of learn what they're working on, how their code works, and it's a great way to sort of identify people who would be good to work with.
And we've also found that when we put projects on the web, other people will often contribute, you know, for free, just because they're interested in how they can make the software better.
So the first thing that you need to do is go set up a GitHub account now that you have Git installed.
And so, you'll need to enter a username, email, a password, and click sign up for GitHub.
An important note here is that you should use the same email address that you used when you signed up for Git in the previous lecture so that it, you'll be able to have the two pieces of software work together.
It's free, so it's not, it shouldn't be a problem.
After signing up, you will find yourself on this page, which has several helpful resources for learning about Git and GitHub.
I suggest that you read those tutorials, as they're more in depth than what we'll be able to cover in this class, and they're incredibly useful.
If you click up here on your username in the upper right hand corner up there, you can see your GitHub profile.
So, see all the projects that you currently have, which when you start your account, wont be many.
It'll also show other people who you are and what you're working on.
So, you can fill out information about what kind of projects you're interested in.
our plan is for this course is to use this GitHub Profile as the place that you can sort of build a profile.
Which is a portfolio of the work that you've developed that shows off your skills as a data scientist.
If you click edit your profile, the right hand portion of the screen you can add basic information about yourself.
But if you're doing good work, so for example, if in the course of this class you create interesting data science products and ideas, you want to be able to take credit for that.
In the next lecture, we'll talk you through how you actually create a repository, a repo, and put it up on GitHub.
In the meantime, definitely explore the documentation on the GitHub site because it gives you lots of different information.
When you download R from the comprehensive R Archive Network CRAN, you get the base R system.
And this includes a bunch of functions that you can use to summarize data and make plots and things like that.
But the real reason R is so useful is that there are a lot of add-on packages that extend this basic functionality in a bunch of different directions.
Everything from cleaning data, to plotting data, to analyzing data and making interactive applications.
So, R Packages are developed and published by the larger R community, hopefully including you at the end of this course.
So, to obtain R Packages the primary place that you're going to go is CRAN.
But for some biological applications, and some big data applications, you might also go to the Bioconductor Project that I have linked to both the websites here.
You can also obtain information about the available packages on CRAN with the available packages function.
And so what you would do is you can enter R, start up, and you'll get a prompt and you can type this command: a.
And then give it the available packages argument just like this.
So instead you can use the head command to look at say a certain number, say just three of those, packages so these are the first three in alphabetical order.
As of the making of this lecture there are approximately 5200 packages on CRAN covering a wide range of topics.
One thing that you can do is if you know the area that you're working in, but you don't know the R package you're after, you can go to the Task Views link which groups together many R packages that are related to a specific topic.
So to install an R Package you primarily use the function install.packages.
So what you would, you could do is just use that with the package name as the argument.
So for example if I want to install the Slidify package what I would do is I would just type install.packages and then in quotes, slidify.
And what that would do is that would go to CRAN and it would install that package on your computer.
Any package on which that package depends will also be downloaded and installed.
This is actually one of the nicest parts about R, is that it's relatively straightforward to install new packages.
And then what that would do is install the slidify, ggplot2, and devtools packages.
You can also install packages relatively straightforward procedure in RStudio, so hopefully you've installed R in RStudio.
You can go up to the Tools Menu and then just go down to Install Packages, and that will open up a folder that will allow you to pick the repository and then pick the package that you want to be able to install from, and it will install that package for you.
Installing packages from Bioconductor is a little bit different.
You don't use install.package, but it's still quite since, straightforward.
So what you do is you go and you type this command, source and then this website right here, and that will load the biocLite function.
And so then first you just type biocLite by itself and what that will do is it will install the basic version of Bioconductor.
That's actually quite a few packages so be prepared for a lot of packages to be installed the first time you run it.
You can also load the packages after you've installed them.
So if you install it, it doesn't mean that all of the functions are immediately available to you.
You need to use the library command to tell R which packages to load in.
So, for example, if you've installed the ggplot2 library, and you want to be able to use the functions in ggplot2, you need to type in the command library(ggplot2) in order to get access to that functions in that package.
some packages produce messages when they are loading and some don't.
And then if you type search, open parentheses, close parentheses, you will see all of the functions that are part of the ggplot2 package.
So the summary is that R package is a powerful mechanism for extending the functionality of our R Packages could be obtained by CRAN or other repositories.
You install the packages, function could be used to install packages from the R console and then library is what you do to load the packages in to actually get access to the functions.
This lecture's about the Types of Data Science Questions.
So last week we covered a lot of installation and building up software and this week we're going to cover a little bit more about the conceptual ideas behind data science.
So there are, a few different kinds of data science questions that I've listed up here in their approximate order of difficulty of actually achieving the goal of that analysis.
So it starts with descriptive, and then it goes to exploratory, inferential, predictive, causal, and mechanistic.
And I'm going to talk about each of these types of analysis over the next couple of slides.
So the first is the descriptive analysis.
So the goal here is just to describe a set of data.
You're not trying to make any sort of decisions based on it or anything like that.
It's the first kind of data analysis that was ever performed.
And it's most commonly applied when you're talking about census data.
Descriptions can usually not be generalized without additional statistical modeling.
So in other words, you are describing what you are seeing in this data but you are not saying what that might be for the next person that might come along.
So an example of a descriptive analysis is this US census.
So this is a picture of the census twenty ten, a website that has collected a bunch of information about people in the United States and they are not necessarily analyzing it to predict something about, .
Another descriptive ex, analysis is the Google Ngram Viewer.
So what this is is it's a collection of information about pairs or triplets of words.
And so for example this is a plot over time of the observation of those, of the words Albert Einstein, Sherlock Holmes, and Frankenstein in books that have been scraped by Google.
And so, again, this isn't trying to infer anything when making decisions.
You could do that, but this is just purely a description of what's going on.
The next is exploratory analysis.
So here you're trying to look at some data and find relationships that you didn't know about previously, but not necessarily confirm them.
So they're good for discovering new connections, and they're also useful to find, for defining future data science projects, where you're actually trying to confirm the exploration that you've performed.
They're usually not the final say on any particular problem, and they usually shouldn't be used for generalizing or predicting.
The important point is that you've probably heard before that correlation does not imply causation.
You've discovered a relationship that is the critical relationship between two variables based on exploratory analysis alone.
So here's an example of an exploratory analysis, where we're looking at brain images and trying to identify regions of the brain that lit up in response to a particular stimulus.
So they explored this data, and they observed, you know, here's a region that lights up in response to that stimulus.
And they haven't necessarily confirmed that that, what that means, but they've just discovered a new connection that they hadn't seen before they had this data.
Another example that's actually hosted here at Johns Hopkin's is the Sloan Digital Sky Survey.
So this is just terabytes or even more of data that has been collected looking at the night sky.
So it's actually pictures of the night sky at different times and at different places that you can explore to try to discover new stars or try to discover how different things in the universe work together.
And so, that data is actually used for exploration, but not necessarily for confirming anything that you discover.
Then inferential analysis is a goal where you're actually trying to take a small amount of data, on a small number of observations, and sort of extrapolate that information, or generalize that information to a larger population.
Inference is definitely the most common goal of most statistical models, and most statistics you may have heard about.
It involves both estimating some quantity that you're interested in and also, more importantly maybe, the uncertainty of that quantity that you're interested in.
And it depends heavily both on the population that you're looking at, the group of people or the group of objects that you care about, and a sampling you've discovered.
So this is an example of, inferential analysis.
So the idea is, here, you're trying to look at the, effect of air pollution control on life expectancy in the United States.
And they're using that to try to infer something about what's generally happening in the relationship between air pollution and life expectancy.
The inferential analysis is that usually a little bit more challenging.
So the idea is to use the data on some objects you collect the data on, to predict the values for another object for the next observation that comes to the door.
An important thing to keep in mind is that even if x predicts y, it does not mean that x causes y.
That's one of the main fallacies that you can run into when dealing with predictive analysis.
Accurate prediction depends heavily on measuring the right variables.
And although there are better and worse prediction models, it's pretty clear that more data and simple model tends to work really well.
So here's an example of a predictive analysis.
So Nate Silver is one of the data scientists I mentioned earlier and FiveThrityEight is his blog where he tries to predict the outcome of U.S.
So what he does is he takes data from polling and he tries to predict what's going to happen in the next Presidential vote.
Here's another example, so it's another sort of bad example, if you were the teen in question.
So, target figured out a teen girl was pregnant, before her father did, by looking at the purchases she made, and it sent her a flyer saying she was pregnant.
Of course, the father and girl was a little upset, because he didn't know that she was pregnant.
But it was example of how you could use data to predict characteristics of people including metadata.
It's substantially harder to identify causal relationships from data.
So the idea is, what happens if you change the values of one variable?
The gold standard for doing this in general is using randomized studies or randomized controlled trials to identify causation.
And you can try to do it from just observed data that you have saved in the database but it's a much harder sell.
You have to make much stronger assumptions about the way that your model is work, working.
Causal relationships are usually identified as average effects, in other words, on average, if we give this population a particular drug, then on average they will only have a little bit longer then if you didn't give them that drug.
So these are usually the gold standard for data analysis in a particular for most scientific applications the goal is to end up with a causal relationship between variables.
So here's an example of a causal analysis.
It's quite a disgusting procedure of giving people transplanting fecal matter into different people so that the bacteria populate their colon and they recover better for recurrent infection of a particular type here.
And so they were able to randomize people to get the fecal treatments and then they determined that his treatment was constantly associated with better outcomes.
Mechanistic analysis is very rarely covered in data science, and so it's important to keep in mind just to keep a full handle on all types of analyses that could be done, but it's very rarely the goal of most analyses.
The idea is to understand the exact changes and variables that lead to exact changes in other variables.
So this is incredibly hard to infer if the NOIDs, data is noisy at all except in very simple situations or in situations that are very nicely modeled by a deterministic set of equations.
The most common applications where this is possible is in the physical or engineering sciences where some more simplified models can describe a lot of the action that is happening.
And generally the only random component when you're doing a mechanistic analysis is measurement error as opposed to any of the other types of variation you might see in data.
So here's an example of a mechanistic analysis where the idea was to try to actually discover, what was the differences and changes that you would make in par, pavement design, that would directly lead to changes in, the functioning of that pavement.
And so those with mechanistic analysis like I said, tend to end up in, engineering applications or in physics applications.
That is a quick tour of the types of questions we will cover in data science.
Since you're in a data science track, it might be a good idea to figure out what is data.
So, for a definition of data we're going to go to the number one source of all information, Wikipedia.
And, we're going to get the definition, data are values of qualitative or quantitative variables, belonging to a set of items.
So, the first thing that you can see from this definition is that you need a set of items to be measuring things on and so, the set of items is sometimes called the population, in statistical inference.
It's basically, what you're trying to discover something about, so, it might be the set of all websites or it might be the set of all people coming to websites, or it might be, a set of all people getting a particular drug.
But in general, it's a set of things that you're going to make measurements on.
So, they might be measurements as in, you measure the height of a person, or you measure the amount of time a person stays on a website, or they might be more qualitative characteristics.
So it might be the places that the person looks on the website or Whether that you think the person visiting is a man or a woman.
And so you, have both qualitative and quantitative variables.
So qualitative variables are things like country of origin, sex, or treatment.
They're not necessarily ordered, and they're not necessarily measurements in that way.
Quantitative measurements on the other hand are usually Measured on a continuous scale, they're things like height, weight and blood pressure.
And, they usually have an ordering on that scale.
So, what do data look like?
So, you might think in your mind, when I say data, it's something like a big excel table, or something like that, but, actually, most data actually starts off in a very raw form.
So, this is an example of a fast queue file, which is a type of file that's produced by a next generation sequencing machine.
So, a typical experiment will produce hundreds of millions of lines of text file that look like this.
And so, you can actually see here in this file, you can actually see a sequence here, of a particular read that comes from a person's genome.
And so, what you want to be able to do is parse that file, and collect those data, and maybe infer something about their genome.
Another way the data might look is an API.
So this is actually a picture of the Twitt, Twitter API website.
And so, what you might do is you might try to get a particular URL.
So you might try to access that URL and get information from it.
Here's an example of a medical record.
So, this is again another form of data.
People are very interested in studying medical records, and trying to understand how people can either improve the way that we insure people or improve the way that we give people medical care.
And so, these data again are text files that, are not necessarily formatted in a very nice way.
Or subtract or extract with different things were ordered and so forth, and then use that data to maybe answer some questions.
Data might also be a video, so in this particular case machine learning experts developed an algorithm that could learn whether a video was a cat, or a video was something else.
It seems like kind of a trivial application.
It's actually quite a hard problem And they solved.
But in this particular case, the data were actually the videos themselves.
Data might also be an audio file.
So this is an example, DarwinTunes, where people actually study the evolution of music over time, where people decided whether, innovations introduced into the audio file were interesting or not.
So, overtime they evolved music that was more melodious and more interesting for people to listen to.
So, the data itself was actually the audio files in this study.
Data might also look like access to files, whether through an API or through spreadsheets through open government websites.
Rarely do data look exactly like what you'd expected to see at, at the beginning of a data science project.
So, here's a very clear easy data set where you've got variables and columns, and observations in rows.
And it seems like it's very easy to analyze.
It's very rare that the data come that easily processed before the beginning of a study.
So, the data are actually the second most important thing in data science.
The most important thing, in in data science is actually the question you're trying to answer.
It's the second most important thing to the question.
Often the data will limit, or enable the questions you're trying to ask, so in other words, you start with the question, and you might not have the data to be able to answer that question, so you have to modify the question, to be able to answer, sort of a sub-question or a related question.
But having data in general, can't save you if you don't have a question that you're asking.
And this is of the key take home message, maybe the theme of this data scientist toolbox, is focusing on having a question that you want to answer with your data and not being driven by the fact that you have data.
Today we're going to talk about algorithms and data structures for implementing some fundamental data types called bags, queues, and stacks.
You may be somewhat familiar with these, but today we're going to take a careful and close look at them.
We want to add something to the collection, maybe remove something from the collection and iterate through the objects in a collection, performing some operation on them, and of course test if it's empty.
Now for most of these, the intent is very clear.
The two fundamental classic data structures for this, the stack and the queue, differ in the way in which the item to be removed is chosen.
For the stack, we take out the item that was most recently added.
The terminology that we use is pushed to in certain items and pop to remove the item most recently added.
That's also called the LIFO discipline, last in, first out.
And that's also call the FIFO discipline, first in, first out.
So we're going to take a look today at how to implement these things.
And that's going to be a discipline that we're going to follow carefully throughout this course.
The idea is to completely separate the interface and the implementation.
The client can have many different implementations from which to choose, but the client code should only perform the basic operations.
The implementation, on the other hand, can't know the details of the client needs.
All it's supposed to do is implement those operations.
In that way, many clients can reuse the same implementation.
So this allows us to create modular, reusable libraries of algorithms and data structures that we can use to build more complicated algorithms and data structures.
Again, this is a modular programming style that's enabled by object oriented programming languages, such as Java.
And we'll be very disciplined in our use of this style.
So to begin, we will talk about stacks.
Many of you probably implemented stacks in an introductory programming course, but we'll do a thorough introduction to implementations right now.
As a warm up, let's suppose that we have a string, a collection of stings.
And what we want to have is the ability to save away a collection of strings and remove and return the most recently added string periodically, and also test if it's empty.
For insert, we have a method called push that take a string as argument and for remove, we have a method, pop, that returns the string most recently added.
Also in some applications, we would include the size as well.
So again, as always, we'll first write a client and then look at implementations.
And our simple client is to take some strings on standard input and some pop commands which are indicated with hyphens.
If the string is equal to the hyphen character, it'll pop the string at the top of the stack and print it.
Otherwise, if it's a string that's not equal to the hyphen character, it'll just push it onto the stack.
So in the example down below here, if we have this file called tobe.text, then what the client will do is push to be or not to all on the stack.
Then it'll put be on the top of the stack and then pop the top item on the stack which is now be, and then pop the item most recently added.
So this is a simple test client that we can use to test our implementations.
So now let's look at the code for implementing a stack.
The first implementation that we'll look at uses linked lists.
If you're not familiar with linked lists, you'll need to review that in section 1.1 through 1.3 of the book, or in our introduction to programming and Java book.
So the idea is to keep a linked list which consists of nodes that have strings in them, and references, to the next item in the linked list.
And to implement a stack when we do a push operation, we insert a new node at the beginning of the linked list.
That's the most recently added item.
So let's look at what that code looks like.
We use to implement linked list in all linked data structures throughout the course, we use what's called an inner class in Java.
And that's just a way to describe that we're going to be manipulating node objects that each consists of a string and a reference to another node.
So the pop operation for linked lists is very easy to implement.
First, we are going to need to return the first item on the list, so we save that away.
Take first.item and save that in the variable item.
Then, to get rid of the first node, we just advance our pointer to the first item on the list to point to the next item.
And then that first node is ready to be reclaimed by the garbage collector.
And then the last thing we need to do is just return the item that we saved away.
So that is the pop operation, what about the push operation?
Push operation, we want to add a new node at the beginning of the linked list.
Then we create a new node that's going to be the new node that we put at the beginning of the list.
That's first = new Node.
And then we set its instance variables.
Its item is the string that we want to put at the beginning of a list, in this case, not.
So after this operation, we're first pointing to the beginning of the list.
And we have the items on the list in a decreasing order of when they were put onto the stack.
So this is a complete linked-list implementation of all the code to implement a linked-list for a stack of strings in Java.
It's a class, the constructor doesn't have to do anything, there's no constructor.
We have this inner class that we use to build the items in the linked-list and we make it an inner class so we can directly refer to those instance variables.
And then the only instance variable of a stack is a reference to the first node on the list and it starts out being null.
And then isEmpty is just testing whether the first note on the list is null.
And then push is the four lines of code that I gave on the previous line and pop is the three lines of code that I gave on the slide before that.
That is a complete implementation for linked-list that would work with as a fine push down stack implementation for any client.
So now we can analyze the performance of that so that we can provide clients with information on how well the algorithm data structure will perform.
In this case, it's easy to see that every operation takes constant time in the worst case.
So that's obviously a very desirable characteristic.
That depends very much on the implementation and the machine so this is a typical Java implementation that we do the analysis for.
There's some extra overhead, 8 bytes, because it's an inner class.
And then there's 2 references that we built in our class node, 1 to a string and another 1 to a node and those are each 8 bytes.
If we have a stack of size N, we have about 40 N bytes.
There's a little extra for it first, but that's about N overhead for the whole stack.
This does not include the space for the strings themselves, which are owned by the client.
But with that, we can properly assess the resource usage of this implementation for different client programs.
Now, it's constant time but there's faster implementations of stack.
And since stack is used in the inner loop of some algorithms, it's important to think about even faster implementations.
And another natural way to implement a stack is to use an array to store the items on a stack, so let's take a look at that.
This alternative of choosing between linked structures and arrays is fundamental, and it's going to come up again and again when we consider more complicated data structures and algorithms.
So, we want to be sure to analyze it in the simple case for stacks to set the stage for more complicated applications later on.
So to push, we just add a new item at s of N into pop, we remove the item that's at s of N- 1 in decrement N.
Now there's a fundamental defect in using an array and that is that you have to declare the size of the array ahead of time and then so the stack has a certain capacity.
And if there's more items on the stack than the capacity, we'll have to deal with that problem.
And that's a fundamental problem that we have to deal with in array implementations in all sorts of algorithms data structures.
So, again, considering it for this simple case will pay off later on.
So here's the full implementation of stack for using an array to represent the stack.
Now we have an instance variable which is an array of strings, and our variable N which is both the size of the stack and the index of the next open position on the stack.
Now, we're cheating in this implementation to keep it simple, and we'll take care of this cheat in a little while, by requiring the client to provide the capacity of the stack.
The client really can't know how big the stack is.
The client might have a lot of stacks that need to be maintained simultaneously and maybe they reached their maximum capacities at different times and various other things.
So we need to remove this cheat and we will, but the code is nearly trivial if we have the capacity.
To push an item, we use N to index into the array, put the item there and then increment N.
That's the shortcut in many programming languages nowadays for use the index and then increment it.
And to pop, we decrement the index and then use it to return the item in the array.
So each of the operations is a one-liner.
That's array implementations of stack, but it breaks the API by requiring the client to provide the capacity.
So what are we going to do about that?
There are a couple of things that we didn't consider.
We didn't put in code to throw an exception if the client pops from an empty stack.
Probably should do that.
We're going to talk about an approach called resizing that will allow us to avoid overflow for clients.
In this case, we do allow the client to insert null items.
But we do have to worry in Java about a problem called Loitering and that is the idea that we have references to an object in our array implementation in the stack array when we're not really using it.
So when we decrement that value N, there's still a pointer to the thing that we took off the stack in that array.
Even though we know we're not using it, the Java system doesn't know that.
So to avoid that and really allow most efficient use of memory, it's best to set that removed item entry to null.
That's a detail, but an important one that we have to take care of in our implementations to make sure that we're getting most efficient use of memory.
This course provides the foundation for the data warehousing and business intelligence specialization.
I believe that you'll find this course both challenging and rewarding.
Throughout the course you will develop skills for database creation, query formulation, and database development.
By the end of this course, you'll be ready for the other courses of this specialization and to start your journey towards a challenging and rewarding career as a data warehouse or business intelligence professional.
I look forward to having you in my class.
Okay, our basic array implementation of stacks had the defect where we required clients to provide the maximum capacity of the stack ahead of time.
Now we're going to look at a technique for resolving that problem.
The API says we should just be able to create a stack and it should be able to grow and shrink to any size.
So how are we going to grow and shrink the array?
Well, first thing you might think of is, when the client pushes a new item onto the stack, increase the size of the array by 1, and when it pops, decrease the size of the array by 1.
That's easy to code up, but not worth it, because it's much too expensive to do that.
The reason is that you have to create a new array, size one bigger, and copy all the items to that new array.
So, inserting the first N items would take time proportional, if the stack's of size N-1, it's going to take time N, N-2, time N-1.
So first N items would take the sum of the first N integers, which we know is about N squared over 2.
Quadratic time to insert N items into a stack, that kind of performance is unacceptable for large problems, as we've seen, as we will see many times.
So the challenge is to do the resizing, but somehow ensure that it happens infrequently.
So the well-known technique for doing that, called repeated doubling, is to, when the array fills up, create a new array of twice the size and copy all the items over.
Then we don't create new arrays all that often.
So here's an implementation of that.
If we have a full stack, which we know by testing N, which is the number of items in the stack versus the array length, then we just resize the array into one of twice the length before inserting the item.
And how do we resize to a new capacity?
We create a new array of that capacity and just go ahead and copy our current stack into the first half of that and then return it.
And that will reset our instance variable, which is our stack, to this new, bigger array.
So, the idea and the consequence of this is, if you insert N items into an array, into a stack with this array representation, the time will be proportional to N, not N squared.
So if you just calculate the cost of inserting the first N items, you're going to have instead of the sum of the integers from to 1 to N, you're going to have the sum of the powers of 2 from 1 to N.
So that's, in array accesses for the copy, there's two array accesses.
So to insert N items, it's about three array accesses.
This plot is another way of looking at it, which is the number of array accesses taken as you implement push operations.
Every time you hit a power of 2, you take that many array accesses, but in a sense, you've already paid for them by putting those items on the stack.
So that's called amortized analysis, where we consider the total cost averaged over all operations.
And this is a fine example and useful example, of amortized analysis to get efficiency in a stack implementation.
Now we have, what about the pop, we have to think about how to shrink the array.
So, you might think, well, we doubled it when it was full, why don't we cut it in half when it gets to be half full?
We don't want the array to get too empty.
Well, that one doesn't exactly work because of a phenomenon called thrashing.
If the client happens to do push-pop-push-pop alternating when the array is full, then it's going to be doubling, having, doubling, having, doubling, having.
The efficient solution is to wait until the array gets one-quarter full before you have it.
And that's very easy to implement.
We can just test if the array is one quarter full, if it is, we resize it to half full.
And so then at that point, it's half full, and it can either grow by adding stuff or shrink by subtracting stuff.
But there won't be another resizing array operation until it either gets totally full or half again full.
So the invariant of that is that the array is always between 25% and 100% full, number one.
So here's just what happens to the array for our small client example.
And you can see at the beginning, it doubles from one to two to four, but once it gets to four, it stays, once it gets to eight, it stays at that size for awhile even though there's some operations.
And it doesn't shrink back to four until after there's only two items in there, and then it shrinks, and so forth.
So array resizing doesn't happen that often, but it's a very effective way of implementing the stack API with an array where the client does not have to provide the maximum capacity of the stack.
But still, we're guaranteed that the amount of the memory that we are use is always only a constant multiple of the number of items actually on the stack.
So, the analysis now says that the average running time per operation for whatever the sequence of operations is, the average running time is going to be proportional to a constant.
Now, there is a worst case, that is, at the point when the stack doubles, it takes time proportional to N.
But the advantage that we get is very fast pushes and pops, just access array and increment it, and very efficient for most operations.
And for many, many clients, that's an effective tradeoff to make.
Well, this is the analysis of memory usage for stacks, and it's actually less memory than for strings.
The amount used is between 8N and 32N, depending on how full the array is and just a quick analysis of the amount of space that arrays take in Java.
So, again, this analysis is just for the stack itself, not for the strings, which the client owns.
Those are two different implementations of the same API, and the client can use them interchangeably.
Which one is better?
In many situations, we're going to have multiple implementations of APIs, and depending on properties of the client program, we're going to have to choose which one is the better one to use.
So for linked lists, every operation takes constant time in the worst case, that's a guarantee.
So it's going to be slower.
We have a good amortized time, so total averaged over the whole process is good.
We have less wasted space and probably faster implementation of each operation.
And so for some clients, maybe that makes a difference.
Perhaps you wouldn't want to use a resizing-array implementation at the moment that your plane's coming in for a landing.
If you need that kind of order, maybe in an internet switch where packets are coming through at a great rate, you wouldn't want to be in a situation where you're missing some data because something got slow all of a sudden.
So that's a tradeoff that the client can make.
If I want that guarantee, if I want to be sure that every operation's going to be fast, I'll use a linked list.
And if I don't need that guarantee, if I just care about the total amount of time, I'll probably use the resizing-array because the total will be much less, because individual operations are fast.
So even with these simple data structures, we have really important tradeoffs that actually make a difference in lots of practical situations.
Welcome to the Johns Hopkins Data Science Track.
I'm incredibly excited to tell you a little bit about the track and about where you're going to be going over the next nine months.
My name is Jeff Leek, and I'm a professor in the Johns Hopkins Bloomberg School of Public Health.
I thought I'd lead off this introductory video with a quote by one of my favorite US Presidents, Teddy Roosevelt.
It's not the person who points out how the person who's actually doing things is doing them wrong or messing up.
It's the person who's actually trying to get things done, even when there are obstacles in the way.
And a lot of data science right now is being able to push through a lot of the difficulties that you have when you're dealing with either large or messy data.
It includes collecting the data clean them up and then building new announced techniques that exploring new information about that data.
And so, all of those steps are a little bit complicated and sometimes it opens you to criticism when you're trying to do something new and interesting.
And so I wanted to lead with a quote that said it's important to strive the valiantly do these sorts of things, even if you're going to take some criticism.
So the key challenge in data science is actually really nicely summed up in this quote by Dan Myer.
He says, ask yourselves, what problem you, have you ever solved, ever, that was worth solving, where you knew all of the given information in advance?
Where you didn't have a surplus of information and have to filter some of it out, or you didn't have insufficient information and have to go find some?
You're either in a situation where you really don't have enough data to answer the question that you're interested in, and you have to go out and try to search for it, find it on the web, or find it in other places.
Or you're in a situation where you are overwhelmed with a surplus of data and you have to filter out all of the irrelevant information to try to narrow in on your question.
And you'll notice that I said question in both of those cases.
And I think this goes to the heart of our philosophy about data science.
We're interested in answering questions with data.
And that actually makes it more challenging, because sometimes, you can answer a question with some data but you might not be able to answer your question with some data.
So this track is about refocusing on answering the question that you're interested in solving with the data that you have.
So we are all faculty in the Johns Hopkins Blumberg School of Public Health in the Biostatistics Department.
And you could say that we all do data intensive statistics in biology and medicine.
Brian Caffo works on the statistics of brain, analyzing brain imaging data.
And I work on the statistics of analyzing genomics data.
And Roger Peng works on the statistics of analyzing fine particulate matter.
All of us work on problems where the data aren't always clean and nice and easy to handle.
All of us work on problems where the questions that we want to answer are complicated and you have to break them down into parts.
And all of us, sort of, work on questions where we're very passionate about trying to get the right answer so that we can help people in human health.
But the techniques that you're going to be learning about are not exclusive to biology and medicine.
That's just one area where there's been a recent upsurge in the amount of data that's available.
So why data science?
Why should you take this program?
This is a cover of The Economist now.
It's a little bit old I guess ancient history from a couple of years ago.
It's much easier to store.
And there's so many free computing tools out there right now, that you can actually do something with this entire data deluge that's sort of assaulting all different areas of science and business.
So the other thing is that you've probably heard the term big data.
And so we'll hear a little bit more about what we think about big data throughout the course of this particular course, the Data Scientist's Toolbox.
But big data is, sort of a new frontier in the sense that, we have data in areas that we didn't used to have that data.
We didn't have access to information about GPS coordinates from cars from everybody in the entire world.
It wasn't possible to sequence everybody's genome.
And now that's all possible.
So we have access to this data and it allows us to answer questions we never could before.
So, it's an incredibly exciting time, and you're somebody who can get in there and use that data to answer those questions.
So why statistical data science?
You'll notice that we're, all of your instructors are biostatistics professors and so this will, this data science track will obviously have a little bit of a statistical bend.
I think that that's appropriate given that statistics is the science of learning from data.
So, data is very, very, it's very rare that you'll get a data set where all of the answers are really clear, and there's no uncertainty.
In any case where there is uncertainty, that's where statistics comes and plays a role.
So, this is a again, a little bit older New York Times article now, but it talks about how the key word for a lot of graduates to open the door for a lot of jobs, is to learn about statistics.
So why are you lucky?
He got into building a internet company at the time when there was this explosive growth in internet usage and it just opened the door for the opportunity to build something amazing and huge and wonderful.
And sort of, that's the right, that's what the time is right now for data.
It sort of there's an explosive growth of data in every possible area you can imagine.
You're also lucky because tools and competitions and websites have all been developed around the idea of helping to learn about data, but also getting involved in projects that have super high profile results.
So, one example is the Heritage Health Prize, which I'm showing you a picture of here.
The Heritage Health Prize was a $3 million contest for people who could analyze data and come up with a better predictor of who would be admitted to a hospital in another year.
So you can see that's a huge amount of money that's being invested in these ideas of algorithm development and data science of prediction.
So it gives you an exciting opportunity to get involved in projects that, sort of, weren't happening five or ten years ago.
This course track will focus almost exclusively on the use of the R programming language.
And so I thought it was appropriate to talk a little bit about why we like R so much.
So we like R obviously, because we all use it.
But it's also sort of increasingly the most commonly used language for data science.
There are other languages that are also very useful.
And we won't be talking about them a lot in this course but they're obviously good complements to the R programming language.
Like, Python, in this class we'll be focusing on R because it has a broad range of packages that allow you to go from the rawest of raw files, all the way to interactive reports and documents and web apps that you can share with your collaborators.
It has one of the best development environments of any programming language, in our studio.
It also has an amazing ecosystem of developers.
And what I mean by that is there are a lot of people that are developing our packages.
And they're also available to get in touch with on mailing lists or by email or on stack overflow.
And so it's really possible to learn about the cutting edge of packages that are being developed.
There also very easy to install and play nicely together, which is a, a feature that doesn't always happen in a lot of the languages that are used for data science.
So the next thing I thought I would mention is, who is a data scientist?
And I thought I'd mention that some people that I think are data scientists, that might not, either label themselves that way or have other people label them that way.
So the first is Daryl Morey, who'd the general manager of the Houston Rockets basketball team in the US.
So he uses data to analyze basketball players and transactions and making trades.
And so I would consider him to be a data scientist Because he's a person who uses data to answer questions about basketball.
So, she used to be the Chief, Data Scientist at Bentley, and now she's at Accel Partners.
And so, she uses data to answer all sorts of questions about mining the web, and understanding that way that humans interact with each other through social media.
So, again she might not label herself a data scientist, but I think the way that she uses data, is a evocative of the sort of ideas, that we would like to convey in this data sciences track.
If you're taking this course, you probably know who Daphne Koller is.
She's the CEO of Coursera.
But she's also another person who's using all the data they're collecting through Coursera to better, to improve the way that we do educational delivery and educational assessment at this huge scale that Coursera is providing.
And finally, Nate Silver is one of the most famous data scientists, or statisticians in the world today.
So he used a large amount of totally free public data to make predictions about who would win elections in the United States, and was remarkably accurate.
So our goal is to teach you about a bunch different skills that will be useful for you as a data scientist.
So, this is a Venn Diagram and some statisticians and data scientists don't like Venn Diagrams but I'm going to get, show you one anyway.
And so, this Venn Diagram has Data Science at the, sort of, the center of this Venn diagram that intersects several different skills.
So, if you look right here there's data science and it involves three different components.
And so our data science track will focus a little bit on each of these, but it will primarily focus on math and statistics knowledge and hacking skills.
And so math and statistics knowledge sort of speaks for itself.
We're going to teach you a little bit about math and a little bit about statistics.
But hacking skills also has another component to it which is the ability to go out and answer questions for yourself.
One key component of a data scientist job right now is that most of the answers aren't already outlined in the textbook.
This is all new stuff that's happening.
So what are the major skills of being a data scientist is being to go to Google, and go to Stack Overflow, and go to one of the other sites and look up what you need to learn and figure out what answers you know and what answers you don't know, and then figuring out how you can use the information you have to answer the question that you'd like to answer.
That might be the reason you're taking this course track.
And so you can see this is a plot of listings are for data science jobs over time and of course it's exploding.
And we'll talk a little bit about why you shouldn't extrapolate, necessarily, from your data forever, but it does suggest that data science is a hot area that's growing and I think obviously we're very excited about it and hope you're excited about it too.
So this course, Data Scientist's Toolbox, will continue with lectures on the following three things.
First, we're going to introduce you to the course track.
Then we're going to tell you a little bit about getting the tools that you need to get set up and get installed, hopefully get you over that hump.
And then we're going to give you the basic background on data science sort of writ large, so that you'll be ready to jump into any of the individual classes and really take off.
Looking forward to seeing you in the rest of the class.
In week two of course, we're going to be covering a bunch of software that you're going to install that will constitute the data scientist's toolbox, as we described it for this course's track.
So the first question you might ask yourself is, what software do you need?
Well to know what, software you need, you have to know what exactly a data scientist is going to do.
So, in this course sequence we're going to talk about all the different components of being a data scientist.
Determining if that data is even accessible, a lot of times the ideal dataset isn't even available.
Then ways that you can go out and actually obtain the data whether it's from a database, or from a website, cleaning the data up so that it can be processed and analyzed.
Performing some sort of exploratory analysis, including making plots and clusterings so you can identify patterns that you didn't know about before hand in the data set.
Performing statistical prediction or modeling to try to, build a sort of an intuition about what's going to happen in the next sample you might take.
Then synthesizing them and writing them up in reproducible ways that can be shared with other people.
Finally, we're going to talk about distributing results through things like interacting graphics, also through right ups and presentations, and finally through interactive apps built on top of R.
So the main workhorse of data science in terms of this data science track is the R programming language.
And it's widely supported by a large group of developers.
Who can contribute new packages all the time that can improve and extend the functionality of R.
We'll be installing this in the second week of the class.
We'll do most of our coding in RStudio.
RStudio is an Integrated Development Environment, an IDE for R.
It's actually one of the best IDE's I think for many other languages as well in terms of data science.
The R IDE is free as well just like the language R, and so we will be downloading this IDE and setting it up again the second week of class.
The interface looks something like this.
And we'll talk a lot more about this in the second week and later on in the rest of the class.
So this is a new .R file that's going to contain some code that we're going to be writing in.
So we can write that code, here in the file at the prompt and then down here, you see a console.
See plots you recently made, the packages that you have loaded, or help files for specific functions that you might be interested in.
There are a lot of other really nice functions that come with Rstudio, and we'll be talking about those more throughout the class.
The primary type of file that we'll be interacting with, for the most part in this class, is an R script.
So, an R script is a file with the extension .R, and so it's just a, actually a text file.
Except the text file contains bits of R code, so here it's you can see a comment.
So this isn't actually executed but R you could include that so that people can understand what's happening in the code.
And then there're things like functions and so forth which we'll be talking about a lot more when we're coding.
If this seems intimidating to look at this function right now you should worry about it when you get through R programming.
You'll be a wizard and be able to do things much more complicated than this.
The other thing that we'll be using is R markdown documents.
In other words, they can be rerun and produce the exact same numbers that you got when you did your analysis.
So this is a file with an extension ,RMD and this .RMD file has a very structured format of text file.
And so we'll talk a lot more about what that format is later but you could take this structured file and you can knit it to html with this button here.
And you actually create an html file that will actually be formatted very nicely.
So for example, what you type in text looks like this, and it turns into a nice bulleted list in HTML, once you knit HTML.
And we'll talk a lot more about how that file works later in the class.
We're going to talk about how we are going to do distributed version control with Github and Git.
Or you can share and contribute to other projects, so that you can get your name out there in the data science community.
We're going to running most of the commands from the shell or from the command line interface.
So, there's a brief tour of all the tools that we're going to be using in this class.
This lecture is about getting help.
This lecture applies both to this cla-, this course that you're taking right now, the Data Scientist Toolbox.
So, keep in mind that in a standard class you may have taken in a class of 30 or 100 people, you would raise your hand and ask a question.
But in a class like this in a massive online open class there could be up to a 100,000 people taking the class.
And what you're going to do instead is post your questions to the message board.
And then hopefully, your fellow students will upload them if they're good questions.
And you instructor will try to respond to as many as possible, but probably more often than that your peers or community TAs will be responding.
And so, there are three of us that are teaching these nine classes and we are going to try to put in as much as we can to answer your questions.
And so relying on your fellow peers and your community TAs, we found is a great way to get involved.
We've also learned that the community that's built around the message boards and the massive online open courses is amazing.
And it's a, probably the best learning part of the entire experience.
And so hopefully, you'll get involved and you'll be an active participant in those message boards.
It's very clear that the fastest answer is often the one that you find for yourself.
So to try to answer your questions yourself, you should try to look it up on Google or look it up on Stack Overflow.
If you ask a question that's very simple to Google, you'll often a get response that says Google it or read the documentation.
Which is not the easiest way to get the answer that you're going for.
An important part of being an active participant in a community environment here is to, if you figure out an answer to a question is to post it to the message board.
It's almost a sure bet that there's a lot of other people that are struggling with the same thing.
And so, they'll really appreciate it if you take the time to post the message board the way that you figured out how to solve that problem.
So, I thought I'd mention just a few important R functions that will help you to find answers for some of the questions you might have.
So, when you have an R function, we'll talk a little bit more about R more later in the class.
So, one example is that you can type like this.
And if you use help.search, you might not even necessarily have to get the function name exactly right.
It'll still search through, through the help files and try to find things for you.
And then, if you want to get the arguments for a function, you can use the function, you can use, the, command args, like this.
Args of rnorm and that'll tell you the function arguments.
These functions are very useful if your goal is to try to figure out how r is working for a particular function.
But it might not be so useful, if you want to understand the sort of underlying concepts involved in those functions.
So another thing is you might want to do is actually look a little bit deeper into the code.
So if you wanted to do that you can actually just type the function name without any brackets and it will actually reproduce the entire code for you.
Then what I end up getting out on the R console is actually this right here.
You could also see this link here to a reference card with a lot of helpful R functions.
So, an important point that you'll run into a lot in this class is how to ask an R question.
And so there are a few different components of it that you should keep in mind.
First is, you will want to outline what are the steps that you have executed in order to create this problem.
So, if you ran three functions in order you should reproduce what those three functions are.
And then you should say what you expect the output to be.
And then what you saw instead.
So I expected it to give me the answer to this question and instead, it gave me an error.
And so a really important thing to keep in mind is that R packages and R and all of these other tools that we're going to be telling you about are going to be evolving over time.
And so it's really important that you tell the version of the product that you're using.
So, the version of the package, the version of R that you're using and then what operating system you're working on.
When you're asking a data analysis question, there's a similar set of things that you need to re, re, report.
So first is what is the question you are trying to answer.
And then, what steps or tools do you use to answer it?
This may be a combination of R tools and outside tools and maybe some intuition.
And then, you again, you report what you expected to see.
I expected to be able to tell the relationship between them and what do I see instead?
I see oh, I don't know, I see some crazy scatter plot and I don't know what that means.
And so important thing to think, keep in mind here too is what other solutions you might have thought about.
So sometimes you run through three or four different things to try to get the right answer.
And so, if you're report what you try or the different things you try, there when people try to answer your question, they can go directly to something you haven't tried.
So an important point of asking questions in highly massive class like this is to make sure that you're very specific in the titles of the questions that you're using on the message forum.
I can't fit a linear model.
Then you're not exactly giving a lot of detail as what exactly your problem is or how it can be addressed?
So, a better question to ask is, sort of saying, okay, I have this function and it's happening in that version of R 2.15.
And is only being produced when I have a large data set and here's the software that I'm using.
I'm using Mac OS X 10.6.3.
And even better question is to use a title that's a little bit more succinct.
So, here you lead off again, the function that you're asking about, you say okay, I'm asking about R 2.15 and again it's on this operating system.
And then I very succinctly describe seg fault on large data frame.
So by focusing on the very specific details, it means people can jump very quickly to the answers that you might need.
So there's similar sorts of questions, specific details you would want to give when asking questions about data analysis problems.
So, in general, the more specific you are the faster your answer will come.
So there's some etiquette that we would like to encourage in terms of using these forums.
Or in, in just using help sites in general not necessarily the ones in these forums.
What's the question you're trying to answer?
Try to provide the minimum amount of information.
If you, you provide way to much information it's very hard for people to filter through and figure out what their real problem is.
Being polite never hurt anybody and will often get your answer more quickly.
It's the polite thing to do, post that you found on the course website so that people can search it and find that answer as well.
But it's very easy to overwhelm the inboxes of your instructors or community TAs if you all start sending emails simultaneously.
When there's a typo in the assignment, please report it on the forums and we will address it as fast as we possibly can.
Some things that you shouldn't necessarily do are immediately assume you found a bug in a major program.
So, saying you found a bug in R and that's why things aren't working.
So begging other people to do your work for you.
Please don't post homework questions on mailing lists or on the course forums.
If you post the questions or the answers on the forums it, it sort of takes away from the experience of everybody else.
Please don't e-mail a lot of different lists all simultaneously.
Try to figure out what the right mailing list is and only e-mail that.
And then, you don't want to ask general data analysis questions on R forums.
So try to keep those who are R course forums, where hopefully there'll be a big group of interested people all trying to answer the same questions.
So the transfer of these slides go to Roger Payne who's another instructor in the course track.
That's a link to his video on YouTube and it was inspired by Eric Raymond's lecture, How to ask questions the smart way.
This is a brief follow-up video to getting help and it's about finding answers.
The reason why there are two videos about this is because it's such a critical skill in data science.
And the reason why it's one of the three fundamental skill is because almost of none of the knowledge that you will need is already sort of set in standardized text books.
It's often scattered in a bunch of different places and you have to be able to sort of synthesize it or find the information that you need about.
Whether it's about which data set you need to be using, or the statistical analysis you need to be doing, or the R Package that you need to be using.
All of this is sort of scattered around, and you have to be willing to do a little bit of hard work and elbow grease to find it yourself.
Obviously we'll tell you as much as we can in lectures, but we're necessarily limited by the amount of time that we can lecture every week, and so it's important to be able to find that information yourself.
So key, some key characteristics packers are that they're willing to go out and find the answers on their own even if it takes a little bit of time or a little bit of effort.
They're knowledgeable about where to find those answers whether its Google, or stack over glow, or cat.
They're unintimidated by new data types or packages.
And so a key characteristic I would say the way to summarize it up is being alive but relentless here.
Going after the answer and you just trying to find it But you're very polite while doing it.
And so Google knows this too.
In their hiring practices they're looking for these sort of characteristics.
So an important question is where to look for, for different types of questions.
So for our programming you might want to go straight to the the archive of the class forums.
Where the class you're taking will focus on very specific questions or functions.
And there'll be a large group of interested people.
You could read the manual or help files like I showed you in the getting help lecture.
That's actually one of the best ways to do it.
That's even better if you've got a person that you know that already is a bit of a data scientist.
They can often help you out.
And then you can post to the class forums and try to get your answers.
You can also post to forums outside of the class.
The R Mailing List or Stackoverflow, if you have R questions.
For data analysis or statistics type questions, you want to go to start again with the class forums, and then go to the web or to friends.
And then there's another outside forum called CrossValidated where you can ask these types of questions.
So forget HUB, they have a lot of tutorials and nice information that you can use to get answers there.
So an important point to know is that Googling data science questions isn't always the easiest thing in the world.
So, the best place to start with if you have a pretty general question is often in the forums.
And if people can direct you to where you should be searching outside of the forums.
Keep in mind that Stackoverflow with the tag R is a really good place to get information about R.
And, so, you have to use this tag because if you just use the letter R, it obviously is, sometimes, a little bit hard to search for.
You can also try the R mailing list for software questions or CrossValidated for more general questions.
Usually what I've found is that if I'm going to work in Google, searching Google, I use usually type something like the data type and then data analysis or I type the data type and then the R package.
Another thing to keep in mind is that data analysis or data science is often called something different depending on what kind of data you are looking at, so for example medical data it might be called biostatistics.
For data in computer vision it might be machine learning or natural language processing for data from text and so on.
And so, you can often find that out by posting to forums and people will let you know what the right word to be googling is.
And it was inspired by Eric Raymond's How to Ask Questions the Right Way.
This is the first in a series of overview lectures that tell'll you about the other courses in the Data Science course track.
I'm going to start off with R programming, which is another one of the most fundamental classes in our Data Science track.
R is the language that we're going to be using for most of the data analysis and data science that we're going to be doing on the computer science end.
How to write functions, to do things to that data, how to debug them and then a little bit about simulation and optimization.
So now I'm just going to show you a couple of examples of the sorts of things that you'll learn in that class.
So for example you'll learn about the readLines function for reading text from a file.
So in this case what we're going to be doing is we're going to be reading lines actually from the website of the Johns Hopkins Bloomberg School of Public Health.
So this is the website right there.
And so what we do is we go to that website and then we use the readLine func, readLines function to read the text from that site.
And then we look at that text and you can actually see the HTML code, and it's actually been sucked into R that you can then use to analyze the website.
Another thing that you'll be learning about is how to figure out when there's something wrong with your function.
So, you'll be writing lots of functions in this class.
And so, one thing that you want to know is when they aren't working, why aren't they working?
And so this is a slide that comes from one of those about how do you figure out, what were you expecting, and what did you get?
And how do you reproduce the problems so that you can figure out how that function works?
And so the lapply function takes a particular kind of argument.
And a list in this case, and applies a function to all the elements of that list and returns something back to you.
But you don't actually have to access to that.
You can actually just use the R function.
So this will cover everything from sort of the basics, to more complicated functions like lapply.
This is the Getting and Cleaning Data course overview.
This is actually one of the more unique classes in our data science track, but I think its sort of one of the most fundamental components of being a data scientist.
Which is being able to go out and get data from whatever source it's in and whatever form it's in, and turning it into a clean processed data set, that then you can use to answer questions.
Reading in data from a very large number of different sources, merging it together, reshaping it, summarizing it, and then finding some data resources that you can use to augment the data that you already have.
So here are a couple of different things that you might learn about.
So, for example, how to connect to a MySQL database, a MySQL database, from R.
So there might be one cloud that contains reviews and one cloud that ca, contains solutions, say from a peer assessment, and you want to combine them together.
And so, you can use commands in R to merge those data sets together.
And then, talking about, sort of, raw versus processed data.
So talking about, what are the data that come to you in their rawest possible form, the original source of the data versus the processed data.
The data that's ready for analysis, ready to be used by people that has happened after you've merged it, and sort, subsetted it, and transformed it into the nice tidy data set that people can use.
So that's getting data.
This is a review of exploratory data analysis, which is the next course in the course sequence.
Exploratory data analysis course will cover the principles of how do you create analytic graphics, graphics that allow you to analyze data.
It'll talk about exploratory graphs, how you explore the data and get in, create enough graphs to sort of figure out the structure of what's going on.
It will talk about the plotting systems in R.
So it'l talk about base plotting, lattice plotting and then ggplot2 which is a popular newer platform.
It'll talk about hierarchical clustering, K-means clustering and a little about dimension reduction.
These are all techniques that you can use to get in and explore data as a first pass.
So, for example, it will talk about how to use ggplot2 package to make plots like this, sort of, sort of pretty smooth scatter plots that allow you to like understand the relationship between different variables.
It will talk about the principles of analytic graphics, so what are the principles that you need to create graphics that'll be useful sort of to figure out what's actually going on with the data you'll be working with.
So the idea of how do we, if we have a bunch of observations of collecting data on that, how we cluster them into relative groups that are similar to each other as a method of exploring the data and figuring out the structure of what's going on.
So this is just a couple of the ideas that will be covered in exploratory data analysis.
So here's the corresponding API for QueueOfStrings.
Actually it's the same API as for stacks, just the names are different.
Instead of push we have enqueue instead of pop we have dequeue.
And the semantics is different, for enqueue we add an item say at the end of the queue, and for dequeue we remove an item from the beginning.
It's as if you're waiting in line to buy a ticket.
When you're enqueue you go at the end, and when the one that's been in there the longest is the one that comes off.
So lets look at how we implement those, first using linked list and then arrays.
One, to the first item in the list and the other to the last item in the list.
When we insert, we're going to add the item at the end of the list instead of at the beginning.
So here's the implementation of dequeue.
It's identical to the code for pop for a stack.
We save away the item, we delete the first node by advancing the reference and then we return the item, so identical.
So we, to add it at the end, so first thing we need to do is save a link, the last node.
We're going to need that because we need to change it's reference from null to point to the new node.
We'll populate its fields and then that old link will change that from null to a pointer to the new node.
Actually years ago when we taught courses in algorithms and data structures, much of the course would be about this kind of pointer manipulation.
We encapsulate them in basic data types like these.
All right, so let's go back to our full implementation and this is just taking care of collecting the code from the previous slides.
To make sure that if the queue is empty after we move an item we gotta set last to null.
Make sure that both first and last are always what we want them to be.
Okay, what about arrays?
Well, we won't do the details, but it's not difficult to implement queues with resizing arrays as well.
Not difficult, but a definitely tricky programming exercise that people are welcome to try.
So we'll maintain two pointers, the first item in the queue and the tail, which is the position for the next item to appear.
So for enqueue, you add a new item a tail.
And the trick is that once you get past the capacity, you have to reset back to zero.
And so that's a little extra code, and then you have to add the resizing capability as well to implement the data structure the same as for stack.
And we'll leave that as an exercise.
Statistical Inference is going to be a course that covers many of the foundational ideas that are involved with extracting generalizable information from data.
And so, the course will cover things like basic probability, likelihoods common distributions, confidence intervals, hypothesis tests, bootstrapping and power.
These are the sort of fundamental ideas that you often hear coming up when people are reporting data analysis.
So, for example, we'll talk about sort of the way that you model mathematically coin flips or proportions.
We'll also talk a little bit about how you model more continuous distributions, things like, with the normal distribution which you've probably heard about.
As a way to measure sort of the variability about a large number of different things including IQ and height and things like that.
And then we'll talk about things like bootstrapping, where you actually use the data itself to sort of create measures of variability that you can use to sort of decide how generalizable are the answers that you get from performing any particular analysis.
One of the most widely used tools for performing any sort of statistical or data science analysis is a regression model.
So the next course will be covering those regression models.
Some would say it's just one other form of just pre, creating a supervised predictive function.
But it's a little bit more than that in that it's, one of the more interpretable and easily used, tools that you can use to sort of explain you analyses.
So, this course will cover linear regression and multiple regression, ideas like confounding which we'll see a little bit in this class even, some prediction using linear models.
Scatterplots smoothing its splines, and then resampling inference, and maybe weighted regression.
So, this will cover also some ideas including ideas that you hear about often when you read articles about statistical analyses in the popular press.
So, why is it that children of tall parents tend to be tall but not as tall as their parents were?
So these sorts of fundamental ideas will be explained in the regression class.
So we'll also talk a little bit about the basic regression model, there'll be a little bit more mathematics in this class than there are in some of the other classes and sort of deriving and understanding the basic ideas behind a regression model.
We've worked hard to make it so that, basic understanding of algebra is sufficient to follow this class.
We'll also learn about multivariable regression analyses so, sometimes you want to relate one variable to another variable but you want to account for, what happens when you include other variables, adjusting your analysis.
You often hear about adjusting the analysis, and that will be covered in this class as well.
This is an overview of practical machine learning.
There are a large number of machine learning classes out there, and they are often very good.
So, the focus of this class will be primarily on hand-drawn application of machine learning in R.
So, the idea being that we'll try to focus on the R packages and the ideas that will allow you to actually take data and perform machine learning on those data.
We'll also talk a little bit conceptually about each of these prediction methods work and maybe some of the cases where there might be trouble.
So the Practical Machine Learning Content.
Predicting what the variety of different ideas like regression and trees.
We'll talk about common ideas like boosting, bagging, model blending, and a little bit about forecasting.
We'll cover basic terms, like what are true positives and false positives?
What are true negatives and false negatives, sensitivity and specificity, those sorts of things.
We'll also cover how to deal with correlated predictors by preprocessing out data that had correlated predictors.
So, this is a very more technical machine learning idea, but can be applied quite simply using the functions of a R to really improve your prediction accuracy.
I just wanted to briefly describe how to install R for a Windows machine.
So the first thing you need to do is load, launch your web browser, so I'll do that here.
And you need to go to the Comprehensive R Archive Network, or CRAN, so I'll just type that in here.
And you'll see that there is a, at the top there's three options, there's Linux a Mac and Windows.
So you can go to the Mac version here, and you want to go click on the base link here.
And the download will start, and so, depending on how fast your internet connection is, this might take a few minutes.
And you'll probably have to click on Yes for this.
And so, you can choose your language here.
There are a number of choices in terms of the translations that you can choose from.
And then you can just click through the installer, it'll kind of walk you through the various steps.
And so we'll do that right now just to see what the options are.
You have to agree to the license, which is the gener, the GNU General Public License.
There are other kind of installation setups that you can choose from.
If you know you only, you have a 32 bit machine it maybe an older machine you may, you can click on that.
By default it will install both versions so you don't have to really worry about that.
So just click through Next on this one.
So what that means is basically do you want R to kind of run in one big window with kind of different sub windows within inside of a big window, or you want it to run in kind of like separate windows.
I prefer to use the SDI mode where the, so the console will be in one window and the kind of graphics window will be a separate window.
So I'm going to click on the SDI option.
And then you can choose how you want to look at your help files.
And the Plain Text Help is well it's just plain text.
So maybe I'll just click on Plain Text just to be different.
This, generally speaking, you should not mess with, so you just click on Next.
You can create a shortcut in the Startup menu, Start menu so it's usually a good idea.
And you can usually choose the defaults here in your terms of creating a desktop icon unless your desktop is very cluttered and want to you know, avoid that.
And then it'll start installing the files on your computer.
If we can just click on Finish here.
And so I'll just close this browser here.
In this video, I'm going to to briefly show how you can install R on the Mac.
You just have to, it only takes a few steps.
So the first thing you need to do is open your web browser, and go to cran, says the comprehensive R archive network.
So you can just type in cran here, there are a number of options for you to download here for different platforms, and so we're going to download the Mac platform here.
So we go to download R for the Mac.
And you see that the latest version here, is version 3.0.3.
You want to download this package file here, so just click on this, and you'll see that the download meter will start going.
And it might take a few minutes depending on the speed of your internet connection.
Uh,and it'll guide you through all the steps you need to install R 3.0.3.
So, I'll click continue here, and this is just the description of what's going to get installed.
The software license agreement is the new general public license version 2.
So you should agree to the license, after having read it of course.
Now that's finished, I can hit close, and then it'll be in my Applications folder.
So I can just go to my Applications folder, which is right here, and there alphab, alphabetic order.
In this video, I'm going to talk about how to install RStudio for the Mac.
It's a very simple process and only involves just a few steps.
The one thing I'll say though is that you must have R already installed before you can install RStudio.
You can go to the RStudio website, which is Rstudio.com.
And you can see down here on the lower left, there's a green button that that directs you to kind of download RStudio.
So, here there's two versions of RStudio, studio that you can download.
One is for the desktop and one is for the server down here.
Now you, we're not going to be talking about the server version at all here so, you just want to download the desktop version, so that's this button right here.
So, I'm just going to download that right now.
And, you'll see the download meter go.
Once that's finished downloading you go to the Downloads folder, and it should be the most left thing here so we're just going to click on it to install it.
And then just like any other Mac application, all you have to do to install is drag it into the Applications folder.
So, I'm going to do that right now.
So, I can just go into the Applications folder here and find RStudio.
I'll say yes, I want to open this application.
Prior to that, I was the interim lead producer at Miniclip on the mobile division, not the whole company.
But I'm now looking, as my children are getting older, to perhaps getting back into the workforce.
>> I'm a policy and public affairs professional, and over 10 years I've worked in policy lobbying in Westminster in London.
But in fact it does require a bit of preparation, listening to the lecture.
So in other words, it needs some time to be put aside.
There is never enough time.
The fact that the lectures are in video form is a very handy thing for someone like me who hasn't taken notes in a really long time, because I can repeatedly pause it and rewind it and go back over it again if I need to.
And then I create my notes in a tidy way that I keep on a different notebook.
>> Well, there's another side of Coursera that I really appreciate, and that is the peer review.
At first I was slightly skeptical, and also a bit daunted because it's an additional coursework and actually it proved really helpful for my own coursework because it helped me understand what are the sort of average standards?
And after awhile, you just start to realize that there is something as a common ground.
They helped a lot of people who had some difficulties because they didn't really have the coding background.
Rseek in the case of R helped a lot, but if it was for some other programming language, I would probably go to Stack Overflow.
The things that I'm doing right now, in my job, with what I learned is really nice and was a great experience.
>> I also learned so much that I felt clever again all of a sudden.
It was nice, it activated parts of my brain that I hadn't used in a long time.
>> Just in my household there is three of us, and all three of us have done at least one Coursera course.
So it's really changed what we do in our spare time.
This is a very brief introduction to the Git Version Control System.
So Version Control is a system that records all the changes that you've made to a file or a set o files over time so that you can, recall specific versions later.
And maybe other people will be working at the same time on a similar set of functions that you want to be able to keep track of everything that's being done to those files.
And so, Version Control means we're just going to try and save or manage all of those intermediate files.
And it's really important when you're sort of collaborating with others because, they might be using as, a different intermediate file and you might want to know how to coordinate what happened when you get to the final version.
So Git is a free and open source version of of a version control system.
It's distributed so it can handle everything from small to very large projects with speed and efficiency.
It's created by the same people who developed Linux.
It's definitely the most popular version control today compared to all the other version control systems like SVN.
Everything is stored in local repositories, or on your computer, and they're called repos and then you do most of the operations from the command line.
And so this is the link I've given you here is a, sort of a short history of how Git was developed, and how to get started.
So, the first thing that you need to do is go and get, download Git.
So, if you go to that website and download the appropriate version of the software for your operating system, that would be the right place to start.
The next thing that you do is, once it's done downloading, you open it up and you begin the installation process, so there'll be an install wizard that will take you through the steps of installing Git.
Once the installation is finished, you might want to hit the Finish button, although you may want to check uncheck the box next to review the release notes because you probably won't be interested in that at this point.
So the first thing that you want to do is open up a program called Git Bash which is the command line enr, environment for interacting with Git.
It should be loca, located in to the directory in which Git was installed or for Windows users, it will be in the Start menu now.
So, once you have Git Bash open you'll see a short welcome message followed by the name of your computer and a dollar sign on the next line.
And so the dollar sign means that it's again, the prompt like you've seen in the sort of command line interface lecture and so, it's your turn to type a command.
And so, each commit to a Git repository will be tagged with the username of the person the commit.
So what you need to do to sort of get things set up is, you need to enter your username and your e-mail.
So you type these commands where you type Git config dash global username.
And here, you're going to type in the email that you're going to be using with GitHub.
You only have to do this once when the system opens up, but you can always change it down the road if you want to use the same commands, if you want to change say your user name or the email that's associated with the Git account.
Now type the following to confirm your changes.
And, so, you should be able to see your username and your email and all of that.
So right now we're actually going to actually just exit Git Bash.
And so so you can do that with this command, just type exit and hit return.
It's dealing with Git, it's widely, widely used among scientists and does lots of neat stuff.
And so, once that's up and running we'll show you how to do some of the most important things that you need to do with the Version Control System.
This is a really brief introduction to GitHub.
Git is a version control software that allows you to control and manage the revisions of projects that you're working on locally on your computer.
And as such, it's a very useful piece of software on its own.
It allows for you to collaborate on projects together at a bigger scale.
So GitHub is a web -based hosting service for software development that uses Git revis, revision control as sort of a driving force.
And so what it allows you to do is contribute to projects online And to have your projects posted online so that other people can see them and contribute to them as well.
It also provides users with a home page that displays all of their repositories.
And the repositories that you have on GitHub are backed up on the server in case something happens to your local ca, copies.
But the real key aspect of GitHub is the social aspect and so the social aspect allows users to follow one another and to share projects and to contribute to each other's projects and so that's really the power of GitHub.
One of the things that we noticed bout GitHub is that often when you see somebody else's work You can sort of learn what they're working on, how their code works, and it's a great way to sort of identify people who would be good to work with.
And we've also found that when we put projects on the web, other people will often contribute, you know, for free, just because they're interested in how they can make the software better.
So the first thing that you need to do is go set up a GitHub account now that you have Git installed.
And so, you'll need to enter a username, email, a password, and click sign up for GitHub.
An important note here is that you should use the same email address that you used when you signed up for Git in the previous lecture so that it, you'll be able to have the two pieces of software work together.
It's free, so it's not, it shouldn't be a problem.
After signing up, you will find yourself on this page, which has several helpful resources for learning about Git and GitHub.
I suggest that you read those tutorials, as they're more in depth than what we'll be able to cover in this class, and they're incredibly useful.
If you click up here on your username in the upper right hand corner up there, you can see your GitHub profile.
So, see all the projects that you currently have, which when you start your account, wont be many.
It'll also show other people who you are and what you're working on.
So, you can fill out information about what kind of projects you're interested in.
our plan is for this course is to use this GitHub Profile as the place that you can sort of build a profile.
Which is a portfolio of the work that you've developed that shows off your skills as a data scientist.
If you click edit your profile, the right hand portion of the screen you can add basic information about yourself.
But if you're doing good work, so for example, if in the course of this class you create interesting data science products and ideas, you want to be able to take credit for that.
In the next lecture, we'll talk you through how you actually create a repository, a repo, and put it up on GitHub.
In the meantime, definitely explore the documentation on the GitHub site because it gives you lots of different information.
What if we want to have queues and stacks of other types of data?
So, we implemented stack of strings but in applications we have all different types of data that we might want to implement like stack of int say or URLs or cars or vans or whatever data that we might be processing.
Well, first thing that we might that we might consider and actually we're forced to consider this one in lots of programming environment, is to implement a separate stack class for each type of data that we're using.
And what if we have hundreds of different types of data that we're processing.
We have hundreds of different implementations.
Unfortunately that situation at the beginning of Java where we stuck with that and there are plenty of programming languages where basically we're stuck with that so what we want to look at is a modern approach to avoiding having multiple implementations for each type of data.
So the a quick hack that is widely used is to use casting to implement to reuse the code for different data types.
So, we make our implementation with type Object so everything in Java is a sub type of Object and then the client, when the client comes to use it, will simply cast the result to the corresponding type.
I don't want to spend a lot of time with this cuz I think this is a unsatisfactory solution.
So, in this example we have two types with two stacks one of apples and one of oranges.
And then, it's up to the client when it pops something off the apple stacks to cast at the apple to keep the type checking system happy.
The problem with this is that the client code has to do this, this casting and it's kind of an insidious bug if it doesn't quite get it.
So, the third attempt that we're going to talk about uses generics.
And that way the client code doesn't do casting.
We can discover mistakes in typed mismatches at compile-time instead of at run-time.
And just the guiding principal in good modular programming is that we should welcome compile-time errors and avoid run-time errors because if we can detect an error at compile-time, then we can ship our product or deploy our implementation our implementation of an API and have some confident that it's going to work for any client whereas, the error is not going to get discovered until run-time it might occur with some client development.
Okay.
On the left is our implementation of a stack of strings using link list.
On the right is a generic implementation.
So, every place that we used string type on the left we used the word item on the right.
And at the top, the class declaration we declared an angle brackets that item is the generic type that we're going to use.
The implementation could hardly be more straightforward and it's an excellent way to solve the problem of handling multiple types of data with one implementation.
With arrays, it doesn't quite work and again all programming languages and, you know, many programming languages nowadays have difficulties with this and Java's got a particular difficulty.
So, what we would like to do is just declare a new array using our generic name Item as in the highlighted line here.
Otherwise it's the same.
Unfortunately, Java does not allow generic array creation.
So there's various technical reasons for that and you can read, read extensive debates about this on the web that's going to go beyond our scope.
For now, what we need to do is put a cast in to make this work.
So, we create an array of objects and then we cast it down to an array of items.
Now in my view, a good code has zero cast.
It's not something that you will come up with on your own and that's, and that's an undesirable feature, I think for codes so simple as this.
But fortunately, we can get through pretty much everything that we're going to do in this course just knowing about this one of lay cast.
So now, when we compile this program we get a, a warning message from Java.
It says that we're using unchecked or unsafe operations and we should recompile with a minus -Xlint equals unchecked for details.
And okay, that's fine and you're going to see that when you do compiles using code like these.
I, I think maybe they might have added to this warning statement "We apologize for making you do this".
It's not our fault that we had to do that, we had to do that cuz of your requirement about not allowing us to declare generic arrays.
So Integer with the capitalized rapid type for int and so forth and many of you were probably familiar with that.
And there's a process called auto-boxing which automatically cast between primitive types and wrappers so all of that handles of the, the problem of dealing with primitive types, kind of behind the scenes.
And the bottom line is that we can articulate an API for generic stacks that works for any type of data and we've got two implementations, link list and arrays that, that performed very well for any type of data using the, the resizing or link list as we've described.
When you download R from the comprehensive R Archive Network CRAN, you get the base R system.
And this includes a bunch of functions that you can use to summarize data and make plots and things like that.
But the real reason R is so useful is that there are a lot of add-on packages that extend this basic functionality in a bunch of different directions.
Everything from cleaning data, to plotting data, to analyzing data and making interactive applications.
So, R Packages are developed and published by the larger R community, hopefully including you at the end of this course.
So, to obtain R Packages the primary place that you're going to go is CRAN.
But for some biological applications, and some big data applications, you might also go to the Bioconductor Project that I have linked to both the websites here.
You can also obtain information about the available packages on CRAN with the available packages function.
And so what you would do is you can enter R, start up, and you'll get a prompt and you can type this command: a.
And then give it the available packages argument just like this.
So instead you can use the head command to look at say a certain number, say just three of those, packages so these are the first three in alphabetical order.
As of the making of this lecture there are approximately 5200 packages on CRAN covering a wide range of topics.
One thing that you can do is if you know the area that you're working in, but you don't know the R package you're after, you can go to the Task Views link which groups together many R packages that are related to a specific topic.
So to install an R Package you primarily use the function install.packages.
So what you would, you could do is just use that with the package name as the argument.
So for example if I want to install the Slidify package what I would do is I would just type install.packages and then in quotes, slidify.
And what that would do is that would go to CRAN and it would install that package on your computer.
Any package on which that package depends will also be downloaded and installed.
This is actually one of the nicest parts about R, is that it's relatively straightforward to install new packages.
And then what that would do is install the slidify, ggplot2, and devtools packages.
You can also install packages relatively straightforward procedure in RStudio, so hopefully you've installed R in RStudio.
You can go up to the Tools Menu and then just go down to Install Packages, and that will open up a folder that will allow you to pick the repository and then pick the package that you want to be able to install from, and it will install that package for you.
Installing packages from Bioconductor is a little bit different.
You don't use install.package, but it's still quite since, straightforward.
So what you do is you go and you type this command, source and then this website right here, and that will load the biocLite function.
And so then first you just type biocLite by itself and what that will do is it will install the basic version of Bioconductor.
That's actually quite a few packages so be prepared for a lot of packages to be installed the first time you run it.
You can also load the packages after you've installed them.
So if you install it, it doesn't mean that all of the functions are immediately available to you.
You need to use the library command to tell R which packages to load in.
So, for example, if you've installed the ggplot2 library, and you want to be able to use the functions in ggplot2, you need to type in the command library(ggplot2) in order to get access to that functions in that package.
some packages produce messages when they are loading and some don't.
And then if you type search, open parentheses, close parentheses, you will see all of the functions that are part of the ggplot2 package.
So the summary is that R package is a powerful mechanism for extending the functionality of our R Packages could be obtained by CRAN or other repositories.
You install the packages, function could be used to install packages from the R console and then library is what you do to load the packages in to actually get access to the functions.
This lecture's about the Types of Data Science Questions.
So last week we covered a lot of installation and building up software and this week we're going to cover a little bit more about the conceptual ideas behind data science.
So there are, a few different kinds of data science questions that I've listed up here in their approximate order of difficulty of actually achieving the goal of that analysis.
So it starts with descriptive, and then it goes to exploratory, inferential, predictive, causal, and mechanistic.
And I'm going to talk about each of these types of analysis over the next couple of slides.
So the first is the descriptive analysis.
So the goal here is just to describe a set of data.
You're not trying to make any sort of decisions based on it or anything like that.
It's the first kind of data analysis that was ever performed.
And it's most commonly applied when you're talking about census data.
Descriptions can usually not be generalized without additional statistical modeling.
So in other words, you are describing what you are seeing in this data but you are not saying what that might be for the next person that might come along.
So an example of a descriptive analysis is this US census.
So this is a picture of the census twenty ten, a website that has collected a bunch of information about people in the United States and they are not necessarily analyzing it to predict something about, .
Another descriptive ex, analysis is the Google Ngram Viewer.
So what this is is it's a collection of information about pairs or triplets of words.
And so for example this is a plot over time of the observation of those, of the words Albert Einstein, Sherlock Holmes, and Frankenstein in books that have been scraped by Google.
And so, again, this isn't trying to infer anything when making decisions.
You could do that, but this is just purely a description of what's going on.
The next is exploratory analysis.
So here you're trying to look at some data and find relationships that you didn't know about previously, but not necessarily confirm them.
So they're good for discovering new connections, and they're also useful to find, for defining future data science projects, where you're actually trying to confirm the exploration that you've performed.
They're usually not the final say on any particular problem, and they usually shouldn't be used for generalizing or predicting.
The important point is that you've probably heard before that correlation does not imply causation.
You've discovered a relationship that is the critical relationship between two variables based on exploratory analysis alone.
So here's an example of an exploratory analysis, where we're looking at brain images and trying to identify regions of the brain that lit up in response to a particular stimulus.
So they explored this data, and they observed, you know, here's a region that lights up in response to that stimulus.
And they haven't necessarily confirmed that that, what that means, but they've just discovered a new connection that they hadn't seen before they had this data.
Another example that's actually hosted here at Johns Hopkin's is the Sloan Digital Sky Survey.
So this is just terabytes or even more of data that has been collected looking at the night sky.
So it's actually pictures of the night sky at different times and at different places that you can explore to try to discover new stars or try to discover how different things in the universe work together.
And so, that data is actually used for exploration, but not necessarily for confirming anything that you discover.
Then inferential analysis is a goal where you're actually trying to take a small amount of data, on a small number of observations, and sort of extrapolate that information, or generalize that information to a larger population.
Inference is definitely the most common goal of most statistical models, and most statistics you may have heard about.
It involves both estimating some quantity that you're interested in and also, more importantly maybe, the uncertainty of that quantity that you're interested in.
And it depends heavily both on the population that you're looking at, the group of people or the group of objects that you care about, and a sampling you've discovered.
So this is an example of, inferential analysis.
So the idea is, here, you're trying to look at the, effect of air pollution control on life expectancy in the United States.
And they're using that to try to infer something about what's generally happening in the relationship between air pollution and life expectancy.
The inferential analysis is that usually a little bit more challenging.
So the idea is to use the data on some objects you collect the data on, to predict the values for another object for the next observation that comes to the door.
An important thing to keep in mind is that even if x predicts y, it does not mean that x causes y.
That's one of the main fallacies that you can run into when dealing with predictive analysis.
Accurate prediction depends heavily on measuring the right variables.
And although there are better and worse prediction models, it's pretty clear that more data and simple model tends to work really well.
So here's an example of a predictive analysis.
So Nate Silver is one of the data scientists I mentioned earlier and FiveThrityEight is his blog where he tries to predict the outcome of U.S.
So what he does is he takes data from polling and he tries to predict what's going to happen in the next Presidential vote.
Here's another example, so it's another sort of bad example, if you were the teen in question.
So, target figured out a teen girl was pregnant, before her father did, by looking at the purchases she made, and it sent her a flyer saying she was pregnant.
Of course, the father and girl was a little upset, because he didn't know that she was pregnant.
But it was example of how you could use data to predict characteristics of people including metadata.
It's substantially harder to identify causal relationships from data.
So the idea is, what happens if you change the values of one variable?
The gold standard for doing this in general is using randomized studies or randomized controlled trials to identify causation.
And you can try to do it from just observed data that you have saved in the database but it's a much harder sell.
You have to make much stronger assumptions about the way that your model is work, working.
Causal relationships are usually identified as average effects, in other words, on average, if we give this population a particular drug, then on average they will only have a little bit longer then if you didn't give them that drug.
So these are usually the gold standard for data analysis in a particular for most scientific applications the goal is to end up with a causal relationship between variables.
So here's an example of a causal analysis.
It's quite a disgusting procedure of giving people transplanting fecal matter into different people so that the bacteria populate their colon and they recover better for recurrent infection of a particular type here.
And so they were able to randomize people to get the fecal treatments and then they determined that his treatment was constantly associated with better outcomes.
Mechanistic analysis is very rarely covered in data science, and so it's important to keep in mind just to keep a full handle on all types of analyses that could be done, but it's very rarely the goal of most analyses.
The idea is to understand the exact changes and variables that lead to exact changes in other variables.
So this is incredibly hard to infer if the NOIDs, data is noisy at all except in very simple situations or in situations that are very nicely modeled by a deterministic set of equations.
The most common applications where this is possible is in the physical or engineering sciences where some more simplified models can describe a lot of the action that is happening.
And generally the only random component when you're doing a mechanistic analysis is measurement error as opposed to any of the other types of variation you might see in data.
So here's an example of a mechanistic analysis where the idea was to try to actually discover, what was the differences and changes that you would make in par, pavement design, that would directly lead to changes in, the functioning of that pavement.
And so those with mechanistic analysis like I said, tend to end up in, engineering applications or in physics applications.
That is a quick tour of the types of questions we will cover in data science.
Since you're in a data science track, it might be a good idea to figure out what is data.
So, for a definition of data we're going to go to the number one source of all information, Wikipedia.
And, we're going to get the definition, data are values of qualitative or quantitative variables, belonging to a set of items.
So, the first thing that you can see from this definition is that you need a set of items to be measuring things on and so, the set of items is sometimes called the population, in statistical inference.
It's basically, what you're trying to discover something about, so, it might be the set of all websites or it might be the set of all people coming to websites, or it might be, a set of all people getting a particular drug.
But in general, it's a set of things that you're going to make measurements on.
So, they might be measurements as in, you measure the height of a person, or you measure the amount of time a person stays on a website, or they might be more qualitative characteristics.
So it might be the places that the person looks on the website or Whether that you think the person visiting is a man or a woman.
And so you, have both qualitative and quantitative variables.
So qualitative variables are things like country of origin, sex, or treatment.
They're not necessarily ordered, and they're not necessarily measurements in that way.
Quantitative measurements on the other hand are usually Measured on a continuous scale, they're things like height, weight and blood pressure.
And, they usually have an ordering on that scale.
So, what do data look like?
So, you might think in your mind, when I say data, it's something like a big excel table, or something like that, but, actually, most data actually starts off in a very raw form.
So, this is an example of a fast queue file, which is a type of file that's produced by a next generation sequencing machine.
So, a typical experiment will produce hundreds of millions of lines of text file that look like this.
And so, you can actually see here in this file, you can actually see a sequence here, of a particular read that comes from a person's genome.
And so, what you want to be able to do is parse that file, and collect those data, and maybe infer something about their genome.
Another way the data might look is an API.
So this is actually a picture of the Twitt, Twitter API website.
And so, what you might do is you might try to get a particular URL.
So you might try to access that URL and get information from it.
Here's an example of a medical record.
So, this is again another form of data.
People are very interested in studying medical records, and trying to understand how people can either improve the way that we insure people or improve the way that we give people medical care.
And so, these data again are text files that, are not necessarily formatted in a very nice way.
Or subtract or extract with different things were ordered and so forth, and then use that data to maybe answer some questions.
Data might also be a video, so in this particular case machine learning experts developed an algorithm that could learn whether a video was a cat, or a video was something else.
It seems like kind of a trivial application.
It's actually quite a hard problem And they solved.
But in this particular case, the data were actually the videos themselves.
Data might also be an audio file.
So this is an example, DarwinTunes, where people actually study the evolution of music over time, where people decided whether, innovations introduced into the audio file were interesting or not.
So, overtime they evolved music that was more melodious and more interesting for people to listen to.
So, the data itself was actually the audio files in this study.
Data might also look like access to files, whether through an API or through spreadsheets through open government websites.
Rarely do data look exactly like what you'd expected to see at, at the beginning of a data science project.
So, here's a very clear easy data set where you've got variables and columns, and observations in rows.
And it seems like it's very easy to analyze.
It's very rare that the data come that easily processed before the beginning of a study.
So, the data are actually the second most important thing in data science.
The most important thing, in in data science is actually the question you're trying to answer.
It's the second most important thing to the question.
Often the data will limit, or enable the questions you're trying to ask, so in other words, you start with the question, and you might not have the data to be able to answer that question, so you have to modify the question, to be able to answer, sort of a sub-question or a related question.
But having data in general, can't save you if you don't have a question that you're asking.
And this is of the key take home message, maybe the theme of this data scientist toolbox, is focusing on having a question that you want to answer with your data and not being driven by the fact that you have data.
So, what we want to do is to allow the client to iterate through the items in the collection.
But we don't have the client to know whether we're using an array or link list or whatever internal representation we might have in mind.
And a lot of clients only want to do is just iterate through the stuff in the collection.
But Java does provide a nice a solution to this called iteration.
So what we're going to do is look at how to make our stack, and queue, and other data structures that we consider later on implement the so-called Iterable interface and it will work for client code no matter which implementation we used so let's take a look at the details of that.
So what's an Iterable?
Well, in Java lingo what an Iterable is, it's, it's a class that has a method that returns an iterator.
Well an Iterator is something, a class that has methods hasNext() and next().
We think that one is bad news, we don't use it can lead to insidious debug, bug debugging problems.
So, it's hasNext() and next() and so to make the data structure iterable, we're going to implement those things.
It seems like a lot of baggage to carry around and the reason that we do it, why do we go to the trouble doing it is that we can, if we have a data structure that's iterable we can use a very compact and elegant client code in Java, the so called for-each statement.
And if we didn't have that we would now, if we're using iterators, we could go ahead and write this longhand code but nobody would ever do that cuz it's equivalent to the shorthand or we might have to write client code that does a lot of unnecessary pushes and pops just to do this iteration.
So that's the key is to be able to have client code that is so compact for iterating through items in the data structure so we're going to provide iteration for all our basic data structures and it's not too hard to do definitely worthwhile the effort.
So here's what it looks like for link list.
So it's got to implement Iterable so what does that mean implement Iterable?
It's got to have a, a method iterator() that returns an iterator.
In this case, we'll call it ListIterator that implements Iterator and it's generic.
And basically what this thing has to do is implement these methods hasNext() and next().
hasNext() is supposed to if, if we're done is supposed to return false.
If we're not done we're supposed to return true and the next() is supposed to give the next item in the iteration.
We have that's the, our first item in the list and we're going to maintain an instance variable current inside this iterator which is the current thing that we're iterating.
So, get the next one just like if we want to remove the first.
The client is always going to be testing hasNext() as I showed as I showed and that stub code before and so when it gets to null it will return false in the iterational stop.
But for our iteration, we just have to worry about implementing next() and hasNext() and perhaps using a local instance variable to get it done.
And then hasNext() is okay as long as that thing is positive.
So a little Java code to provide this iteration facility but actually within this framework not too much to do and you can see how to implement this for your own data type and we'll use this paradigm for every basic data type that we, that involves collections of objects that we'll encounter.
Alright, and in fact, it leads us to actually for a lot of clients it doesn't really matter what order we get the items.
Really often what we're doing is just inserting items into a collection and then, later on, iterating through the items that we have.
Order doesn't matter so all we want to do is add an item maybe you want to know the size and we want to iterate through all the items in the bag.
So this is a simpler, narrower API but still it expresses an important little collection of operations and, and we'll use this one and we've already seen the implementations.
You just take stack and remove the pop, or queue and remove the dequeue and you have fine implementation of a useful data structure.
Welcome to Data Driven Decision Making, the first course in Data Analysis and Presentation Skills, the PWC approach.
I'm Mike Fenlon and I serve as the global talent leader at PWC.
>> And I'm Amity Millhiser, and I'm the chief clients officer for PWC.
In this first course, you'll engage in a high level exploration of the field of data and analytics.
You'll hear from some of our PWC leaders in the area and learn how they applied data and analytics to solve real client issues.
Through a series of videos, readings, assessments, a practice simulation and a course project, you'll explore key topic areas in data and analytics.
>> In week one, you'll learn how organizations use the data and analytics framework to solve problems.
We'll talk about the different careers and roles in the field and you'll begin to explore some of the technology and tools that are impacting how we capture and use data.
>> Week two focuses on the different types of data available that are used to solve problems.
You'll learn more about emerging trends in data and we'll get into the differences between structured, unstructured, and semi-structured data.
In week three, the focus shifts to how data is analyzed.
We'll talk about the different types of analysis you can perform.
And then we'll go into a high level introduction to some of the tools that are used like R, Python, Tableau, QlikView, Excel, and SAS.
Finally, you'll find out how to create visualizations that let your data and insights tell a story.
You'll also have the opportunity to apply what you have learned in an interactive course simulation and course project.
These tools and skills will enable you to extract insight from data and communicate those insights with simplicity and clarity.
>> We're sure you'll find this course an insightful introduction to data and analytics that will encourage you to continue on in data analysis and presentation skills.
The PWC approach specialization, where you will have an opportunity to further develop and apply data and analytic skills to solve problems.
At the end of each week, Mike and I will be back to give you a recap of what you learned and share our perspectives.
Those are some basic data structures and implementations and it seem quite elementary and simple but actually right away we can get to some very sophisticated applications of these basic concepts and that's what we're going to consider next.
Now, first thing to mention is that often the kinds of data types and data structures that we implement or found in a Java library.
So, for example stacks and queues you can find those words mentioned in the Java library so there's a Java collection library and the so-called List interface which is displayed here.
So Java has general API for sequences of items and its got things like a, append at the end, remove from the beginning, and so forth.
Any uses of the resizing array, so many of the principles that we consider does also a, a link list interface.
So, why not just use those?
Well, the problem is often in such library code is kind of designed by committee phenomenon that more and more operations get added and the API becomes too broad or bloated.
It's not a good idea to have lots and lots of, you know, operations in the same API.
The problem, the real problem is that when you do that you can't know much about the performance or you can't assume much about the performance.
And so you can kind of immediately arrive at that performance even for simple clients.
So our best practice that we recommend is so few that these basic data structures that we use and there's so simple is to go ahead and use the implementations that we've just discussed for these fundamental data structures.
Maybe later, later on, after an experienced programmer who knows what he or she is doing could use some of these library collections effectively.
But inexperienced programmers often have trouble with it.
So, we have an assignment where you need to generate a random open sites in a percolation system.
And so, I'll just use that one and pick an index at random and delete and that program took quadratic time and poor Kenny, when trying to run his program for the huge instance that we asked found out that it wasn't finishing.
And the reason is that the Java linked list implementation takes a linear time to find an item with a given index.
And that's difficult for Kenny to think about and difficult to drive that information from the implementation so program is just too slow.
And with the Swiss knife implementation with so many operations it's hard to know whether or not the particular set of operations that your client needs is efficiently implemented.
So our insistence in this course is that students should not use the library until we've implemented it in class.
At least that some indication that you understand the performance characteristics.
So now, let's look at some applications then of, of stacks.
Right now we will look at two examples.
One, having to deal with compiling from a programming language or interpreting into an actual computation and then the other one is the PostScript language which is widely used for, for printing and publishing.
So, so the way the compilers implement functions is using stacks.
When there's a function call the whole local environment is pushed and then along with the return address and then the function returned is pop the return address in the local environment.
The stack contains the recursion.
In fact, you can always use an explicit stack to make a recursive program non-recursive.
And as this graphic integrates, it just does it by saving the information on a stack.
We have operands and operators and you want to evaluate it.
And Dijkstra's algorithm is very simple to express.
You processes through the expression from left to right.
Right parenthesis, you pop the operator and two values and push the result.
So we start out with the empty value stack and operator stack and we're going to move from left to right.
So, that one goes right in to the value stack.
Operator, we put on to the operator stack.
And plus it goes on the operator stack.
It seems strange to be ignoring parenthesis and we'll get back to that in a second.
Value, put in the value stack.
Operator, put on the operating stack.
What it says is to you have the top operator and the top two values and that's what you want to do.
Supply that operator to those values and put the resulting value that you get back on to the operation stack.
So, we take off the top two things, we do the operation and then we put the thing that we get onto the value stack.
The right goes to the value stack and now we got a lot of stuff on the stacks and we got through right parenthesis and that's going to finish up the computation, take the top two items off the stack and the top operator off the operator stack, perform the operation, put the result back on the value stack.
Another right parenthesis, take the top two values off.
Put the value on to the value stack and finally, the last right parenthesis, take the two operators of the value stack, operators of the value stack, and operator of the operator stack, perform the operation, put the result back on the value stack.
Okay?
Here's the code that implements Dijkstra's two-stack algorithm.
The operand stack the operator stack is string, it could be characters which is just our operator.
And then simply perform Dijkstra's algorithm.
If we have a left parenthesis, do nothing.
If we have plus or times, push it.
If we have a right parenthesis, then go ahead and pop the operator.
And if it's plus, add the result of the two values at the top of the value stack and if it's a star, multiply the two values on the top of the stack and, and then push the result.
So and then when you're done then simply print out the value on the stack and that's a fine and elegant implementation using stacks for any arithmetic expression.
And it's easy to extend that to handle other types of things and so, why does this work?
So, just go in from the inside out for every operation enclosed within parenthesis like that it's just repeat the argument that's exactly as if the original expression were (one + five) twenty and then again, replacing that one, one + 100, 101.
That's, that's why Dijkstra's algorithm works.
Actually fairly easy to understand why it works.
And you can go ahead and extend this algorithm to add functions like logs and sines or other operators and have precedence among operators, have them associate and multiple operations, and so forth.
And actually that's on the road to developing a compiler or a way to translate a, a program from a programming language to a computation, so Dijkstra's algorithm that uses stack is one way for entering and understanding of the basis of computation.
Welcome to the first video in the data driven decision making course.
In this first video, Dan will provide you with an overview of what data and analytics is.
As you move through the course, you'll go into more detail about many of the topics introduced in this video.
And we'll be back again at the end of the week to talk about what you've learned.
I lead a global team that helps clients use the data they have and the data need to make better and faster decisions.
Rapid technology change means how we deal with data is fundamentally different today than it was just a few years ago.
In this session, I'll discuss what data and analytics is and why it's important.
The impact it's having on business and how it can help organizations make better and faster decisions.
Webster's define data as a collection of facts, observations or other information related to a particular question or problem.
Data can be structured or unstructured.
Structured data is information with a high degree of organization that could be included in databases or spreadsheets and is easily searchable by simple search engine algorithms.
Think of how a multiple choice question forces your answer into a predefined category.
Unstructured data is the opposite and is usually text heavy though it may contain video, data or numbers and facts as well.
Think of an open field text box that allows you to provide additional comments on a survey.
Adding to the complexity Data can also come from a variety of internal and external sources for organizations.
The conversation gets really interesting when we look at the wide variety of data available to us today, and the powerful analytics that can be applied to that data.
Analytics is the science of examining raw data in order to draw conclusions about the information.
It's an exciting field, and is dramatically impacting how organizations in many industries are making decisions.
Low cost storage and powerful visualization technology is enabling organizations to gain insight once technologically impossible, or economically impractical.
It is also enabling new entities to startup and scale quickly, which can bring great benefit to the market and to society but can also be very disruptive and challenge the status quo.
So where is this data coming from?
From market research and social media, to the network of physical objects we call the internet of things.
The world we live in today is creating a constant and ever increasing stream of data.
For most organizations, the data they can access is increasing at a rate of 40% each year which creates significant challenges in the way data is captured and secured, organized, analyzed and reported.
Let's quickly touch on three ways that data analytics is impacting business today.
First, data is enabling new products and services, creating markets that didn't previously exist and bringing new capabilities to existing markets.
Wearables, such as your Fitbit or Apple watch are some examples of new products.
Second, it is disrupting existing markets with innovative upstarts unseating traditionally secure businesses, think of Uber.
Third, data and analytics is driving increased efficiency.
For example, retailers have the ability to automate and optimize their supply chain.
Tailoring offerings for customers making services such as Amazon's same day delivery in major US cities logistically possible.
In short data is providing the organizations the ability to identify growth opportunities, drive innovation, operate more efficiently, and manage risk in new ways.
So if data can do all that, organizations simply must use it to stay competitive, but how?
Organizations have always use data in some form to inform their decisions.
But the volume, variety and velocity of data available today presents huge challenges.
Traditional approaches to data analysis, identify a problem or business opportunity, collect data, and use spreadsheets or software to understand it no longer apply.
They're using new technology such us data visualization.
The presentation of data in a pictoral or graphical format to help decision markers see analytics presented visually and more easily identified new patterns.
This kind of insight is powerful and can fundamentally change the speed and sophistication of decision making.
At PWC, we work with clients to effectively use data in every part of their business, from customer acquisition, talent retention, and market expansion.
We'll talk more about applying data and analytics in business settings as part of this course.
In future videos, we'll look at some examples and talk to PWC professionals to help bring these concepts to life.
So let's quickly recap what we covered in this short introduction to data and analytics.
We talked about structured and unstructured data and how the explosion of data is leading to new business challenges and opportunities.
We talked about how important it is for organizations to take advantage of all that data and we spoke about how new technologies can help to do that.
By aggregating and presenting data in meaningful and impactful ways, that can help companies make better decisions.
Thanks for watching, and I hope you enjoy the rest of the sessions.
Welcome back.
Organizations are constantly trying to improve and transform, whether to address periodic strategic challenges or everyday operational improvements.
Where their own experience, market insight, and what they hear from advisers.
Let me walk you through a fine example.
For those of you who don't immediately recognize the face, this is Dick Rowe, a music industry executive.
But luckily for Dick, he learned from that decision and was redeemed when he later signed the Rolling Stones.
More than 50 years later, many business leaders continue to rely heavily on intuition to make really important decisions.
Our PWC big decision survey has revealed that highly data-driven organizations are three times more likely to report significant improvement in decision making.
In conversations with business leaders, we often hear that executives have readily available access to vast amounts of data at any point in time.
The question is, how to better combine the art and science of decision making?
At PWC, we believe a more effective use of data combined with the ability to extracts insights, offer opportunities for organizations to drive greater value.
PWC helped develop an analytical model to predict up to 30% of maintenance delays before they occurred.
The cost savings to the organization was in the millions of dollars for the pilot stage of the effort.
Thereby helping the airlines stay ahead of it's competition on timely performance.
Another client of global financial services organization needed to strengthen its internal anti-money laundering and counter terrorist financing controls.
Besides the obvious benefits from this program, they also wanted to improve regulatory relations and gain deeper insight into their business.
PWC develop a model to connect the series of data sets and performed trend analyses that uncovered a network of relationships among accounts.
We also developed real time dashboards and visualizations to more efficiently monitor for suspicious activity and identify operational risks.
Lastly, we worked with an oil field services organization to improve utilization of its field office staff.
With our client, we combine the organization's global field activity data with utilization, cost, employee demographic and other information to develop an analytical model, to improve operating cost, as well as improve speed of response to its clients.
So, lets recap what we covered in this video on how businesses solve problems and where data and analytics fits in.
Organizations are constantly trying to improve, whether they are addressing new challenges and opportunities, or trying to make operational improvements.
When we overlay data and analytics on this process, the result is better and faster decision making.
In the next video, we'll take an in depth look at the data and analytics process used to help make big decisions.
In today's environment highly data driven organizations are making better and faster decisions.
At PwC we believe data and analytics can make a huge difference when it comes to the most significant decisions about the strategic direction of an organization.
Now, let's take a look at how data helps organizations make decisions.
Decisions that will shift the course of a business, or even an industry, and shape the world we live in.
These are what we call big decisions.
They set the direction for the business and are both high value and high stakes.
They can be reactive, forced by circumstances beyond our control.
Executives tell us their decision making lacks the sophistication and speed they need for competitive advantage, the sophistication to reach clarity on critical decisions, creatively use new sources of data, use analytics to assess options and estimate value.
And the speed to opportunistically make decisions, quickly source and experiment with new data, monitor results, and adjust decision making.
To think as expansively as technology makes possible, we need to bring together our most powerful assets, the art of instinct and experience with the science of data and analytics.
So the decisions like growing or shrinking the business or collaborating with competitors are seen more clearly.
We will have more opportunities to identify, model, and map multiple futures, reducing the risks of innovation and accelerating the decision making process.
So that we'll not only be there for the next big breakthrough, we'll be leading the field.
Executives in highly data driven organizations are three times more likely to report significant improvements in their decisions.
So, in a world where opportunities are more complex and more accelerated, and technology will continue to deliver evermore data, inform our experience with analytical power for those decisions that really count.
By blending the art of leadership and judgment with the science of analytics excellence, we can make better and faster decisions.
Learn more about improving your ability to compete with our practical advice on better decision making.
Get started by visiting our website.
>> In this video, you heard how organizations make thousands of decisions every day.
Some are simple, but some are very complex and can shift the course of a business or industry.
These big decisions set the direction for a business.
Data and analytics help solve these problems.
In the next video, Anand Rao will introduce the data and analytics framework.
Anand is a principal in PwC's data and analytics team.
He is our Innovation Lead, Global Co-lead for Future of Insurance 2020, and an artificial intelligence specialist.
Anand will discuss how the data and analytics framework can be applied consistently to solve problems.
I am Anand Rao and I lead a team of data scientists.
We're constantly looking for innovative techniques, tools and technologies to apply to our client problems.
We work closely with academic institutions, start-up companies and establish clients to bring innovative solutions.
I'm going to talk about the compliments of the framework and explain why it's important to follow a framework when solving a business problem.
Let me give you an example.
A global insurance company came to us with the desire to incorporate advanced data and analytics within their organization.
They're a number of business objectives that they wanted to achieve, including improving retention and cross selling in one country and increasing acquisition in another country.
They wanted to build an analytics organization, while at the same time ensuring that they solve a business problem.
We went through our data and analytics framework to first determine the outcomes in each country.
For example, as we said, greater cross-product holding in one country.
Then we listed all the actions or decisions they can take to effect that outcome.
For example, who to target, when, why and through which channel.
That led us to investigate how they were making those decisions today and how they could be improved with better insights.
For example, insights around next best product, channel preferences.
This led us to the techniques that are required to generate those insights and the data required to generate those insights.
For example, characteristics of existing customers with one, two or three products with the client.
So why do we need data and analytics framework?
The short answer is a framework allows you to move through data analysis in an organized way.
It provides you with a process to follow as you walk with your teams and clients to solve problems.
The framework allows us to focus on the business outcomes first and the actions and decisions that enable the outcomes.
It focuses our attention on what generates value to our clients first before examining all the data that we do have or data that we don't have that needs to be procured.
In summary, the framework allows us to structure of a discretions with the client and follow a path that leads to actionable insights and business outcomes.
If you're not using a framework, there's a good chance that different people will use different approaches to solve the same problem.
And then try to figure out all the cool analytics that one can do and then try and figure out how they can be applied.
It is an approach that is fought with dangers of overanalysis and a hammer looking for a nail to hit.
Welcome back.
In this video, we're going to talk about five types of data analytics, and the tools used to help build our analysis.
These are the broad categories that will help you deliver on the data and analytics framework we discussed in the previous video.
The framework is abstract, but these types of analytics will help you operationalize it.
As we discussed earlier, one of the common uses of analytics in marketing is in cross-selling multiple products to customers.
When we looked at the outcome of increasing the number of cross product holdings of our customers, we started with the descriptive analytics.
We looked at their data to profile their customers with respect to one product holders, two product holders, etc.
These profiles included the sociodemographics of the customer, their online and offline behaviors, their attitudes, life stages at which they bought these products, and so on.
It lets you look at what is happening today and it's what has happened in the past.
This type of analytics typically provides summarized information to understand currently existing sales patterns or customer behavior, customer profitability, past competitor actions, etc.
Specific techniques might include simple box plots, histogram charts with means, minimums, and maximums.
Descriptive analytics is very powerful for understanding the current state of affairs and for developing the hypothesis to anticipate where business problems and opportunities may lie.
It helps us answer the question, what happened?
For example, from the descriptive analytics, it was clear that a large proportion of the customers of the insurance company we talked about in the previous video, had only one product, and a very small number of customers had four products or more.
In addition, there were three products that all had more or less equal share within the one product customers.
After we had a good description of what the cross product holding of the different customers were, we started investigating why the cross product holding was so low.
It turned out that the insurance company had multiple channels to sell their products, captive agents, independent agents and telemarketing staff.
Each of these channels sold a specific type of product well and this resulted in an equal number of one product customers across all three channels.
Given the expertise of these channels, there was very little cross selling.
Multiple product holdings was more a result of customers demanding the additional products, as opposed to any deliberate cross selling process.
It provides the reasons for what happened in the past.
This type of analytics typically tries to go deeper into a specific reason or hypotheses based on the descriptive analytics.
While descriptive analytics cast a wide net to understand the breadth of the data, diagnostic analytics goes deep, probing into the costs of issues.
For example, we might look at creating a decision tree analysis of the cross product holdings to reveal the types of customers who have bought these products, the channels they use, the products they've bought and when they bought them.
Once we knew what some of the major issues in a low cost product holding were, we started formulating hypothesis on what we can do to increase cross-sale of products.
We built predictive model to rank customers on their propensity to buy a specific second or third or fourth product.
This predictive model was built based on the understanding we gained from the two previous steps of descriptive and diagnostic analytics.
Predictive analytics lets you envision what could happen in the future.
Predictive analytics typically predicts what could happen based on the evidence we have seen.
In our insurance case study, once we've built our propensity model, we were able to identify some of the high potential targets for cross sale, and what product they should be cross sold.
Given the different propensities to buy, we computed the next best offer for each and every customer and how the cross sell message should be personalized for each customer and distribution channel.
Prescriptive analytics goes beyond providing recommendations to actually executing the actions or taking the decisions that are right for a particular situation.
It does this by looking at what happened in the past, the present state and all the future possibilities.
Prescriptive analytics provides answers to the question, what steps or interventions need to be taken to achieve the desired outcomes?
It frequently involves scenario analysis and or searching for optimal solutions.
Prescriptive analytics is powerful in understanding the right actions needed today to address future possibilities and put an organization the best possible position to take advantage of future conditions.
While we built a one off solution for the client to increase the cross-product holding of their customers, what they really needed was an adaptive and continuous system that learns from the behavioral interventions and actions taken by customers to automatically change their recommendations and try out new measures.
Certain always on insights platform where the system builds a model of the real world, takes actions, learns form the environment, and continuously adapts itself is the ultimate adaptive, autonomous solution.
Adaptive and autonomous analytics is still in it's infancy, most systems today are either predictive or prescriptive.
However, there are a number of companies that are building more adaptive, or autonomous analytic solutions where we are eliminating the human in the loop.
Autonomous car driving is a great example of an adaptive or autonomous analytic solution.
Adaptive and autonomous analytics provides answers to the question how does the system adapt to changes?
Constantly learning and correcting its behavior to optimize its performance.
We may not want to build adaptive and autonomous systems in all cases.
There may be instances where we may want to retain the human decision maker.
But there may be other situations where the speed of decision making, is such that having a human in the loop may be counter productive.
Now that I've given you a high level overview of the different types of analyses, let's look at the tools available to help you perform each one.
Descriptive and diagnostic analytics usually rely on analytic tools that can handle manipulation of large sets of data or that help visualize and interact with summarized information.
Examples include SQL, Oracle database or Oracle DB, Hadoop/Spark, Tableau, QlikView, Microsoft Access, SAS, R, Python and various statistical packages within them.
Predictive and prescriptive analytics have traditionally relied on analytics tools that have significant mathematical modeling capabilities or scenario planning or simulation capabilities.
Examples of these tools include SAS, R, SPSS, Python, and various packages associated with them.
Optimization tools like Garrobi, ILOG, RiverLogic, etc.
Simulation tools like Vensim, AnyLogic, STELLA.
Machine learning and deep learning tools, like Scikit, TensorFlow, Caffe, Theano, etc.
Natural language processing tools like NLTK or Natural Language Tool Kit or OpenNLP.
In this video, we talked about five different types of analytics you can use to analyze data.
Descriptive analytics helps you understand the current state of the problem and answer the question, what happened?
Diagnostic analytics helps you understand why it happened or the underlying causes for the observed data.
Predictive analytics helps you understand what could happen in the future given certain conditions.
Prescriptive analytics helps you understand the right course of actions needed today to address future concerns.
Adaptive and autonomous analytics helps you answer the question of how to continuously adapt to change.
We also took a very high level look at the tools available to help you perform these analytics.
Later in the course, we will take a much closer look at what some of these tools do and how they provide value.
In the next video, you'll have the opportunity to hear some of our PWC professionals talk about data and analytics at PWC.
Today I'm joined by Paul Blaze, PWC's Global and US Data and Analytics Consulting Leader.
We'll hear from three business leaders who joined the PWC's round table who joined on fall of 2015.
Even in a world where we're able to make increasingly more sophisticated and faster decisions, we're not suggesting it's just about the data.
But how do you really kind of combine that in the best possible way?
>> When you think about all the databases, the systems being design in your organizations, how they interface with the users.
Is there a better way to combine the art and science of decision making with all the tools we have available?
>> But I like to actually think of it as a translator skill.
You need someone to ride along as the business is exploring the business problem and you have this highly technical person who understands capabilities, but they don't understand each other's worlds, right?
And if you have someone who does on your team, utilize them much like you would use a data scientist as a shared service, and they actually become a translator.
The clientine, based on the problem, brings together the technical person, with the client engagement manager, to make sure that two things happen, right?
The work that has been done appropriately reflects the question that the executive is asking and then it's presented back in the way that work's for you not for the analyst who did the work.
>> The biggest data successes I have seen are when somebody takes idea from one domain combine's it with a data asset they have and just come's up with a brilliant execution in the news base.
And those are the kinds of things you only can see if you understand the technology and its capabilities, you understand your data and what it can actually tell you about the world, and you are thinking about the future of business all at the same time.
>> We all, in our respective industries we're used to saying, what is happening?
Which is root cause analysis.
And I think that we're all working through those three layers pretty rapidly as industries.
You just heard PWC professionals and business leaders tell us how they made better and faster decisions using data and analytics.
Take sometime to think about it and then join other learners on a discussion board.
In the next video, we'll look at how technology advancements and data trends are changing the ways organizations use data.
I help clients solve complex tax challenges by helping to deliver quality data to the right people and enable them with effective processes and technology.
After changing my career focus a few years ago, I have a significant focus on data and analytics to improve how tax professionals work.
This is fundamental in tax.
We must apply the law to the specific circumstances, and use data for a tax payer to determine their obligation to pay tax under the law.
At PWC we think of data as the life blood of tax professionals.
Without access to quality data, our ability to provide advice and guide the business in making decisions is greatly diminished.
For several years, many tax professionals have worked with data in whatever format was provided to them.
Changes to the source data often require a rework of these manual processes.
Not a great use of time for these subject matter experts.
These challenges play out both within PWC and at our clients.
The solutions we bring to clients focused on people, process, data and technology.
Our solutions usually touch on all four areas and almost definitely will touch on data.
Helping to deliver quality information to tax professionals when they need it is a key element of our work.
There are many ways we approach these challenges, including transforming the raw data, improving the way in which non-standard data is collected and using analytics to help visualize or bring a different perspective to the data.
Tax is a challenging and technical area of study which traditionally has not how it's been well understood throughout organizations.
Analytics is helping to bring tax to the forefront since a well crafted analytics report can communicate in complex content and improve the ability of the business to make decisions.
So, having a clear understanding of the organization's obligations and tracking the status of those is imperative.
For many organizations, this is a manual and time consuming process.
We've helped many organizations to leverage technology to reduce the effort and risk associated with these activities.
In addition, the technology allows us to standardize the collection of data across the globe in real time.
An immediate benefit is that we can generate analytics on data and produce reports that allow people to visualize the information in a different way.
For example, we use a world map to display the status of tax filings in each jurisdiction around the world.
This can bring life to information which historically has been viewed in a two dimensional spreadsheet and is usually several days out of date.
Transparency and information reporting are high in the agenda of tax authorities around the world.
This requires tax professionals to produce reports for new and changing requirements.
This is extremely challenging using traditional approaches.
We have helped several organizations to rethink the approach to collecting information for these reports and reduce the effort and risk in the process.
Having collected the information we also build analytics to give them deeper insight into the information so that they can consider how the information may be perceived.
This allows them to proactively plan and provide better insight and support to the business.
There are diverse skill sets needed to solve problems using data and analytics.
For me, most importantly is communication.
We often need to address business, finance, technology, and tax technical considerations to solve these problems.
It's rare that one person has the professional experiences to solve the problem alone.
As a result, communicating within a team of diverse individuals is critical.
I started my career focused on using data analytics to help clients solve problems.
This meant thinking about better ways to collect data, analyze it, and present it in meaningful ways.
Solving problems using an analytical approach is a differentiator for professionals today.
There's such demand for people who can understand business problems, and then apply analytics.
The ability to use machines and computers to help us process information has rapidly increased in the last 10 years.
Every time we look at a problem today we have to think about how we can collect more information, how we can process it and visualize it so we can get a better answer in the end.
Personally I work in financial crime.
And I helped our client used data to prevent money laundering, fraud, and identify bad actors externally and internally.
We used huge amounts of data, customer data, transactional information To find needles in the haystack that lead to the identification of suicidal issues like human trafficking, narcotics dealing, and tax evasion.
Today we're using web crawling and machine learning to identify events and potential threats to our society using more data than ever before.
As the need for more analytics increases, we need to raise the IQ of every professional to be able to conduct sophisticated analytics and breakdown traditional skills of barriers.
>> In this video you heard how we apply data and analytics to solve problems.
You also heard about the key skills needed to do so.
You can learn more about data and analytics careers and roles at PWC by reading the white paper that follows this video.
You made it through the first week.
You learned about why data and analytics is important, and spent some time learning about the data and analytics framework.
You also had the opportunity to spend some time this week hearing from our PWC professionals, and they talked about the skills needed to perform data and analytic tasks to solve problems.
>> You've now read and discussed the white paper on careers and roles in data analytics and data science in the professional services industry.
I know Amity would agree that building data IQ and related skills is quickly becoming a requirement for a career in business.
And by taking this course all of you are building the foundation of knowledge that will be highly beneficial for your careers going forward.
In this video, Alex Mannela will share where he's seen data and analytics in action.
Adding value to business practices, helping leaders make business decisions and where it's having an impact from data modeling to social media.
I'm Alex Mannella and analytics and data has played a critical role to me and my career over the past 20 years.
Data and analytics continues to add value to organizations by examining how decisions are made.
Next generation analytics can automate the way decisions are made in areas like making inventory management, financial risk management, and sensor data management.
There is enhanced visibility of relevant information and massive amounts of data are now easily accessible.
We can use retail, social and clinical data to precisely customize offerings and marketing campaigns to consumers.
Think about how the ability to use employee data to search for and discover new needs can enable organizations to fine tune optimal performance and efficiency.
By using data and analytics to identify emerging trends, organizations will be able to create new service offerings for their consumers.
Using data and analytics isn't limited to only high tech industries.
Whatever sector you operate in, be it finance, healthcare, retail, or just about anything else, data and analytics can and will play a critical role.
Some examples include discovering patterns in large numbers of service requests for a large bank, discovering which brands are most similar based on social media platforms and followers on each, gaining insight into an annuity policyholder behavior based upon terabytes of consumer data.
Now, when one observes or collects data firsthand, this is called primary data.
Primary data is very valuable in getting consumer behavioral insights.
If asking a consumer what kind of coffee they like or what kind they intend to purchase, we don't learn what they've actually purchased.
That's where secondary data comes in.
Secondary data is data that is collected by someone or something else.
In this case, one could collect the data from someone's credit card statement and determine whether or not they actually bought the coffee.
Both primary and secondary data are used in building strategic decisions.
Right now, rapidly evolving technology and the availability of real time data is allowing organizations to use data analytics as the true game changer and the table stakes of the future.
Our clients are coming to us because their customers are expecting that this data is to be used to improve communications, improve products, and ultimately the services that are being offered.
If an organization is going to be an industry leader or an innovator, analytics is key to understanding correlation and causation in turning strategy into reality to.
Organizations today are facing information overload as data increasingly comes at them in new formats, and at faster speeds and higher volumes than ever before.
So they can address the progressively complex decisions they have to make from operational control, to management control, to strategic planning.
The groups, the analytic centers of excellence, and how to take these organizations to the next level to drive value.
What does the organizational structure need to look like?
What does it mean?
If you can't get the data through the organization efficiently, it's just a statistical model or it's just an answer.
Our clients are challenging us on a daily basis to help them figure out what an organization that fully uses the data and analytics must look like.
Another vital source of data is social media.
Generally, social media is defined as a set of internet technologies that allow users to generate and share content, collaborate, exchange ideas and form community with shared or opposing interests.
So many clients think there is so much to find, but there is a lot of noise in social media.
So how do you extract that signal from the noise?
It's important to look at data collected from social media platforms, along with all other relevant datasets.
Social media is a powerful platform but it's one that many organizations are chasing, and don't have a sound social media or overall integrated data strategy.
When you think about data and analytics, you need to think about the social media strategy in the organization.
What can someone bring from a social perspective?
Being able to challenge how social media is being used, and if it's going to be used from an analytics perspective.
Whatever social media data an organization is trying to use, it's very important that you tie it to other relevant data sets to validate findings and ensure the accuracy of what you are projecting.
We've seen our organizations misuse data from social media and not tie it back to other data assets that they have into the analytics and models that they are building.
When used properly, data and analytics can change how organizations operate, allowing them to become more efficient and have greater impact on their bottom line and most importantly, their customers.
Now let's look at how data and analytics can be used in the retail industry.
Companies can use consumer purchase data, social networks, and geolocation information to optimize product mixes and make decisions related to product development.
For example, a retailer can use data generated from consumer mobile devices for location based sales and offerings.
Take a local drug store where a customer has their mobile app installed on their phone.
Organizations can also use data from mobile devices for payments and purchase patterns.
The organization can go well beyond just pushing offers, but using the data and analytics to optimize products and segments is one of the core components that underlies social media and data analytics.
The operations department at the same retailer can evaluate store traffic patterns to improve product placement and point of sales processes.
And finally, the service department can evaluate online and real time interactions to improve and tailor in-store and post-sale experiences.
Another example of data analytics in action is from the healthcare industry.
In terms of product development, analysis of disease trends in clinical studies can direct, and optimize research and development efforts for drug discovery.
Data can help bring new drugs to market more quickly, and more efficiently, using things like claims data to more efficiently communicate with policyholders on how they can manage their health and prevent specific disease or illnesses from happening, diabetes or the common cold.
Analysis of patient history and disease patterns allows sales and marketing teams to target patients with care or lifestyle improvements.
By using claims data and patient demographics, hospitals can improve operations by optimizing treatment selections.
And in terms of customer service, health care providers can improve treatments and manage chronic illnesses through data collected from ongoing patient monitoring.
As the processing capacity of data analytics continues to increase, it opens the door to a broad range of advanced algorithms and modeling techniques that organization can employ to draw a valuable insights from data and analytics.
There are different ways to model structured and unstructured data.
Of course there are the traditional methods, but we also see many new modelling techniques emerging to handle all the different types of data that is available.
For the analytics individual or for the advanced data scientist, there are a portfolio of methods that can be used today, more so than ever, given the advancements in processing power, mathematics, data storage and most importantly visualization.
Having the right people, the right tools, and the right algorithms in place to take advantage of the massive amounts of data that organizations have access to today.
In this video, we've learned how data and analytics is helping add value to business practices And becoming a critical game changer in making business decisions.
Today we're going to look at Mergesort, which is one of two classic sorting algorithms that are critical components in the world's computational infrastructure.
We have a full scientific understanding of the properties of these algorithms, and they've been developed as practical system sorts and application sorts that have been heavily used over the past 50 years.
In fact Quicksort, which we'll consider next time, was honored as one of the top 10 algorithms of the 20th century in science and engineering.
On this lecture we're going to look in Mergesort, which is the basic sort in plenty of different programming systems including Java.
Next time we'll look at Quicksort which is also used in Java for different applications.
What's it going to look like?
The idea is very simple.
What we're going to do is divide an array into two halves.
Recursively, recursively sort each of the halves.
And then merge the result.
That's the over-view of Mergesort.
It was actually one of the first non trivial algorithms I implemented on a computer.
He's widely accredited as being the inventor of Mergesort.
So the idea of Mergesort is, is based on the idea of merging.
So, we've got an array A and its first half is sorted and its second half is sorted and the computation we need to perform is to replace that with the sorted array where those two sub-halves are merged together.
Let's look at a demo.
The method that we're going to use is based on taking an auxiliary array to hold the data.
This is a, one of the easiest ways to implement the merge.
So the first thing we do is copy everything over to the auxiliary array.
Now, once that's done, what we'll want to do is copy back to the original array to get it in sorted order.
In order to do that, we're going to maintain three indices.
I, the current entry in the left half, j, the current entry on the right half and k, the current entry in the sorted result.
so the first thing we do is, take the smaller of the two entries pointed to by i and j, and compare those, and take the smallest one, and move that one to be the next item output.
Now we compare the minimum again, again, the one pointed group by j is smaller, so we move that one to k.
Now there's two E's, equal we always take the first.
So the one on the left array goes to k's position.
And again, it's an E and they're equal.
We'll take the first one so we move that one up increment i and k.
And now j's E is smaller than g.
It's the next thing that has to go in the output.
Now the one pointed to my i, the G is smallest so move that and increment i and k.
Now the last element in the left sub array is the one that's going to get moved next.
And now that first subarray is exhausted so really all we need to do is take the rest of the elements from the right part and move them back in.
Actually since we copied, we could optimize by avoiding these moves.
That's an abstract in-place merge for taking the two sorted sub-halves of an array using an auxiliary array, move them out, and then put them back in in sorted order.
Alright, so here's the code for merging, which is quite straightforward from the demo.
We first in order to sort an array of comparables in this implementation we pass a link to the auxiliary array, in as well.
And we have three arguments lo, mid, and hi.
Mid's the midpoint that divides the first part from the second, so our conditions are that from lo to mid is sorted, and from mid plus 1 to hi is sorted.
We start our I pointer at the left heart on the left half.
And for every value of k what we're most often doing is comparing whether aux of j is less than aux of i.
And if it is, we move the element of j over in increment j.
If it's greater we move the element i over in increment i.
If the i pointer is exhausted, then we just move over the j, next jth element.
So every time we're moving a new element into k and that's the code that impelements the abstract in place merge.
In this case, this insertion just says we want to be sure that a of lo to mid assorted and that mid plus one to high is sorted before our code and then we want to check that, the whole thing is sorted after our code.
And generally programmers, Java programmers know that it's a good idea to try to do these assertions.
Not only does it help detect bugs, but it also documents what the code is supposed to do.
And that merge code is a good example of this.
If you put at the beginning of the code what you expect in the, in the form of an assertion, which is code itself.
And you put at the end of the code what you think it's going to do, again in the form of an assertion.
You're both testing that these conditions hold, and also telling someone reading the code, what you're trying to do with it.
So Java is just an assert statement.
In this case, we're using that method is sorted that we were before.
That returns true if the ported is sorted and false if it's not.
And that's really important, because it means you can put them into your code to check while developing.
But it doesn't incur any extra cost at all in production code.
Something goes wrong somebody analyzing the situation can enable insertions and they often will help find out where, what the problem is.
So, the best practice is to use insertions just as we did in that example with merge and to assume that they're not going to be there in production codes.
You shouldn't use them for the things like checking if the input is the way you like it.
Alright, so with that merge implementation, then the sort implementation is a quite simple, recursive procedure shown here.
So we use the merge procedure we just showed, and then our sort procedure.
It's recursive so, checks that we have something to do first.
Sort the first half.
And then the actual sort is takes just the one argument of the array creates the auxiliary array and then uses that.
Now, it's important to not create the auxiliary array in the re in the recursive routine because that could lead to extensive cost of extra array creation.
And you'll sometimes see Mergesort performing poorly because of that bug.
Otherwise this is a very straight forward implementation.
And it's actually a prototype for algorithm design that we'll see come up again and again.
Solve a problem by dividing it into two halves, solving the two halves, and then putting the solutions together to get the appropriate answer.
here's a trace of what Mergesort does and if you haven't studied a recursive program before it's worthwhile studying this thing in, in some detail.
This gives exactly what happens during each of the calls to merge.
We start out with a big problem to solve but we divide it in half, then we divide that one in half, and then we divide that one in half.
And the very first thing that we actually do is just compare and exchange if necessary the first two elements.
And then we do the same thing for the next two elements.
Then merge those two together to get the first four done.
And then we do the same thing for the next four in the array.
And we merge those together to get one of size eight.
And then we do the same thing on the right, and eventually we have two eights that we merge together to get the final result.
Very instructive to study this trace to really understand what this recursive algorithm is doing.
So now we can animate and again Mergesort's more efficient, so we can do more and more items.
You can see it's got the first half sorted, now it's working on the second half.
It's got a little extra dynamics in the animation because of the auxiliary array.
So you can run a Mergesort on huge problems.
It's a very efficient algorithm.
And so, for example, what this table shows, if you were to try to use a insertion sort for a huge file, say a file with a billion elements, on your PC it'd take a few centuries to finish.
Even on a super computer, if you're using insertion sort nowadays it'd maybe take a week or more.
But if you have a good algorithm like Mergesort, and you're trying to do a billion items, you can do it in just less than half an hour on your PC.
So you can spend a lot of money or a lot of time, or you can use a good algorithm.
A good algorithm is much more effective than spending money or time wasting money or time using a bad one.
So let's look at the analysis of Mergesort, that's a bit of math but very instructive because this really shows the power of the divide and conquer method.
And allow us to take a problem that was taking us quadratic time with methods like insertion and selection sort, and get it done in, in log N time with Mergesort.
So that's the proposition Mergesort uses at most N lg N compares and 6 N lg N array accesses to sort any array of size N.
And the way to prove this proposition is to from examining the code, to write down what's called a recurrence relation.
And all that is, it's a mathematical reflection of what's going on in the code.
If we're sorting N items then let C of N denote the number of compares that we need to sort the N items.
And then for the merge, we need at least, at most N compares.
If neither one exhausts, we need exactly N compares.
And so and that's true as long as N is bigger than 1.
If there's only one thing, we're not doing any compares at all.
So this is a mathematical formula that we derive by examining the code but it completely describes mathematically what we an upper bound on the number of compares that are going to be needed.
And similarly for the number of array accesses, if you count up the number of times you're accessing an array for a merge you could be at most six in.
So these are mathematical formulas and there's techniques for solving them and we won't go into that.
This is not a course on discrete mathematics.
But what we then do is show how to solve the recurrence when N is a power of 2.
And then it turns out that it holds for all N, which we can prove by induction from the recurrence.
So if you have this recurrence which is similar to the ones that we're talking about.
It's exactly the same when N is a power of 2 let's, let's look at this one.
If N is a power of 2, then N over 2 is also a power of two, so the recurrence makes sense.
So this is just a graphical representation if we want to compute D of N we want to compute D of N over 2 twice.
And how many stages do we have here?
Well, it's the number of times you divide N by 2 to get down to 2.
That's exactly log base 2 of N, so the grand total of all the costs for the merge, which is where the compares are, is log N times N, N log N.
It's kind of a graphical proof or a proof by picture that that recurrence has that solution.
Here's a little bit more mathematical one: we write the recurrence down, and then we divide both sides by N.
The first term on the right hand side is exactly the same as the left hand side so we can apply the same formula.
And we keep doing that until we get down to D of 1 which is 0.
So we get D of N over N equals log N, or D of N equals N log N.
That's another proof by expansion.
Or using either one of those techniques you could just get the idea that D of N is close to Log N or you can write a program to expand the recurrence and find that.
And then once we have the idea that D of N equals N lg N, we can plug back into the original formula.
With the inductive hypothesis that D of N equals N lg N, we want to show that D of 2N equals 2N lg 2N, using the recurrence D of 2N equals 2D of N plus throw out the 2N.
We use this same idea on our initial recurrences for comparison array accesses to show that the running, the number of comparison array accesses is proportional to N log N for Mergesort.
And one of Mergesort's characteristics is that in practical applications, it uses extra space proportional to N.
That is, we need that extra auxiliary array for the last merge.
We want to fill up the memory with stuff to sort and then sort it.
And search and selection in shellsort are in place, they don't use any extra memory.
But Mergesort you can only sort really half of what you can fit in memory, because you need that auxiliary array for the other half.
If you want, again, if you think that the things we're studying are easy, think about the idea of actually doing an in-place merge.
People have come up with methods for getting this done.
So it's theoretically possible, but the methods are generally too complex to be useful in practice and their not used.
But there could be out there some easy way to doing in place merge.
That's another great algorithm waiting to be discovered.
First thing is that Mergesort is too complicated to use for tiny arrays.
So say the subarrays are only of two, or three, or four there's too much overhead with the recursive calls and so forth to get that done efficiently.
And what's worse is, the recursive nature of the sort definitely means that there's going to be lots of subarrays to be sorted.
So, one improvement that we can make is to use insertion sort, and just cut off and use insertion sort which is simple and efficient for small subarrays.
So that's adding this one line of code to Mergesort will make it quite a bit faster.
The second improvement that we can make that'll improve the performance for cases when the array is partly sorted, is to just stop if it's already sorted.
And that's going to happen in the case where the biggest element in the first half is less or equal to the smallest item in the second half.
That means it's done.
So that's easy.
We just put a test in the recursive Mergesort for that, through this one line of code, to check whether we're done.
That way, for example, if you were to call Mergesort for an array that's already in order it would just do this test every time and it would be done in linear time.
The other thing that's possible to do and it's a little mind bending so recommended only for experts.
Is to save a little bit of time you don't really have to copy over into the auxiliary array.
You can kind of switch the role of the input and the auxiliary array every time you make a recursive call.
You still need that array but you can set up the code in this way which sort, to sort an array, put the result in the other one.
To merge an array, put the result back in the first one.
And it's effective, it means you don't have to actually move items, and that saves a little bit of time.
So you got a visual feeling of how this sort gets the job done.
So it's the first little chunck and then the next little chunk and then merges those together, and so forth and so on.
It's a good visual representation of how Mergesort gets its job done.
Welcome back.
Let's start with agriculture, one of the oldest sectors.
Farmers are typically use their experience and the weather to decide when to plant seeds, when to irrigate them, and when to harvest them.
But now thanks to advance analytics, they can log into a system and analyze the best time to plant their seeds to obtain the best yield.
Selects the money if you want to invest for the next two years and let the system know our risk appetite.
The robo-advisor then selects the right mutual funds and ideas or exchange traded funds that she should own buys them through the exchange and continuously monitors the value of her portfolio and is ready to sell if the situation warrants.
When we look at what's going on in the world we can see three major implications of technology advancements.
Let's start by talking about how customers are changing the way they choose products and services.
Online sales of products is increasing, and organizations need better online marketing and access to optimal distribution channels.
At the same time, customers increasingly rely on information from social media.
Organizations need to be aware of changing customer behavior and perceptions.
The farmer practicing precision agriculture is demanding timely information, relevant and personalized information with respect to their firm and what they should do.
Similarly the high net worth in professional is making decisions late at night from the comfort of her home.
In both cases, the customers trust their online systems but have high demands on simplicity, personalization, ease of use, and transparency.
Next, let's consider how competitors are faster and nimbler than ever before.
For every organization time to market for competitors has decreased.
Managers at all levels need to access information on market changes so they can make quick adjustments in product strategies.
Although the initial decision supports software product used by the farmer was from a start-up.
Where start ups innovate and established companies acquire them in order to become more nimble and competitive.
Now you see all of the major agribusiness companies using advanced analytics censors and other technologies to extract more from the farms.
Similarly, the use of digital advice or robot advice is now no longer restricted to just startups.
There's an arms race within the asset management sector to build better analytic tools for their customers and advisers.
Better global connectivity has allowed businesses to purchase imports from around the world.
This makes purchasing decisions more complex.
Increasingly, industry sectors are becoming more global and interconnected.
Internet of things and sensors are revolutionizing physical supply chains and enabling data driven optimization and decisions.
For example, the robo-advisors can manage funds across multiple parties distributed across the world.
They can execute trades 24/7 and they're not dependent on the traders in each local market.
The business benefits from advance data and analytics are four-fold.
Increased revenues and profits as companies look at hyper targeting customers and selling tailored solutions to them.
Decreased cost and enhanced productivity as more automation takes over from human decision making.
Better customer experience as the omni channel interactions for why the convenience for customers and the low cost for providers.
Reduced risk and better quality as standardization and automation become the norm.
Increasingly, the workforce will be asked to focus on high value tasks as more of the repetitive, manual and intellectual tasks are taken over by machines.
Over time, the ability to use data and analytics and make data driven decisions will become standard practise.
Data and analytics is becoming a part of the rapporteur of all of our consultants.
There are three key factors increasing the relevance and importance of data and analytics.
The amount of data generated has exploded because of technology advancements.
There are many new types of data available that cover a much wider range of activity.
In the new normal of lower growth, regulated markets and cost constraints our clients are increasingly considering data and analytics as unexploited assets they can use to help them meet their goals.
Technology has changed the data we have access to and how we can analyze and then visualize that data.
We are now seeing things like big data, non-traditional data, information synthesis, sophisticated analytics and visual insights.
Let's talk about what each of these are.
The exponential growth of data and computing power is multiplying the number of opportunities to drive insights from information.
That's what we call big data.
Nontraditional data are telematics, satellites, voice, video-to-text, and other emerging technologies that create data from previously non-quantifiable concepts.
Information synthesis is a catchall term for how evolving data analysis and processing technologies are increasing our ability to draw insights from complex, messy and unstructured data.
Sophisticated analytics are the advanced techniques such as simulation and optimization that are making it possible to pursue previously out-of-reach insights from data.
Finally, there are visual insights as data visualization disciplines mature organizations and software tools are simplifying and accelerating the path to insights and decisions.
In this video, we talked about the major implications of technology advancements.
Customers are changing the way they select products and services.
Competitors are faster and nimbler than ever before.
Think about how some of this changes have impacted you personally.
How have you chosen products differently since the bought are social media?
Compare this how you bought products before social media?
Think about other technology advancements that you have seen.
Then join your fellow learners on the discussion board and engage in a dialogue on how technology advancements have changed your behaviors.
And from that consider the big question in what ways do you think organizations need to use data to help them think differently?
In this video we'll share PwC's perspective on big data.
Big data's about much more than technology and data.
It's about how insights from data can drive big decisions that solve real business issues.
Often creating innovation and opportunity in the process.
Success demands focus on the business issue first, and data and technology second.
>> PwC's 2014 Digital IQ Survey confirmed something that many of us in the industry have thought for quite sometime.
Over 40% of all respondents confirm that their big bet in the near future is going to be on analytics and big data.
>> When we talk about big data, oftentimes people think about volume or velocity, how fast it comes at those.
I like to also think about as in variety, how many different sources of information do we have and that we can bring together?
It is not uncommon now for big data projects to take 20, 30, 40 data sources and mash that data up and drive value from that.
If you think about, just the Federal Government in the United States has released about 300,000 different data sets in the last five years.
And there's the federal government, there's state and local authorities that release data.
There is commercially available data sources.
It's part of the big data business is to understand what's out there and to use the right sources of information to derive value.
>> Big data is not all about the data and the technology, which is the two things that come to mind when people think about big data.
We think that companies should be thinking about three additional things in addition to big data and big technology and big data technology.
One is the decisions that they make.
How am I making certain decisions, and is there a better way of making those?
And how can insights from the data, and the analytics that work on that data, help me?
So that's the number one that they should be thinking about, the big decisions.
The second one is also around the big data analytics.
So the data alone is not useful.
Again, but given the volume of data that's now available, extracting the insights is a challenging task.
So you're an essentially, literally looking for a needle in a haystack.
And to come to that needle, you need to understand and frame your business problem and business decision and then use the analytics to generate those insights or draw out that insights.
Third thing that we also see coming into form now as we compare more transitional organizations who have been there in the industry for 20, 30, 50, 100 years, was that some of the companies that are, cropping up if you like, in the Bay Area, there's a substantial difference in their mindset.
We call it the big data mindset.
>> The opportunities for big data are to really show what people are thinking, how they are behaving.
And those insights had heretofore never been available.
Now we can really look into what a customer thinks about a product.
We can look at traffic patterns and use those traffic patterns to be able to pick the best group, real time.
We've never been able to those things before.
However, we realize that to really untap the value of big data, the business has to be engaged.
I think that you have people sitting on huge volumes of very valuable data.
And another core group of people in the business that would love access to it, that have questions, that might not know how to ask the right questions.
And that somehow those two have to come together in order for companies to be successful.
>> So I do believe that the industry and the leaders out there do understand the transformative change that can come from big data analytics.
And how do we get there is really a very measured step-by-step approach.
You should start small.
Start with a very well defined business problem and create value from there.
As Anan said, data alone is not useful.
And considering the volume of data we often start with, extracting insights can seem daunting.
Remember, you must first frame the business problem and the business decision, and then use the analytics to draw out insights.
Start small, address a valid business challenger opportunity, and create value from there.
In the next video, we'll look out how you gather data, and what tools you can use to analyze data.
In this video, you're going to hear some of our PWC professionals have applied data and analytics to address business challenges.
Including identifying growth opportunities, and driving customer engagement to operate more efficiently.
While you watch this video consider how organizations can use data and analytics.
This can be helpful to you when you engage on the discussion boards with other learners following this video.
>> Big data projects can be accomplished in two to three months, and I'll give you an example.
We had a content provider client that wanted to know more about the effectiveness of placement of their content within web storefronts and what was driving customer behaviors to go view that content and purchase that content.
We're able to do that analysis using big data and analytics to show what customer behavior was, what preferences there were, and where that placement could drive more customers to make purchases.
In addition to that finding, the answer that we came back with beget more questions, and that spawned a couple of other initiatives within the company.
We had a client in the communications industry that has the ability to distinguish viewing patterns of their customers.
And what they wanted to do was track what's called pathing, and following customers as they go from channel to channel to understand, how do I optimize my advertising by making sure that the right segments get hit with those messages.
The complexity of trying to figure out the behavior of all of my customers quantified by all the channels and content that I offer becomes a little bit mind-boggling.
But if you plot that into some sort of visual representation on neural net if you will, which shows the connection points, the highest probability connection points between say news channel and lifestyle channels.
>> There are a lot of new ways that companies are using the so called big data technology and new sources of data.
Let me give an example, there's a very rich, very large beverage company, and traditionally what they had done in terms of stocking up supplies with the retailers was essentially looking at what was the past demand, and based on the past demand, they would essentially stock up the shelf.
In other words, when a person comes to the store they can't find the specific brand of beverage that they wanted.
So they might have the overall brand but they may not have a light version or they may not have the right flavor.
And they did an exercise to find out what the stock was and it was a substantial number.
So what this particular organization did, and they came to us, and they had a number of people with internally who were crunching through a lot of algorithms to find the right optimal solution for stocking but none of that had actually included interesting data from the external world.
In fact, real time data, real time data about other, is there a football match happening in the vicinity of where these retailers are?
Taking into consideration all of those leads to substantial variations in how we want to stack up various retailers.
And also they were able to do that in a way that was able to combine that information but also disseminate the information in a way that a normal person, a retailer, in a normal mom and pop shop could actually use that data.
So we help them bring in data literally on a smartphone, and very simple ways of telling them how much they should be stocking and how often they should be stocking.
And this is something which we call intelligence at the moment.
In other words, there is no point in having all of the fantastic analytics happen in the head office where you're generating those insights.
They are not that useful if it doesn't make it's way on the shop floor, as in this particular instance had the retailer.
And the retailers are not statistical PhDs, so you need to tell in a way that they can understand and they can input the values.
>> You just heard two examples of data and analytics were applied to address real life business challenges.
Think about these examples and spend some time with your fellow learners discussing data in action on the discussion board.
In this video we're going to discuss how organizations capture data, how they store and process it, and ultimately how they visualize it.
One piece of data won't provide much value but when you look everything holistically, the result will be better decision making and insights.
With the very different types of data that are available today, there are traditional approaches and emerging approaches to what organizations are doing with their data.
Let's start by talking about the traditional approach where you need to extract from a relational database in order to develop a traditional segmentation model from marketing program.
To share this with your client, you can use tools like Excel, and Access and PowerPoint to tell the story and communicate the results.
When you think about new types of data that are available you need to take an innovative approach.
An example of this would be when you have multiple types of data coming from traditional databases at well as something like social media.
You have all these different types of data that you need to bring together in order to build insights.
Using these different types of data you can tell the story of what it means using advanced visualization tools like a tableau or a click view.
All of this data combined can be used in a way that allows organizations to make decisions in real time.
You'll hear more about the different types of data later this week but data available to organizations is coming from a wide variety of sources.
Mobile, web, email, social media, sensors, operational data, logs, texts, the lists goes on and on.
With all of this data we need to look at four things to figure out how we will get the insights from this data.
Here is an example of how we can capture different types of data through one interaction and use it make operational changes to improve the customer experience.
Let's say your client is a national pharmacy chain.
A customer uses her mobile device to chat with customer service when she has issues with her prescription not being filled in a reasonable amount of time.
From this single chat, the organization is able to collect three primary pieces of data.
An indicator of the customer's preferences on the channel that they choose to communicate.
We can use this data and visualize it to unveil segments in the customer population that have an affinity for one channel or the other.
I just talked about gathering data from a mobile device but how else do we get data?
Let's say, you have a client that is looking to increase multimedia sales.
We start by looking at purchase patterns and multimedia and uses to develop better marketing strategy.
What platforms are your customers using to purchase multimedia, such as music, movies, or television shows?
How much are they purchasing?
Not just understanding the segments, but also the price points, the timing, and the preferences for one piece of multimedia over another.
We can get all of these data from traditional data stores as well as from other sources like third party data suppliers, social media, and user device data.
How do we store the data?
In the digital age, there's so much data but we're housing every bit and byte is always the answer.
It has to be high quality data.
It has to be where organizational leaders can access it.
And it has to be the data they need to help assess their risk and pursue strategic opportunities.
It's not up to an analytics person to store the data efficiently.
We work with our technology people and think about the business prom and the data we're trying to collect.
Understanding that the platform will continue to evolve, there will be traditional and emerging platforms and it's up to the data scientist to help to find the analytics path and the data they need.
It is necessary to have a base understanding of the different platforms so that we're asking intelligent questions to store the data that is out there.
In many organizations, a data and analytics person would work with the technology department to figure out what the right platform is to collect, store and analyze the data.
How do we process this data?
Once the organization have the data and it's stored the goal is to transform it and the insights that help address complex, strategic and operational challenges.
And in many cases gain that competitive advantage.
Our clients often think it's an either or but traditional and emerging data both serve a purpose.
It's up to the people doing the analytics in an effective technology team to figure out the best platform.
How do you process these data sets?
We use software packages like SAS, R, Excel and Access.
But it's on us as the analytics team to work with our clients to identify the tools that will solve the issues for us today but we also need think about what implication does that have for building the organization in the future.
We work with our clients to understand the issues, come up with hypotheses and then determine if we need business intelligent tools like Tableau or Spotfire or more advance statistical tools like R or SAS.
And finally, what tools help us visualize the data and tells us a story of what the data means.
Let's talk about the key tools and technologies available to harness all of the power of the data that's out there.
There are static desktop graphics like Excel or PowerPoint.
We can use BI reporting dashboards that are regularly refreshed to show important operational data.
An example is Microsoft Power BI which is a collection of online services and features that enable users to find and visualized data, share discoveries and collaborate in intuitive ways.
There is Google's platform, dynamic web or there's G predicts.
All our tools that are analytics teams work on with our clients.
There are also dynamic web visualization tools that allow for interactive visualization, like QlikView, Tableau and Spotfire.
Next week, you'll learn about some of the uses and the benefits of these tools.
In this video, we talked about how organizations capture data, how they store it, how they process it.
And finally, how they visualize it and use to tell a story or answer a key question.
In this video we're going to look at the different types of analyses you can perform once you have identified the business problem or opportunity, developed a hypothesis and collected relevant data.
As processing capacity continues to increase, it has opened the door to a broad range of advanced algorithms and modeling techniques.
That organizations can use to produce valuable insights from data.
We will discuss a series of analytical techniques and how they are used in the real world.
In the course materials, you have access to a quick reference sheet that lists out all techniques for easy future reference.
I'm Lorie Wijntjes, managing director in our data and analytics practice with almost 30 years experience as a statistician.
At PWC, I have worked on a wide variety of business problems involving predictive analytics, data management, statistical sampling, and survey design.
Some fairly straightforward, and many that have been complex, across a wide range of business problems in industries including healthcare, financial services, and retail and consumer.
In this video I will give you a high level overview of the different types of analysis that you can perform on data.
As part of the course you will find supplemental reading that covers each of these analysis types and how they are used.
Now, it's important to keep in mind that the analysis you choose to perform will depend on a couple of things.
First, the problem you are trying to solve, and second, the data you can use to solve that problem.
I'm going to start by talking about cluster analysis.
Cluster analysis is when you group a set of objects in a way that objects in the same group or cluster are more similar to one another than those in the other clusters.
Cluster analysis is often used in market research when working with data from focus groups and surveys.
A cluster analysis can be used to segment a population of consumers into market groups to better understand the relationships between different groups of consumers.
Are there groups that have similar attributes so that products, services, price offerings, can be used to customize segments?
Now, let's move on to decision tree analysis.
A decision support tool that uses a tree-like graph of decisions and their possible consequences.
Decision tree analysis is often used to assist healthcare practitioners considering varying treatments along with each one's associated costs and probability of a successful outcome.
For example, healthcare providers can use this analysis to assess options and deliver more cost effective treatments that minimize the risk of hospital readmission.
To analyze large numbers of dependent and independent variables, we might use factor analysis.
This type of analysis can help detect what aspects of the independent variables are related to the dependent variables.
When we receive the data, sets that are fairly wide, meaning that they had more variables in observations or records.
We need a way to identify the core set of variables or drivers that will help to gain meaningful insight.
Factor analysis can help identify that reduced subset of variables, meaning some of those variables represent similar relationships as those not included, but perhaps in a stronger way.
Machine learning is a type of artificial intelligence that provides computers with the ability to learn without being explicitly programmed to do so.
For forward-thinking retailers, the possibilities for advanced machine learning are limitless.
Take for example a company trying to predict what customers will be buying next spring.
Machine learning algorithms can determine availability of materials from outside vendors, incorporate various supply chain scenarios.
And recommend the quantity, price, shelf placement, and marketing channel that would best reach the target consumer in a particular geographic area.
These algorithms can also be used to optimize sales for an individual store.
Regression analysis is a statistical process for estimating relationships between a dependent variable and one or more independent variables.
Variables are the pieces of information.
This type of analysis helps you understand how the value of a dependent variable changes when any one of the independent variables change.
For example, a large insurance company wants to identify the characteristics including age group, income, gender, educational level, etc.
This type of analysis can be used to assess risk, and also assist with determining pricing for various automobile insurance products.
Multivariate analysis is the observation and analysis of more than one statistical outcome variable at a time.
This often includes as a first step correlation analysis, which can help you understand and visualize relationships between pairs of variables.
Multivariate regression is a technique that estimates a single regression model with more than one outcome variable.
When there is more than one predictor variable in a multivariate regression model, the model is a multivariate multiple regression.
To understand the relationships of outcome effectiveness of a particular medical treatment, one may also need to understand confounding variables.
Such as age, weight, gender, or other medications the patient may be receiving.
There may be multiple ways to assess outcome and thus, more than one dependent variable and multiple independent variables.
Segmentation analysis divides a broad category into subsets that have or are perceived to have common features, needs, interests, or priorities.
Often, segmentation analysis is used to better understand customer needs by diving a large number of individuals into smaller groups based on a logical scheme.
Segmentation provides a convenient mechanism around which to develop products, construct programs, and execute marketing tactics.
Imagine that a bank was developing a strategy to become a leader in mobile payments and mobile banking.
Traditionally, product penetration was driven by the bank's relationship managers and its branches.
Segmentation analysis could help the bank gain market share by identifying key customer segments and developing product recommendations for those that are more likely to use mobile banking.
Sentiment analysis is a process of identifying and categorizing opinions expressed in a piece of text to determine whether the writer's attitude towards a topic or issue is positive, negative, or neutral.
This analysis often relies on natural language processing or NLP.
These allows companies to better understand what their consumers are saying about their product offerings and to adjust strategies where feasible to improve customer sentiment.
Categorization of the information scraped from the Internet can then be use to develop models.
Sometimes it's hard to determine if a system or a process will react to a change the way we think it will.
One way to test changes to a system or process is by performing a simulation.
A simulation is the imitation of the operation of a real world process or system over time.
It requires a model that represents the key characteristics or behaviors of a selective system or process.
For a hospital wanting to figure out how to reduce wait time, analytic tools could help simulate the admission process.
Allowing the hospital to change the values of certain variables and see the impact on a patient's wait time.
Time series analysis can be used to design a methodology to identify the factors affecting airline passenger demand on routes by leveraging macroeconomic, demographic, and other external data, at a local, state, and national level.
Such models can be developed to produce a route level forecast of total demand for air travel.
Helping to optimize route and capacity planning and identify new routes for market entry.
Time series analysis comprises methods for analyzing data that are collected over time to extract meaningful statistics.
Stock prices, sales volumes, interest rates, and quality measurements are all typical examples.
Because of this sequential nature of the data, special statistical techniques accounting for the dynamic nature of the data are required.
Now, let's answer one last assessment question for this segment.
And as you can see there are many different analytical techniques that can be used to address a problem or opportunity.
As I mentioned at the beginning of this video, there is a quick reference guide available as part of this week's materials.
Use the guide to review the different analytic techniques.
In the upcoming videos you're going to hear from some of PWC's subject matter specialists on tools used for data and analytics and for visualizing data.
In this video we're going to look at the role of Excel in data and analytics.
Excel has been around for a long time, and many viewer as the first tool to learn when you're starting out in the data and analytics field.
The next two courses in this specialization will go into detail on exactly what Excel can do and how you can use it.
In this video, I'm going to talk at a high level on what the tool is, how it's used, and what types of problems it can solve.
Excel is a spreadsheet developed by Microsoft.
It has calculation, graphics tools, pivot tables, and a macro programming language called Visual Basic for Applications, VBA.
Excel lets you organize numeric or text-base data in spreadsheets or workbooks.
You can take raw data and organize it and rearrange it, so that you can perform complex analysis of the data.
To visualize your data, Excel allows you to create different types of charts, including line and column charts, or add miniature graphs called sparkline.
You can also use Excel to apply a table style, create pivot tables, quickly insert totals, and apply conditional formatting.
So, why would you use Excel, when there are so many more robust and analytics tool available?
Here are some of the key benefits of Excel.
It's easy to use.
It's dynamic, making it easy to explore "what if?" scenarios.
Complex data can be presented in a clear and visually appealing way.
It integrates with Microsoft Office.
And of course, everybody has it.
Excel is a very common tool for data and analytics.
There are many, many options out there that you'll learn about in this course, but Excel is an excellent one to start with in your career in data and analytics.
It can be used to analyze data in many different job types for different reasons, and many of the Excel skills you will learn translate to more advanced tools in the industry.
Here's an example of how we used Excel to combine sales data by distribution channel to look at growth opportunities by product and country for a medical device organization.
We combined their historical data along with macroeconomic data, and developed models that allowed the company to predict sales based on varying assumptions.
These models were also displayed in graphs, and BBA was used to provide a user interface that allows the client to toggle between the views and produce multiple scenarios based on varying assumptions for comparison purposes.
In this video, we discussed the role of Excel in data analytics.
Excel is an easy to use tool that is extremely versatile.
Learning Excel will make it much easier for you to pick up more complex data and analytics tools in the future.
In this video we're going to look at the role of SAS in data and analytics.
SAS stands for Statistical Analysis System, a licensed software system for data analysis, graphs, and report writing.
SAS comprises a group of computer programs that work together to store data values and retrieve them, modify data, compute simple and complex statistical analysis, and create reports.
Commercial and public organizations use SAS to perform data analysis.
There are also more advanced programming options, called SAS language, that allow you to perform more complex data management and advanced analysis on data.
We have used SAS to aggregate large and varied data sets, merging multiple datasets on key variables to construct longitudinal patient and customer histories.
These data sets may include third party external data that has been purchased or subscribed, publicly available data, and of course, our client's data.
SAS allows us to maintain logs and lists of the programs run and the outcome of each merger step where data were combined to provide record of the number of observations processed to our clients and for review by third parties, such as regulatory agencies.
It also allows us the capability to make changes to existing SAS programs for re-use and scalability.
You now have a high level understanding of how SAS is used in data and analytics.
Before joining PwC, I was a tenure track professor of statistics at American University.
Now I focus on farmer research and development, applying my theoretical statistics and machine learning knowledge to a diverse set of complex issues facing our by pharma clients.
In this video, I'm going to talk to you about our R in RStudio.
I'll describe what the tools are, what they are used for and I'll share a client example where R was used to solve a business problem.
Why do we like R?
R is an open-source software environment and language for statistical computing, and graphics.
Open-source means that the language is freely available and may be distributed and modified by anyone, so that R has a very active contributor and user base.
R is the leading statistical analysis package, as it allows the import of data from multiple sources and multiple formats.
For example, flat files, SAS files and direct connect to graph databases.
In addition to data management capabilities, R contains over 7,000 specialist packages that are all free.
These packages allow users to employ cutting-edge statistics, econometrics, optimization, machine learning and simulation techniques.
These all makes are the leading analytics language in academia and industry.
There's also a set of integrated tools design to help you be more productive with R.
It's a powerful and user-friendly graphics user interface called RStudio.
RStudio includes a console, syntax highlighting editor that supports direct code execution as well as tools for plotting, history, debugging and workspace management.
More specifically, RStudio includes integrated R help and documentation.
The ability to easily manage multiple working directories using projects.
A workspace browser and data viewer, and and interactive debugger to diagnose, and fix errors quickly.
View data in spreadsheet format and see all objects defined in a session.
RStudio allows users to employ packages for automated Word or PDF report generation and also contains a powerful visualization plugin called Shining.
Shiny allows development of iterative and flexible visualizations, and dashboards that can be accessed by non-programmers via internet browsers.
As mentioned earlier, R is a powerful and flexible analytics tool that can be used to implement various data management, statistical analysis and machine learning tasks.
We could spend years going over all the years all of the methods implemented in R, but I will highlight some of the most commonly used R features.
For data management, R is used for importing data, assessing data quality by identifying data qualifiers, implausible information and missing observations, merging data as well as stacking data.
In summary statistics, R helps create routine summary statistics describing distribution of a variable.
For example, means, medians, standard deviations and skewness.
For statistical tests, R produces means tests, proportion tests, association tests, distributional tests and tests of stationarity.
In regression models, R is used for ordinary regressions, logistic regression, stepwise regressions, ridge regressions, analysis of variance, multivariate adaptive regression splines, support vector machine nonlinear regressions.
For clustering, R is used k-means, partitioning around medoids and hierarchical clustering.
In dimensionality reduction, R works in principal components and multidimensional scaling.
And in decision trees and random forests, R supports classification, regression and survival trees and random forests.
The flexibility of R makes it the top choice for executing complex data management and statistical analysis client engagements.
For example, a leading by far more organizations sought our help in aggregating and standardizing data across a drug platform.
Our goal was to identify tumor gene expression cut points associated with differentiated survival outcomes to develop an interactive visualization solution for cut point identification and validation.
R was a natural choice for this engagement as it allowed us to quickly import assess, standardize and aggregate data that were messy and incongruous.
For example, data had missing variable labels, missing values, multiple unit measurements for the same variable across trials.
We then wanted to identify important genes associated with survival after accounting for confounding clinical and demographic covariance using the random forest technique for survival objects.
We then followed it up with cogs proportional hazards and a number of more advanced barometric survival models to assess whether the identified cut points were associated with differentiated survival outputs.
To bring all of the analysis to life, we use an interactive Shiny visualization that then allowed the client to independently identify genes in their cut points without having to program an R.
As you can see in our examples, R is an important tool for data management, analytics, statistical modeling and machine learning.
So, we've covered a lot of materials in this segment.
If some of the terms were not familiar to you, be sure to reference the course glossary.
Next, we're going to look at a bottom-up version of Mergesort.
Well, Mergesort is easy to understand as a recursive program.
This bottom-up version that has no recursion, it's also quite simple to understand and to code up.
The basic idea is to think of the array as being a little at the begining a set of little sorted sub arrays of size one.
And then what this method will do is go through and merge those little subarrays of size one together in pairs to get subarrays of size two.
Then, the whole array consists of sorted subarrays to size two, and then we make another pass through to get size four, and then size eight, and so forth.
Then on another pass through, we can take the E, M and the G, R and merge them together to make EGMR, and the E, S and the O, R merge those together to make EORS, and so forth.
And we have four subarrays of size four.
One more pass makes two subarrays of size eight, and the last pass is just a sorted array.
The bottom line in this is sequence of passes through the whole array and there's no recursion needed at all.
It's extremely easy to code up as you can see from this code.
We use the same merge code as before and we take a nested for loop.
The only downsize as would regular Mergesort is that it uses extra space proportional to the size of the array.
But otherwise, that's a fine method for merging.
If you look at this visual trace you can see how it works.
Now in this case the second subarray to be sorted is smaller but the merge routine doesn't really care about that so much.
You can merge things that are not equal in size.
Whatever the size, bottom of Mergesort gets the job done in log N passes.
Each pass using about N compares for a total cost of about N log N.
In this video, we're going to look at the role Python plays in data science and analytics.
Python is an open source, general purpose programming language that can be used for everything from building web applications and enterprise programs to performing analysis on large amounts of data.
Python is popular because it is freely available to use, emphasizes code readability, and it is easy for newcomers to learn.
Also, it is popular because of its user friendliness and the ability to integrate with a variety of programs, tools and websites.
Python has become one of the most popular languages for data management and analysis.
Today, Python is widely used by startups and tech companies to embed analytics into their products, and by data scientists to quickly manage and analyze large amounts of data.
Python has a set of tools called the Python Data Analytics Stack that address every step of the analytics workflow.
These tools are assembled into Python libraries, which are collections of code that are easy to use.
While the names of these specific libraries may change, here's a few examples of common libraries for data science.
Pandas for importing and assessing data including outline analysis, and data cleansing, as well as summary statistics.
NumPY and SciPy for performing extremely fast matrix, mathematical and scientific operations.
Statsmodels for fitting a wide range of statistical models to the data.
Scikit-Learn from applying machine learning techniques like, clustering, dimensionality reduction, random forests and logistic regression.
Matplotlib, Seaborn and Bokeh for producing attractive visuals.
And finally, Apache Spark, for processing data on a massive scale across a cluster of computers.
In addition to normal data science and numeric data, Python has libraries that can also handle unstructured data like text and images.
For example, NLTK, Spacy, and Gensim process text data.
OpenCV manipulates and analyzes images.
BeautifulSoup and Scrapy make web scraping easy and intuitive.
Python can interact with tools like Caffe to use deep learning techniques on powerful GPU enabled machines for cutting edge machine learning on images, sound, and text.
And Flask or Django for building websites and web services that can embed machine learning models that can be accessed through the Internet.
We've outlined some of the capabilities of Python, but the big question is, why Python?
Well, our boasts more extensive, advanced, statistical model and capabilities.
Where Python really shines is when the data is unstructured or analytics need to be embedded in other programs or applications.
Because Python is a general purpose programming language, it was easy for the community to build extremely efficient libraries to process all kinds of data, and interact with many of the leading big data tools like Hadoop or Apache Spark.
Here at PWC, we rely on Python extensively for many of our demonstration projects.
We evaluate which leading data tool to use based on the client's need.
I'll highlight a couple of examples where Python was used.
First, there are projects that use natural language processing.
For example, you've heard describe our work to help a major banking client understand the feedback it was getting from it's customers through customer support channels, as well as social media.
We use Python to scrape the data, parse and understand it, and then describe the customer's sentiment present in it to better priorities the issues the bank needed to address to improve customer satisfaction.
Ultimately, the client was able to better mean customers need and increase customer engagement.
On another recent project with an oil and gas client who had a massive amount of census on pumps and oil wells, almost 1 billion records, we used Python as well.
The goal was to create a machine learning model to predict when any given pump might fail given its sensor readings.
We used Python and Apache Spark to efficiently process the data in parallel so we could do all of our data cleaning and feature engineering before finally fitting a variety of models to it.
This was a good example of why Python was chosen, not only because it let us process all high volume data, but also because the client used Python and wanted deployable code that could be kept after the engagement was completed.
Ultimately, we were able to provide them with models to predict pump failures two days in advance of an actual failure.
Sometimes the choice of the appropriate analysis tool can seem daunting as there are so many options.
Python is a great choice because it handles many of the data science use cases, from simple descriptive statistic,s to statistical models, to complex machine learning and distributed computing embedded in dynamic web applications.
Python is easy to use because it was designed to be easy for programmers so that the learning curve is not too steep.
If you haven't tried it yet, it's worth exploring.
In this video, we've discussed the role of Python in data and analytics.
Python is free, easy to use, fast, and useful for both simple and complex data analysis tasks.
You just learned that a key to solving business problems with data and analytics is the use of visualization techniques to make sense of all that data.
I'm going to talk about what Tableau is and when and why to use it.
Analyzing customer behavior to make data driven decisions is one of the biggest challenges that organizations face today.
With a software like Tableau, understanding customer's spending habits can be done with filters, draw downs, and charts.
With the interactive capabilities of Tableau, we are now able to know customer shopping patterns.
And most importantly, we are able to take decisions and bring those insights to action.
Tableau is a visualization tool that allows you to connect to volumes of data and visualize this data on the fly.
It allows you to bring spreadsheets and databases and big data sources and to create visualizations, reports, and dashboards very quickly.
It is increasingly being used in a variety of product offerings and allows you to provide a client with interactive deliverables.
Tableau is easy enough to use that anyone who knows Excel can learn it, but powerful enough to visualize even the most complex analytical problems.
It is an in memory tool meaning data is held in memory so as to provide a fast user experience.
For one of our clients we needed to create a customer level risk score across 30 million records.
We needed to be able to show the client what the customer level score meant and not just produce a bunch of different spreadsheets.
Once we did the analysis of the data, we brought it into Tableau and presented the client with the visualization of the 30 million records.
We were able to leave the client with her data so she could manipulate it and help answer different questions using the functionality within Tableau Reader.
Tableau allows you to take complex data sets and complex analysis and present your findings to non-technical, non-analytic people.
They don't need to understand the data, but they can make decisions and solve problems by seeing exactly what all the data means.
Tableau is very different than using something like a spreadsheet because you can create a variety of different views that can answer many, many different questions.
There are other tools that can do the same thing.
But Tableau is simple to use, and you don't need to give up control of your data sets.
You simply provide your clients with Tableau Reader, and they continue to use the data visualizations you have created for them.
My teammate, Ramy Sedra is going to share some of the key benefits of Tableau.
With its drag and drop approach, Tableau gives the opportunity to both technical and nontechnical users to perform pretty complex data analysis.
The visualizations are innovative, interactive, and really of excellent quality.
With Tableau, users can drill down, filter, organize data in a variety of ways to tell a story.
With Tableau you can connect multiple data sources, link them together, create calculated fields with a SQL like language without having to write any code of your own.
The software can integrate any kind of data.
Right now, big data is transforming industries, and Tableau is compatible with Hadoop.
In addition, Tableau becomes even more powerful by integrating with the R statistical engine.
People carry phones and tablets everywhere.
They want their analytics to follow them along.
Whether they're in meetings or in the field, they want to be aware of what's happening in their projects.
Tableau Visualization are mobile enabled so you can have your insights on the go, and not to mention, well integrated with real time data.
Tableau can be used for data analytics, visualizations, dynamic dashboards to generate actionable insights that are based on facts.
But to use Tableau to its greatest potential, users should experiment with it with all kinds of different types of interactive visualization that it offers, including charts, graphs, and maps.
You can then dig into information, gain unexpected insights from the generated dynamic graphs.
And the bottom line, Tableau should be used to explore your data and present the results.
>> Thanks Ramy, so to recap, Tableau is easy to use and can help you connect large amounts of data and create visualizations at a very rapid pace.
You should now have an understanding of the role of Tableau in data and analytics.
You'll learn what QlikView is, when, and why to use it.
QlikView is an analytics and visualization tool for advanced data investigation.
QlikView allows you to bring in all of your data from different sources to create visualizations.
This allows decision makers to see their data in real time, to find opportunities, and make changes where needed.
QlikView is similar to dev low, but it can be used for more complex analytics.
You can create graphs and charts on the front end, and the user can interact with that data and slice it and dice it.
The interface of the software is easy to understand, and is likely to target more professional users, or power users.
The software is flexible and customizable, with its programmable BI platform.
Not only can the user develop new types of charts, but using functions, the user can save part of the work for later use.
Users can use clip view either for analytic purpose, with ad hoc analysis and predictable analytics, as well as reporting features like ad hoc reporting and customizable dashboards.
The software can support multiple data sources which gives it the ability to do complex analysis.
My colleague, Rammy Cedra, is going to talk about how his team uses QlikView to solve client problems.
My team and I worked with the organizations to turn data into actionable insights.
While working with the financial services organization they want it to optimize the channel that our clients were assigned to.
A channel is a branch, private banking, or tele-banking team.
So we leverage collect to build a decision tree, the statistical model, and to analyze and optimize the allocation of clients to channels based on client segments, product portfolio, geography, and other related client and market data.
We use the data from the financial institution, some geospatial data, census data, and other proprietary data sets to perform the analysis, build the model, and the visualizations.
We did this work in approximately six weeks.
So the agility of the tool was really a big factor in our success.
Qlik enabled us to rapidly pull the data together, the links between datasets and show the visualizations in a compelling in interactive manner.
The value to the client is that they can quickly see the insights from the analysis and really paints the picture.
Qlik leaves the client with a tool they can interact with.
They can perform their own analysis, think of more questions that they can answer with their own data.
It really closes the gap between the business users.
One of the benefits of using Qlick is that it can integrated with other softwares such as SAP, Microsoft SQL server, Oracle, Excel.
And as a result, gaining access to a broad set of data is really quite simple and can be done cost effectively.
Another benefit of collect is that it can be used to create a complete BI infrastructure needed for advanced reporting, dashboards that leads, and supports really complex analysis.
The Qlik interface is easy to use and easy to understand.
That's likely to be adopted by business users and power users alike.
The software is flexible, customizable, with it's programmable, and analytic platform.
Not only can the users develop new types of charts, and visualizations.
The calculation in Qlik is very powerful.
The tool can handle large data volumes without impacting performance thanks to it's in memory features.
Qlik's mobile solution is quite interactive and easy to use.
Collaborative features such as chat are very powerful for sharing insights amongst a group of stakeholders.
While Qlik is a great tool, for even more compelling visualizations you may want to consider exploring Qlik Sense, Qlik's softwares other product.
These our some of the benefits of using QlikView to visualize your data.
So now you have a high level understanding of the world QlikView in data and analytics.
This week was more intense and really went into more details on the different types of data and analytic techniques and some of the tools that are used to analyze and visualize data.
>> You started off the week hearing Laurie talk about and share examples of the different types of analysis techniques that we use to help solve problems for our client.
You had the opportunity to download the interactive PDF that gives an overview of each technique.
Keep this and reference it whenever you need it.
Being able to distinguish between these techniques and knowing what techniques can help you answer your data questions will help you distinguish yourself from your peers.
You also heard Laurie, Eddie, Amy, and Rammy talk about quite a few different tools that we use here at PWC.
There are so many different tools out there that can help you perform different tasks and solve different types of problems.
Mike, as our Chief People Officer, how can a person know all of these tools?
At PWC we don't expect you to come in knowing every tool, but having the base data and analytic skills, and knowing what tools exist and what they can do, can set you apart.
That's why we're focused on giving you a high level overview of some of the tools used today for data and analytics.
We know technology and tools are constantly evolving, but knowing one or two tools very well will help you to be able to learn additional data and analytics tools in the future.
That's one reason why courses two and three cover commonly used tools like Excel.
It doesn't matter what role you have in business, it's likely you're going to need to work with data and perform analyses, extract insights.
You'll find most companies use these tools all over the world to capture and analyze all kinds of data.
>> Next week, you're going to take everything you've learned in this course and apply it in a simulation and in the course project.
Your final week will be something a little different.
This week, we're giving you the opportunity to apply what you've learned and demonstrate it in two final assignments.
In this simulation, you'll have a chance to interact with fictional clients.
You will learn the business opportunity and challenges they face.
>> This simulation gives you the opportunity to demonstrate what you've learned by making decisions that get you closer or farther away from a successful outcome.
Your choices in the simulation determine your path and final results.
Next, we're going to ask you to complete a course project.
>> On the course site we've placed three business scenarios for the project.
You can select one of these scenarios or you can choose one from your own current business.
From your scenarios we're asking you to find as much information as possible about the organization or situation and put together a plan for data analysis.
Your plan should address all the elements of the data analytics framework and any other considerations you think are important.
There your peers will review your plan and give you a score.
We've built a rubric into the course so that all scoring is consistent and fair.
We're asking each learner to review three of their peers' plans.
You'll find detailed instructions within the assignment on the site.
It will give you a chance to show what you've learned in a way that is engaging and impactful.
You've now completed the introduction to Data Driven Decision Making course.
In the specialization, data analysis and presentation skills.
>> In this first course you took part in a high level exploration in the field of data and analytics.
You heard from some of our PWC leaders in the area and learned how they applied data and analytics to solve real client issues.
>> Through a series of videos, readings, assessments, a practice simulation, and a course project, you explored key topic areas in data and analytics.
In week one, we discussed how organizations used the data analytics framework to solve problems.
>> In addition to being an essential foundation, the ability to capture insights and express them with clarity to tell a story is a real differentiator in people's careers Week two focused on the different types of data available that are used to solve business problems.
You learned more about emerging trends and data analytics, and explored the differences between structured, unstructured, and semi-structured data.
We talked about the different types of analysis techniques you can perform.
We explored some of the tools that are used, like R, Python, Tableaux, Click View, Excel, and SAS.
We also looked at visualizations that help your data tell a story.
>> Then, once you've got the data, you need to have the skills, tools, and the ability to ask the right questions and do something with it.
>> Finally, we gave you the opportunity to show what you had learned through an interactive simulation and your course project.
You also had the chance to see what your peers created with their projects and to provide feedback.
>> We hope you found this course to be an insightful introduction to data and analytics.
We also hope that you continue on with the full specialization.
Data analysis and presentation skills the PWC approach, where you'll have an opportunity to further develop and apply data and analytic skills to solve business problems.
In upcoming courses we're going to look at problem solving using Excel, creating data visualization with advanced Excel, and creating effective business presentations using PowerPoint.
The idea of complexity is it's a frame work for studying the efficiency of all the algorithms for solving a particular problem.
That's called Computational Complexity.
And in order to do this sensibly, we need what's called a model of computation.
The operations that the algorithms are allowed to perform.
For sorting that's kind of straight forward, what we're going to do is have a cost model where we count the comparisons.
One is an, what's called an upper bound which is a cost guarantee that's provided by some algorithm for solving the problem.
That's an upper bound and how difficult it is to solve the problem.
We have an algorithm that can solve it it's the least that easy.
And then we also look for a lower bound which is a limit on the cost guarantee of all algorithms.
No algorithm can do better.
Now, what we seek ideally is what's called an optimal algorithm where we prove that the upper bound and the lower bound are the same.
That's an algorithm that's, that we know that has the best possible cost guarantee.
So, for sorting, let's look at what each of these are.
The model of computation is what's called a decision tree, tree.
So, our cost model is the number compares.
Mergesort provides, provides an upper bound, that's an algorithm that's guaranteed to get the sort done in time proportional to N log N.
And what we'll look at now is the lower bound.
So, here's the basic idea for proving a lower bound for sorting.
Let's say, we ha ve three different items, a, b and c.
Whatever algorithm we have is going to, first, do a comparison between two of the items.
Let's say, there a and b.
And then there's two cases.
And there will be some code between the compares but either way then there is going to be a different compare.
If it's less than b, maybe the next compare is b against c.
And if you find that b is less than c and a is less than b, then you know that they're in the, any algorithm that does that knows that the items are in the order a, b, c.
If b less than c goes the other way, then it takes another comparison to determine the order.
The only possibility is c, a, b.
In continuing on the right perhaps the next compare is a less than c and maybe if c is less than a, then another compare, b less than c.
So, in this case, if you go from top to bottom in the tree with three compares at most you can determine the ordering of the three different items.
The idea of the lower bound generalizes this argument to figure out a number of compares that you need for a minimum to determine the ordering among N items.
Now, the height of the tree, as I just mentioned, is the worst case number of compares.
And there's got to be at least one leaf for each possible ordering.
If there's some ordering that is not appear in a tree corresponding the particular algorithm then that algorithm hasn't can't sort, can't, can't tell the difference between two different orderings.
So, the lower bound as a proposition, that uses the decision tree like that to prove that any compare base sorting algorithm has to use at least log base two (N) factorial compares in the worst case.
And then the proof is generalizes what I talked about on the decision tree on the last side, slide.
So, this three has to have at least N factorial leaves and if the three of height h, it has utmost two^h leaves.
The only, the, the tree that has the most leaves of height h is totally complete and that one has two^h leaves.
Two^h has to be greater than or equal to the number of leaves.
That's a lower bound on the complexity of sorting.
That's the first goal of algorithm design is to try and find optimal algorithms for the problems that we need to solve.
Now, you have to take these results in context.
Really what we proved is that mergesort is optimal with respect to number of compares but we already know that it's not optimal with respect to space usage.
Mergesort uses twice as extra space proportional to the size of the array it has to sort.
And simple algorithms like insertions or dump, they've they don't use any extra space at all.
So , what we want to take from these theoretical results is, is a guide when we're looking at implementations and trying to solve practical problems.
In this example what it tells us, what theory tells us is don't try to design a sorting algorithm that guarantees to use substantially for your compares than merge sort.
Is there a method that use one-half N log N compares?
The lower bound says, no.
And that's a very useful thing because otherwise, we might try to define such an algorithm.
On the other hand, maybe there is an algorithm that uses N log N compares and also uses optimal space.
And that's what we're going to look at soon.
The other thing is that the lower bound is for the particular model of computation being studied.
Or it's something about the distribution of key values if there are a lot of equal keys we can get sorted, get it sorted faster than, N log N.
And maybe the way the keys are represented.
We'll look at different methods that take advantage of such properties.
So, partially ordered arrays we may not need N log N compares.
Duplicate keys, we may not need N log N compares, we're going to look at the method that I guess that down in linear time and a lot of situations.
And later on, we'll look at digital properties of keys where we can use digital character compares instead of whole key compares and got a faster sort for certain practical applications.
Computational complexity is very useful way to help us understand properties of algorithm and help guide our design decisions.
You have now heard a lot about how to search for good hyperparameters.
Before wrapping up our discussion on hyperparameter search, I want to share with you just a couple of final tips and tricks for how to organize your hyperparameter search process.
Deep learning today is applied to many different application areas and that intuitions about hyperparameter settings from one application area may or may not transfer to a different one.
There is a lot of cross-fertilization among different applications' domains, so for example, I've seen ideas developed in the computer vision community, such as Confonets or ResNets, which we'll talk about in a later course, successfully applied to speech.
I've seen ideas that were first developed in speech successfully applied in NLP, and so on.
So one nice development in deep learning is that people from different application domains do read increasingly research papers from other application domains to look for inspiration for cross-fertilization.
In terms of your settings for the hyperparameters, though, I've seen that intuitions do get stale.
So even if you work on just one problem, say logistics, you might have found a good setting for the hyperparameters and kept on developing your algorithm, or maybe seen your data gradually change over the course of several months, or maybe just upgraded servers in your data center.
And because of those changes, the best setting of your hyperparameters can get stale.
Finally, in terms of how people go about searching for hyperparameters, I see maybe two major schools of thought, or maybe two major different ways in which people go about it.
And usually you do this if you have maybe a huge data set but not a lot of computational resources, not a lot of CPUs and GPUs, so you can basically afford to train only one model or a very small number of models at a time.
In that case you might gradually babysit that model even as it's training.
So, for example, on Day 0 you might initialize your parameter as random and then start training.
And you gradually watch your learning curve, maybe the cost function J or your dataset error or something else, gradually decrease over the first day.
And then maybe it does better.
And after two days you say, okay, it's still doing quite well.
Maybe I'll fill the momentum term a bit or decrease the learning variable a bit now, and then you're now into Day 3.
But you're kind of babysitting the model one day at a time even as it's training over a course of many days or over the course of several different weeks.
So that's one approach, and people that babysit one model, that is watching performance and patiently nudging the learning rate up or down.
But that's usually what happens if you don't have enough computational capacity to train a lot of models at the same time.
The other approach would be if you train many models in parallel.
And then at the same time you might start up a different model with a different setting of the hyperparameters.
And so, your second model might generate a different learning curve, maybe one that looks like that.
I will say that one looks better.
Or you might train many different models in parallel, where these orange lines are different models, right, and so this way you can try a lot of different hyperparameter settings and then just maybe quickly at the end pick the one that works best.
So to make an analogy, I'm going to call the approach on the left the panda approach.
When pandas have children, they have very few children, usually one child at a time, and then they really put a lot of effort into making sure that the baby panda survives.
One model or one baby panda.
Whereas the approach on the right is more like what fish do.
I'm going to call this the caviar strategy.
There's some fish that lay over 100 million eggs in one mating season.
But the way fish reproduce is they lay a lot of eggs and don't pay too much attention to any one of them but just see that hopefully one of them, or maybe a bunch of them, will do well.
But I'm going to call it the panda approach versus the caviar approach, since that's more fun and memorable.
So the way to choose between these two approaches is really a function of how much computational resources you have.
If you have enough computers to train a lot of models in parallel, then by all means take the caviar approach and try a lot of different hyperparameters and see what works.
But in some application domains, I see this in some online advertising settings as well as in some computer vision applications, where there's just so much data and the models you want to train are so big that it's difficult to train a lot of models at the same time.
It's really application dependent of course, but I've seen those communities use the panda approach a little bit more, where you are kind of babying a single model along and nudging the parameters up and down and trying to make this one model work.
So hopefully this gives you a good sense of how to go about the hyperparameter search process.
Now, it turns out that there's one other technique that can make your neural network much more robust to the choice of hyperparameters.
It doesn't work for all neural networks, but when it does, it can make the hyperparameter search much easier and also make training go much faster.
Let's talk about this technique in the next video.
Your music library maybe I, at one point, you sort it by the artist's name.
In this case we're looking at the b's.
But in another situation, you might want to sort it by song names to look through it by song names.
That's the same data using different sort keys.
How do we arrange to do something is natural as this in our Java sorts?
Now, we use the fourth in order to be able to implement sorts that can sort any type of data, we use Java's Comparable interface.
And that concept is that there's some natural ordering of the data that you'll want to use most of the time, that's what the Comparable interface is all about.
But there's a different interface called the Comparator Interface which is a way to help a sort, using some alternate order or many different orders on the same data.
And the Comparator interface again just says that it's going to implement a method compare() that compares two different keys of the given type, of the generic type.
There's many different ways that we might want to sort strings.
We might want to use the natural alphabetic order or we might want to make it case insensitive or maybe there is just different languages that have different rules of the ordering.
That's what the Comparator interface is for.
So the Java system sort will have a different.
The idea is that you create a comparator object and then pass that as a second argument to Java's sort routine and we can do the same thing for our sorts.
The idea is when a decouple, the definition of the data type from the definition of what it means to compare to items of that type.
With the natural order, we had to put the definition compared to within the data type.
With comparators, we can do that outside of the data type even at some later time.
Strings were defined and as part of the Java system but we can define our own ordering on strings with the comparator.
So in our sort implementations we can change them as shown in this example to support comparators.
Then, the less method will take that comparator as an argument and this is the one that actually invokes the method compare two different keys.
This is a straightforward modification to our sorts.
And then exchange of course rather doing comparable has to use object.
So with these straightforward changes at the comparator as argument to the sort and to less and make array to be sorted array of objects, it's easy to convert any of our implementations to support comparators.
I won't go through it all in detail just to point out that this implements two different comparators as nested classes.
Say, for this fictional class Student, that's got two instance variables - name and section.
If you're going to implement it compared to students by section, then it'll return just the difference of the sections which is my minus if less zero if equal then plus if greater.
And this code is straight forward way to implement comparators that you can use as a model.
If you need to be able to sort data on two different keys.
And if you give it to by section comparator, it will them in order by the second field very convenient for all kinds of data processing applications.
And we came up with that before when we're talking about using a sort for the Graham scan.
We needed to have a comparison for points that orders them by the polar angle they make, make with the given point p.
That's what we needed for the Graham scan algorithm for the convex hull.
Points are defined data type for geometric objects and so what we need is code that will compute the polar angle and use that as the basis for comparison.
There's an easy way to do this based on CCW that is described here in this text.
Most of the time all you need to do is do the CCW of the two points.
You either have to check whether the, one of the points is above p and the other one is below.
But otherwise, usually it's a CCW call in this code which again I won't go through in detail as an implementation of a comparator for two D points.
It implements the compare method that takes two points as argument and with just a little bit of calculation is able to do the compare.
So this code is the basis for applying the sort, system sort method or any sort method for the Graham scan for the convex hull that we did at the end of the last lecture.
What is harmony?
Harmony is the study of chords, and scales, and melodies.
And how we typically hear them when music is played.
Another term we would like to help you define is the term ear training.
Which helps you to do so something like this.
So what is ear training?
And we will do exercises to train your ear to be more effective.
Everything we do is going to come from the C major scale.
And if you look at the screen, you'll see a C major scale.
There are the names of the notes.
The first degree of the scale is C, the second is D, the third degree is E, F is the fourth degree, and so on.
So I'm going to play the C major scale.
We'll start with C.
That's the major scale.
Simply put, an interval is the distance between two notes.
That would be a Perfect 4th.
We're going from the root, which is the 1 .
An interval is the distance between notes.
It's a Major 3rd.
So again, the interval is the distance between two notes.
So those three terms, harmony, ear training, intervals, along with the major scale, are going to give the foundation that you're going to need to be successful, not only in this class, but throughout your musical career.
I'm a Professor of Harmony at the Berkley College of Music.
I'm also a Professor of Piano.
I started playing the piano a long time ago.
I started playing classical music.
When I was around 11 or 12-years-old, I started playing at my church.
So, I had the classical side where I was reading notes, and then I had the whole gospel church side where we use no music at all.
They were kind of in two different camps.
Then I was able to mend and mold those two different styles and fuse those two different areas of my life together.
So, I was able to identify what I was playing, and it just made life a lot easier.
What are we going to be sharing in this course?
W hat we're going to be sharing a little bit about the major scale, the major triads, minor triads, major and dominant seventh chords.
We're going to talk about the minor pentatonic scale.
Very important thing to remember is that in order for you to get the optimum out of this experience, it is imperative that you have a keyboard to practice on.
A piano would be best, but a keyboard would work also.
I want you to commit to practicing 15 minutes every day.
Doesn't have to be fast, you just need to practice it and just be aware and get your fingers accustomed to playing the keyboard.
Can you make that commitment for me?
Trust me, you will not regret it.
One more condition for you taking this class, it is mandatory that you have fun.
What is harmony?
Another term we'd like to help you define is the term ear training, which helps you to do something like this.
So, what is ear training?
Now, the first thing we'd like to do is we'd like to start with the C-major scale.
There are the names of the notes, underneath that you have the solfege syllables.
The first degree of the scale C, second degree is D, third degree is E, F is the fourth degree, and so on.
So, I'm going to play the C-major scale.
We'll start with C.
That's the major scale.
Simply put an interval is the distance between two notes.
We're going from the root which is the one to the four.
That's a major third.
I'm going to one to the five.
So, again an interval is the distance between two notes.
So, those three terms; harmony, ear training, and intervals along with the major scale are going to give the foundation that you're going to need to be successful not only in this class, but throughout your musical career.
Finally, we talk about stability.
This is really one of the rules of the game but it's much easier to talk about in the context of the real algorithms that we've seen so far.
And really it doesn't make sense if you don't know about comparators which we just introduced.
So, the typical application that I just used as an example is say the set of student records.
Maybe the third line there is the final grade.
So it's all fine sorted by name and but then in order to distribute it out to the people leading it to the sections, what we want to do is sort by the second fields, sort by section.
The problem is that when we do that, it messes up the sort by name and that's annoying.
You might assume that once you have it sorted by name, then when you sorted by the second field then it should maintain the sort of by name for all that have equal keys in that second field.
Actually not all sorts preserve that property that is called stability.
And clearly, it's worthwhile to think about for your application whether you want or need a stable sort.
And so, it's an annoying surprise for many people and many applications.
So a stable sort is a sort that preserves the relative order of items with equal keys.
That's an interesting question that we'll take a look at now.
The quick bottom line is that insertion sort and mergesort are stable but not selection sort or Shellsort.
You have to carefully check the code to be sure.
Always, in this class, we have an exercise or exam question is this version of this sort stable or not?
So, students learn to recognize whether the code is stable.
So this is just another typical example where we've got things sorted by time, and then what we want to do is maybe these are important events.
But if they use a stable sort, then it stay sorted by time and lots of applications you want stability.
Alright, so let's just look at each of the algorithms that we've considered so far.
Insertion Sort is stable.
Well, we never move equal items pass one another.
In this example here, when we get A1, well that's so in this case, the index is just one that appears in the array, it's just A's and B's.
When we get our second A, we stop the sort as long as we're not less.
Or if we did the other way around and proceeded accordingly.
Usually way, the way to show that a sort is not stable and it's just to see if it has a long distance exchange that might move an item pass some equal item.
So, where we found the minimum A and B is in position zero.
We did a long distance exchange and that catapulted that first item past any item that it might be equal putting them out of order.
And that's may not get fixed so that sort is not stable.
It might move items past some equal item and leave a result where items that are equal or in different order than they were originally in the file.
Shellsort also has long distance exchange and so it's not stable.
It moves keys past other keys that could be equal and so its easy to construct examples showing that Selection Sort is not stable.
And, and in our code, if the two keys are equal, it takes from the left subarray so that means that, it will always take the, if there's a two sets of equal keys, it will preserve the relative order and that's enough to show that the merge operation is stable and then therefore Mergesort is stable.
Stability is an important property in sorting algorithms.
Mergesort is not only efficient, it's also
Here's some extra practice for you, with major second and major third intervals, just for you to practice on.
Today we're going to look at Quicksort.
It was named as one of the most important algorithms of the twentieth century and it's widely used for system sorts and many other applications.
Last lecture, we looked at Mergesort, another classic sorting algorithm, that's used in many systems, and today we are looking at Quicksort which is used in many others.
So, the idea is first randomly shuffle the array.
There's no larger entry to the left of j and no smaller entry to the right of j.
Once we have the array partitioned in that way, shown here in the middle.
Right here, we have K in its position.
Once we have it arranged in that way, then we recursively sort the two parts.
Sort the left part, sort the right part.
And then after those two things are done, the whole thing is sorted.
This method was invented in 1961 by Tony Hore, who won the Turing Award in 1980 for this and other work.
The idea is to arbitrarily choose the first element to be the partitioning element.
Since we shuffled the array, that's our random element from the array.
And then we're going to maintain an I pointer that moves from left to right, and a J pointer that moves from right to left.
Let's look how it works in the demo.
And then our method is to move the I pointer from left to right.
As long as what we have is less than the partitioning element.
And move the j pointer from right to left as long as it points to an item that's greater than the partitioning element.
The j pointer decrements until it gets to the c which it stops there which is less than the partitioning element.
And so now what's going to happen is those two elements are out of place.
The partitioning elements in between them and they're in the wrong order.
So what we want to do is exchange those.
Now we increment I, as long as it's pointing to an element that's less than the partitioning element.
Stop here at t cuz that's bigger.
And now we decrement j, as long as it's pointing to something that's bigger than the partitioning element.
Again, t and I are in the wrong places.
If we exchange them, we'll maintain the invariant that everything to the left of I is less than the partitioning element, or nothing to the left of I is greater than the partitioning element, and nothing to the right of j is less than the partitioning element.
So exchange increment I as long as it's less.
J points to the, rightmost element in the left subfiles, everything that's not greater than K.
Now, the code for partitioning is straight forward to implement.
In the, all during the partitioning process, the code is maintaining this invariant.
Where everything to the left of I is less than or equal to V.
So, finding, incrementing I, as long as it's less is a simple while loop.
As long as it's pointing to a bigger element that's similarly just a wide loop we put in to test to make sure we don't run off the left end of the array.
Then there's a test to see if the pointers cross.
Swap the elements of I and j.
When we get to the pointers cross we break out of the loop and exchange the partitioning element into position.
So that's a quick implementation of the Quicksort partitioning method.
Now, Quicksort itself then is going to be a recursive program that uses that partitioning method.
First thing we do is the public sort method that takes the array of comparable items as its argument.
And then it calls the recursive method that takes as arguments the limits of the subarray that's gonna be sorted.
Tells us where, which element is in position, and then recursively sorts the last part that's loaded, J -one.
And this one is kind of upside down as compared to Mergesort.
The first line shows the partitioning where k is put into position.
Then the method calls the sort for the left subfile first, and then that's gonna be partitioned on this e, and so forth.
Again, studying this, a, a trace like this, gives a, a good feeling for exactly what's going on in the recursive program.
Now it's working on the left.
Now it's working on the left part of the right.
Doing the left part of that.
And working from left to right, by dividing each sub-array in half as it goes.
Consider some of the details in implementation of partitioning with quick sort.
But one of the big advantages of Quicksort over Mergesort is that it doesn't take any extra space.
Now you have to be a little bit careful with terminating the loop.
When we give you working code it's not hard to see why it works.
And I, actually, in our implementation the test of the J pointer running off the left end is redundant.
Why is it redundant?
Well, the partitioning element is sitting there and it'll stop when it hits the partitioning element.
And the key thing, one key thing is that the way that these implementations work.
If the in-, the file is, the array is randomly ordered, then the two sub-arrays after partitioning will also be randomly ordered.
Actually, some implementations of Quick Sort out in the wild don't have this property, and they suffer a little bit in performance.
That random shuffle at the beginning is important and needed for guaranteeing performance.
And the other thing I have referred to but not talked about in detail is the presence of equal keys.
You might think it would be better to handle equal keys in some special way.
But this general purpose implementation stops the pointers on keys equal to the partitioning items key and we'll take a look at why that's important in a minute.
This is extending the table we looked at last time, and you can see over in the right column here, Quicksort is quite a bit faster than Mergesort.
And again, a good algorithm is much better than having a super computer.
Even on your PC you can sort huge array of a million items in less then a second and a million items in only a few minutes.
Cuz it's simply just faster than Mergesort.
And in the worst case if the random shuffle winds up putting the items exactly in order, then partitioning doesn't, doesn't really do anything except find the smallest, peel off the smallest item.
Kind of discover that everything to the right is greater.
That's a bad case.
But if we shuffled randomly, it's extremely unlikely to happen.
Most interesting thing about the study of Quicksort is the average case analysis.
So what we do is, as we did for Merge Sort, is write down a mathematical recurrence relation that corresponds to what the program does.
In the case of Quick Sort, the number of comparisons taken to sort N items is N+1 for the partitioning.
Any particular value happens with probability one over n, and if it's k, then the left subfile has k - one items in it, and the right subfile has n - k items in it.
So, for every value of k, if you add those up the probability that the partitioning element is k, plus the cost for the two subfiles, we get this equation.
This looks like a fairly daunting equation, but actually it's not too difficult to solve.
It's a simpler equation already.
Now what we can do is get rid of that sum by subtracting the same equation for N minus one.
This sum, minus the same sum for N - one, just leaves the 2CN - one.
Now that's looking like a much simpler equation.
Rearrange the terms, so we get n+1 cn-1 and then divided by n, n+1.
That's a kind of a magic step, but we will see that it makes possible to solve the equation easily.
It's the same as the term on the left.
We apply for n - one we get one less here and we can throw out a lot two over n.
And then that gives us an easy sum that we can approximate by an integral.
It's one over X from three to N+1.
And that's a pretty close approximation, in this case.
That's the average number of comparisons taken by Quicksort, and actually they for a random permutation of the elements which is what we do with the shuffle.
But with random, the random shuffle it's more likely that this lecture will end, because of a lightning strike.
Or your computer will be struck by a lightning bolt.
The average case, which is extremely likely for any practical application, is going to be about 1.39 n log n.
So that's more compares than Mergesort uses.
Whereas, Mergesort has to move the items into and out of the auxiliary array, which is more expensive.
So the random shuffle is a key for good performance in Quicksort.
It gives us the guarantee that the worst case is not gonna happen.
And also, it allows us to develop a math model that we can go ahead and validate with experimentation.
You run Quick Sort and you count compares.
If you did the random shuffle, it'll be about 1.39 n log n compares.
And its running time will be proportional to n log n, and it'll be a fast sort.
And that's what people do, and that's why people use it.
And you'll find textbook implementations or implementations out on the web that wind up running in quadratic time in certain situations.
You have to be a little bit careful of that and even if everything is randomized if there's lots of duplicates and the implementation is not done quite right the quick sort might take quadratic time.
So, let's summarize the properties of Quicksort.
Again, dependent on the random shuffling, is going to be logarithmic.
You can, limit the depth of recursion by always doing the smaller sub-array before the larger sub-array.
This is our fastest sorting algorithm, and there's a few ways to make it even faster.
And it's definitely worthwhile taking implementing for a Quicksort.
Even Quicksort has more overhead than you want for a tiny array, like one of size two or three or four.
So can implement it to cut off to insertion sort for small arrays.
Anywhere between ten and twenty will improve the running time by maybe twenty%.
Also you could just not do anything for small arrays, and then do the insertion sorting in one pass at the end.
So, that's a first improvement.
A second improvement is to, try to estimate the partitioning element to be near the middle.
Which on average will be at the middle.
So one thing that we can do is sample the items, and then take a median of the sample.
And that's actually not worth the cost for enlarged samples, not usually.
So that'll also improve the running time by maybe ten%.
So this is a summary of the optimized Quicksort with cut off the small subfiles in median-of-three partitioning.
So partition usually happens pretty close to the middle when you do that sample median-of-three and then small subfiles can just be left unsorted to be picked up with insertion sort right at the end.
Number of items that have to be touched during quick sort.
That's a summary of Quicksort, our best sorting algorithm that we've seen to date.
This online class is based on the class I’ve been teaching in Stanford for several years now, and it synthesizes materials from a number of sources.
First and foremost is the human, the person that’s using the system and the other people that they work and communicate with.
And then you got the interface that represents the system to the user.
HCI is the design, implementation and evaluation of user interfaces.
This course is going to teach you a set of tools for doing this effectively.
At the onset of the design project, we often don’t know what the problem is or what the space of possibilities might be, let alone what the solution should be.
Often it benefits from trying and comparing options.
Finally, it’s important to focus on the people who are going to use your system.
Good design brings people joy: it helps people do things that we care about, and helps us connect people that we care about.
Good user interfaces can have a tremendous impact on both individual’s ability to accomplish things, and societies’.
Graphical user interfaces help with computing a hundreds of millions of tasks, enabling us to do things like create documents, and share photo and connect with family and find information.
Bad design is frustrating and costs lives: medical devices, airplane accidents and nuclear disasters are just three domains where bad user interfaces and software errors have caused serious injury and many deaths.
These are big ticket items that take a lot of time to produce.
What really gets me is that many of these interface problems could have easily been avoided.
Bad design causes problems and degrades people quality of life in many smaller ways too.
Think of all the time that you waste on your bank's website or trying to figure out why the wifi doesn't work, or trying to set something on your digital camera.
Let's say these frustrations take 10 minutes a day for the average American.
With 300 million people in America alone, that’s 3 billion person-minutes a day.
or 18 billion person-hours a year.
That's a lot of time that we could’ve spent making the world a better place.
When an interface becomes automatic by practice, by design and most often by a combination, our attention shifts from manipulating an interface to accomplishing a task.
After all those hours of practice, they no longer feel the cane.
That attentional shift is what happens when an interface becomes intuitive.
Summarize this introduction: In this course you're going to learn a process where people’s tasks, goals and values drive development.
As my colleague John Zimmerman reminded me recently, users are just one of the many stakeholders in the design process.
In designing for people, don't forget the other pieces of the puzzle.
For those who'd like to learn more, I’ve put a Further Reading slide at the end of many of my lectures.
I'm a Professor of Harmony at the Berkley College of Music.
I'm also a Professor of Piano.
I started playing the piano a long time ago.
I started playing classical music.
When I was around 11 or 12-years-old, I started playing at my church.
So, I had the classical side where I was reading notes, and then I had the whole gospel church side where we use no music at all.
They were kind of in two different camps.
Then I was able to mend and mold those two different styles and fuse those two different areas of my life together.
So, I was able to identify what I was playing, and it just made life a lot easier.
What are we going to be sharing in this course?
W hat we're going to be sharing a little bit about the major scale, the major triads, minor triads, major and dominant seventh chords.
We're going to talk about the minor pentatonic scale.
Very important thing to remember is that in order for you to get the optimum out of this experience, it is imperative that you have a keyboard to practice on.
A piano would be best, but a keyboard would work also.
I want you to commit to practicing 15 minutes every day.
Doesn't have to be fast, you just need to practice it and just be aware and get your fingers accustomed to playing the keyboard.
Can you make that commitment for me?
Trust me, you will not regret it.
One more condition for you taking this class, it is mandatory that you have fun.
What is harmony?
Another term we'd like to help you define is the term ear training, which helps you to do something like this.
So, what is ear training?
Now, the first thing we'd like to do is we'd like to start with the C-major scale.
There are the names of the notes, underneath that you have the solfege syllables.
The first degree of the scale C, second degree is D, third degree is E, F is the fourth degree, and so on.
So, I'm going to play the C-major scale.
We'll start with C.
That's the major scale.
Simply put an interval is the distance between two notes.
We're going from the root which is the one to the four.
That's a major third.
I'm going to one to the five.
So, again an interval is the distance between two notes.
So, those three terms; harmony, ear training, and intervals along with the major scale are going to give the foundation that you're going to need to be successful not only in this class, but throughout your musical career.
Here's some extra practice for you, with major second and major third intervals, just for you to practice on.
You're already familiar with the Internet of Things.
The global network of interconnected objects that can collect and exchange data.
The IoT can be a powerful resource for interpreting and harnessing this vast amount of data to create cloud-based solutions with real value.
That's why we've developed this course on cognitive IoT.
You'll get hands on experience, building an IoT solution, using your Raspberry Pi, a Sense Hat, and IBM's IoT Platform.
Your instructors, Brian Innes and Yianna Papadakis Kantos, have a wealth of expertise in this field.
They'll keep the course informative, interesting and enjoyable.
My name's Brian Innes, and I'm one of the developer advocates for The Internet of Things, at IBM.
>> And together, we're going to take you through the developing for Internet of Things course.
A couple of years ago, I was quite amazed at a maker hack that I went to.
What a small team achieved in two days.
They took an idea and created a prototype at the end of those two days.
Not so long ago that would have taken a corporate R&D department several months to achieve a similar effect.
>> It's really quite simple when you're talking about an IT solution how easy it is to take a device nowadays And connect it to the Cloud and create an end-to-end solution.
>> So then I'll show you how to create an end-to-end solution.
We're going to show you how to get trusted data.
So you know that data coming from the sensor or the device is trusted data when it gets to your application.
We're going to show you how to exploit the many services available on a typical Cloud platform to get value from that data.
And on this course we're going to be using a Rasberry Pi, for the device and the sensors.
And we're going to be using IBM's cloud platform called Bluemix to actually do the practical work.
And that combination is an ideal solution because the Pi already has some sensors that you can utilize with the sense hat.
And you have the development environment on the platform that you can use to write your application and deploy your application.
So you can sense the world, analyze the data, and respond to it And you learn how to do that all within the course.
>> To start with, I'm going to teach you how to use an open-source visual development environment called Node-RED.
It allows you to very, very quickly build your application code, both on the Raspberry Pi device, but also on the cloud platform.
Such as connecting the device, you use Node-RED to help you connect the device to the platform.
And then you bring in services such as analytics >> to help you process the data.
And you use more services to help you push out the data to let's say, a cellphone for example and make the world react.
And you learn how to do this not only on Node-RED but also using the API's.
And the idea is that by the end of the course you have the basic functionality that allows you to create your own IRT solution.
>> Brian and Giuliana will show you how to create apps that leverage connectivity and analytics as part of an integrated, cloud based IoT development platform.
They'll put the power of the Internet of Things in your hands.
Sign up for this comprehensive, hands on course today.
Before you start working on this course, there are a number of prerequisites that you need to have in place.
For hardware, you must have one of the current models of Raspberry Pi, to be able to do the programming assignments.
There's also an additional add-on board called a SenseHAT.
The SenseHAT provides a number of sensors that you can use to read the current environment, that we'll use in the programming assignments too.
To get the Raspberry Pi working you'll need a power supply and an SD card and then, depending on how you want to connect the Raspberry Pi, you may also need an additional wi-fi dongle.
The Raspberry Pi 3 comes with built in wi-fi, but earlier models you will need to provide a USB dongle if you need to connect via wi-fi.
When you start up the Raspberry Pi, you may also need a USB keyboard, mouse and then HDMI monitor or TV to be able to initially configure the Raspberry Pi to the network.
In the resources section of the course, under programming resources, I provide the link to the Node,js webpage where you can download the latest version.
You must ensure that you include the NPM package manager as part of your Node install.
The other piece of software you need is the Cloud Foundry Command Line tool.
And again, under the Bluemix resources for the course, I have provided the download link where you can get the latest version of the tool.
You can verify that you have all the software prerequisites by using the -V option after the commands, so that's node -v, npm -v, and cf -v.
That will verify that all of the commands are correctly installed and you're ready to start the course.
During the course, we'll show you how to set up the Raspberry Pi, so you don't need to worry about that now.
However, if you are ordering hardware, I would recommend that you wait for the hardware to arrive before you go through and sign up for BlueMix.
In the next lesson, we'll ask you to sign up for IBM Bluemix, the Cloud platform that we're going to use in this course.
And when you sign up, you get a 30 day free trial.
So my recommendation will be wait until the hardware arrives before you start that 30 day trial.
Let's look and see what this course is going to cover.
What is it?
And why now?
In the next lesson, we're going to start looking at how do you go about creating an Internet of Things?
A typical Internet of Things solution has some code or some part of your application running on a server, which is increasingly on the cloud.
And there are also parts that will run on a device or an intermediary gateway.
And then in the following lesson, we'll switch and look at developing the application on a device or a gateway.
Again, using the same rapid application development environment.
The hardware we're going to use for this course is a Raspberry Pi with a SenseHAT add-on board.
This will give the ability to monitor the environment and then sent that data back to your service site application.
We're going to look at how you get data flowing from your sensors through the Raspberry Pi to your back-end solution.
But we want to ensure that in an IoT solution the data that arrives at your server application is trusted data.
You know where the data comes from and that device has been pre-registered with the platform, so you know the data you receive is trusted data.
An application will then process your data and then you often need to send messages back to the device.
In the last lesson, we're going to switch from using the rapid application development environment to a lower level APIs.
I'll show you a number of APIs you can use to establish that trusted data flow in different programming languages and suitable for different run-time environments.
So we have APIs that will run on very, very limited resource embedded devices, right the way through to the cloud platforms where you have lots of environments.
And this will allow you to take what you learned on this course using the Raspberry Pi and apply it to any device that has Internet connectivity.
So in summary, this is a hands-on introductory course to programming for the Internet of Things.
We'll be touching many areas you need to consider when creating an Internet of Things solution.
A lot of those areas we won't have time to go into in depth But it will put them into context and allow you to determine any additional learning you want to do following this course.
And by the end of this course, you will have have a solution running on your Raspberry Pi talking to a cloud-based solution.
Before we get into the first lecture on the Internet of Things, I just want to discuss briefly the practical work you'll be doing during the course.
After this lesson, each of the following lessons will require you to complete two assessed programming assignments.
Along with those programming assignments, many of the lectures include a demonstration or a walk through of some code.
I strongly advise you to follow along with the demonstrations on your own machine.
Where there is a demonstration in a lecture, you'll find a reading task following the lecture with step by step instructions on how to complete the demonstration.
You should have some basic skills in both of these languages before starting this course.
But you do need to have some experience of using these two languages.
But if your experience of JavaScript is only on the client side or in a browser, don't worry.
There's a lecture before your first programming assignment, where I take you through how to create a Node.js application and use the express framework.
For the practical work in this course, you'll use a Raspberry Pi.
You do need to have a Raspberry Pi to complete the programming assignments in the course.
In addition to the Raspberry Pi there's an option to get the SenseHAT add-on board.
This board contains all the senses we'll use during the programming assignments.
But if you don't have a SenseHAT, we do provide simulators both in JavaScript and in Python.
So you can do the programming assignments without having to have a SenseHAT.
Bluemix offers a 30 day free trial, so there's plenty of time for you to complete this course without having to pay anything or without even having to enter any payment details into the system.
So enjoy this course, and we're now going to get on with the first lecture looking at an overview of the Internet of Things.
Welcome to this learning module, where we try to answer these questions.
What is IoT?
Why has IoT become such a focus these days?
And, what makes IoT so special?
So, let ́s start off with what is IoT.
IoT, the Internet of Things is a network of interconnected things, objects, devices, sensors and systems.
That collect and transmit data and exchange data between them.
The data they generate is collected, analyzed, and acted upon.
More and more of the world's activity is being expressed digitally by billions of devices.
IoT based customer devices, such as wearables and smart appliances, receive a high degree of media attention but think about the smart meters, GPS devices, phones.
All of this data can be collected and analysed with resulting actions that can help us better take care of our health.
Protect our homes, become more effective.
Collecting such data enables business to learn more about their operating environment.
This way, businesses can identify and act on the potential to create new value.
Value by unlocking your revenue from existing products and services, value by inspiring new working practices and processes, value by changing or creating new business models or strategies.
But sensors, networks and the Internet have been around for a long time.
Over the last three years a number of factors have allowed for our world to be more connected.
For years we have been seeing sensors in our world.
Lights turned on or doors opened when motion was detected, fire alarms sent out signals with the detection of smoke, and so forth.
In recent years, sensor cost has dropped, making them more affordable and thus more readily available.
We also have better control of power, yes, devices can be plugged in.
But they can also self generate power by harnessing solar energy, for example.
In addition to efficient power, consumption of local sensors, there are a variety of affordable ways to connect the sensors to other things and to the cloud.
The options for a connectivity are vast, ranging from direct internet connections, to low cost radio, to available and affordable WiFi, to the abundance of cell phones.
So now, we can have for example, a low cost sensor, feed it with a low cost power radio that can efficiently capture and relates data to other, more powerful devices that they can in turn collect and transmit data to the internet.
Platforms are another reason why IoT is generating a lot of attention.
They no longer have to keep all of the software and hardware locally, requiring infrastructure management for development of applications.
Instead they can take advantage of a number of cloud solutions.
Ranging from infrastructure as a service which provides the virtual machines or storage.
To software as a service, which takes it one step further and provides software in the cloud.
Or, platform as a service which provides servers, run time and services that help developers develop, test, and deploy applications.
IBM Watson IoT Platform is a blooming service which provides device management capabilities, connectivity management, such as support for a number of connectivity protocols, and varying levels of security, application management, such as API support for the cloud and uses, IBM Watson cognitive computing technologies to analyze the data as well as dashboards and reporting to support decision making.
But, what makes IoT so special?
A variety of particles, domains and applications allow collection of data from a vast number of things not hindered by location.
Those things can be configured in a number of different ways.
Some with processor, storage, keyboards, screens, but somehow or another they must communicate with the internet either directly, or via an internet connected device.
There are consistently new sources of data for businesses.
And businesses are creating systems of insight by unlocking data from billions of interconnected devices.
IoT takes computing power out of the data center, and onto the cloud.
The cloud is critical for devices beyond the reach of the data center.
To connect and communicate from anywhere in the world through open standards.
Personalized services designed from usage data creates opportunity for new sources of revenue.
You have probably notices some of this with advertisement after a Google search or with suggested videos and YouTube.
But there is so much more data, 90% of it which is created at the edges of IoT that is never even captured, analyzed, or acted upon.
And from the data that is captured, 60% of it loses its value within milliseconds of being generated.
This means that most of the data is never turn into insight.
IoT will allow us to innovate, operate, and engage at the next level.
In summary, getting things, devise a center systems, to monitor our world and communicate with each other, is easier than ever.
Collecting and intelligently analyzing the data leads to new opportunities for value and industry transformation supported by applications written specifically for the Internet of Things.
To get started, let's identify how development effort, whether for the Internet of Things or any application in general, benefit from cloud computing.
Cloud computing gives access to a variation of hardware, software, databases, applications, and so forth from the cloud instead of on-premise.
Of course, there are hybrid cloud solutions, but we will not cover those at this time.
Traditionally, you have service, storage, networks that connect them and the teams together, virtualization of the service so teams can work independently, and VMs that allow application development.
If companies are managing this infrastructure locally, then you also need a team of experts to install, update, maintain, plan for growth, and real estate to host all of this in.
There are a number of companies out there, including IBM, who offer infrastructure as a service, which means that companies utilize storage, servers, and networks for their data and can even host their VMs and applications on infrastructure managed remotely by a service provider.
With infrastructure as a service, someone else manages the infrastructure, but you manage everything about the virtualization.
So you will still manage the VMs, pick the OS and software, patches, licensing, development of the application, instances, brokers, and so forth.
This is all very expensive and takes away from the innovation process and developing the applications.
With platform as a service, the service provider makes a development provider available and the service provider manages that environment.
The developer is provided with an environment that they can develop and deploy their applications on.
They just need to worry about the logic of the application, developing the application, and managing the data.
Software as a service is another cloud computing solution which makes applications available to the end user, for example email applications or IBM Bluemix developer services or Citrix GoToMeeting.
All of these services are available to companies, and each has its strengths and weaknesses.
As you can imagine, there are more options for customization and control when everything is managed on-premise.
We briefly explained how services such as IBM Bluemix offer lots of benefits that can simplify the development, management, and deployment of your applications.
We concluded with a tutorial of Bluemix where you saw how to create a Bluemix account.
And you were introduced to some Bluemix foundational concepts such as organization, spaces, and boilerplates.
The first flow that we're going to create is the simplest flow possible.
We're going to create one input node, and an input simply has a connector coming out of the right-hand side.
So there is no input to the left-hand side.
This is a starter node which is going to start the flow.
The other node we're going to add is an output node.
This node terminates the flow.
And we're going to use the debug node that we've already seen.
Now you have the two nodes on the sheet, we need to connect them.
To make a connection, it's very easy.
Mouse click down on the output node, drag across to the node you want to connect to, and release the mouse over the input connection of that node.
And you'll see we've now got the two nodes connected.
The way Node-RED works is by sending messages down these connection.
Each node can take the input objects and then either send out a modified version of it, or create an entirely new object.
When a JavaScript object arrives at a node, it is available using a variable code, msg.
The most important data within the object is usually in the payload property of the object.
And you'll see by default the debug node outputs the content of the payload property of the incoming object.
But this can be modified in the configuration.
If there are multiple connections leaving a node, a copy of the object goes down each of the connections, to the next node in those chains.
So I can split the flow and send messages down to different sub branches of the flow.
Each node can have a configuration panel, and to bring up the configuration panel, you simply double click the node.
If we do that on the inject node, you see I have a number of options to send different data types.
I can also set options to allow messages to be repeated, or to start when the flow has started.
So an inject node can start when the flow starts, and then send a message at a set interval.
When I create the flow in Node-RED running on Bluemix, the flow is stored in a no secret data base which is also running in the cloud.
But when I create a flow from a default install, like a the flow is stored in the local file system.
Within the Node-RED user interface, I have the option of storing flows into a library, so i can save then and then call them up in a later date.
This also how you can save a flow outside the Node-RED environment.
Similarly, using the menu command, I can then take a flow and import it.
I take the text file that I previously exported and paste it into the dialogue to import the flow.
One thing to note though, passwords are not saved when the import and export flows.
So you have to reinput any passwords stored in the flow.
If you have a quick look at the pallet, you'll see there are nodes installed.
There are nodes to access data bases, nodes to access social media and various messaging systems.
But sometimes you want to install a new node, and looking out on the Internet of the Node-RED site, you'll see there are a large number of nodes that you can install into Node-RED.
And there are a few ways to install a new node into Node-RED.
But with the release of the latest release of Node-RED, which is version 0.15, you can install publicly available nodes using the menu.
It's also possible to install nodes by altering the configuration of the underlying Node.js application running Node-RED, or by manually installing nodes using the NPM command.
I'm not going to add a new node that will generate a random number.
On the Node-RED flows page, I can see the details of the node I want to install.
So in the Node-RED interface, select Manage Palette from the menu.
Select the Install tab, and then enter Random in the search field.
The random node should appear in the list of available nodes.
Select Install and then wait to be adviced that the node has been added to the palette.
And I can now drag it on to the sheet, then select it, and switch to the Info tab, where I see how to see the node.
If I connect it to the flow, I can now generate random numbers.
An addition to adding nodes shared by other developers, you can also create your nodes.
And details of how to do this are available in the Node-RED documentation.
But that's out of scope for this session.
In this module we're going to continue looking at NodeRED.
And we're going to look at how you add new functionality to your flow.
There will be times when you can't find an existing node that delivers the functionality you need for your application.
And that's where the function node comes into play to allow you to write code to participate in your flow.
But before we jump into the function node I just want to show you a couple features to help you debug your flows.
So if we go into nodeRED, into the flow editor, and, like the last lesson, if we an an inject node and a debug node and connect them.
So change the type to string, and we're simply going to add the text Hello.
So whenever I hit the inject button, I'm going to send an object containing the payload as a string with the content Hello.
And we can see in the debug tab that that message comes out.
If you look at the debug node on the properties there, you'll see there are also some properties available.
By default the debug node is showing the content of the msg.payload property.
But it is possible to change that to show other properties within the message object or using this drop down you can show the entire object that we sent from the previous node.
You'll also notice that if I name the debug node, then in the debug pane I get to see what node created the output.
Again, if you've got multiple debug nodes this can be very useful to help you identify where a message originated.
And as we look into the function node you'll see it's possible for other nodes to directly output content to the.
So we're going to continue now and start to look at the function node.
As I said previously, the function node allows you to write some JavaScript code to manipulate the object, the message object from the previous node.
And send out any message object.
The JavaScript you write runs in the sandbox, so there are some restrictions.
And there are some special features within the function node that I'm going to talk to you through now.
To help explore the function node, I've created a small flow.
And I provide the business as a text file that you can import and follow along.
So from the menu, we use import, select clipboard, and then paste in the content of the text file.
That allows you to place the flow on your work sheet.
And what we're going to do is we're going to look at these various function and I will explain what's going on.
So the first thing to remember is you must return a JavaScript object.
In this first example I'm simply setting the return value as a JavaScript strain.
And when I do this, and initiate the flow, you'll see we actually get an arrow displayed.
Because what NodeREDs trying to do is, it's trying to add some internal properties as that message flows along the flow.
So you must return a JavaScript object.
So looking at the next example I've simply put the string object inside a JavaScript object.
And now you'll see that I can send the message.
And I get the correct output in the debug node.
If we look at the next node down, you'll see that we're creating an array of JavaScript object.
Now going back to my first comment where you have to send an object as a return, this may look a little strange.
But the function node handles JavaScript arrays.
In a very unique manner.
This allows you to output multiple flows from a single node, and you'll see if you open the configuration here, you have the option of creating more than one output connector from the function node.
And the way an array works is the first item of the array will go to output one.
If there's not an output configured, then any items in the array that don't match up with an output are simply thrown away.
If I enclose an array, within an array, then the function node will separate the items in the inner array, and send them as separate messages.
So in this example you see I have the original array from the previous example.
And that item is also an array.
And if I run this flow, you'll see that I now get four separate messages sent from the node.
So the first three items get sent to three outputs, and the fourth item is discarded.
The first object get sent to output one.
There are then two objects, outputs on output two, and then the last object is output on output three.
So you can see how you can easily split a large set of data into separate messages using this very useful functionality within the function node.
The next three nodes, we're going to look at concerned JSON object.
You've seen how we JSON object to send data down to node.
So this first one creates an object, sends it down the flow, and then the next node along is going to extract one of the properties within that object.
But when you interact with third party sites using APIs, libraries, and packages, you may not get the data back as a JSON object.
It's quite common to get the JSON data back as a string.
And when you have a string, you then can't pause and access properties within that object until you convert that string into a JSON object.
But in node red, we do have a node which does that conversion for us.
You'll notice that if I run and try and access from a string, I get an error reported in a debug tab.
But when I parse out a string into a JSON object, I can then successfully access the properties.
And just for your information, the JSON object would also work the other way.
If I pass in the JSON object, it will return a string.
Although they look similar in debug tab, you can look at the type of object reported in the debug tab to verify if you're looking at a string or a java script object.
The last function node, we're going to look at a number of things here.
The first one is the ability to put some status information onto the flow worksheet.
If you're going to do something that might take a short while, you might want to just let the user know that things are happening.
You can add text, and you can also add visual indicators wIth different colors to show what's going on.
So in this function, I've got a series of timers that last for a second, and I just update the status when each one of those timers gets fired.
And then the last status, I simply return an empty object, which will clear all status information from the sheet.
And as I run it, you'll see that we see the text.
The first visual indicator with text, the second visual indicator with text, and then finally the status is removed.
The other thing that this function shows you is how to handle a synchronous functionality.
Many APIs in JavaScript use function callbacks.
So when I call a function, I pass in another function to be executed when the initial function completes.
Within the flow of the calling application, that function will return immediately.
So you'll see here that I've got a series of set timer functions.
And this function takes as the first parameter, a function that's to be run after the number of milliseconds specified by the second parameter.
In this case, I'm using one second.
And you'll see, I have a number of nested timer functions here.
At the end of my function node, you'll see I just simply have a return, I'm not returning any object.
So at this point, when we get to here in the flow, nothing we'll be sent along the connection.
So this shows you how you can call an asynchronous function, and when that function completes, it will then carry on the flow.
The last thing that this example shows you is how you can interact with the login features of NodeRED.
The node object has a number of methods that you can call to log to either the console or debug pane.
So I've got node.log which will output to the system console.
I've got node.warn, and that will put to the system console but it will also put a warning message in the debug tab.
And this would allow me to send the message to a special node called the Couch Node.
When an error happens anywhere on a sheet, I can get a catch node or multiple catch nodes to handle those errors.
By adding an object to the error method, it means that, that catch node will be invoked.
And a flow will be initiated from that catch node.
I can then do any functionality I need to handle the error.
If I look inside the catch node in the properties, you can see I can get the catch node to handle errors on all my nodes on this sheet, or I can simply ask it to catch for a specific or set of nodes on this sheet.
If you notice when it's logged, the name of the function node that contained the login function is output in the debunk tab, so I can identify which node created this log entry.
Sometimes, you might want data to persist between different indications of your flow or even share some data with other nodes on the sheets or within your application.
A NodeRED provides three objects to allow you to do this.
If you just want to save some data between indications of your node?
And I see there's a Get and a Set method where I can just store data against the key.
If you want to share data on the same sheet of the same tab in the flow editor with other nodes.
Then you can use the flow object and again, you've got the get and the set methods to store data against the key.
However, you need to be aware that this data presides in memory and is not saved on restart of the environment.
For your application, you may prefer to use one of the many services available on the cloud platform to persist your data.
Which will survive across restarts of the system.
There is one of the feature that the global object allows you to do and that is to import new packages.
So to do that, we need to add any packages your function node wants to use to the global system and then that allows your function node to use it.
And to do this, we need to go and edit a conflict file.
So you need to restart NodeRED after adding the package.
So if we go back to Bluemix, go into the application and then select edit code.
We can find the file and then go and find the global function, and then add any package we want.
And for this example I'm going to use a package that calculates a cyclic redundancy check.
You also need to add this to the packages.json so the package is included at the build.
Push this to Git which will then cause my NodeRED application to be re-staged and restarted.
And now I can use the global object to go and get that package, and then use it in my code.
Now that you can create a web end point, you need to be able to format data to return to the requester.
You can do that within a function node.
But there is another node that will help you create the output, and that is the template node.
The template node allows you to create the content that you want to return to the sender, but mark place holders where you want data to be inserted.
And the template language used is called moustache.
And it's called that because it uses a pair of curly brackets at the start and the end, and they look a little bit like a mustache.
If you open up the documentation in the info tab, there is a link where you can actually get information about the mustache tempting language, but it's really simple.
If you just want to replace an item or a property from the JSON document, you just name the JSON document.
And if you look at the properties on the Mustache template node, you'll see that I can specify where within the message that I want to take the data from.
There are also options within the Mustache template language using the hash or the pound sign to say if this property exists, then complete this section.
But if the property doesn’t exist, then a section can be omitted.
So you can actually drive the template based on the data sent to it.
If the property within the JSON document is a list, you can then get the template to iterate over that list once per item in the list.
Again, this is a very useful way of just formatting variable length data that you may have.
And then the last point is if you use the hash sign, you can say if this property doesn't exist, or if it exists but it's actually false, the value is false, then complete the section.
So very, very simple templating language, but it can be quite powerful.
We can pass functions to the templating engine, but we're not going to cover them today.
I'll let you explore them at your own time.
So I'm going to put the HTTP request and response nodes and the template node together in a short example.
I've provided the input text file, so you can follow long if you want to.
And I'm now going to import it onto my NODE-Red workspace, and then we're going to have a look at it.
So the first thing you'll notice, I have two in points.
One is called menu and one is called specials.
They just link into a function node which sets up a JSON object.
The difference between the two objects is the specials flow contains some additional data.
And the idea here is we just want to display a menu of beverages.
So opening up the template node, we'll walk through this.
I'm using HTML syntax here, and we're going to display the output on a web page.
The first thing I do is put a title on the page.
And here, I just want to pull in a single property from my JSON object, and that's what is today.
And you can see here how I can access that property using this mustache tag.
The next section, I want to list out all the drinks that are in the list.
So I'm using the hash or the pound template to say iterate over all the items within the drinks property.
And I go and list all of the items in the drinks property.
The next section is where I want to say what the specials are.
The first case uses the hat or the caret symbol, which says if the special section does not exist or is false, then include this section.
It's saying if the specials exists and is non-false, then include this section.
And we simply do the same as we did for the drinks.
So you can see it's very, very simple to create a webpage taking data, putting it to the template, and that putting it in the desired format.
And I can use the same template node to create any format I want, whether it's email or a tweet or any other post to social media that I want.
We can now test this flow by opening a new browser window and entering the URL for the menu endpoint and the specials endpoint.
And you can see, here, that both pages render as I would expect based on the data.
There's another way to control our node works.
And that is to send some additional data to the node.
If I look at the info tab at the HTTP response node, you'll notice it looks for three properties on the incoming message.
The first one is the payload and that's what would be sent to the responder as the body but it also accepts values for status code and also the HTTP headers.
If you want to return JSON in a rest API, you need to make sure you set the right content type in the headers to let the requester know you're sending JSON data back.
For an HTML page, I typically send text slash HTML as the content type.
So I'm going to add a function node and I'm going to add the content type HTTP header and set it be text/html.
When node allows you to specify a property in the configuration page and also as an incoming property the incoming data flow will override the configuration page.
Many nodes allow you to dynamically configure them using incoming properties from the flow.
So going back to node red we'll see in the output section I also have a number of options.
We've seen the debug node and how useful that is, in just helping work out what's going on in a flow, and help to debug a flow.
But you'll see we can also output messages to thinks like MQTT.
We can send data down an HTTP socket or a TCP socket.
There is a node from Twilio, a third party company that allows you to send SMSs and make voice calls automatically.
So, on our mobile phones we are all used to getting notifications from the apps.
This service allows you to do that.
You can also send data to the Watson IoT service.
You've already met the function and the template node, but you'll see there are some additional notes here that can be useful.
I'm not going to cover them all but I'm just going to point out a couple that you might want to investigate.
So, there is an HTTP request node.
Now these nodes are all in the middle of a flow.
They have connectors at both ends of the node so they appear after an input node and before the output node.
And the HTTP request allows you to make a request maybe a REST API or even call up a webpage from any server on the Internet.
If I just grab this node onto the canvas and open up the properties you can see I can provide a URL.
I can specify whether I want it to be a get, post, put, delete.
But then can also specify how I want the return to be handled.
Now again, APIs I can call may return a number of different formats.
And in the pallet of function nodes you'll see we do have some nodes to help you handle that.
So we've got a node that will convert an XML document into a JSON object.
There is an HTML node that will help you pull data from an HTML page and also a CSV, or comma separated value, node that will help you work with comma separated value files.
They're a section of nodes that help you put logic into how data flows through your application.
So, I can use this node and it acts a bit like a switch statement in traditional programming.
So I can set up values and based on the value of the data it will send the output along different paths leaving this node.
I can also use this node to switch values.
So there may be a value in the flow that needs to be transformed before it can be used in another flow.
This node allows me to do that.
And then the last node we're going to look at in this section is the report by exception.
There are many times where you may be checking for a certain condition to happen, and you want to report that condition.
It's not helpful to have that condition reported every time a sensor reading comes in.
So, say if I was reading temperature every five minutes, I don't want to get a text message every five minutes saying that a temperature has exceeded the threshold.
I only want to know about it when the temperature first crosses that threshold.
And the report by exception node helps you achieve that functionality.
Moving to the social section, you see we've got a number of nodes that allow you to send or receive emails or send and receive Twitter messages.
These make interacting with social media very, very simple.
The next section is the storage section, and you can see there are a number of options available here.
What I'm going to do is just focus on one of the nodes, the cloudant node.
If we switch back to the Bluemix console and look at our NodeRED application.
You'll see that there is a service already bound, that is the cloudant service which holds the configuration and all the flow data for the environment we're using.
And we can actually use this cloudant database to our application specific data.
And I'm going to show you how simple that is.
So cloudant is a NoSQL database.
To use cloudant we're going to drag the cloudant output node.
So notice it's an output node, the connection is on the left-hand side.
And if I open up the properties, you'll see I can specify how to connect to the cloudant database.
And the first option in the list is actually the Bluemix service.
So many nodes in NodeRED understand Bluemix.
And they have a configuration option available when they recognize that the companion service is already linked to your application.
So for this cloudant node we can very simply connect to the bound cloudant service to our application.
If we don't use Bluemix service linking, we have an option to configure an external service.
So here I have to go and create the connection information to connect to an external database.
So that's the host name, username and password.
But we're going to use the linked cloudant database.
The next thing I have to provide is the name of a database.
So that's just the collection of documents within cloudant.
And this node is very, very helpful, if the database doesn't exist in the database, it will create it for you.
So I'm just going to put here coursera as my database name.
So what this is going to do in effect is just write a random number to the database every five seconds.
And then if I switch back to Bluemix and look at my cloudant database, you can see I'm adding records.
The analysis in IBM Watson sections in the palette are where you'll find the nodes that usually link to a Bluemix service to allow you to analyze the data that's coming in to your application.
As I mentioned at the start of this module, collecting data is not where the value of your Internet of Things solution is going to come from, it's what you do with that data.
And typically you may want to do some analytics over that data to actually determine what's going on.
So we think of a real world example, your mobile phone.
Your network provider can track where your mobile phone is and work out the location of it.
Now for a single phone, that may not be too useful to the provider, but if I take all the mobile phones in an area and look at how they're moving, say along a road.
I can get free travel information.
If all of a sudden, all of the phones on a particular major highway start slowing down, it indicates a problem on the road.
So just by using the data, combining it from multiple sources, multiple phones, I can all of a sudden get travel information.
So a good internet solution is going to unlock that hidden data and make it available as a useful service.
So there are a number of different techniques available here.
Again, out of the scope of this course, but moving forward with your Internet of Things solution, you going to really need to look at the various analytics options, whether you going to collect all the historic data, look for patterns within that data to work out cause and effect.
And then once you've created that historic model, you can then use live data to do predictive analytics.
So, if I see a certain value in a sensor, going out of its normal range.
But the data may also tell me what the problem is likely to be.
So again, these are the sort of solutions that add value.
And lastly remember your application is running within IBM Bluemix.
And that has a rich set of services that you can pull into your application.
There may not be a NodeRED node available for all the services, but the services have API Breeze or Rest APIs.
And then the other option is NodeRED at the end of the day is a Node.js application.
So you have the option of extending that application using JavaScript code.
And you can then mix your flow's application with traditionally coded applications.
Similarly, if you look at the NodeRED documentation and you have an existing Node.js application, you can easily add NodeRED to an existing application.
So it's a very, very flexible programming environment.
The Raspberry Pi is quite a powerful, little computing platform.
Most Pi models have an ethernet socket available, and the Pi 3 has an additional Wi-Fi and Bluetooth built in.
Other models you need to provide a USB dongle for Wi-Fi and Bluetooth connectivity.
Because of the small footprint, it doesn't have the Ethernet socket, and you usually need to provide a USB hub and connector cable to convert from Micro USB to USB to allow you to connect your USB peripherals like your Wi-Fi dongle, Bluetooth dongle, and keyboard and mouse.
So again, you may need a connector to allow you to connect it to your HDMI TV or monitor.
We're using the Raspberry Pi as an example of a device, but there are a number of devices available that you can buy off the shelf.
And I'm going to talk about them in two categories.
One is what I'm calling the platform category.
Where these are quite powerful compute platforms that usually run an operating system like Linux, and they really do provide you with a lot of computing power in a small form factor and limited power consumption.
The other type of device is the embedded device.
This is usually a smaller footprint with very limited compute power.
You're often limited to just a few K of programming memory.
Some devices provide very low level access to hardware, such as timers and other features that allow you to drive sensors.
Another difference with the devices that you encounter is the programming languages they support and also the integrated development environments you can use to program them.
So off the shelf, you have a very wide range of devices available.
You can choose from quite powerful platforms, to very small embedded platforms.
And you can choose whichever programming language and development environment you want.
Let's say, I want to create an environmental monitoring solution.
I want to be able to go into a building and leave sensors in strategic places for a period of time just to monitor what's going on, temperature, humidity.
I don't need a very large compute platform for that.
I just need a small device and a temperature and humidity sensor.
So something like I'm showing you here, the NodeMCU with a temperature-humidity sensor, is fine.
But then I might want something like a Raspberry Pi to consolidate all that data before I report it to my Cloud platform.
So that's a quick example of how you might use different devices to implement your solution.
One thing I often see, however, is more than one device connected together to provide a solution.
So I often see a device like the Raspberry Pi used in conjunction with something like a Arduino or Genuino where the Raspberry Pi does the compute and implements the solution, but offloads all of the control of the sensors to the embedded platform.
And this is a model you'll also see in quite common use in production hardware, including the Sense HAT.
If you look at the schematic of the Sense HAT, you'll see there is an IT tiny processor onboard that.
So the Raspberry Pi talks to that processor, and then that processor deals with the lower level device control and sensor control on the board.
So now we can look at the Sense HAT.
There's also the eight by eight LED output matrix, and then there is the joystick.
So in this one add-on board, you've got a number of sensors and output options.
But again, this isn't the only sensor and output option available.
There are a wide range of sensors available.
But there are other options that allow you to connect sensors and output devices using a plug and play mechanism such as the Grove Kits.
These provide a standard connector, usually an add-on board for your device, and then a range of different sensor options.
So as you go to develop your own IoT solution, just be aware you've got a wide range of choice of device and sensors available.
And it's really up to you to decide what you're comfortable with.
As we progress through the rest of this course, we'll use the Raspberry Pi and the Sense HAT or the Sense HAT simulator to connect to the Internet and the Cloud platform.
But the techniques and APIs we'll be using can be applied to any device with any sensor.
As we go through the APIs, I'll show you the options for different programming languages and different runtime environments, how you can connect different devices to the IoT platform.
In this video, we will look at how to set up your Raspberry Pi and Sense HAT for use with the IBM Course, a developer's guide to the Internet of Things (IoT).
What other required hardware for setting up and using the Raspberry Pi and Sense HAT, installing the OS, and configuration of everything.
This course uses a Raspberry Pi and a Raspberry Pi Sense HAT.
The Raspberry Pi is a small computer with a CPU, one or more USB ports to connect the keyboard and mouse, for example.
Some models have an RJ45 internet port, and the Pi 3 has an onboard wifi and bluetooth for internet connectivity.
Mounting holes for securing the sense hat on the board, for example and a five volt micro USB connection for power.
It is not compatible with the earlier 26 pin models of Raspberry Pi one model Bs and As.
The board has sensors for gyroscope, accelerometer, magnetometer, temperature, barometric pressure and humidity.
There's a specific Python library named Sense HAT that you can use to control the Raspberry Pi Sense HAT.
With a Raspberry Pi Sense HAT combination, you can sense the environment, send and receive information to and from the cloud, so, you have your own little thing that senses the world, and IBM Bluemix will be the cloud it reacts with.
The Raspberry Pi pages have a wealth of information and fun ideas of what you can do with the Pi and Sense HAT.
Along with your Raspberry Pi and Sense HAT, you will need power supply for your Pi, you will also need a micro SD card that will act as the Pi's hard drive, holding the operating systems, software and applications you create.
At a minimum four gigabytes, but we recommend eight gigabytes for your micro card.
But to prepare the SD card, you need to use your computer with either Linux Macro windows operating systems.
Since computers usually don't have a micro SD card port, you need a micro SD adapter, or a micro SD USB adapter for your laptop.
You will also a monitor, HDMI cable for the monitor, keyboard and mouse, and power supplies for all.
Installing the OS on the micro SD card, before you can use your Pi, you need to download an OS for it.
It comes with a lot of software, including LibreOffice, which is a fully featured office suite compatible with Microsoft Office files, Node-RED, which is an open source visual editor for wiring together hardware devices, APIs and online services for the internet of things, and other software.
In the documentation, under installation, you will find detailed instructions to download, on downloading the latest Raspbian Jessie OS and how to write the OS image on your SD card.
In the extra researches for this module, I have included in the example for the Windows OS, since that is the computer that I am using.
Once the image is on the SD card, you are ready to power on your Raspberry Pi and Sense HAT.
Before you power on the unit, assure that you attach the Sense HAT and that you have secured it.
Attach the keyboard and mouse in the USB port, the screen on the HDMI port.
To connect to the internet, I used an ethernet cable and I connected it to my router, but you could choose to go wireless.
The primary desktop is displayed when the boot is complete.
Click on the terminal icon to open the terminal window.
The rest of the setup needs to be done from the terminal window.
You could continue to work on the Raspberry Pi or switch to using your remote connection from your laptop.
This will allow you to copy and paste from the documentation, rather than having to type every command.
To set up a remote connection, you need the Pi address of your Raspberry Pi.
>> The change user password option is selected, press enter, and change your password from the default.
Using the up down arrow keys, select host name, press enter and set the host name for your Pi.
The default is Raspberry Pi, you can use the tab keys to jump to the available options, I press enter, since I made no changes.
Now, let's modify the localization option.
Set the default for cal, use the spacebar to select and deselect what you need, and set one of the locals as default.
If you have the WiFi option, set it to use the correct frequency for your country.
For interfacing options, select P2 SSH and enable it, this will allow you to connect the Raspberry Pi via SSH.
You're now done with the configuration tool, reboot your Raspberry Pi.
Update the Node.js, Confirm that you want to update.
This command will allow node applications to run bluetooth scans.
Please reboot before starting, I hope you found this useful.
Install the Raspbian OS on a SD micro card.
This work will be done on the computer.
To do this, you need to download the latest Raspbian.
Uncompress the image using 7-Zip, for example, and install Win32DiskImager.
Okay, let's get the OS on the SD card.
Put the SD Micro in an SD adapter and plug it in the SD card port on your computer.
If you don't have an SD port, use a USB adapter.
My SD card is in my D Drive.
Start 132 disk imager, point it to the Rasbian image you extracted and tell it which drive holds your SD card.
Remember that the separation will override the card, so make sure you're using the correct drive.
Do not click read, because that will take the image from your SD card and override the Raspbian image.
Click write, this will replace the SD card content with the image specified.
But eventually, if all goes well, the success message is displayed.
This is the file system on the SD card, once the install is complete.
Once the SD card is imaged, you are ready to configure the Raspberry Pie.
In this module, we're switching focus from programming on the backend in the cloud to programming on the Raspberry Pi.
In the last lesson, I showed you how to use NodeRED to implement your backend solution.
And now I'm going to use NodeRed on the Raspberry Pi to program our device part of the application.
If you look here, I'm in the graphical user interface of and from the menu, I can select to start NodeRED.
And that gets the environment running, and then I can launch a browser either running on the Raspberry Pie or on a laptop connected to the same network.
So having a quick look through the pallet, you'll see that there are some different notes installed on the Raspberry Pi.
Including this section here at the bottom where we've got nodes specific to controlling GPIO and accessing features of the Raspberry Pi.
Where we start the flow in a cloud and database.
And if you open up a terminal window and go to your home directory, you'll see that there's a .node-red directory.
And this is where your configuration and settings file.
Can all be found for your install of NodeRED.
There are some differences in how we install new packages to be made available to the function node.
Or to install new nodes on the palate when running on the Raspberry Pi.
Because we have no access to the command line when running on Bluemix, we have to go modify the package.json file to add any new packages to the environment and then rebuild the environment.
For NodeRED to be able to see any new packages you install, you have to run the install from within the .node-red directory or you could make them available using the Global install option, but we're going to install them into the .node-red directory.
So, first of all I'm going to add a new Package and make it available to the function node.
Unlike we did on Bluemix, we're going to use the crc function.
Again, this is different from what we did in Bluemix.
We used the Bluemix settings.js file, but on the Raspberry Pi it's just settings.js.
And you'll find that in the .node-red directory.
So, editing that file I simply go and look for where the global context is defined and then add the new entry to the end of that object.
Once I've saved that file, I need to install the package and for that I use npm install.
I have to stop and start node red for these changes to take effect.
So again in the command line it's node-red-stop.
And then node-red-start, we'll start NodeRED running again.
On then I can go and try the sample I did on Bluemix simply create a function node and get it to calculate the COC for a string.
And I'm going to output that as decimal to the debug So you can see how I can now run the CRC check correctly.
The next thing we going to do is add a new node to the palette.
I'm going to use a node that converts a binary file to bay 64 encoding and also goes the other way.
So in sending binary data across the net, it's often converted to a text format.
And this node will do that for you, so to make the node available, I simply go onto the command line, make sure I'm in the .node-red directory.
And then just issue the NPM install command.
Once the node is installed, stopping and then starting NodeRED.
And then refreshing the browser screen, we'll see that node show up in the pallet.
We can look at the info tab.
I get shown the command on how to install NodeRED, so it boots at system startup.
And if I want to stop it starting as the ii boots, I've also got the command here on how to disable the autostart at boot.
So I'm going to start my environment, and sure it start when the pi boots, so enter the command.
Another node that's not installed by default on Bluemix, but is available at install time on the Raspberry Pi is the exec node.
With the exec node, I can run a system command as if I was running it from the command line.
Any output generated by the command is unavailable to my flow.
And I'm going to get it to issue the netstat command.
You'll see I have the option of a pending msg.payload to the command.
So this allows me to effectively pipe commands together like I would on the Linux command line.
But I'm going to select to add an additional parameter.
And I'm going to add the minus A parameter to the netstat command.
I see the expected output coming to the debug tab.
So we're now going to look at the IBM Internet of Things platform.
In the next module, we'll go in to details, but for now we're going to set up, similar to the initial sample application with the simulated device.
We're now going to show you how to connect the Raspberry Pi to the Internet of things platform using that quick start service.
So the quick start service is a sandbox environment, it doesn't require any security or pre-registration of device it just sits there.
So to do that, we're going to use an IBM IoT output node.
If we open up the Configuration, you can see we get offered the option to be a Quickstart or a Registered device.
We're going to select Quickstart and it predefines a device ID.
So whenever you use a device with the IBM Internet of Things platform it has to have a unique device ID.
Usually, when there is a network connected device, we'll use the network adapter MAC address.
But the device ID has to be any string that guarantees its unique within the device type and organization.
You'll notice that on the configuration node, there's also a very handy link to the quick start application.
If i click this link, it will open up the quick start visualization page using the generated device ID.
And we're simply going to use the random node to send the random data to the quick start application.
So, I create an inject node, the random node, connect it through to the IoT node.
And I'm just going to put a debug node there, so I get confirmation that I am actually sending the correct data, but now I also need to format the data.
So, I am going to put a function node in, before sending the data.
To get Quickstart to visualize the data correctly, it has to be in the right format for the platform to understand.
So within the object, we need a D property, D for device, and within that property I can have any data that I want to publish in my event.
For me, I'm just going to create a random property and then can fill it in with the data coming from the random node.
So now, I've got the inject node.
Publishing the data every five seconds.
And if I just deploy this application, you see in the debug tab, I'm getting the expected data.
In this module, we're going to look a little deeper into the Internet of Things platform.
In the previous module, you saw how we can add the platform to an application, and we also covered the organization.
It's the organization that ensures that all data coming to and from a device is trusted data from a trusted source.
So now let's look at who you can actually send and receive data.
Within the platform, there are three types of applications that can connect to the platform.
The first one is from a device.
So, a device is something that can send data to the platform.
Before a device can send data, it must be registered with the platform.
Before you can register a device, you need to create a device type.
A device type allows you to organize your devices into their capabilities.
Next, we have an application.
A gateway is a special type of device.
Sometimes you have sensors or sensor networks that aren't able to connect directly to the internet.
So, cannot connect to the IOT platform.
The Gateway acts as a bridge to connect the sensor network to the internet and the IBM IoT platform.
Like a device, a gateway must be registered before it can communicate with the platform.
When a device wants to send data to the platform, it creates an event, and the data flows in an event.
So, devices send events to the platform, and applications receive those events.
If an application wants to send data back to the device, it issues a command to that device.
So, to summarize, we have devices, we have gateways, and we have applications.
Devices in gateway need to be preregistered and be assigned to a type, whereas an application needs to present an API key before it can connect.
Devices in gateways send events to the platform.
An application can issue commands to be sent to devices.
So, now I'm going to look at how you create device types, and then how you create and register a device.
So, now in the overview section.
To create a device type, I switch to the device section, and then select to add a device.
On this screen, I can choose a pre-existing device type if I've created one, or I can press this button to create a new device type.
And then I just go through and add any data that I want to that device type.
I have the option of defining attributes, I won't capture it when defining a new device, or if I prefer I can just leave this all blank.
Once you've gone through and you've created your device type, you then need to go and add a device.
So, while in the screen, I can go and add a device and select the previously defined device type.
If I define any attributes, I get asked to complete these when I'm registering the device, but eventually I get to this screen, where I'm asked to either select a pre-assigned key or create my own key.
As a tip, when you're registering a device, I always use a common token.
So as I'm modifying the code or changing the code, I always know what the token for any given device is.
And that's because, once you get to this screen, this is the last chance you get to record the token.
Once you close this screen, you cannot recover a token.
And if you lose a token for a device, the only option you have, is to delete or unregister that device, and then reregister it again with a new token.
So when developing, I always use a common token, so I don't have to keep enregistering and registering devices if I get what the token was.
The system places no demands on how you organize and classify your devices.
So, it's useful to classify different types of device, using a different device type.
We've looked at how devices registered, you create a token, then you'll see as we progress through the course where you use that token.
We're now going to look at how an application authenticates to the platform.
As I mentioned previously, applications don't need to be pre-registered, but they do need to present an API key when they connect.
So in the platform dashboard, if I'm switched to the Access section, you see here I can select to create an application API key.
There is one special type of application that does not need an application key to be generated manually.
And that's, like this Node-RED application, when a Bluemix application is bound to the platform service.
If I switch to this tab, you'll see that these applications are automatically added to the platform and a key generated for them.
But if I'm not connecting the application and linking it in Bluemix then I do need to generate an API key.
So I press the button to generate a new API key.
As you see, I'm presented with the key and the token, and I can also name the key or provide some comment as to where the key is being used to help me manage the keys.
But, like the device registration, once this screen is closed, there's no way that I can recover this token.
So, I need to take note of the token here.
Otherwise I would have to delete this key and regenerate a new one if I lose this token.
Switching back to device tab, like the device we can go and create a gateway type.
So we click to add a new device and here we can select Create new device type.
Or you got the option to Create device type or a gateway type.
Again I simply go through adding any attributes I want until I get to the summary screen.
And like the device and the application, this is the only time I get to see the token.
So if you're in developement mode, I suggest using a common token.
But if you're in production mode remember that this is the only time you get to see it.
So if you don't take a note of it here, you cannot recover it.
So now we've seen how to register device and gateway types.
And then register a device and a gateway.
And for applications, we now know how to generate the API key.
We're now going to look at how to use these in an application.
So going back to Node-RED, we've already seen the Watson IoT node connecting to the Quick Start service.
We're now going to modify this to connect to our organization onto our registered device type.
So back in Node-RED on my Raspberry Pi, if I select the what's in IOT output node, click to open the configuration, and then change it from Quickstart to a Registered device.
I click to open the authentication details, and here I need to fill any details for the device.
First thing I have to enter is the six letter organization ID, and then I need to put in the device type.
This must match exactly the device type that we created for the raspberry pie and it is case sensitive.
Next we enter a device ID.
As I mentioned previously, with the network connected device, we usually use the MAC address without the colons.
So this is the MAC address for the active interface.
And then we add the authentication token.
Now if you didn't set a standard token that you can remember.
So save to close that.
And then close the configuration tab and simply redeploy.
And we're now publishing data to our organization.
I can no longer use the quickstart application to look at my data and verify being sent.
So we're now going to move into Bluemix on the Node-RED application on Bluemix.
On Bluemix I have a different IBM IoT node and this node connects to the platform as an application rather than a device or a gateway.
So I'm not going to use the quickstart service, so I'm going to select to use my organization.
And I'm actually going to bind to these Bluemix service here.
Once I've done that, you see I now have the option to select the input type, and I want to receive device events.
But I'm going to leave this to receive all events coming into my organization.
I close the editor, and then connect the node to a debug node, and deploy the flow.
And you can see, I'm now receiving the data from my Raspberry Pi device.
And instead of connecting as a device, we're going to use the other registration and connect as a gateway.
So I open up the IoT node and now I select to connect as a gateway.
And you'll notice in the info tab, where I can actually send data into this node and we'll override the default configuration.
For the purposes of the practical work, we're actually going to use the Sense HAT as a remote sensor.
So we're going to use the CPU temperature as a gateway status or event and then we're going to use data coming from the Sense HAT as a remote sensor.
So when you do the practical work, you'll see you're going to create a Sense HAT device type and then use the Pi as a gateway to send that data to the Bluemix.
I've shown you how to use the Internet of Things Platform dashboard to register and create devices.
But in reality when you're scaling up in production, you wouldn't want to manually have to enter hundreds, thousands or even millions of devices.
The last thing we're going to look at in this module is how an application can send information back down to the device or gateway.
And it does this by creating a JSON package and then sending that using the API to the device.
A device must register to receive commands.
In Node-RED using the input node, a device can register for all commands, or you can configure a node to receive only a specific command.
As a gateway, you can receive commands for yourself, or you can choose to receive commands for devices that connect through yourself.
When I choose to receive device commands, I get to specify the device type and the device ID of the commands I'm registering for.
When you register to a sequel of commands, you need to look at what command was sent and then handle that specific command appropriately.
And remember, a device can not send a command to another device.
When we looked at sending device events, we have to use a specific message format so the QuickStart application could display the data correctly.
For commands, there's no such recommended format.
However, sometimes the command name itself is sufficient information for the device to understand what to do.
So there's no additional data needed for the command.
In that case, you can just send an empty JSON object.
Let's now go and create a command flow.
So if you imagine I have an LED connected to my Raspberry Pi, and I wanted to send a command to either turn that on or turn that off.
So I'm going to have the statusIndicator command, and my status indicator is either going to be in an alert state or a normal state.
Now I'm then going to send this out through the Watson IoT output node.
So I put in here, the device ID of the device to receive this.
I can use the service, Linux service, to get the authentication credentials for this application.
And I simply then connect it all up, and deploy it.
And now when I inject one of these two options, I can either send my normal or my alert message.
Switching over to the Rasberry Pi, I use a Watson IoT input node to receive the command.
I can then select either all commands or choose to select only a single command.
I'm simply then going to connect a debug node so we can see the output of the command coming into the servers.
But typically you'd have to put a flow coming out of this node to actually handle the command correctly.
So if I'm receiving all commands, I have to work out which command I received, and then switch to the appropriate flow to implement that command.
In this session, I'm going to take you through some of the common reasons why previous learners have failed the end to end assignment.
The first suggestion I'm going to make is to read the instructions carefully.
There's a lot of information in the assignment instructions, and one of the common causes of failure is where learners partially implement a solution, so they don't complete all the steps necessary to pass the assignment.
In this assignment, we are simulating having a gateway and remote sensors that use the gateway to publish data and receive commands.
Maybe because they're not on a TCP/IP enabled network, or maybe for security reasons they maybe on a private network and can't access the internet.
So, you need to ensure that your device types and your devices are correctly setup in the Watson IoT platform and that you have the correct device types and device IDs For your Raspberry Pi and your SenseHat.
You need to publish the CPU temperature of the Raspberry Pi using the Raspberry Pi device ID and Device Type, and they need to be registered as a gateway device in the IOT platform.
The next issue encountered is the format used to produce a data.
The assignment instructions provide clear details on the CPU temperature on the senseHAT temperature and humidity.
And please note, the difference between using a number and the string for the temperature.
As the grader does check, the format of the data published.
Publishing the sense of data at the correct rate is another common problem learners experience.
While the video lectures may not have covered all of the nodes in depth, it did show you how to explore the capability of the available nodes.
It's important to test your solution to ensure that messages are not sent faster than once every five seconds.
And that when a value is sent, it is the latest temperature value sent.
Many failed submissions end up putting all the data in a queue and sending the next item from the front of the queue, which is also the oldest temperature in the queue.
Updating the LED panel on the SenseHAT is the biggest source of forum discussions.
Again reading the assignment instructions is important.
The LED should display information from two sources, and the instructions on how to display the information is very explicit, and the grade does verify that the assignment instructions have been correctly implemented.
The background color shown on the LED panel should be one of three specific colors.
The colors are specified in the instructions and the exact colors need to be used for the grader to pass your assignment.
The background color should be set on the command received from the server.
The Raspberry Pi should not be doing any calculations using the current temperature.
If no previous command has been received, then the background color should be black.
If a command has been received, then the background color should be green or maroon depending on the value of the screen, in the command.
Displaying the temperature, again uses a very specific color of silver.
The grader will treat any color other than silver as part of the background.
So it will compare it to what the background color should be and report any differences found as part of the failure message.
And note, white is not a valid color for the temperature pixels, again another common source of error.
So ensure that you're displaying the temperature from the senseHIAT and not the CPU temperature, again this is a common source of error.
It does not matter which pixels are showing, it's just the numbers of pixels showing the silver color within the marked areas.
So a common source of failure is getting the rows and columns mixed up.
So they're not numbered one to eight, they're zero to seven.
You must ensure that the LED panel is updated whenever a new temperature is published from the SenseHAT, and also when a new command is received.
This means you have to have the last temperature value and the last command received available when updating the LED panel.
And achieving this should be familiar to you, as in a previous assignment, you had to do a similar thing with times and random numbers.
Hopefully, this video will help you determine why your submission failed.
I'll put you back on track to successfully competing the assignment.
Up to this point in the course, we've used Node-RED as the programming environment for all practical work.
From this point, we're going to switch to using the IBM IoT API.
If we switch to the documentation, you'll see that there are APIs for application and device and gateway.
The APIs are presented in a number of formats, there is a REST API an HTTP API that you can call and the documentation shows you how to make all of those calls.
And then there is a low level MQTT API.
And we'll cover MQTT in the next module.
The application API allows you to listen for events, and also to register and manage devices within your organization.
The device and gateway API allow you to publish events and register for commands.
If we look at the Python documentation for a device, you'll see there is an example, an explanation, of all the steps needed to connect, to publish data and to register for commands.
But at the top here, there's also a link to the Git repository hosting the API.
And within this, there are a number of samples.
You'll see here that I have samples for a device, for a gateway, but also how to implement a managed device.
If you go back to the documentation, you'll notice that the API is also registered with the Python Package Index.
So I can use package management tools such as Pit to install the package on my local platform.
Similarly, if I look up the JavaScript, the Node option, you'll see that again I have access to the Git repository containing samples.
But this time, the API is registered with the NPM, which is the packet manager for Node environments.
So looking a little bit deeper at the Python API, you'll see here that all the stages needed are laid out.
Again, you'll notice that the information I provide here is the same information I provided in Node-RED, where I need to give my organization, my device ID, and the device token.
And we can connect, publish events, and register for commands and then handle those events when they arrive.
If I just switch now to the Node API, you'll notice that it's very much in the style of Node programming.
Whereas, the Python API was synchronous, in Node it's asynchronous.
So the API very much matches the programming style of the language.
So far, we've always used the JSON data format when sending events to the IBM IoT platform.
Obviously, the QuickStart application will not be able to display this, but once you have your own organization, you can select to choose a different data format if you wish.
And again, there is a sample in the Git repository, to show you how to do that in the various language options available.
So now, we're leaving Node-RED, and we're working with the APIs.
I'm going to show you how you access the SenseHAT, using the Python API.
Again, I'll show you how to stimulate the syntax with the API, during this presentation.
And I've included the link in the resources section on where you access the API documentation.
So you see, it's quite an easy API to use, you just bring in the library.
So I've got calls to actually get the sensor data, and also I have a series of code where I can manipulate the eight by eight LED matrix.
Programming Python on the Raspberry Pi can be done directly using the graphical user interface.
So be sure that you pick the version two of the IDE, not the version using Python 3.
So we can simply launch the IDE, and now we can program in Python.
If you want to program on your work station, and then copy the files across, you can do that as well.
So if I just take one of the sample applications, from the IDE, on this one is going to output a question mark on the LED panel.
And you notice, from within the IDE, I can run the application and on my SenseHAT the display changes and I see a red question mark on a white background.
In the next assignment instructions, which is SenseHat API in Python, you'll see that there is some code that you can download.
That bundle contains the emulator for the syntax, using the Python API.
You simply unzip that archive onto your Raspberry Pi into a directory and then you need to do all the programming within that directory.
When you code in that directory, and run your application from within that directory, you'll pick up the SenseHAT simulated API rather than the system installed API for the real SenseHAT.
So it's important that you run your Python applications from where you extract that archive.
The simulated API only supports two functions, which are the functions you will need for your assignment.
And they are the get_temperature function and the set_pixels function.
So that allows you to get a temperature and also output to the 8 by 8 LED matrix.
And like the node red, there is a web UI to allow you to set the value for the temperature, and also see the, LED matrix output.
So before you start your application you need to go and start running the web server to serve that UI.
So in the archive that you unzipped, you'll see that there is a public directory.
So you have to open up a command line window And go into to that directory.
You can then open up a browser to point to that server, and there is a Read Me to explain all this.
If you're not running the browser on your Raspberry Pi, there is an update you have to go make to input the IP address of your Raspberry Pi.
But I'm running on the Raspberry Pi, so I can just leave it as is.
And you'll see, I have the same user interface that I got when I run the Node-RED simulated nodes.
And here, if I run the test application again, from inside this directory, you'll see that I'm now controlling the LED matrix on the simulated SenseHAT.
In this module we're going to start looking at how to develop an application on Bluemix.
Whilst this is not specific to an IoT application, the cloud has enabled IoT solutions to be deployed without having to have a large physical IT infrastructure.
But in addition to the platform as a service features, it also offers an additional two ways of running applications.
And this is built on top of the open-source Cloud Foundry platform.
When developing an application for a platform as a service, you need to be aware that you have to take how the platform manages your application into account when implementing the solution.
With the platform as a service, you don't have any options to go in and configure the lower level operating system or middleware configuration.
If anything goes wrong, you don't have the opportunity to go in and debug your application.
The platform manages the application, under most circumstances will simply deploy a new instance of your application and delete the old instance.
So anything you have stored locally on that application runtime is likely to get deleted and thrown away.
This is why you need to be very aware when implementing your solution, how the platform will manage your application.
The platform provides services for storage and for cache management.
You need to use those services rather than local runtime resources.
And that is an option you can use when developing applications for Bluemix.
There's also a plugin available to the Eclipse IDE.
To use this, you simply go to the Eclipse marketplace within your IDE and search for Bluemix.
You'll find the plugin in the marketplace, you simply install it.
And then you can use the features to develop a Java or a JavaScript application in Eclipse, and use the plugin features to deploy and monitor on Bluemix.
But for the rest of this module, I'm going to show you how to do it using the command line.
So Bluemix as being based on Cloud Foundry uses the Cloud Foundry command line tool to manage and deploy applications to the Bluemix platform.
So in the prerequisites, we give you a link to where you can go and install the latest version of that tool and we'll be using that going forward.
I also asked you to install a Node.js runtime, on your computer.
I'm going to use that now to create an application from scratch.
So I'm going to open up a command line window and start the project.
What this does is capture the basic configuration of your project.
So this is the code.
Very simply it installs the express framework and then creates an application using that framework, and starts the application listening on the local computer at port 3000.
So I need to install express into my local environment.
So I can use the npm install command, and if I put an optional parameter save on this command, it will automatically update the package.json with the requirement for the express framework.
And if I type npm start, it will automatically look for that server.js and run the file.
And you can see here, I'm now listening to a server on that port.
But just having a server listening is of not much interest.
What we want to do now is add a root or an endpoint so I can point my browser at this server and get a response.
So I'm now going to use the express framework to add a root, and then provide some content to return when a browser asks for that root.
Now that I provided the root to my code, we can run the server again.
And I can point my browser at it to show that my code and my endpoint are now live.
So I now have a basic Node.js application using the express framework running locally on my computer.
What we want to do now is run this on Bluemix.
So the first thing you need to understand is for Bluemix to manage the platform, it needs to know where the application is listening for traffic.
And the way Bluemix and Cloud Foundry works is it tells your application where it should listen to.
It's also telling you where it's going to monitor your application from.
It expects you to listen to and respond to traffic on the port that it asks you to listen on.
So, even if your application is only interested in handling IoT events, you still need to run a web listener on the port that Bluemix advises you to listen on.
If you don't respond to that traffic, it will assume that your application is not running correctly and it will restart you application.
The environment variables that Bluemix uses to tell you where to listen to are vcap app host and vcap up port.
So we modify our application to look for these environment variables, we can then get our application listening to where Bluemix tells us.
And I'm using this notation, so the code will continue to run locally on my computer or on Bluemix.
So, this has now modified my application to run on Bluemix.
The next thing we need to do is have some information to tell Bluemix how to deploy this application.
Now I can do this using commandline on the CF tool.
But Bluemix will look for a file called manifest.yml.
And if this file exists, it will use the information that file to work out how to deploy the application.
So I'm going to show you how to create a manifest.yml file.
To deploy an application on Bluemix, the only information that is mandatory is to have a unique name for your application.
Now the application name also forms the URL.
So you need to pick something that is unique within the default demain for Bluemix.
So you can see the format here, I create a section called application and I just create an entry for the name.
That is the minimal manifest.yml file.
And that is all you need to actually get your application to deploy.
If you look at the Bluemix documentation or the Cloud Foundry documentation, you will see there are other options you can put in this file.
Such as the number of instances you want the platform to start, how much memory you want to give the application and so on.
So now that we've got our server.js file, our package.json file and the manifest,yml file, we're ready to deploy to Bluemix.
So the first thing I need to do with the command line utility is log on to Bluemix.
And I'm going to use the shortcuts, but if you want to know what commands, you can type, if you just type cf and then Enter, it'll display this help screen.
And again, if you want to look at any further commands, you can drill down to the specific commands and get the help screen for those commands.
Again there are command line options so I could type this is one single line.
So I've now got a session established with Bluemix.
And the next thing I want to do is deploy my application to Bluemix.
I must be in the current directory, so that's the directory with the manifest.yml file and the package.json file.
So, you can see I've now deployed the application and it's running on Bluemix.
I can go to the URL and I can use the entry point or the roots that we defined and I've now got the application running on Bluemix.
So I go to the Bluemix user interface, I've found my application running there.
And if you go in and look at the files, I can see what got deployed.
So you'll notice that there are more than just a three files that we created.
And the way that the command line CF tool works is when you push an application, it pushes by default, the current directory and all sub-directories and all files within those directories are sent to Bluemix.
But that's not always what you want to happen.
So there is another file you can create called .cfignore and that allows you to specify individual files or directories that you don't want to send to Bluemix.
So I can go and create a .cfignore, add these entries in and then repush the application.
Now when I do a cfpush, because the application name already exists, I'm simply going to update the application.
So, this will push the files that aren't in the .cfignore, to Bluemix and then redeploy the application.
And here you can see we've now got the files that we want deployed in the application.
In this module, we are going to continue looking at deployingg applications to the Bluemix platform.
In the previous module, you saw me deploy a JavaScript Node.js application to the Bluemix.
But at no point did I tell Bluemix I was deploying a Node application, but I did get the right runtime for my application.
And the way that that works is using buildpacks.
So Cloud Foundry and Bluemix use buildpacks to provide the runtime for an application.
A buildpack is just the collection of files and configuration needed to support an application.
Bluemix comes pre-configured with a number of buildpacks, but because Cloud Foundry is a open-source project, there is an active community creating additional buildpacks.
And many of the buildpacks that are able to run a Cloud Foundry will also run on Bluemix.
So how does Bluemix work out which is the correct runtime for an application?
Well, to see this, I'm going to issue the command, cf buildpacks.
And this shows me all of the buildpacks installed on the platform.
And the way that Bluemix works out what's the appropriate runtime for an application, is to ask each of the buildpacks in turn, starting at position one and going through all of the remaining buildpacks in order, to establish if they can actually run my application.
So in every buildpack, there is a script which detects if it can run an application based on the files that were uploaded.
Now, that is a Java buildpack and it will not recognize the files that I uploaded, so it will say can't run the application.
We'll next go to buildpack in position 2, and that's that.
Now that is the Node.js application and now buildpack simply looks for a package.json file.
Now, as I uploaded that file It will say it can run my application, so that that is the buildpack that will be assigned to run my application.
If Bluemix goes through all of the pre-installed buildpacks and none of them can run the application, then I would get an error displayed, saying that there's no supported buildpack to run my application.
If I want to bypass the auto selection mechanism, maybe bring in a community buildpack or select one of the older buildpacks that's at the bottom of the list, I can provide the buildpack option in a manifest.yml file or I can use the command line option to specify the buildpack I want to use throughout my application.
Now that I have an application running on Bluemix, the next thing I want to do is talk to the IBM IoT platform.
And Bluemix again uses environment variables to tell my application what services are bound.
So if you go into Bluemix, into my Node-RED application that we were using in previous lessons, I can see that I have the Cloudant database connected and also the IBM platform service connected.
So if I go to the runtime and look at the environment variables, you see I have two entries in the environment variables for the serves.
One for Cloudant and one for the IBM IoT Platform.
And within these environment variables are all the credentials I need to connect to the platform.
So to connect to any service bound to a Bluemix application, I simply need to look at this environment variable, which is vcap_services.
And from there I can parse out the connection information.
As we need the IBM Internet of Things platform linked to our application.
We need to modify the manifest.yml file to include the service that we want bound to our application.
Within the documentation for any service should be information about how to connect and use the service.
So the API specification or any libraries I can install to access the service.
We've already seen that there is an API for JavaScript, for the IBM IoT platform.
Now that I've got connection information, and have the API available within my application, I can very easily register or subscribe to receive the events coming from my IoT devices.
Again, the JavaScript API is asynchronous, and uses callback functions.
So, I've made the change to the application.
I've pushed the change back to Bluemix using the cf push command.
So, I want for the application to restart.
My Raspberry Pi is still publishing data to the Internet of Things platform, and then I can simply point my browser to the Bluemix application, and you can see that I'm getting the date and time and the value of the last received information.
So I've now connected to the service from my Node.js application.
You just completed a developers guide to the internet of things.
In this course you were introduced to the basics of creating an IoT solution.
You learned that the many ways to develop on the cloud either by having infrastructure managed by others like infrastructures a service.
In the course, you used Linux, and on the platform you had all the software you needed to develop the IT solution, plus services to enhance the solution, as well as deploy and scale the solution.
You learned that an IT solution has part of application running on the cloud, and part of it running on other devices and gateways.
You started with a boiler plate and you deployed an application on the cloud.
You learn how to access the application's code, modify the application by having more nodes and redeploy it.
You spent some time exploring Node RED, and you built some flows.
The true value of IT comes from working with the data, so you learn how to collect the data, store it, use it, reformat it, and learn how to go about analyzing it.
Continuing, you build the solution.
On the thing of the IoT solution, the thing that was used was a Raspberry Pi which can act as a device on it's own, or as a gateway for other devices, such as the Sense HAT.
The Raspberry Pi has enough resources to hold the part of the IoT solution, and communicate with the Sense HAT in the cloud.
Using IBMs Internet of Things platform services on Bluemix, you learn how to securely connect the device and the gateway, to an organization, and push data to the organization.
As well as secure these on commands, to devices, either directly, or through a gateway.
As you became more comfortable with developing for IoT, you switched from using Node-RED to using the APIs and more traditional development.
You've developed a solution, and eventually you've deployed it as well.
You accomplished a lot, and you should be very proud.
If you paid for the course and you met the passing grade criteria, you will be receiving information on receiving the course certification.
We hope that this course has started your IT journey.
Now that you have concluded this course, you have the basic knowledge required to develop a more advanced and complex IT solution.
Hi, my name is Tess Wilkinson-Ryan and I'm a law professor at the University of Pennsylvania Law School, which was founded in 1790.
I teach contract law and law and psychology.
I'm here to talk to you about American contract law.
Let's start with what is a contract?
A contract is a promissory agreement, a set of promises, that people make to each other and that the law recognizes and enforces.
Contract law is the law of exchange, the legal rules that enforce agreements to trade one thing for another.
I'm going to start by introducing two foundational facts of contracting that both motivate and explain many of the doctrines I'll discuss in the next hour.
Let's start with the idea of mutual benefit.
Why do people engage in exchange at all?
They trade because it makes them to a person better off.
We both like this deal, right?
Because we both want to eat bread.
My neighbor cannot turn inedible raw wheat into bread without a heat source.
And though I have the tool to bake with, I can't make bread dough without wheat.
This means that the exchange has value just by trading, we have both gotten something we wanted and didn't have before.
When I agree to pay the cable company a monthly fee for Internet services, I might complain about the exorbitant rates and the terrible service.
So I part with the money and take the Internet in return, making both me and the cable company better off than we were before the deal.
But we don't know that a particular claimant really preferred to be bound by the state's criminal code.
All else being equal, or believed himself better off in a legal system that permitted his neighbor to sue for trespass.
In contract though, we know that each of the parties prefers this particular legal obligation, and we know it because they chose it.
Of course, this is not to say that every party to a contract thinks the terms could not be improved, only if that the parties preferred this contract, the available alternatives including no contract.
Contracts can create mutual benefit, but unfortunately contracts cannot create time.
Time turns out though, to be an important motivating and complicating factor in life of an exchange.
So, take for example, my wheat for oven time exchange.
Now, one way that exchange could go, is that every time my neighbor wants to bake bread, he shows up at my house with his bag of wheat, and his bowl of bread dough.
We don't need a state enforcement mechanism making us trade.
We'll just trade because we both want to.
He says, I promise to deliver the wheat to you next month, if you will let me use your oven this weekend.
If I let my neighbor use my oven now, how can I be sure he's going to deliver the wheat as promised later?
The contract is the legal mechanism to enforce my neighbor's promise and give me the assurances I need to participate in this beneficial exchange.
It permits me to rely on the deal.
In this way, contract law facilitates the creation of mutually beneficial deals.
Voluntary exchanges create value are good, but there are lots of reasons that exchanges require planning or multi step performances.
In order to protect the party's investments in their deals, contract law enforces their promises to one another.
The ability, for example, to plan to plant more wheat.
To know in advance whether or not I'll have Internet service on the day that I need to send an important email.
To be able to do what I promised at a ti, at a convenient time, rather than a time that protects me against possible exploitation by my counter party.
But of course, time also makes exchanges worse, because it means that things can change.
So that they're no longer interested or benefited in the same way.
When those things happen, the law of contracts gives people an essentially revised cost benefit analysis to do.
They have to ask themselves whether it's worth it to go back on the deal, in a world in which they'll have to compensate the other party with money.
Breach of contract is really about what happens to a deal over time?
We're typically not talking about people who have lied about their intentions to participate in a deal, but about people who have changed their mind for one reason or another in time.
What I've said about benefit and time, these are really universal.
But as you know, the title of this talk is An Introduction to American Contract Law.
American contract law enforces the right of autonomous agents, that's us, to bind our future selves.
In the common law tradition, the will of the party in question is central.
Common law courts are very liberal about letting people choose to bind themselves to whatever deals they want, while also protecting them from contractual liability they haven't explicitly undertaken.
The second theme of American contract law is the notion that the role of contracts in our society is as an economic tool.
The Subject of Contract is economic exchanges.
This might seem obvious, given what I have said about beneficial trades.
But we'll see how narrowing the analytical framework of contract, from the promissory obligation broadly speaking, to one of economic exchange more narrowly has serious doctrinal implications.
So we have both an underlying principle of autonomy and freedom of contract, but with legal enforcement essentially confined to the commercial domain.
In this course, we will learn the foundations of economic growth.
And how to design, a tax and transfer system that would maximize society wellbeing, namely happiness.
This course, will signficantly improve your ability to understand economic issues presented in the media and to assess the wisdom of social economic policies.
And is likely, to change the way you see the economic world.
Also, I promise you, it's going to be lots of fun.
So, please join me, welcome to the course Economic Growth and Distributive Justice.
And congratulations as you begin this final step towards completion of this specialization, improve your English communication skills.
With different options for job seekers and current entrepreneurs or professionals this Capstone builds on the language and content skills you've improved and gained.
And develops them further through peer work and course lessons presented by me, Jerry, and Leah, you'll expand and practice the language and networking skills necessary for success in the professional world.
In this course, you'll study and compare cultural influences more thoroughly in Module 1.
Engage in email correspondence to set up interviews and meetings in Module 2.
And in our last module, you'll work on maximizing your English skills for now and the future.
Throughout the capstone, as you practice your language skills, make connections with people important to you, and develop your network, you'll increase your opportunities for success.
Completing this capstone will help you- >> Take your English communication skills to the next level.
Hello and welcome to our course, build your professional eportfolio in English.
My name is Karen Peterson and I will be your instructor for this course.
As a part of our specialization, improve your English communication skills, this course will go over how to build each aspect of your professional eportfolio.
From writing the headline and describing your work to putting them on social media.
Like this sign for Georgia Tech, your ePortfolio will be your way to brand yourself so that others will know who you are and what you can do.
Here's more of what you'll learn.
And in our last module, we will look at how to network with other professionals in your field.
As we move through the course, you will learn about all the main parts of a professional eportfolio.
You will practice how to write each of those main parts including your headline, summary, description in your work, educational background, and professional experience.
You will also get to practice networking and you will get the opportunity to receive feedback about your eportfolio from other course participants.
In that way, you and your classmates can learn together and grow together professionally.
By the end of the course, you will be able to write the main parts of your eportfolio professionally in English.
I hope you're excited to be in this course.
I know I'm excited to have you in the class and to be teaching you.
I look forward to your participation in this specialization.
And for you to build your brand, your name, like Georgia Tech, in my course, build your professional eportfolio in English.
Handheld systems, like all computing devices today, increasingly contain multiple computing cores.
And one thing this means is that multiple programs or execution threads can be running on your device all at the same time.
And that's a powerful thing, because it lets you do more work in a shorter amount of time.
But it can also make your programs much more complex, leading to errors and performance problems, if you're not careful.
So in this lesson, we're going to talk about writing multi-threaded programs for Android.
And we're also going to discuss some of the classes that Android provides to support this.
In particular, in this lesson I'll start with a brief discussion of threading itself.
Next, I'll talk about Android's user interface thread, the main thread in which Android applications perform most of their work.
And I'll also discuss how this impacts the design of your application software.
After that, I'll talk about the AsyncTask class, which helps to simplify threading in Android.
And finally, I'll wrap up with a discussion of the Handler class, another Android threading mechanism.
Well, conceptually a thread is one of possibly many computations running at the same time, within an operating system process.
In terms of implementation, each thread has its own program counter and run time stack, but shares the heap and static memory areas with other threads running within an operating system process.
Now this graphic depicts these concepts.
Each of these CPUs can carry out the instructions that make up the applications running on your device.
Now on CPU 2, I'm showing two processes running, p3 and p4.
Now, one way to think about processes is that they're self-contained execution environments.
They have resources such as memory, open files, network connections, and other things that they manage and keep separate from other processes on your device.
And within one of these processes, p4, I'm showing two running threads, T7 and T8.
Now, each of these threads is a sequentially executing stream of instructions, with it's own call stack.
But since they're within the same process, they can each access shared process resources, including heat memory and static variables.
In Java, threads are represented by an object of type thread in the java.lang package.
Java threads implement the runnable interface.
Which means that they must have a public method called run, that takes no arguments, and that has no return value.
However, if you need a refresher, please take a look at the Concurrency tutorial at the following URL.
Now some of the thread methods that we'll see in this lesson include the start method for starting a thread.
Some object methods that you may need when you're using, when you're using threads include the wait method, which allows the current thread to give up a lock that it holds, and to wait until another thread invokes a corresponding method, such as notify, or notify all.
And when this happens the waiting thread can reacquire the lock that it gave up when it called wait and can continue executing.
The notify method wakes up a single thread that is waiting on this object.
Now to use a thread you normally do the following things.
First, you create the thread.
Now threads don't automatically start when you create them.
To start the thread, you need to invoke the thread's start method.
Doing this eventually leads to the thread's run method being called, and the thread continues executing until that run method terminates.
This graphic helps to show this behavior.
First, a running application issues a new command to create a new thread object.
When this call finishes, the application continues, and sometime later invokes the thread's start method.
And this call returns back to the application, but also causes the code in the thread's run method to run as well.
And as the program continues, there are now two threads executing.
And of course, you can do this multiple times, creating and executing as many threads as you want.
So, let's look at an application in which threading would be helpful.
The first application that we'll discuss in this lesson is called ThreadingNoThreading.
And as you'll see in a second, the application displays a simple user interface with two buttons.
The first button is labeled LoadIcon.
When the user clicks on this button, the application opens, and reads a file, containing a bitmap.
And the idea here is that this operation takes a noticeable amount of time.
Now, in the code I use throughout this lesson, I'm actually going to exaggerate how long this takes, okay?
But don't let that distract you, the point is still the same.
Some operations take a relatively long amount of time.
And you as a developer, have to understand and deal with that.
The second button is labeled Other Button.
When the user clicks on this button, a toast message pops up displaying some text.
And the idea here is that if you see the text, then you know that the button's working.
Now if you can't click the button or you don't see the text, then something's wrong.
In particular, the user should be able to click either of the buttons at any time, and the system should just work.
So, let's run a version of this application that does not use any threading.
Now what do you think is going to happen?
Will I be able to press both buttons whenever I want?
Let's see.
Here, I'll start up the ThreadingNoThreading application.
I'll first press the Other Button.
And as you can see, I can click on it and the promised message appears on the display.
Now I'm going to do two things.
I will first press the Load Icon button, which will start the time consuming operation of reading in the bitmap from a file, and then displaying it.
And right after I press the Load Icon button, I'm going to press the Other Button again.
Here we go.
Now, I'll press the Load Icon button, and now I'll press the Other Button, okay.
So what, what's going on here?
The Other Button seems to be stuck.
Well, the answer is that when I was trying to press the Other Button, Android was still loading the icon from back when I pressed the Load Icon button.
And that first operation was preventing the second operation from taking place.
Okay, so one seemingly obvious but ultimately incorrect solution to this problem, would be to go to the listener that's attached to the Load Icon button.
And simply create a new thread that loads the bitmap, and then displays it.
So I've implemented that approach in an application called Threadingsimple.
Let's take a look at that application and talk about why it doesn't actually work.
So, here's the code for the Threadingsimple application.
Here's the button listener, for the Load Icon button.
It calls the loadIcon method, which is listed just below.
This code creates a new thread, which takes a while loading the bitmap.
And then tries to set the bitmap on an image view that's part of the layout.
So let's run this code.
And now I'll press the Load Icon button, and now I'll press the Other Button.
Well first off, I pressed the Other Button and saw that it responded.
So loading the icon doesn't appear to block pressing the Other Button.
So that's good, we've made some progress.
So, Android simply won't allow threads to start messing around with views that were created by other threads.
So that means while the new thread that we created to load the bitmap can do that work, it can't actually take the last step and add the resulting bitmap to the display.
So which thread actually created this application's view hierarchy?
Well, all Android applications have a main thread, which is also called the UI thread.
Application components that run in the same process, which they all do by default, use the same UI thread.
In all those lifecycle methods that we've been talking about OnCreate, OnStart etc, they're all handled in the UI thread.
And in addition, the UI toolkit itself is not thread-safe.
Now what all this means is that if you block the UI thread with some long-running operation, then you're going to prevent your application from responding to other things that the user's doing.
In fact, we saw that in the threading no threading application.
So, long running operations need to be put in background threads.
At the same time however, we can't access the UI toolkit from a non UI thread.
And that's what got us into trouble with the threading simple application.
So, we need to do work in a background thread, but when that work is done, we need to do the UI updates back in the UI thread.
And Android in fact gives us a bunch of ways to do just that.
In particular, Android provides several methods that are guaranteed to run on the UI thread.
Two of those methods are the view classes post method, and the activity classes run on UI thread.
Both of these methods take a runnable parameter.
This runnable would, for example, contain the code that updates the display in our recent examples.
So if we're using these methods, we would load the bitmap in a background thread, and when that operation completes, we would use one of these methods to execute a runable, that then sets the bitmap on the display.
Let's see that in action.
And again, I'm going to do two things now.
I'll press the Load Icon button.
And then right after that, I'll press the Other Button.
And, I expect to see that the icon actually loads without crashing the application.
Now, I'll press the Load Icon button, and now I'll press the Other Button.
Let's take a look at the source code as well.
So here's my application open in the IDE.
As before, this code creates a new thread, and then loads the bitmap.
The next threading support class that we'll discuss is the AsyncTask class.
This class provides a general framework for managing tasks that, as in our previous examples, involve work that has to be shared between a background thread and a UI thread.
The general work flow that you follow when you're using an AsyncTask is that work is divided between a background thread and the U-I thread.
The UI thread, on the other hand, is responsible for the initial setup of the long running operation.
And it's responsible for completing the operation after the background thread has done it's work.
AsyncTask is a generic class.
It takes three type parameters, params, progress, and result.
Params is the type of the parameters that are input to the A, to the AsyncTask.
Progress is the type of any interment progress reports, and result is the type of result that is commuted by the AsyncTask.
The workflow of an AsyncTask goes as follows.
First, the onPreExecute method is run in the UI Thread before the doInBackground method starts.
After that, the doInBackground method does the bulk of the operation in the background thread.
And this method takes a variable list of input parameters and it returns a result of type Result.
Now, while doInBackground is running, it can optionally call the publishProgress method passing in a variable list of values, which presumably provides some indication of the long running operation's progress.
If the background thread makes calls to publish progress, then some calls to onProgressUpdate would normally be made in the UI thread as long as the background thread is still running.
And finally onPostExecute will be called in the UI thread with the result re, with the result returned by the background thread as its parameter.
Let's look at a version of our icon loading application implemented with an Async task.
It looks similar to the previous examples, but I've added a new UI element, a progress bar, that represents how much of the bitmap loading has been done already.
So, here I'll press the load icon button.
Then you can see that a small progress bar has appeared and is slowly getting filled in.
Let's look at the source code for this application.
And here, I'm displaying the button listener for the load icon button.
This code creates a new instance of the LoadIconTask.
And then calls execute on it, passing in the icons resource id as a parameter.
So, let's look at the LoadIconTask class in more detail.
LoadIconTask is an AsyncTask and its type perimeters are integer, for params, integer for progress, and bitmap for the result.
This method is executed in the UI thread, and it's purpose is to make a progress bar visible on the display.
The next method is doInBackground.
This method receives an integer as a parameter.
And this integer is the resourceid for the bitmap that was passed in to the LoadiconTasks execute method.
doInBackground does the work of loading the bitmap.
As it does this, it periodically calls publish progress passing in an integer which represents the percentage of the loading that's been done so far.
And again, this example's a bit contrived in, in the hope of keeping things simple.
The example might have been a bit more realistic though, if we were downloading an image from the Internet or if we were waiting for the result from a database query.
But hopefully this still gives you a good flavor of how Asynctasks work.
The next method is onProgressUpdate.
This method runs in the UI thread, receives the integer that was passed into PublishProgress, and then sets the progress bar to reflect the percentage of work done.
And finally, the last method is onPostExecute.
This method, again, runs in the UI thread and it receives the justLoadedBitmap as a parameter.
It first makes the progress bar invisible since that's no longer needed, and then it sets the loaded bitmap on the image view.
The last thing I want to talk about in this lesson is the handler class.
Like the AsyncTask, the handler class is designed to support handing off work between two threads.
The handler class is more flexible, however, in that it will work for any two threads, not just for a background thread and the UI thread.
A handler is associated with a specific thread.
One thread can hand off work to another thread by sending messages or by posting runnables to a handler that's associated with that other thread.
So first, let's discuss messages and runnables and then we'll get into the architecture of the handler class itself.
Now, you already know about runnables.
You use these when the sender knows exactly what work steps it wants performed, but it wants that work performed on the handler's thread.
A message, on the other hand, is a class that can contain data such as a message code, an arbitrary data object, and some integer values.
And you use messages when the sender thread wants to indicate an operation that should be done in another thread.
But it leaves the implementation of that operation to the handler itself.
So, now let's talk about how handlers use these messages and runnables.
Each Android thread is associated with a messageQueue and a looper.
The looper takes these messages and runnables off of the messageQueue and dispatches them as appropriate.
When thread A does this, the runnable is placed on the messageQueue of the thread associated with the handler.
Now, something pretty similar happens with messages.
And this graphic depicts a thread B that has created a message, and that has used a handler's thre, a handler's sendMessage method to send that message to the handler's thread.
When Thread B does this, the message is placed on the MessageQueue associated with that handler.
Now, while all this is going on, the looper object is sitting there just waiting for work to appear on the messageQueue.
And when that work does appear, the looper reacts in one of two ways depending on the kind of work that has just arrived.
Now, If that work is a message, the looper will handle the message by calling the handler's handleMessage method and passing in the message itself.
If instead, that work is a runnable, then the looper will handle it by simply calling that runnable's run method.
Now, here are some of the methods that you use when posting runnables to a handler.
We've already seen the post method.
There are a number of other methods that allow you to schedule work for execution at different times.
For instance, you can use the postAtTime method to add a runnable to the messageQueue.
But to run it at a specific time, there is also a postDelayed method.
And that allows you to add a runnable to the messageQueue, but to run it after a specified delay.
If you want to send messages, you first need to create the message.
One way to do that is to use the handler's obtainMessage method, which gives you a message with the handler already set.
You can also use the message classes obtain method and once you have the message, you'll want to set the data or the message.
And there are a number of variations for doing this so please check out the documentation.
As with runnables, there are a number of methods that you can use to send the message.
There's also a version that allows you to put the message at the front of the messageQueue to have it execute as soon as possible.
There's a sendMessageAtTime method to queue the message according to the specified time.
There's also a sendMessageDelayed method that queues the message at the current time plus the specified delay.
And first, you see that this code is creating a new handler.
This handler will be created by the main UI thread.
So the runnables that this handler receives will be executed in the UI thread.
Now, here I'm showing you the button listener for the loadIcon button.
When the user presses the loadIcon button, this code creates and starts a new thread whose run method is defined by the runnable loadIcon task.
Let's look at that class.
Now this run method begins by posting a new runnable that when executed, will make the progress bar visible.
It then posts a runnable that sets the newly loaded bitmap on the display, and it finishes by posting a last runnable that makes the progress bar invisible.
Let's also look at a second version of this application that sends messages instead of posting runnables.
Here's the ThreadingHandlerMessages application.
And first, you see that this code is creating a new handler.
And again, this handler will be created by the main UI thread.
The work that this handler performs will be executed in the UI thread.
As you can see, this handler has a handleMessageMethod in which it implements the various kinds of work.
This method starts by checking the message code that's in the message, and then it takes the appropriate action for that message code.
For instance, if the code is set_progress_bar_visibility, then this code sets the visibility status of the progress bar.
If the code is instead progress_update, then this code sets the progress state on the progress bar.
If the code is set_bitmap, then the code sets the bitmap on the display.
Now, let's go to the button listener for the loadIcon button.
And same as before, when the user presses the loadIcon button, this code creates and starts a new thread whose run method is defined by the runnable loadIconTask.
And this run method begins by obtaining a message with a code set to set_ progress_bar_visibility.
And with an argument indicating that the progress bar should be made visible.
It then sends that message to the handler, which will handle it and make the progress bar visible.
It then continues by loading the bitmap.
And while it's doing that, it periodically publishes progress by obtaining and sending a message with the code progress_update and with an argument that indicates the percent, the percentage of work done.
And finally, it sends a last message to make the progress bar invisible.
In this lesson, we're going to talk about notifications.
Notifications are basically messages, sometimes quite rich.
That applications show to users outside the normal user interface of the application.
For example, suppose you have an application that can download an e-book from over the internet.
In that case, you probably want to let the user select a book to download.
But then continue to use the application, or even exit it all together, while the book is downloading.
And, if so, you'll probably also want to let the user know when the download finishes.
To do that, you need to do a few things, you need to figure out when the download finishes.
And then you need to display some kind of message to give the user that information.
In this lesson, I'll talk about two different kinds of user notifications that Android supports.
The first kind are toast messages.
Which, I suppose get their name from the fact that they pop up on the screen.
We've actually already seen toast messages many times in previous lessons.
For example, we've used them quite a bit to demonstrate that something was happening.
These notifications are visible and can be accessed in the system controlled notification area at the top of the device.
And again, you've already seen examples of this.
For instance, in the application fundamentals lesson, I showed how a device was receiving an incoming MMS message.
And, you might remember, that when the MMS message actually arrived, an icon appeared at the top left of the phone.
And the user could then pull down on the notification area to expose more information about that incoming MMS message.
Android provides several different kinds of user notifications.
And these notifications are messages to the user that are sent on an as needed basis.
And that appeared outside the normal user interface of the application.
So, and edit text of you in which you type and mms message, or the button that you hit to send the resulting sms message.
Those are not user notifications.
But a message that pops up a few seconds after you hit the send button, that tells you, for example, the message was sent successfully.
Those things are user notifications, and those are the things that we're going to talk about today.
Now, some Android user notifications exist to provide feedback to the user about something that they're doing.
And one such mechanism are the toasts messages that we talked about.
And these are typically used to announce unpredictable events to the user, and to do it in a way that doesn't interrupt.
And again, think of the incoming SMS message situation.
Putting an icon in the notification area tells you that a message has arrived.
But it doesn't do it in an obtrusive or peremptory way.
Whenever it's convenient for you.
Toast messages, as you've seen, are temporary messages that pop up on the display.
For instance, to let the user know that an operation has completed successfully.
Toasts automatically fade in and fade out of view.
And their job is to provide information to the user, but they're not meant to gather information that's going to get sent back to the hosting application.
You can create toast messages using the toast classes make text method.
That method takes a couple parameters, including the text that you want to display.
And the amount of time over which you want that text to be visible.
And after you've created the toast you can then display it by calling the show method on the toast you've just created.
So let's take a look at an example application that uses toast messages.
Here I'm starting up the notification Toast application.
This application displays a single button labeled Show Toast, which is exactly what'll it do when I press it.
So I'll press that button now.
And there near the bottom of the screen you see a small pop up window that says, you're toast.
Now if we open up the application source code in the IDE, we'll see how this is implemented.
Here I'm highlighting the button listener for the show toast button.
Inside, you see a call to the makeText method, passing in the text.
And passing in the constant Toast.LENGTH_LONG, which ends up making the text visible for about three and a half seconds.
There's a call to the show method that actually displays the toast.
Now if you want to fancier toast message, you can also create a custom view for your toast.
For example, you can create a custom layout in XML, inflate it.
And attach the inflated view to the toast message with the call to the setView method.
Let's see an example.
Like the simple toast example.
This application displays one button labeled show Toast.
And I can press that button to display the Toast message.
In this case however, when I do press the button you'll see a custom Toast view rather than the simple gray pop-up that we saw before.
So here we go.
And there's your custom toast message with a text, your toast and an extra eyeball to help drive home the message.
So let's open up the main activity for this application and look at how we created the toast message.
Now as you can see when the show toast button is pressed, the code first creates a new toast object.
The next two lines set the location of the toast on the display.
And specify the length of time for which it will be visible.
Then there's a call to set view, in which the first parameter is the result of inflating the XML layout that's in the custom underscore toast dot XML file.
Let's open that file.
Now here we can see that the custom view is a relativeLayout containing two children.
The first child is the image view that holds the eyeball.
The second child is a text view that displays the text, You're Toast!
And then, back in the main activity, there's a final line that calls the show method to display the toast.
The other kind of user notification that we'll talk about in this lesson, are notifications that appear in the notification area.
And as I said earlier, this kind of user notification appears in the system control area at the top of the device, called the notification area or the status bar.
Applications and the Android system itself, can use this area, to inform users about the occurrence of various events.
And once it's open you can see additional information about the various notifications, that have been placed in the notification area.
Let's see an example of how these notifications are used in Android.
And I'll open up the phone application, and now I'll start dialing a phone number.
And now I'll hit the dial button, and the phone will start dialing the number and connecting the phone call.
Now let's say that, in the middle of this phone call, I need to get some information off the internet.
So, I hit the Home button to go back to my home screen.
And now notice that up at the top-left of my device, a new icon has appeared, that's a notification.
When I backed out of the phone application, Android created this notification object, and put it in the notification area.
And this notification serves as a reminder to me that the phone call is still connected, and it also serves as a way for me to quickly return to that phone call.
Now back in the browser, I'll go to www.google.com and I'll execute a search.
Let's assume at this point I'm armed with the information that I needed, and I want to go back to my phone call.
So now, I'll pull down on the notification area to open the notification drawer.
And once it's open, I can see a view, which shows me some information about the call.
And it allows me to either reconnect to the call, or to hang up.
Now in this case, I want to continue the call.
So I'll click on the notification area.
And that brings up the phone application, brings it back into the foreground, and allows me to keep talking.
When you want to send a notification, there are several things that you need to consider.
First, there's the basic notification itself, which must have at least text for its title and content, and also a small icon.
When the notification is sent, it will eventually arrive in the notification area, where the small icon will be displayed.
Additionally, you can set the notification's ticker text, in which case that text will also be displayed when the notification first appears in the notification area.
Finally, if the user opens the notification drawer, there's a view that they'll see.
Now, by default, this includes the title, the detail or content text, the small icon, and a time stamp.
You'll also need to define any action that will occur should the user click on the notification draw, drawer view.
Now once you've created the notification you may want to send it.
Update it, cancel it or things like that.
These operations are managed by an Android system service called the Notification Manager.
So here I'll open the notification status bar application.
And this user interface displays a single button labeled Notify.
So, let me click on the button now.
You can also see the ticker text scrolling up in the notification area.
You can see the drawer view showing the icon, the notification title text, the notification detail text, which shows the number one in parentheses, indicating that the notify button has been pressed one time.
And finally, there's also a time stamp.
Now at this point, I'll just close the, the notification drawer and go back, and hit the Notify button one more time.
At this point, I'll click on the notification, and you can see that a new activity has started, printing out the words: Got the intent.
And the point here of course is that you can attach an intent, to the notification drawer view.
In order to bring the user to the application that should handle whatever follow on action that notification was intended to provoke.
Let's look at a second application notification status bar, with custom view.
This application does the same thing as the last example.
However it shows a custom view when the notification drawer is opened.
Now I'll start the application and hit the notify button just like before.
However, when I open the notification drawer, I'm not going to to see the standard view, I'll see my own custom view.
Let me open the notification drawer now.
I'll open the drawer again, and you can see that everything is the same except that the number one has become the number two, to show that this is the second notification, which updated the first one.
And finally, I'll click on the notification drawer view, which starts up a new activity displaying the words Got The Intent.
Okay, so let's look at the code for that second application, notification status bar with custom view.
And here I'm back in the IDE, and I'll open the application's main activity.
And this allows the notification manager to update this notification, after it's first been sent.
And next, there's some variables that hold the text elements of the notification, including its ticker text, title, and content.
After that, the code sets up some information that is used to play a sound, and to vibrate the device when this notification arrives.
Next, the code creates the custom view that will be displayed in the notification drawer.
The layout for that view is in the custom_notification.xml file.
Let's take a look at that.
As you can see, this view is a linear layout, with two child views.
One is an image view, the one that displays the eyeball.
Back in the main activity, let's look at the on create method.
And here the code creates an intent, called M notification intent.
The next line of code, is something that we haven't talked about before.
This line creates something called the pending intent.
Based on the M notification intent, that was created on the previous line.
A pending intent is essentially a permission slip that allows one piece of code to stand in for another piece of code.
And what I mean by that, is that this permission slip allows the second piece of code, to activate the underlying intent as if it were the first piece of code.
And that is, it does it with its, the permissions and the identity of that first piece of code.
So, moving on, the notify button's listener first updates the content text.
They indicate the number of times the buttons been pressed.
Then it constructs the actual notification, using the notification.builder class.
A code makes new notification.Builder object, and then it sets the ticker text, sets the small icon and then sets auto cancel to true.
Next it sets the content intent, and this is the pending intent that defines the.
action to take, when the user clicks on the drawer view.
Next, it sets the sounds, and vibration patterns that should play when the notification arrives.
And lastly, it sets the custom view that should be displayed when the user pulls down the notification drawer.
Now the notification is set up, the code then gets a reference to the notification manager by calling get system service, passing in the ID of the notification service.
Then finally, the code calls notify on the notification manager, passing in the ID of the notification.
Which allows existing notifications to be updated, and it also passes in the result of calling build on the notification .builder object.
And that build method is what actually generates, the actual notification object.
What do you do when you just can't figure something out?
For zombies, it's pretty simple.
They can just keep bashing their brains against the wall.
But living brains are a lot more complex.
It turns out, though, that if you understand just a little bit of some of the basics about how your brain works, you can learn more easily and be less frustrated.
Researchers have found that we have two fundamentally different modes of thinking.
Here, I'll call them the Focused and the Diffuse modes.
It's when you concentrate intently on something you're trying to learn or to understand.
But we're not so familiar with diffuse thinking.
Turns out that this more relaxed thinking style is related to a set of neural resting states.
We're going to use an analogy of the game of pinball to help us understand these two thinking modes.
Incidentally, both metaphor and analogy are really helpful when you're trying to learn something new.
If you remember, a pinball game works by, you pull back on the plunger, release it, and a ball goes boinking out, bouncing around on the rubber bumpers, and that's how you get points.
So, here's your brain, with the ears right here, and the eyes looking upwards.
And we can lay that pinball machine right down inside it.
There's the analogy for the focused mode.
It represents a familiar thought pattern.
Maybe involving something simple like adding some numbers, or more advanced ideas like literary criticism or calculating electromagnetic flows.
You think a thought, boom, it takes off, moves smoothly along.
And then, as it's bouncing around on the bumpers, you're able to figure out the problem you're trying to solve, or.
So look at how that thought moves smoothly around on the fuzzy underlying orange neural pathway.
In some sense it's as if it's traveling along a familiar, nicely paved road.
But what if the problem you're working on needs new ideas or approaches?
Concepts you haven't thought of before.
That's symbolized here by this neural pattern towards the bottom of the pinball machine area.
But if you haven't thought that thought before, you don't even know how that pattern feels or where it is.
So how are you going to develop that new thought in the first place?
Not only do you not know where the pattern is or what the pattern looks like, but see all the rubber bumpers that are blocking your access whatever direction you do decide to move in?
To get to this new thought pattern, you need a different way of thinking.
And that's represented here, by the diffuse mode.
It could travel a long way before being interrupted by hitting a bumper.
In this diffuse mode of thinking, you can look at things broadly from a very different, big-picture perspective.
You can make new neural connections traveling along new pathways.
You can't focus in as tightly as you often need to, to finalize any kind of problem solving.
But you can at least get to the initial place you need to be in to home in on a solution.
Now as far as neuroscientists know right now, you're either in the focused mode or the diffuse mode of thinking.
It seems you can't be in both thinking modes at the same time.
It's kind of like a coin.
We can see either one side, or the other side of the coin.
But not both sides at the same time.
Being in one mode seems to limit your access to the other mode's way of thinking.
In our next video we're going to see how some extraordinary people access their diffuse ways of thinking to do great things.
Perhaps the greatest gift that our brains give us is the ability to learn new things every day.
On my way here, I thought about the journey that will take us to the last day of the course, and how much we will learn along the way.
Our goal is to give you a better understanding of how we learn, so that your brain becomes a better learner.
These insights are based on solid research from neuroscience, from cognitive psychology, and also from dozens of leading instructors and practitioners in difficult-to-learn subjects.
Whether you're a novice or an expert, you will find great new ways to improve your skills and techniques for learning, especially related to math and science.
This course is meant to help you reframe how you think about learning, to help reduce your frustration, and increase your understanding.
We approach things a little differently.
You're not expected to have an in-depth background in any particular subject.
Instead, you're expected to take these ideas and apply them to whatever subject you're trying to learn or improve in, to help you learn more deeply, effectively, and with less frustration.
You'll hear experts from a variety of different disciplines talking about their best tips for learning more effectively.
You can benefit from these ideas whether you're struggling in high school or soaring through math and science at graduate levels at a university.
I'm a co-director of a Science and Learning Center that is sponsored by the National Science Foundation based here in La Hoya.
In recent years, we've made great strides from research and discovering how to learn most effectively.
Finding a way to simply and effectively share these ideas with you has been a big undertaking, but we feel it's well worth doing.
You will see that many of these ideas, although simple, are incredibly powerful.
And along the way, we will also learn a lot in the process of teaching you.
You'll see how you can fool yourself about whether you actually know the material.
You'll discover new ways to hold your focus and embed the material more deeply and powerfully in your mind, and you'll learn to condense key ideas you're learning about, so you can grasp them more easily.
Master the simple practical approaches outlined here, including simple tips to help prevent procrastination, and you'll be able to learn more effectively and with less frustration.
This course is meant to enrich both your learning and your life.
You'll be able to get what you want from this material.
So, welcome to the course and happy learning
So, let's take a look at some famous people from history who used their different thinking modes to help them with their problem solving.
He was the very definition of a wild and crazy guy.
Dalí used to have an interesting technique to help him come up with his fantastically creative Surrealist paintings.
He'd relax in a chair and let his mind go free, often still vaguely thinking about what he had previously been focusing on.
Now, you might think, well, you know that's okay for an artist.
But what does it have to do with more scientific or mathematical kinds of thinking?
Well, if you look down here, this guy was Thomas Edison, one of the most brilliant inventors ever.
According to legend, what Edison used to do was he'd sit and relax in his chair, holding ball bearings in his hand.
Although, it would often noodle back in a much more relaxed way to what he'd been focusing on previously.
When Edison would fall asleep, the ball bearings would drop and clatter to the ground just as with Dalí, and it would wake Edison up, and off he'd go with his ideas from the diffuse mode ready to take them into the focus mode and build on them.
So, the bottom line is, when you're learning something new, especially something that's a little more difficult, your mind needs to be able to go back and forth between the two different learning modes.
You might think of it as a bit analogous to building your strength by lifting weights.
You would never plan to compete in a weightlifting competition by waiting until the very day before a meet and then spending the entire day working out like a fiend.
I mean, it just doesn't happen that way.
To gain muscular structure, you need to do a little work every day, gradually allowing your muscles to grow.
Similarly, to build neural structure, you need to do a little work every day, gradually allowing yourself to grow a neuro-scaffold to hang your thinking on a little bit, every day, and that's the trick.
In summary then, we learned that analogies provide powerful techniques for learning.
We learned about how the brain's two different thinking modes focused and diffuse, each helps us learn but in very different ways.
Finally, we learned that learning something difficult can take time.
Your brain needs to alternate it's ways of learning as it grapples with and assimilates the new material.
Everybody has some issues with procrastination.
Because if you're working on something, it means you're not working, on a lot of other things.
But some people have more issues with procrastination than others.
In this video, we're going to give you a little insight into procrastination.
Why it arises, and a powerful little tool to help you address it.
When you look at something that you really rather not do, it seems that you activate the areas of your brain associated with pain.
Your brain, naturally enough, looks for a way to stop that negative stimulation by switching your attention to something else.
But here's the trick.
Researchers discovered that not long after people might start actually working out what they didn't like, that neurodiscomfort disappeared.
So it seems what happens when you procrastinate, is something like this.
First, you observe, and get a cue about something that causes a tiny bit of unease.
You don't like it, so to make the sensation go away you turn your attention from whatever caused that unease.
The result, you feel happier, temporarily.
But in the mean, time I'm going to let you in on a handy little mental tool.
It was invented by Francesco Cirillo, in the early 1980's.
All you need to do, is set a timer to 25 minutes, turn off all interruptions, and then focus.
That's it!
Most anybody can focus for 25 minutes.
The only last important thing is to give yourself a little reward when you're done.
A few minutes of web surfing, a cup of coffee, or a bite of chocolate, even just stretching or chatting mindlessly, allowing your brain to enjoyably change its focus for a while.
You'll find that using the Pomodoro technique is very effective.
It's a little like doing an intense 25 minute workout at a mental gym.
Give it a try.
Next, we're going to see how one very shy ten year old, changed her brain.
This week, we're going to be talking about chunks, compact packages of information that your mind can easily access.
How you can use them to improve your understanding of, and creativity with the material, and how chunks can help you do better on tests.
We will also talk about illusions of competence in learning.
We'll cover what those less effective study methods are and tell you what methods research has shown will work better to help you in your studies.
You can make your study time more valuable by interleaving, providing intelligent variety in your studies.
This week, we're going to be talking about two seemingly different ideas: procrastination and memory.
But the two topics are intimately related, why?
Because building solid council long-term memory, chunks that are easily accessible by your short term memory takes time.
It's not the kind of thing you want to be putting off until the last minute.
Then we'll move on to talking about some of the best ways to access your brain's most powerful long-term memory systems.
But again, low cost, and much lower compared to what you would have to pay for a traditionally manufactured bionic hand.
So this one has motors embedded in it and can actually respond to signals from your muscles, and this is the Exiii Project by a student in Japan.
It started out as a student project, but now he's trying to set up commercial operation, it's an open-source project.
So we'll hear from the Exiii Project right now and see another example of how 3D printing provides low-cost and customized solutions for individuals.
I'm from Tokyo, Japan and I'm making this robotic hand called Hackberry in a team called Exiii.
This is 3D printed open source hand.
So since we use 3D printer, it only took less than $1,000 to make one unit.
And since it's open source, everybody around the world, including you, can access to our data and just replicate this.
Originally, I studied bionic hand in college as a software engineer, but back then, making hardware was really expensive.
But these five years, 3D printer came out and it became easy to prototype hardware, so I started three years ago to start building my original bionic hand.
Since the conventional hand has to go through the mass production process, the initial cost was really expensive, so each unit, it costed more than $15,000, or even more.
This hand, while it's still a prototype, the material costs for this model was less than $1000.
It's not only me, at the same time, a guy in the US and another guy in the UK started developing 3D printed bionic hand just like us.
We haven't sold it yet.
We are all in prototyping, developing phase still.
Most of us have open source and we're sharing lots of tips together.
Well if you want to involve in our project, please access to exiii-hackberry.com.
We also have a forum to discuss about it, and we respond pretty quickly, so yeah.
I really want to make this personal item, and make hardware as easy as cooking a meal so that actual user can just download it, customize it, and print it all by him or herself.
So that's our future vision.
This is our atomic absorption spectrometer.
This compartment here houses the hollow cathode lamp which is the light source for the spectrometer.
The central part of the instrument houses the flame.
Currently, this is an acetylene oxygen flame, burning at about 1,000 degrees centigrade.
And the sample dissolved in water or acid travels up this little tube here and then on upwards, into the flame.
The light from the hollow cathode lamp passes through the flame, into this section of the instrument where we have the detector.
It's not just the electrons of the atom that can be used for analysis.
In this technique we need to irradiate the sample with neutrons.
And just as the electrons were put into excited states the nucleus is also excited.
And it will ultimately end up as a product nucleus.
Just as the radiation given out by the electrons was characteristic, so the gamma rays given out by these nuclei is also characteristic.
So if we measure the energy of the gamma rays given out, we can once again analyze the element.
So it's a good technique in that it is non-destructive of your sample.
In order to get the neutrons to do this analysis, you do need to have a nuclear reactor.
If you don't have a nuclear reactor then you really can't do this method.
On the x axis, this is the energy of the gamma rays given out, and you can see that different elements give quite distinct peaks.
So this particular sample here which is an archeological sample contains elements such as scandium, iron, cobalt, sodium and some minor elements as well.
Now, we are ready to answer the first question I posed in the first lecture in this week.
So this is, this segment represents the set of all the possible policies.
Okay, and let's suppose your ideal policy is here.
And this is determines the payoff of Democrats and Republicans.
Okay, so if Democrat chooses a policy platform here, very liberal policy, and the Republican chooses a very conservative policy here, what happens?
And all of the people whose ideal policy is located here, vote for Democrats.
And all conservative people, whose ideal policy is located over here, vote for Republicans.
So, you can apply the Nash equilibrium concept to the policy choice game.
And the result is, this is the even Nash equilibrium.
Okay, Democrats, and the Republican choose exactly the same policy.
This may not be true, okay.
So let's generalize the model by weakening this restrictive assumption.
Okay, so let's consider a general distribution of voters ideal policies.
It may look like this.
Okay, then you can determine what is called median.
So, half of the population is here and the other half of the population is here.
And this point here is called, the median of the distribution of voters' ideal policies, okay.
So intuitively median means the following, okay.
So if you linearly order everybody from very liberal to very conservative, you can find someone just in the middle.
And then you can find the person just in the middle.
Okay.
So our analogies shows that, policies parties when there are only two parties tend to be very similar and they choose this location, Median location where they get half of the of the voters.
So the answer to the question number one is the following.
So you linearly order everybody from very liberal to conservative and you find someone, just in the middle, okay.
The opinion of this guy, the median voter, determines two parties policy.
This is called median voter theorem, in politics.
And this is a very prominent application of game theory in political science.
Okay, so lets reexamine this game's already prediction.
As you can see the prediction is not so accurate.
Well, prediction says that the democrats and the republicans should choose exactly the same policy, and in reality it's not true.
Okay, but nonetheless, I'd like to argue that game theory is useful.
Okay, the game theory prediction is not as accurate as Newton's law, like in this example, the prediction is lopsided, but.
Okay, they are trying to maximize the number of votes they get.
And as they move closer they can steal voters from the opponent.
Okay, so they are inclined to choose very similar policies.
And also game theoretic approach is very useful to answer this question here.
What determines the policies of two parties?
It's a very vague and general question.
And if I am asked this question I don't know where to start.
But game theory says well, any social problem can be formulated as a mathematical model of game, and then you can apply the solution concept, the Nash equilibrium, and then you get an answer, okay.
So I would like to say that game theory provides a useful reference point.
Useful benchmark of the analysis.
So, let me try to explain what I said by means of a metaphor.
So look at this picture here.
Okay, so this line here, indicates the trajectory of a falling leaf.
It's a very complicated phenomenon.
Okay, and it's very difficult to come, come up with a very simple theory to explain the trajectory of a falling leaf.
But you can examine what would happen if there is no air.
Okay, and the law of motion in vacuum is given by Newton's Law, and it's very simple.
It doesn't give you perfect prediction about the trajectory of a falling leaf.
But it gives you a very useful insight, because it captures one of the driving forces of the falling leaf.
Okay, so let's suppose, this falling leaf represents human behavior which you'd like to examine.
It's very, very complex, and maybe you cannot get a very simple theory to explain everything perfectly, okay.
But game theory, gives you an answer, unified answer, what people what people might behave in any given social situation.
So game theoretic prediction, captures one of the very important driving forces, okay.
Under this complex phenomenon of human behavior can be fruitfully analyzed by getting some benchmark.
Reference point and the by comparing this basic driving force on reality you can get deeper understanding of real human behavior.
And probably this is the most important value of game theory analysis.
But non the less, it's very useful in providing you know, useful reference point, or benchmark of the analysis, and it captures important driving points of human behavior.
So what's this course about?
It's important I think to start with a set of learning goals, especially because gamification is a novel concept.
It's not something like introductory physics where it's obvious what a course is going to teach you about.
So there are four things that I hope that you will get out of this course, if you stick with it all the way through, watch the video, do the homework, and so forth.
The first is to understand what gamification is.
The third is to learn how to do it effectively, and the fourth is to understand some specific, concrete applications of gamification.
So, let me say a little bit about each of those.
What is gamification is not obvious.
Gamification is a new concept, and, in many ways, it's misunderstood.
So, we'll talk a lot about understanding just what gamification is, and what it isn't, as well as some of the history and some of the context for this emerging business practice.
Then we'll talk about how gamification can be used and why it might be effective.
And notice I say here might be.
And I'll give you lots of examples of companies and other organizations that are successfully applying game mechanics and applying other lessons from games to address their problems.
But it's important to have some measure of skepticism, to realize that gamification isn't right for every problem.
And furthermore, doing gamification requires you to understand how to do it well and that's why we have this third learning goal, to talk about how to do gamification effectively.
You can understand how gamification might be relative to a problem but you need to understand the different techniques, the different components that you can use, and the pros and cons of different forms of gamification in order to know how to do the right sort of thing when faced with a particular situation.
And finally some applications, there will be examples running throughout the course.
But we'll look towards the end of the course at some specific domains like Inside the Enterprise and For Social Good, where there are particular issues that come up with applying gamification.
It's important to note, this is not a technical class.
So, there's no requirement that you be familiar with any of the technical or aesthetic aspects, artistic aspects, of being a game designer, we’re going to talk about some of those concepts in the course.
Because in order to do gamification effectively, even just as a business person, you need to understand something about game design.
But there are no detailed prerequisites involved anyone who has a basic kind of understanding about online services, and about digital technology, will be fine understanding this course.
I mentioned all of the stuff behind me on the bookcases, keep an eye on it.
Some things that look different from video to video and if you really notice what's going on you might notice something else, from time to time, appearing back there and who knows, maybe a message.
Now, this course is novel in a few different ways which I wanted to highlight here at the outset.
The first, obviously, is this new method of open online delivery.
That's something that has been used in certain experiments for the past few years but has really expanded greatly only recently.
So this is a new way for me in teaching and probably for you a fairly new way in learning this kind of material.
But this course in particular has some other aspects that distinguish it even from other courses that use this mechanism.
The first is that gamification is a brand new concept.
As I’ll talk about, it has roots that go back many years.
And it’s going to draw on some very old concepts in psychology, and management, and so forth.
But gamification as a phrase to describe what I’m going to talk about is really only a couple of years old.
And as I said, just understanding what gamification is, is not universal today.
So we're going to have to start by learning what the concept is to begin with.
The third thing that's new is that this is a new course.
In fact, I think that I offered the first class on gamification for business that had ever been offered anywhere at any university.
But for this massive open online version on Coursera, I rebuilt the course entirely from scratch, to take advantage of some of the unique aspects of this new kind of online environment.
And finally, this course is about practical knowledge, which may be somewhat different from some of the other courses that you take.
This is not necessarily about theory.
There's a lot of theory that we'll touch on that goes in to concepts we discuss in the class, but this is a course, ultimately, that is designed to give you some practical knowledge.
That's designed to help you understand how gamification is used today in the real world and how you potentially can be someone who uses it yourself.
But one resource in particular that many students find helpful is my book For the Win, How Game Thinking Can Revolutionize Your Business which I co-wrote with a colleague, Dan Hunter.
You don't have to purchase it in order to take the course, but I hope that you will take a look and consider it.
Students often find that the book is helpful because it's laid out in the same basic structure as the course, and expands upon it with additional examples and frameworks that you can then take with you after you finish up the.
It's available in e-book form on all the major e-book platforms and also in paperback.
It's also now available, in addition to English, in Spanish and Japanese translation with a number of other translations in the works.
If you go to the link at the bottom of the page, the Wharton Digital Press link, it will give you a list of retailers to purchase it in e-book or hard copy format in various countries around the world.
I hope you will at least take look at the book and consider it as a useful resource to deepen your understanding of gamification.
You don't throw the baby out with the water, I mean, you can all see because of this.
>> We live in an era where there's very significance demographic change, some quite significance political instability and complex.
So if anything that need for a source of policy, how it responds is going to continue and might even be magnified.
In terms of changes to the political structure, to the U.N.
And it's significant, I think that now we're beginning to see the recession of the nation states some critic of what have been going in terms of globalization, global institutions.
The UN rather avoid some these criticisms that perhaps the EU or NATO are, and that's probably an indication of weakness.
And by the top, I mean the big powers who have been in their own ways always pretty casual use of the UN.
It's the one place the UN General Assembly, where their voice can be raised as loud of that as the United States, or Russia, or China.
And many countries, because there were only 48 when the UN started and it's now 193.
So they look at the UN as very much part of the history of their independence and nationhood and sovereignty.
But if the US or other big powers choose to all but pull out of it, cut their funding, go to other places to mediate problems.
When the US didn't join the League of Nations, having nevertheless been a founder, it wasn't that the League of Nations failed because of that, it failed because it was subsequently unable to stop a war.
And also, I think the second hesitation I would have is how quickly we can get to that stage.
The UN is still a vital lifeline for millions of people around the world.
So what I think needs to happen is a transition.
But recognize that increasingly, direct delivery so the real provision of service is on the ground or coordination of aid, etc., can come from local organizations from bigger NGOs and from the private sector.
And I think there's a need for us to stop thinking like this because the UN is horrendously overstretched and under funded.
Some agencies, The World Food Programme, they have to raise every year, all of their funding, they don't get a sort of handout from governments.
That makes it really, really difficult to plan.
And if an unanticipated emergency comes along, that mean it that mean, they're screwed.
It doesn't work like that.
You don't think its time to shop up shop and have a shut up shop and have a coalition of democracies, instead after all UN is full of fairly obnoxious dictatorships and absolute monarchies.
How do we reconcile that with the values that you and I might hold dear?
The whole purpose of the UN is to engage everyone.
You're not going to reduce the incidence of war if you're just hanging out with your friends, for want of a better phrase.
But I think also, what are we going to put in its place?
I talked about 15 transition on the humanitarian side.
I'm not sure that the current set of world leaders that we have, have the imagination or the sense of urgency that leaders did in 1945 to create an organization.
We haven't really been able to design anything better and you can see that in the fact that although there are all these regional organizations and different groups, you still look to the UN for that ultimate seal of legitimacy.
So the climate agreement has to go the UN, an agreement in development has to go to the UN.
No member state has left the UN, not even North Korea, they all want to engage.
So I think it's still fulfills a really, really important function.
As the only universal platform we have, as the center of norms and standards and as the provider of with goods and services.
But it does need to change.
I'm proud to say UNA, you played a real role in that.
He's got a real opportunity to set a much more realistic vision for the UN.
That doesn't mean he shouldn't be ambitious, but it means really look at where the UN can add value.
And therefore, recognizing the value of the UN as a multiplier of dollars and effectiveness and letting it operate.
It might it get a little complicated when it comes to paying UN dues, but not necessarily.
I think that Marine Le Pen has a very ambitious agenda, but certainly getting out of the EU and NATO, but I haven't the UN particularly on that list.
Because France's P5 seat is a representation of a recognition of a defeated France as a great power and of the eternal glory of France, and I doubt that she's against that.
The Chinese and the Russians obviously cherish their seats and the vetoes that come with them.
And the recognition of their great power status.
So it's all negotiable.
It's a tough world we're moving into.
So, for those of you that are thinking, wait a minute, I don't read music.
to get you to understand a little bit about reading music.
But for now, we're going to use a couple of different formats to get the information off the page onto your guitar.
A chord block diagram is probably the most popular and easiest way to translate information onto the neck.
Now, we'll cover chords a little later in the course.
But for now, a chord block diagram is usually a four or five fret picture of a box with horizontal lines representing the frets and vertical lines representing the strings.
Numbers representing the fingers of the left hand are positioned on the frets.
If you see a zero or an O above a string, it means open string, which means no frets being held.
If you see an X, it means that the string isn't played at all, either simply by omission or by muting with the free fingers of the left hand.
If the chord is to be played on a higher fret on the fretboard, a fret number is provided to let you know where exactly this is happening.
A fretboard map is similar to a chord block diagram, but is a more complete view of the entire fretboard from the player's point of view.
The strings are usually labeled, and the numbers on the frets represent the left hand fingers that are going to be used to fret the notes.
Now we're going to talk about major scales and I'm sure many of you, might have heard these sounds before.
scales are used to create melodies and when you have more than one note that you combine from the same scale and you play it, you play them all together, you create what's called harmony.
without getting into a big discussion about the theory of it, what I'm going to do now is try and explain the basis of what we call a major scale.
We spoke about the 12 half steps that occur in western music a building block for our music.
A sequence of half steps and whole steps is what creates a major scale.
And then a half step to get back to the note, an octave higher than the note on which we started.
I'm going to demonstrate that on a single string so that you can hear and see what that actually sounds like.
Fortunately for us, the half step corresponds to one fret.
Now we're going to start with the F on our sixth string and the first fret.
We're going to be at A.
Now we move up a half step, we're at B flat.
Technically they're the same note but it's a B flat because the rule with major scales is that it must go to the next letter name.
So if we go from A, the next note has to be some kind of B in this case it's a B flat.
And then a half step to get back to an F, which is one optive higher then the F on which we've started.
I'll play again a s, a little faster.
Now, if you listen to that sound it might sound very familiar.
I'm sure many of you might have seen the sound of music or music, movies like that where you actually here do, rei, mi, fa, sol, la, ti do.
It's a very familiar sound in western music.
And it's the basis for a lot of the music that we play.
Many of the melodies of pop tunes or tunes that you hear on the radio, traditional tunes, folk tunes from many cultures are patterned or built with pieces of the major scale.
Now that's a demonstration of a major scale as played on a single string and that allows you to see the sequence of half steps and whole steps.
Now the great thing about major scales is that they are movable, and the relationship stays the same regardless of the note on which you start.
We started on F just now.
If I were to start on this note which is a C, on the fifth string, third fret and I did the same sequence of half-steps and whole steps, I would wind up with a C major scale.
It sounds pretty much identical with sort of a different starting note.
So in this case, we're going to play a different root, which is C, same major scale.
C, D, E, F, G, A, B, C.
Of course when we start on a different note we get a different sequence of letters.
C, D, E, F, G, A, B, C.
Every note that we landed on was a pure letter name.
Now fortunately for us we have six strings on the guitar.
That allows us to play things in position.
We don't have to climb up on a single string every time we want to play a melody or a scale.
It's possible to play a C major scale in position without moving up.
It was convenient enough for me to demosntrate the C scale moving up so you can see the sequence of half steps and whole steps.
We can actually play them in position.
So, we'll start with c on the fifth string, third fret.
I'm going to go to an open D, E, F, G, A.
Now, we're going to do the descending portion of the scale.
It's important to do the descending as well as the ascending every time you practice the scale.
Open B, A, open G, F, E, open D and we're back at C again.
C, D, E, F, G, A, B, C.
C, B, A, G, F, E, D and C.
Now I'm going to switch my metronome on to 60 beats and you can play along with me.
That was a C Major scale in first position.
Now it made use of open strings and so it was not what we call a movable fingering.
In the last few videos, I presented some findings on how we devalue happiness and why we do it.
Specifically, I showed you that we devalue happiness by succumbing to the fundamental happiness paradox.
And I also discussed three reasons why we devalue happiness.
In this video, I want to talk about how to avoid the tendency to devalue happiness.
In other words, I want to talk to you about the first habit of the highly happy, the habit that can help us overcome the first deadly happiness sin.
The first habit of the highly happy is, prioritize but don't pursue happiness.
What exactly does it mean to prioritize, but not pursue happiness?
What it means is to consciously make the choice of giving happiness the higher priority over other goals in your life.
And particularly before you make important decisions about what you ultimately want out of life.
If you're like most people, what you ultimately want in life, the reason why you do anything and everything that you do is so that you can lead a happier, more fulfilling and a more meaningful life.
If you remind yourself of this before you make your decisions, it turns out that you won't be as susceptible to the fundamental happiness paradox.
That is, you won't sacrifice happiness for the sake of other goals as much.
Now three of my colleagues, Kelly Goldsmith from Northwestern University, David Gal from the University of Illinois at Chicago, and Lauren Cheatham, a PhD student at Stanford University, and I have conducted several studies in which we tested what happens when people remind themselves to make happiness enhancing decisions on a regular basis.
In one study, which was conducted on employees from seven different Fortune 500 companies.
We divided the employees into two groups.
One group received an email every day for a whole week.
The email gently reminded them to make happiness enhancing decisions.
The second group did not receive any such email.
Then we asked both groups of employees to tell us how happy they were at the end of the week.
As you can see from the graph, what we found was that at the end of the week, those who received the daily email reminding them to make happiness enhancing decisions, were far happier than those who did not receive any emails.
We found similar results in three other studies that we conducted.
These results suggest that reminding yourself to make happiness enhancing decisions can significantly boost your happiness levels.
Does this mean that the more we remind ourselves to make happiness enhancing decisions the happier we'll be?
Although reminding yourself to make happiness enhancing decisions is a good thing, you shouldn't actively monitor or chase happiness, because when you do it's actually likely to lower your happiness levels.
Why?
Because when you pursue happiness too intently, you're likely to monitor how you are feeling with how happy you want to feel.
And since we generally feel less happy then we would ideally like to feel, we end up feeling unhappy about not being as happy as we want to feel.
That's what this paper by Mauss and his co-authors and several others also shows.
By the way, there's also research by Kelly McGonigal on a similar idea that the only thing worse than feeling stressed out about something is feeling stressed out about being stressed out.
That actually makes you less productive than just accepting the stress.
So, it's best to remind yourself to make happiness enhancing decisions, but then not monitor happiness levels constantly.
That's the idea of prioritizing but not pursuing happiness.
This idea of prioritizing but not pursuing happiness is similar to the idea of prioritizing but not pursuing sleep.
When you obsess about getting a good night's sleep, you're less likely to fall asleep.
In fact, constantly asking yourself whether you're about to fall asleep and telling yourself, there, I almost fell asleep right there, is perhaps the best way to stay awake.
So, just like the best way to fall asleep is to follow a lifestyle or adopt a lifestyle that makes it more likely for you to get a good night's sleep.
Definitely don't get into an argument with your wife or your husband about which TV channel to watch.
The best way to be happy is to make decisions that increase your chances of being happy.
So, as we have just seen, the first habit, the antidote to the first sin, is very simple.
That is, remind yourself on a regular basis to make happiness enhancing decisions, but don't chase happiness.
But how exactly do you acquire this habit?
One thing that's obviously important is to know what happiness means to you.
Because unless you know what happiness means to you, you can't really give it a higher priority.
This just makes common sense.
So in other words, you first need to define happiness.
Now, as you probably know, happiness can mean different things to different people.
Here are five definitions of happiness that I want you to consider.
First, happiness can be defined as sensory pleasure.
Everybody knows what this means.
Eating good food, drinking fine wine, enjoying wonderful massages, going on these really awesome vacations etc.
Second, it can be defined as hubristic pride.
In this definition, happiness equals being superior to other people.
So you feel happy when you get the best job, or nab the trophy husband or wife, and you feel that you're superior to others.
Third, it can be defined as authentic pride.
In this definition, happiness equals progressing towards mastery at something.
You compare yourself to how you were earlier, and you feel happy when you're doing better than you were.
Fourth, it can be defined as love or connection.
Or even with an activity actually, like playing the drums or guitar or with an event like a beautiful sunset.
Finally, happiness can be equated to something that I mentioned in a previous video, the feeling of abundance.
The feeling that you have everything that you need, and that life is perfect with its imperfections.
In this state of abundance, you feel that the challenges that you face make life more interesting and not threatening.
Now that I've told you about five different definitions of happiness, let me tell you how I would define happiness if I were you.
I wouldn't equate happiness to either sensory pleasure or to hubristic pride.
This is because as you can imagine it's difficult to sustain happiness if you equate it to sensory pleasure or to hubristic pride.
We all know that pleasure can't last, and as the saying goes.
So I will equate happiness to one of the three other types feelings.
And of these three, if I had to pick one, I would choose abundance.
Why?
Because as we will see in some future videos not only has it got the best potential to last for a long time, it also has some other positive properties.
In the next video I'm going to ask you to come up with your own definition of happiness.
Let me quickly summarize what we discussed in this video.
We discussed the first habit of the highly happy, which is prioritize, but don't pursue happiness.
This means reminding yourself on a regular basis to make happiness enhancing decisions, but then not obsess about how happy you are.
We also discussed the importance of defining happiness.
Because to prioritize happiness, it's important to know what happiness means to you.
And finally, we discuss the various ways in which happiness can be defined, and how it's better to define happiness as authentic pride, or love, or abundance.
And with that, let's move on to the first exercise in the next video which is defining and incorporating happiness.
Welcome to The History of Rock Part Two.
To those of you who took part one of the class, welcome back.
I should say for those of you who had part one, who, who did part one, this class, this will be a continuation.
So, a lot of what I'm going to say now is really for those who are joining us and taking the class for the first time.
So, for those of you who are, who are joining us new here with The History of Rock, Part Two, let me tell you a little bit about what you can expect in the course as it unfolds over the next six weeks.
Because the Coursera philosophy is basically to make these courses available to as many people as possible.
it's, we, we really can't make an expensive textbook required reading for the course.
The lectures all follow the textbook What's that Sound, my textbook on the history of rock music.
the lectures all follow the chapters of that.
So, if, if you are able to get a copy of, of the book, you should be able to follow that along.
I think it's a richer experience with the book.
there's more detail than I'm able to present in these lectures.
So, you, you, you, you, you, if you find the tunes on a listening guide, you can get into the music in, in some detail.
I think it's a richer experience with a textbook, but it's not required.
No material from the textbook will be on any of the quizzes or anything like that.
Anyway there are the, the textbook is currently in its third edition.
My publisher, WW Norton has made an online version of it available for like half the price, less than half the price of the paper version.
But if you can find a used paper version of the first or second edition, it will still line up with the course and, and, and make it a richer experience.
So, I'll leave it to you to decide how you want to do that.
And that's one of the I think one of the drawbacks to this online format.
There are a lot of wonderful pros to the online format, making the course available to so many people in so many different parts of the world.
But one of the drawbacks is that we can't really play music on these Coursera videos.
Because of the nature of the music business, we would have to license that music.
And if a textbook is too expensive, I gotta tell you, licensing music for these lectures would just really be way too expensive.
We couldn't do it for free.
and so what, what's happened is in part one of the class, the students banded together and found all of the music online, posted it in the discussion forum.
And so, they were able to sort of pull the music together.
it turns out that it's available in different places and different countries and that kind of thing.
I'm sorry we can't talk in more detail about the music, but that, that's just the, the, the ways of the music business, and I even have to be careful how much I quote lyrics and that kind of thing because those are all held under copyright law.
one last thing I want to talk to you about a little bit is what the purpose of a course like this.
during part one, a couple of people were wondering, well, you know?
Why are you depending so much on just the groups that are popular?
How about the groups that were influential, but didn't sell many records.
How are you deciding?
And why aren't you mentioning the group that, that I really like.
I think these guys are really important and all of that, and all those are, are valid and interesting kinds of questions.
I think the way to understand this course is that I'm mapping out a kind of big picture survey of the history of rock music.
When I talk about particular artists, I am really only talking about them as representatives of a certain kind of thing.
So, for example, in part one, we talked about the British invasion.
We spent a lot of time talking about the Beatles and Rolling Stones, but there were a lot of other British groups that didn't get mentioned.
It doesn't mean that they're not worthy, or that what they did was not valuable, or whatever.
What we're trying to do was just lay out the, the topography of what the history of rock music looks like.
This is kind of the first pass on the history of rock music.
If there's a group or, or an artist that that you think deserves more attention, and you want to make an argument for it, that's fantastic.
But you know, your argument is much stronger if you understand the broader context of the history of rock music.
So, that's what we're doing.
I'm tying not to just talk about the groups that I like or the groups that I think are important, but I'm trying to remain as objective as I possibly can.
And so, I think that's the way to view an introductory course like this, as a kind of gateway into the world of history of rock.
And then, you know, subsequent work and reading and things like that you might do can be based on a context the context that's established by the course itself.
so I did mention just a minute ago the discussion forums, the discussion focus are fantastic.
They are a great way to to interact with your other students, the other students in the course.
I post questions every week.
you can respond to those, the participation in the discussion forum is in no way a part of the grade.
But it's very much encouraged, and we've had a fantastic, we've had a fantastic time in part one on the discussion forum, a lot of great things.
And it's also such that the place for you, to make the argument for various kinds of groups that you think, that you think also deserve our attention to sort of augment what's already happening in the lectures here, or maybe in the textbook.
So, those are just a few points.
I really hope you enjoy the class.
It makes me so excited to be able to present this information to so many people from around the world.
Here I am standing in the Florida museum of Natural History, here on the UF campus and it's just an amazing place.
That and, and we're so fortunate to be able to have this on campus.
And I thought, what a perfect setting for the first week of the course.
Especially as we talk about the history and evolution of horses and donkeys and zebras and the other equids.
Behind me is a if you don't recognize it, that's a Columbian mammoth.
So the purpose really of this video is to kind of talk about the course, the syllabus kind of go over some of the objectives.
You'll know each week we, you're going to notice there's about 60 to 90 minutes worth of video.
Some of the videos go longer than 15 minutes, and, and generally those are, are, lectures that are really, really important information.
Not to say not all of it is, but that's tend to, that's why they tended to go a little bit longer, and I chose not to reshoot them because you know, that's very, very important information.
So either one you own or a hypothetical animal.
But the idea is to get you thinking about the management and the information presented to you and applying that to, to horse or donkey care.
So also we're going to ask that you evaluate three of your peers if you do turn in your, your weekly assignment.
And you have to really think about it with, with thousands and thousands of students from around the world.
That's the only feasible way we can grade or evaluate your work is, is through peer eval, so, I know through some other Coursera courses is not the most popular option, but really that's the only way we can do it.
I’ve gone in and, and created some, some online games and some app games that you can actually do on your own.
They should be fun, you know some of them are like battleship or jeopardy or.
Some you know, Who Wants to be a Millionaire type games that you have to answer questions relating to the course.
You know, get to know your other students I mean we have people from all over the world so you know, obviously people down in Australia or in Asia or in Africa or South America.
You know, be, be respectful to each other on the discussion boards.
And, kind of introduce you to that week's material.
And I've been teaching this course at the University of Virginia for more than 20 years.
And to help you understand and manage the physical world around you.
I'm delighted to be able to bring How Things Work to an even larger audience online.
I hope that you'll find this course interesting, informative and enjoyable.
Moving How Things Work out of the classroom and onto the web is a challenge.
At Virginia, my class is interactive and improvisational.
In transitioning to the web, I'm going to give up some of the spontaneity, conversation, shared experience, But I am going to gain time and space.
In this first part of How Things Work, we'll explore the physics of six objects or activities.
Skating, falling balls, ramps, see-saws.
We'll see how things move, rotate, and interact with each other.
And watch them exchange energy and momentum as they do.
It's not all of physics, but it's a good start.
It will already give you many useful tools for a living.
I'm breaking tradition however, by releasing this entire course all at once.
Since this is a whole new adventure in education, we're not constrained to sticking to a ordinary class schedule.
One week,next week, next week.
That means if you want to binge learn, you can, you're welcome to charge ahead as fast as you like.
Or take your time, as long as you finish up by May 1st.
Each episode consists of an hour or two of video.
And a ten question homework assignment, to help you think about and use the relevant physics concepts.
To deepen your understanding, I encourage you to read the section on the episode's topic in my textbook, How Things Work.
Or in my general readership book, How Everything Works.
I think that human interaction is an important part of learning.
And I hope that you'll seek out others while taking this course.
Talk with your friends or family.
Kids, parents, and even grandparents.
I think that's the greatest thing ever.
If you have no one local to talk about, please use the forums to reach out.
In fact, you can all enrich the course with your insights and experiences.
So go ahead and post, or link in your own stuff.
We'll naturally revisit concepts in new situations and different circumstances.
And they'll gradually become more familiar and meaningful with each exposure.
Lastly, I hope you'll take the preliminary assessment.
It's not exactly a homework assignment, it's simply 21 questions about physics in the real world.
Designed to see what you know right now.
The fun part will be retaking that same assignment when you finish the course.
And now, on to the first topic.
Hello, I'm Lou Bloomfield and welcome to how things work at the University of Virginia.
Todays topic, skating.
Whether you're gliding across the ice, strapping old rollerskates to your shoes, or cruising down the sidewalk on a skateboard.
You're freeing yourself from the constraints of friction and allowing yourself to move with ease and simplicity.
Like ordinary shoes skates support you vertically.
That is the ground supports the skates and the skates support you.
But unlike ordinary shoes the skates move freely forward and backward and you can coast.
Coasting is also an example of one of the most fundamental principles in all of physics, the principle of inertia.
An object at rest tends to remain at rest, and an object in motion tends to remain in motion.
As you skate, or watch other people skate, you'll notice a couple of common themes.
If you're stationary on a level surface, and nothing pushes you, you'll remain stationary.
But, if you something does push you, you'll begin to move in the direction of that push.
On the other hand, if you're moving on a level surface and nothing pushes on you, you'll continue moving forward in a straight line.
But if something does push on you, you'll speed up or slow down or turn.
My goal in examining skating is to explain those observations.
That effort will introduce us to some of the words that physicists and scientists use to characterize what they see and measure.
It'll also bring up some of the basic laws of motion.
Laws that date back to the times of Galileo and Newton.
Here's a question to think about.
I'm not going to ask it yet, officially, but you should have it in mind as we continue our way through skating.
A rotary lawn mower is a machine that cuts the grass by spinning a sharp blade very rapidly over the grasses.
The question is whether that rotary lawn mower and its spinning blade could cut the grasses if the grasses weren't attached to the ground.
To help guide us through the science of skating, we'll pursue five how and why questions.
Why is a moving skater tend to be moving?
How can we describe the fluid effortless motion of a coasting skater?
How does a skater start, stop or, turn?
Why does a skater need ice or wheels in order to skate?
There is one video sequence for each of those questions, and a summary video at the end.
The short answer to that question is that an object at rest tends to remain at rest.
In other words, if you leave a motionless skater completely alone, you don't push on her, she'll remain motionless.
This behavior is known as inertia.
But don't take my word for it.
Let's do some experiments so you can observe it for yourself.
It's actually not a trick at all.
It's physics in action.
And because I'm going to pull it very fast.
I will influence these slightly, but it'll happen so quickly and for such a short period of time that they'll pretty much be unaffected and they should stay put.
Now, the whole idea of this being called a trick brings up an issue with this class.
This class is not about magic.
You should understand everything that happens and why it happens.
If I fail to convey to you why it happened, what you're seeing and why it happened, then I have missed my goal.
And I have found over the years that I have to be nervous about this, because If I get complacent and do it casually then I flip everything over.
Here we go.
So that I don't, fly everything around the room.
Ready, three, two, one, .
You can try this experiment yourself, but you might want to start with unbreakable dishes.
If you don't want to risk anything you could also do the experiment with a handful of coins and a sheet of paper.
Just lay the coins on the paper and snap the paper off from underneath them.
This demonstration of inertia that an object rest, tends to remain at rest, makes use of a pencil, a wooden hoop and a glass bottle.
The hoop on the bottle.
Next, I try to balance the pencil on the hoop.
And now I'm going to sneak the hoop out from underneath that pencil.
I'm going to grab the hoop very fast, so that the pencil is suddenly left hanging in mid-air.
And it then begins to fall.
Watch how the pencil just hangs there in midair for a few frames before dropping into the bottle.
This brings us to the question I asked you to think about in the introductory video.
Inertia makes it possible for the lawn mower to cut the grasses even when they're not attached to the ground.
Each grass remains in place.
But because it's an object at rest, and it tends to remain at rest.
Rather than cutting grasses, though, I can show you the same effect by cutting an apple with a sharp knife.
This experiment is designed to answer the question.
Can I slice through an apple, even if that apple isn't being held in place by anything?
Now, I'm not much of a swordsman so if I try to swing that knife through the apple, by hand, sometimes I hit it and sometimes I miss.
So, I have built a spring loaded.
Right there for the middle of this apple, it's all good.
And, the spring is so strong I have to hold the table in place.
Get the spring, all lined up here with the apple.
Notice the apple is not attached to the table.
But it's kept in place by its own inertia and we'll see whether this knife can get through the apple.
Okay.
Now, we did exert a little bit of external influence on the apple.
The apple did finally not completely stay put.
So, the question is answered.
Yes, it is quite possible to slice an apple that is not held in place by anything.
Just as a fast-moving knife can slice through a stationary apple, so the fast-moving blade of a rotary lawnmower can slice through stationary grasses.
The blade sweeps so quickly through those grasses that they don't have to be held in place.
Inertia ensures that they don't move as that sharp blade cuts through them.
Many kitchen tools take advantage of inertia.
They use a fast moving blade to slice through objects at rest.
So back to skating.
That's the nature of things in our universe and while it's not very exciting to stand motionless on your skates, it's a relief to know that you won't suddenly start moving swiftly in some random direction for no apparent reason.
Why does a moving skater tend to continue moving?
The short answer to that question is that an object in motion tends to remain in motion.
In other words, if a skater is moving and you leave that skater completely alone, you don't push on him, then that skater will continue to move.
This behavior is actually the other half of inertia and it's how objects in our universe work.
The complete concept of inertia then, is that an object at rest tends to remain at rest, and an object in motion tends to remain in motion.
It's time to demonstrate the second half of inertia using a banana.
This experiment is designed to test the inertia of a moving object.
I'm going to throw the moving object, a banana, to the right and it's going to have a close encounter with a very sharp knife.
Now, I'm not going to be holding the banana when it meets up with the knife.
So, if anyone asks you after the fact, who killed off that banana, it wasn't me, officer.
The banana did it itself.
An object in motion tends to continue in motion even if it encounters things like, sharp knives.
The motion of an inertial object, that is an object that's free of external forces, is very simple.
It moves in a straight line at a steady pace.
No.
Because an object at rest is just a special case of steady pace motion.
We're ready for a formal statement of the concept or principle of intertia.
Because we don't know all the words for some of the physical quantities involved, we'll consider this a first draft.
It's known as Newton's First Law of Motion and it states that an object that is free of external influences moves in a straight line and covers equal distances in equal times.
Skating is full of examples of Newton's First Law.
To perfect our first draft, we need to identify those external influences.
And we need a better way to describe motion in a straight line that covers equal distances in equal times.
Still, we're making progress.
We can already use Newton's First Law to figure out if an object is experiencing external influences.
If that object is not traveling in a straight line or if it is not covering equal distances in equal times, then it's not inertial.
It's not obeying Newton's First Law and it has external influences.
For example, if I skate into that cabinet, then I'm not obeying Newton's First Law.
A skater who is heading straight north at a steady speed is inertial and is obeying Newton's First Law.
That skater is traveling in a straight line path, namely northward, and is covering equal distances in equal times.
Skaters are inertial much of the time and are moving according to Newton's First Law of Motion.
In a word, they're coasting.
How do you describe the fluid, effortless motion of a coasting skater?
A simple answer to that question is that a coasting skater moves at a constant velocity.
In fact, in a short time, I'll restate Newton's first law, using better, more sophisticated language, but in order to do that, I need to introduce three physical quantities associated with motion.
Those physical quantities are position, velocity, and force.
Position is the measure of an object's location in space.
For example, my position is, is about 6.5 feet, or two meters in front of this jar.
You'll notice I needed three things.
If you leave out any one of those three aspects of position, the reference point, the distance and the direction from that reference point to the lo, location you have in mind, you don't know the objects position.
To show you that, let me change my position.
Well first off, if, we lose that bottle.
Okay, we need the bottle, the reference point, okay.
So now, suppose you know that I'm in front of the reference point but you don't know how far, you lose the distance part.
I could be here, I could be here.
Position is a distance and a direction from a reference point.
Physical quantities like position that have both an amount and a direction are known as vector quantities.
You're probably familiar with physical quantities that have just an amount, like the temperature of this room or the duration of a concert or the size of your computer screen.
But there are also many important physical quantities that have both an amount and a direction.
They're vector quantities, and if you leave out the direction part of a vector quantity, you haven't specified the whole thing.
We measure position in units of distance.
Physicists normally use the SI, or system international of units.
And the SI unit of distance, is the meter.
That's about a meter right there.
Well, because most people in the United States are relatively unfamiliar with the SI units, the meter in particular, and because this class is all about familiar things, I'll also use more familiar units.
In this case, more familiar units of distance include the foot and the mile.
When an object is moving, it has a velocity that's not zero.
Velocity measures the rate at which an object's position is changing with time.
Velocity is another vector quantity.
The amount of your velocity is the speed at which you are traveling.
And the direction of your velocity is the direction in which you're heading.
Let me show you my velocity.
Right now, my velocity is zero.
But I'm about to develop a velocity to your left.
I'm now moving toward the left.
And my velocity is, oh, maybe half a foot per second to the left.
Now, I'm moving about half a foot per second toward your right.
That's a different velocity, even though my speed is the same.
As you can see, velocity has an amount, my speed, in this case, and a direction.
And if you don't specify both of them in specifying my velocity, for example, you've left out some important information.
We measure velocity in units of distance per time.
The SI unit of velocity is the meter per second.
In the United States, more familiar units of, of velocity are, feet per second, and miles per hour.
I have one more physical quantity to introduce.
Force is the physics term for a push or a pull.
An it's another vector quantity.
For example, if I push on this book.
I'm exerting a force on it, and that force has both an amount which is how hard I'm pushing, and a direction, which in this case, is away from you.
A more familiar unit in the United States for force, the pound, or, more specifically, the pound-force.
We can now redraft Newton's first law of motion using better language.
To start with, we can replace the vague term influences with the more specific term, forces.
So the Newton's first law of motion becomes an object that is free of forces moves in a straight line and covers equal distances in equal times.
But we can also redraft the second half of that law.
An object that is travelling in a straight line, is always heading in the same direction.
Constant direction.
And an object that is covering equal distances in equal times is always travelling at the same speed.
Constant speed.
An object that has both constant direction and constant speed has constant velocity.
So Newtons first law of motion, in it's final form is an object that is free of external forces moves at a constant velocity.
A skater is experiencing zero force is covered by Newton's first law of motion, and will move at constant velocity.
The skater is coasting.
Avoiding any external force is difficult, or even impossible.
But it's relatively easy to have the individual external forces on a skater cancel one another.
For example, if you push a skater to the right, and I push that same skater to the left, equally hard, our two forces on the skater cancel one another.
An they have no overall effect, on the skater.
If all of the external forces acting on a skater cancel one another in this way, the skater has no overall external force acting on her, and she obeys Newton's First Law of Motion, she is inertial, and she travels at constant velocity.
How does a skater start, stop, or turn?
The answer is that a force acts on the skater and causes the skater to accelerate.
This time, acceleration.
As I said earlier, a skater's velocity consists of the speed in which the skater is traveling and the direction in which he's heading.
If he's inertial, that is if he's experiencing no overall force, then his velocity is constant.
He has a constant speed and a constant direction of travel.
But if he's not inertial, if he's experiencing an overall force, then his velocity changes with time.
He's accelerating.
Acceleration measures the rate at which an object's velocity is changing with time.
It's a subtle quantity.
It's not so easy to observe.
You have to look carefully.
Moreover, it's another vector quantity.
I'm going to, I'll be the object, and I'm going to accelerate.
I'll head over here to start with.
Now initially, I'm not going to accelerate.
So, my velocity is not changed with time, I'm not accelerating.
But I'm about to accelerate to the right at a slow rate and my velocity will develop.
And it will become faster and faster and faster and faster until I disappear from view.
Alright.
So, what you should be looking for is not mine, my movement, per se, that I simply have a velocity.
It goes from slowly to the right, to faster and faster and faster and faster to the right.
And I'm going to do a rather fast acceleration to the left.
In those cases, I was accelerating in the direction of my velocity.
And my velocity was increasing as a result.
I was going faster and faster.
My speed was steadily increasing and that's how a skater starts.
The skater starts from rest with a velocity of zero, chooses a direction to accelerate, and begins to pick up speed in that direction.
And continues to accelerate in that direction, thereby, going faster and faster and faster.
The SI unit of acceleration is the meter per second per second or meter per second squared.
Now, acceleration isn't all that familiar to anyone.
So, the familiar unit for acceleration in the United States is not so familiar.
But it is the foot per second squared.
Well, we now have velocity and acceleration.
My velocity is the speed of my motion in the direction which I'm heading.
My acceleration is how that velocity is changing with time.
And that acceleration has both an amount and a direction.
Well, let me show you a couple of examples of this.
If I accelerate in the direction of my velocity as we've seen, I speed up.
On the other hand, if I accelerate opposite the direction of my velocity, I am going to slow down.
Let me show you.
Let me get started because I, I, I can't do everything at once.
Now, I'm moving to the right but I'm accelerating to the left, and watch what happens to my velocity.
I come momentarily to a stop and if I keep accelerating backwards here towards your left, I pick up speed and disappear off out of view on the, on the left.
Well, accelerating forward, that is in the direction of my velocity, I pick up speed we, we're comfortable calling that acceleration.
if I however, I accelerate opposite my velocity, so let me do this again.
So, I'm going to, let me get started.
So, here we go, ready, start.
During the stopping part of that story, so as I was heading to the right but accelerated to the left and slowing down, we have a special name that we often apply to that type of acceleration, acceleration opposite your velocity.
It's, it's not necessarily a completely separate concept.
It's a, just a special case of acceleration.
But there's at least one other interesting example of acceleration.
What happens if instead of accelerating in the direction of my velocity or opposite the direction of velocity, I accelerate to the side.
I go in a circle.
The point of this is, that if you accelerate not in the direction of your velocity, and not opposite but rather to the side, you turn.
So, we now can really answer the question of how a skater, starts, stops and turns.
To start, the skater, say, the skater is at rest, the skater has to pick a direction and begin to accelerating that direction.
We'll talk about what causes this acceleration surely but I am going to develop a velocity that gets larger and larger toward the right.
So, to start, I pick a direction and then I continue to accelerate in that same direction, thereby picking up speed in the direction that I had chosen.
Alright.
Well, the skater then starts the situation already moving and accelerates opposite the skater's velocity.
So, I'll do it again.
Okay, I'm a skater moving along and I want to stop.
And if the skater wants to turn and the skater accelerates in a direction neither forward or backward but rather, to the side.
So, the skater might have been heading, let me do it differently.
And so, the skater is heading to the right and accelerates towards you.
And the skater's velocity changes and the skater begins to turn.
So, let's see whether you got all of this.
And then, I'm going to ask you about my velocity and my acceleration.
My velocity was up the stairs because that's the direction that I'm moving, but my acceleration was down the stairs because I was slowing down.
So, I started up at great speed and then, because I'm accelerating down the stairs, I slow down.
And if I continued to slide down the stairs, I would have picked up speed in the downward, down the stairs direction.
One of the reasons it's so difficult to see acceleration is that it takes at least three glances to measure it.
In contrast, it takes only one glance to measure position and two glances to measure velocity.
I'll show you.
First, my position.
There, in a single glance, you know my position.
There, in two glances, you can see my position at one moment in time and one second later.
And by comparing the two, you can see how my, my position is changing with time so you know my velocity.
But to see my acceleration, you need three glances.
If you look at those three glances, the first pair tell you my velocity early on.
By comparing those two positions, you know how fast I was moving and in what direction.
The second pair tell you my velocity one second later.
And by comparing those two velocities, the first velocity and my velocity one second later, you can see how my velocity was changing with time.
You can see my acceleration.
When a skater is starting, stopping, or turning, that skater is accelerating.
And the skater's acceleration is caused by an external force exerted on the skater by something in her environment.
When the skater is on level ground or ice, the something that usually pushes on her is the ground itself.
For example, I can accelerate toward the right by pushing the ground toward the left.
When I push the ground toward the left, it will react by pushing me toward the right.
That will be an external force on me toward the right and I'll accelerate toward the right.
But, you could see that the act of pushing the ground toward the left caused the ground to push me toward the right and I accelerated toward the right.
We'll talk about the interaction between my foot and the ground another day.
What does matter is that I obtained a force toward the right and I accelerated toward the right in response.
Now, in most cases, the skater is experiencing more than a single force.
There are many forces.
For example, when I was on the skateboard just standing there, gravity was pulling me downward and the skateboard is pushing me upward.
It's complicated.
You don't respond to each individual force by accelerating.
That sum of all forces acting on you is called the net force.
The net force is acting on you and you accelerate in response to that net force.
When I was accelerating toward the right by pushing the ground towards the left, like this again.
I briefly had a net force toward the right acting on me and I accelerated in response to that.
Your acceleration in response to net force is proportional to that net force.
The larger the net force, the greater your acceleration.
And the two are in the same direction.
That is, your acceleration is in the direction of the net force acting on you.
Now, suppose I decide to go skateboarding with a lead brick.
Physicists like lead bricks.
I go and get my skateboard and so now, I'm not going to do this, I'm bad enough at skateboarding without the lead brick in my hand.
But if I go and stand on the skateboard and push the ground toward the left, the ground pushes me the same just as hard as before toward the right and I begin to accelerate toward the right but not as rapidly.
Somehow, having this extra object with me greatly decreases my acceleration.
And actually, I have more of the measure of inertia which is known as mass.
So, mass is the measure of an object's inertia.
So, what we see is, the more mass an object has, that is, the larger its inertia, the less it accelerates in response to a given force.
In fact, an object's acceleration is inversely proportional to its mass, everything else left the same.
If you push the same hardness on several different objects, each one will accelerate in proportion to one over its mass.
We see overall that an object accelerates in proportion to the net force acting on it and in inverse proportion to its mass.
We can bring those together into a single equation, which is known as Newton's Second Law of Motion, that an object accelerates and its acceleration is equal to the net force acting on it divided by its mass.
The two physical quantities on the right side of that equation, the net force acting on the skater, and the skater's mass are the cause of this effect and the result is the skater's acceleration.
So, we have cause and effect clearly distinguished in this form of Newton's Second Law of Motion.
Nonetheless, it's become traditional to rearrange that equation algebraically to get rid of the division.
And so, the equation is traditionally written as the net force acting on the skater is equal to the mass of the skater times the skater's acceleration.
That traditional way of writing Newton's Second Law of Motion confuses, mixes up cause and effect, and so I'm not particularly fond of it.
Why does skaters need ice or wheels in order to skate?
If you're thinking about friction and about, more or less, eliminating with Ice wheels, you're right.
Skates do a wonderful job of reducing the effects of friction.
But, I'm going to go with the more general answer, that real world complications often mask inertia and Newton's first law.
When Inertia was first published by Sir Isaac Newton in his Principia Mathematica in 1687.
First, there is gravity.
I'll talk more about gravity in the next episode.
According to Newton's first law, if I'm free of all external forces, then I'll move at constant velocity.
Let's go try it!
The problem was the gravity was exerting a downward force on me and I wasn't actually inertial.
Since we can't turn off gravity, we have to cancel it out with another force.
The ground pushes up on the skater by the way of the skates, with just enough upward force to cancel out gravity's downward force on the skater.
So the skater is experiencing no net force and the skater is inertial.
We have gravity under control, but that still doesn't explain the need for ice or wheels on the skates.
So I'm going to ask you a question about this book.
And I want you to answer it truthfully according to your experience.
And according to what you thin in your gut, is the right answer.
I'll give you a chance later on to change that answer, if you like.
Suppose this book is free of external forces except for any that you might exert on it yourself.
How does this book move?
The book's motion is governed by both Newton's first and second laws of motion.
And if you push on the book, and you're exerting the only external force on the book, it accelerates in the direction of your push and it's velocity changes with time.
They make the whole idea of coasting seem counterintuitive.
You've never seen a file cabinet or a carpet or a glass of water even, coast horizontally across a horizontal surface.
You have to push them the whole way, and when you stop pushing, they very quickly come to a stop.
But that's not because Newton's laws are wrong, it's because of friction.
It sure seems like you have to push on something to make it move, and when you stop pushing it comes to a stop.
But that's just friction messing with your head.
If you use skates to eliminate friction, so that friction can't interfere with inertial motion.
Then an object, namely the skater, can be truly free of external forces.
Or, least overall external forces.
And can move according to Newton's first law.
That net force causes the skater to accelerate and the skater's velocity changes according to that acceleration.
What makes skating so fun and interesting is that your skates free you from the constraints of friction.
So that you can enjoy the simple pleasure of inertia.
When you're experiencing no external forces or, more generally, when the net force acting on you is zero, you move according to Newton's first law, and travel at constant velocity.
That's a velocity of zero staying zero.
If you're moving, you move in the same direction at the same speed.
That's your velocity remaining constant and you're coasting.
Moreover that acceleration is in the same direction, as the net force.
Well that's it for skating, glide away and I will see you next time for more of how things work.
Today's topic, falling balls.
They're in most sports, many toys, and they're even in Times Square on New Year's eve.
Whenever a ball isn't touching anything, whether you dropped it or tossed it or kicked it, it's a falling ball, and it moves according to physics of falling objects.
A falling ball is experiencing only one force, it's weight.
That is, the force exerted on the ball by the Earth's gravity.
We've talked about forces in general up to this point, but we have never identified a specific one.
And it's going to play a leading role in this episode.
Any time an object is completely on its own, except for gravity, it's a falling object.
The one notable exception, or at least one I have in mind, is a sheet of paper.
For now, all these objects that we will drop, whether it's a basketball, a tennis ball, a golf ball, we're going to ignore air resistance and treat only the influence of their own weight on their motion.
Now, your head might not be sure that it's really picking up speed, but your gut is.
For that, I need help from my assistant, Katrina here.
Hi.
So, what I'm going to have Katrina do is put her hand right here on the table, okay?
Mm-hm.
And now, I'm going to drop the ball on Katrina's hand.
It doesn't hurt.
Okay.
Not, not too bad, and we're not, we're not going off to in an ambulance yet.
As, as you can tell, so, like Katrina knew that the ball will have picked up a lot of speed on its route to her hand because it will have had a lot of time to fall.
So, its height is going down by bigger and bigger increments as time goes by.
As a second example, if you toss a ball straight up, it rises quickly at first but then more and more slowly as it reaches greater height.
It's going fast at first, but less fast and less fast still.
The ball rises to a peak at which point it's not moving at all, for an instant, and then it drops as though from rest.
Two fundamentally different physical quantities that are related to one another in interesting ways.
Moreover, falling balls are a wonderful example of the laws of motion I introduced in the episode on skating.
It's a simple, yet elegant example, and a good step along the path to the more complicated objects that we'll examine as we continue to look at how things work.
If I take a ball and throw it upward, toss it straight up, during the time when it's above my hand, not touching my hand, and heading upward, is there a force pushing upward on the ball?
So, it's just as the ball is on its way up, not touching my hand, is there an upward force acting on the ball?
To help guide us through the science of falling balls, we'll pursue the following six how and why questions.
Why does a dropped ball fall downward?
How differently do different balls fall?
How does a falling ball move after it is dropped?
How does a ball's horizontal motion, affect it's fall?
There's a video sequence for each of those 6 questions, and a summary video at the end.
So now, on to the first question.
The simple but remarkable answer to that question is, that all balls fall at the same rate.
But don't try to apply the same story to a sheet of paper because the sheet of paper is really affected a lot by air resistance.
So, returning then to the balls and this question whether it's a basketball, a tennis ball, a handball, a golf ball or a baseball, if you drop them together, they all fall together.
So here, we have a tennis ball and a basketball, we'll see whether they fall together.
Not only do all balls fall together, but if you were to begin falling with them, you would keep pace perfectly.
And you'll be looking out that little window at the world in front of you and the balls that are dropping as you drop with them.
There's Catherine down there.
Hi down there, Catherine.
Hi.
You ready to have some balls and the camera drop at you?
Alright.
That's one of the reasons why I didn't drop a bowling ball.
Why does a bowling ball and a baseball fall together and hit the ground at the same time?
After all, the bowling ball weighs much more than the baseball.
So, from a weight point of view, the bowling ball's pulled downward much more strongly by the earths gravity than the baseball, and the so the bowling ball should accelerate faster.
What's wrong with that thinking?
So, when it's pulled downward by the earth's gravity, it should accelerate faster, it should clearly outpace the bowling ball and the baseball should hit the ground first.
Well, you can't separate the weight point of view and mass point of view, you have to combine them.
We have to have one point of view which we take into account both the higher weight of the base, bowling ball and the greater mass of the bowling ball.
But it also has more mass, so it resists accelerations more, and that alone would slow its acceleration.
Those two increases, cancel perfectly, so the bowling balls response, that is its downward acceleration caused by gravity, the earth's gravity, is exactly the same as the down response of the baseball to the earth's gravity.
When you're carrying a ball at constant velocity, the ball is moving at constant velocity, you're most aware of the balls weight because you're having to support that weight.
Without your upward push on the ball, the ball would fall.
So, you are, you are detecting gravity as you walk along a constant velocity.
When you push a ball back and forth on the table, you're causing the ball to accelerate first one direction then the other.
And as a result, you're quite aware of the ball's mass.
The table on the other hand is supporting the weight of the ball, so you are completely oblivious to that weight, it could be large, it could be small, that's the table's responsibility.
Now, this course is about the objects of everyday experience and the Physics concepts that make them do what they do.
In other words, it's about understanding how things work more than it is about calculating how they work.
That said, however, there are times when looking at the Quantitative Physics, opening up the hood and staring at the Mathematics that underlie the concepts is a useful activity and will give us insight into how the machinery of our universe works.
When a ball is falling, the only force acting on it is its weight.
So, the net force on a falling ball is the ball's weight.
Well, Newton's Second Law of Motion tells us, that the acceleration of any object is equal to the net force on that object divided by the object's mass.
So, in this specific case of a falling ball, the acceleration of a falling ball is equal to the net force on the ball, which is the ball's weight.
The falling ball's acceleration is equal to the ball's weight divided by the ball's mass.
That cancels, the ball's mass disappears from this Newton's Second Law and Newton Second Law says that the falling ball's acceleration is simply the constant of proportionality, which is to say, a falling ball's acceleration is 9.8 N/kg or equivalently 2.2 pounds per kilogram.
Well, that's a strange result.
The acceleration of this ball is the same as the acceleration of this ball.
The mass was unimportant and this is consistent with our observation.
You drop all these balls, they all go down together, they all accelerate downward together.
But what remains to be done and it's bizarre, is, that constant proportionality has wacky units.
9.8 Newtons, that is a unit of force, per kilogram, that is unit of mass.
Recall that the SI unit of acceleration is the meter per second squared.
So, where, is the connection?
Well, it turns out that the unit, this unit's Newton per kilogram is exactly same as this unit, the meter per second square, they're the same and how does that ever happen?
One Newton is the force that causes a one kilogram mass to accelerate at one meter per second ^2.
That defines the Newton.
And as a result, Newton's Second Law written out in that way says, that one meter per second squared of acceleration is equal to one Newton of force divided by 1 kilogram of mass.
As a result, that little g constant of proportionality is an acceleration, it is 9.8 meters per second squared.
And that is the acceleration of any falling object here near the Earth's surface, as long as air resistance can be neglected.
How would a ball fall on the moon?
The answer to this question is simple.
The ball would fall much more slowly than on Earth.
It would pick up speed in the downward direction more slowly.
To understand why that's the case, however, we need to revisit the issue of gravity and take a look again at the relationship between weight and mass.
And I've told you that every kilogram of mass, near the Earth's surface, requires a weight of about 9.8 Newtons.
And if you drop an object near the Earth's surface, it accelerates downward at about 9.8 meters per second squared.
You'll notice that I keep saying, near the Earth's surface, and that's because those two statements are dependent on the Earth's gravity here, the local strength of gravity.
And the details, we'll save for that episode.
It depends on the mass of the object producing that gravitational force, and it depends on your distance from that object.
That is the distance between the object in question, namely the Earth and us, is about the distance between us and the center of the Earth.
So, the Earth is very massive and in fact, quite distant from us.
And together, that leads to a strength of gravity that gives every kilogram of mass a weight of 9.8 Newtons, and causes falling objects to accelerate downward at about 9.8 meters per second squared.
If we go somewhere else, that relation, those relationships may change.
But actually, where you are in the Earth surface matters.
Every time you go upward, for example, into the mountains or into a plane and get farther from the center of the Earth, the strength of gravity, the Earth's gravity weaken slightly, and you weigh a little less.
You don't actually have to go up or down, you can move to different locations on Earth.
The Earth, it turns out, is not perfectly spherical.
And you can go, get farther from the center of the Earth by going to the equator and that will affect your weight by about half a percent.
So, you will actually weight, about half a percent more on one of the poles, than you do on the equator.
So, the relationships between mass and weight depend on where you are, and the acceleration of a falling ball also depends on where you are.
If you visit the grocery store, you'll find items being sold by weight, and items being sold by mass, and some items that are sold by both.
This chocolate bar, for example, is labelled according to both weight and mass.
The ounce is a unit of force which is equal to 1/16th of a pound force.
So, that's the weight of this chocolate bar as, as promised by, by the manufacturer.
And a second label here says this chocolate bar has a mass of 100 grams.
A gram is a unit of mass equal to 1/1000th of a kilogram.
It says net weight 16 ounces or 1 pound, those are both units of those are both force amounts, so we have a weight.
That means that this bag of cookies has a mass of 453 grams.
And again, a gram is a unit of mass.
So, these two items are labeled and sold by both weight and by mass.
And if they're not labeled correctly, what has gone wrong with the labeling?
But those labels are way off when it comes to weight.
Mass, after all, is the measure of an object's inertia.
So, the mass of say, this chocolate bar is the same on the Moon as it is on Earth, as it is in deep space.
It's, it simply reflects how difficult it is to make this chocolate bar accelerate.
So, the mass is 100 grams here, it's a mass, mass of 100 grams on the Moon, mass of 100 grams anywhere you like.
On the other hand, weight depends on the local strength of gravity.
So, this bag of cookies weighs 1 pound here on Earth, where the strength of gravity is a certain amount.
It's about 1/6th of a pound.
Long and short of it is, if you're going to be selling items on an intergalactic basis, you do best to label them according to mass because they'll always be properly and accurately labeled, regardless of where they're shipped to.
If you label them according to weight, you're likely to run into trouble with the authorities for selling under, or possibly over weight items.
The bottom line is that a ball's weight and its acceleration due to gravity both depend on the local strength of that gravity.
In most cases, however, we don't notice that dependence.
And that's because the Earth's gravity is so nearly the same anywhere we can go That the variations in weight and accelleration of gravity are very subtle.
The game would be a very different game.
How does a falling ball move after it is dropped?
This question asks for a careful analysis of the ball's velocity and position as it falls.
Now, to help you understand these positions and velocities, let me suppose initially that gravity has vanished, and let's look and see what happens.
In a live class I can make that supposition, but only in my head.
In video, I can show you that possibility.
It's a science class.
So whenever I do this sort of thing, when I show you how things would happen if I changed the rules slightly, I'll let you know.
Lets see what happens to a ball that's released from rest in the absence of gravity.
And lets see what happens when we drop a ball from rest.
There's no acceleration due to gravity, so the ball's velocity starts at 0, which is when I release it, and it stays at 0.
Gravity is still switched off.
But this time, I'm going to plot the ball's velocity versus time.
Now velocity is a vector quantity, and plotting a vector quantity is difficult.
That is, the portion of the ball's velocity that lies along the vertical direction, and therefore that affects the ball's altitude or height above the ground.
So if it's moving downward That contributes a downward component of velocity.
The balls velocity starts at 0, and as time passes, the velocity stays at 0.
And so, the ball's velocity is constant.
Gravity's still switched off, though.
And as it moves I'm going to plot 2 things.
I'm going to, first I'm going to plot the vertical component of the ball's velocity, as before, but I'm also going to plot the vertical component of the ball's position.
Relative to some starting point, some 0, and I'm going to make the 0 the point at which I let go of the ball, so if the ball moves downward relative to the point where I let go of it, that's downward, a position that's down, below where it started.
I'm going to release the ball, not from rest, but with an initial downward component to its velocity, and we'll watch the ball fall in this gravity-free environment.
After all, it has 0 net force acting on it, here in the world of no gravity.
And so whatever velocity it started with it retained.So as time passed,the velocity didn't changed.
The position of the ball did changed however.
And with each passing second, it went lower and lower, lower and lower,until it finally.
Without gravity the ball becomes inertial after you let go of it.
In fact, from the moment I let go of it, it was at rest.
And then it went faster and faster and faster as time passed.
So in the first second, it didn't go very far because it was traveling very slowly on average.
The 3rd second, farther still, and by the time 5 seconds have passed, it had pretty much drifted out of view.
To show you full gravity, the whole earth's gravity, to return to the real world.
I'm going to drop this bowling ball out of the 3rd floor window of the Physics building and let the ball fall all the way past the basement.
But even with that amount of height to work with, the fall's going to be over in a little more than 1.2 seconds.
So we'll do it initially at full speed.
And then because this is video, I'll slow down the video and begin to mark it up, so that you can see how a falling ball moves.
It's hard to even see the bowling ball as it plummets.
To make it easier for you to follow the bowling ball during its descent, I'm going to highlight it with a red dot.
So here's the same fall, but with a red dot marking the position of the bowling ball as it falls.
Because I'm trying to explain how a falling ball moves after is dropped I need to be able to show you how the ball's position and its velocity change with time.
But recall that while it takes only a single glimpse to absorb the ball's position, it takes 2 glimpses to determine the ball's velocity.
It would be helpful therefore, if we had more than the 1 glimpse of the ball's position visible simultaneously.
The camera records 30 frames per second, that's 30 glimpses of the ball's position every second.
So, here's that same falling bowling ball, marked by a red dot, and all the previous red dots will linger on the screen so you can see the, the evolution of the ball's position.
So, there near the bottom of the fall, the ball had a large downward velocity, and so its position was shifting downward rapidly.
To help you observe the motion I just described, I need to slow the video down.
So here's the same fall again at 1/10th of normal speed, slow motion, and I'm going to mark out the ball's position every 5th of a second.
So, here is the same fall, once again in slow motion at 1/10th of full normal speed, with approximate values for the ball's position and it's velocity.
As you can see, the falling bowling ball's velocity is increasing in the downward direction by about 2 meters per second every 5th of a second.
That's an acceleration of 10 meters per second.
This is a falling ball, and falling balls accelerate downward, at about 10m/sec^2.
The acceleration due to gravity.
So this is a falling ball, its velocity's increasing steadily in a downward direction at a rate of 10 meters per second per second or 9.8 meters per second per second if you like, physics works.
So here, here in this next version of the same video, I will give you a plot of the bowling ball's velocity versus time.
After all, this is a falling ball, and falling balls are always accelerating downward at the acceleration due to gravity.
The bowling ball survived it's fall just fine, but the ground outside the Physics Building has a pretty good dent in it.
That is for falling ball drop from rest, its velocity plotted versus time gives you a straight line and its position plotted versus time gives you a curve that bends downward.
To answer those questions, we need to look at how the falling ball dropped from rest, how it's acceleration depends on time, how it's velocity depends on time, and lastly, how it's position depends on time.
What's the formulaic relationship, then, between the velocity and the time?
It turns out that the velocity of the falling ball dropped from rest is simply the acceleration, which is little g, times time.
So that is the formula for a straight line.
When you plot The falling ball dropped from rest at velocity versus time there in a straight line.
The slope of that line is little g, the acceleration due to gravity.
From start, from the drop moment, to, to now, and we have to know it's average velocity over that period, and we also know, have to know, the length that period because the, the, the ball will move using its, its average velocity to make progress, to go somewhere.
In many cases in physics, calculating an average velocity is difficult.This is a very simple case where you can do it pretty easily, the average of a ball it drop from rest is simply.
The average of its starting velocity times 0 and its ending velocity, the moment in question.
The velocity at the end of the drop is, g*time, when, not necessarily the end of the drop, but the moment in question, the moment we're paying attention to.
So that is the average velocity of a falling ball dropped from rest.
The new position of the falling ball dropped from rest.
The, the relationship between acceleration and time, is simple, it's a constant.
The relationship between the falling balls velocity, and time, is, is, is a straight line.
It, it is, that the, the falling balls velocity, is proportional to time; g * time, time.
And finally, the falling ball dropped from rest position is proportional to time squared.
And that kind of a formulaic relationship between position and time gives you an arc, if you plotted against time.
And the shape of that arc is parabolic, so this is the mathematicians would identify that and go, oh, that's a special kind of arc.
It's a parabola and parabolas show up all the time in falling objects, and will see more of them later on in this episode.
During the first second of its fall the stone is moving down relatively slowly on average and so it doesn't travel very far from you hands, but during the second second of its fall The stone is moving downward much faster on average, and so it covers far more distance during that second second than during the first second.
So we've seen that when you drop a ball from rest, all of its motion occurs along that vertical coordinate direction.
And that motion is relatively simple.
The ball's acceleration, is that of a falling object.
It accelerates downward at the acceleration due to gravity.
The ball's velocity, is also pretty simple.
It starts at 0, because we're dropping it from rest, and then it increases in the downward direction In proportion, to the time, over which the ball has been falling.
The balls position, we can define as starting at 0, and then that position, increases in the downward direction, in proportion to the time it's been falling squared.
That's because As the balls moves faster and faster, it covers more and more distance with each passing second.
So, it, it, it, its velocity increases in proportion to time, its position increases in proportion to time ^ 2.
Well, this is the simplest case of falling.
Its actually falling, , from a start in the upward direction.
How can a ball move upward and still be falling?
After all, that's what acceleration is, the rate at which velocity is changing with time.
That's a completely separate issue.
When I drop a ball from rest, I'm choosing the initial velocity for the ball to be zero.
I let go of it, and for that one moment, I have control over the ball's velocity.
I choose it to be zero.
From the moment I let go of it, acceleration, the acceleration due to gravity takes over.
And the ball's velocity, which started at zero by my choice, begins to change with time and become more and more downward.
But, I didn't have to choose an initial velocity of zero.
I could choose, for example, to let, let go of the ball with an intial velocity downward.
In that case, at the moment I let go of the ball and it became a falling object, it already had a large downward velocity.
But once it left my hand, it accelerated according to the rules of a falling object and it picked up speed in the downward direction at the usual rate of 10 meters per second per second.
What if instead of dropping the ball from rest or throwing the ball downward with a downward initial velocity, what if I start the ball with an upward initial velocity?
In that case, it's rising upward.
And so, it continues upward for a while.
But as it goes higher and higher, it's being pulled downward and is accelerated downward, and so it's slowing down.
It eventually comes to a stop, and then it begins to descend faster, and faster, and faster.
Well, to look a little more carefully at all the properties of a ball that is falling but heading upward, we need some more room.
So, let's head outside and start throwing a ball around in the open spaces.
At the peak of its travel, the ball has momentarily come to a stop.
Just before that instant, it was heading upward.
Just after that instant, it'll be heading downward.
But that doesn't mean it's not accelerating.
Like any falling ball, it's still accelerating downward at the full acceleration due to gravity.
To help you see how that movement occurred, I can now begin to play with the video of that basketball toss.
The first thing that I'm going to do is I'm going to show you where the basketball was at each moment in time prior to the present.
Now, the camera records 30 images per second so I'm going to have the images of the basketball linger on the screen, each one separated from the next by 1/30th of a second.
That trail of basketball images provides us with enough information to determine the basketball's velocity and position at each frame of the video.
The graph of the basketball's velocity versus time is a straight line.
So, it began its fall with a large upward velocity but it finished its fall with a large downward velocity.
The velocity change formed a straight line when plotted against time as its downward acceleration, the acceleration of a falling object, gradually reduced, gradually caused its velocity to shift more and more in the downward direction.
The effect of that downward acceleration early on was to slow the rise of the ball.
So that if you are moving forward but accelerating, you slow down.
and it was a constant downward acceleration so the velocity in the upper direction gradually decreased, steadily, steadily, steadily until at one instant in time, one moment, the velocity was reduced all the way to zero.
After that moment, which occurred halfway through the travels, the ball's downward acceleration cause its velocity to become more and more downward, it steadily increased in the downward direction.
So, the 1st half of this trip, the upward part of the trip, is the ball having an upward velocity that decreases steadily towards zero.
The graph of the ball's position versus time is a smooth arc that curves downward.
That reflects the motion of the ball that starts rising quickly at first, and then more and more slowly as the downward acceleration of the falling ball saps its upward velocity.
And so, we get this rapid rise at first and then slower and slower then not at all, then slow descent, slow descent, faster, faster, faster until down it comes at high speed.
The moment at which the basketball reaches peak height is an interesting moment.
Up until that point, the ball had an upward velocity that was gradually decreasing, but it was still rising upward to greater and greater height.
After that moment of peak height, the ball's velocity was downward and gradually increasing.
That's why the, the moment of peak height is the moment at which the ball's velocity stops being upward and hasn't yet been downward.
And, the ball's motion is remarkably symmetrical around that moment of peak height.
If you look at where the ball was one second before the moment of peak height and one second after the moment of peak height, it's at the same altitude.
The ball is the same distance below the peak on both sides of time, one second before, one second after.
Not only that, but the speed of the ball is the same.
Before peak height, the speed was directly upward.
It was an upward velocity.
Because of that symmetry, the rise and fall of the ball looks the same if I play it forward as if I play it backward.
The bottom line here is that a falling ball is falling no matter what its velocity is at the start of the fall.
It can start from rest, it can start with me throwing it downward a little bit, or it can start with me throwing it upward.
Once the ball leaves my hands, the only force acting on it is its weight, and it accelerates downward at the acceleration due to gravity.
So, the formulas that I gave previously for a ball dropped from rest still, still apply, they're still relevant.
But, we need to spruce them up a little to take into account the possibility that the ball started to fall with an initial velocity that wasn't zero.
To take a look at that, those slightly revised formulas, let's go back to my laboratory.
To describe the motion of a falling ball that begins its fall with an initial velocity different from zero, we have to make some modifications to the equations I gave you to describe the motion of a falling ball dropped from rest.
We have to incorporate the possibility of an initial velocity that's not zero.
So, let's look at the ball's acceleration, then its velocity, then its position.
Well, the ball's acceleration doesn't change because of any initial velocity.
The ball's acceleration has nothing to do with its initial velocity.
It's simply the acceleration due to gravity.
It's a falling ball.
And whether the ball is going up, or down, or sideways, or any which way, as long as the only force acting on it is its weight, it's accelerating downward at the acceleration due to gravity.
So, that was easy.
Okay, that brings us to velocity.
In the old relationship, we had for a ball dropped from rest that the velocity at, at any given time is, is simply the acceleration due to gravity times the time over which the ball has been falling.
So, at time zero, when the ball hans't had any time to fall and threfore hasn't undergone any acceleration due to falling, the velocity of the ball is the velocity it started at.
So, the, the, the formula that gives us the velocity of a falling ball that started with an initial velocity is the ball's initial velocity plus the acceleration due to gravity times time.
First off, we should really allow for the ball to start its fall at a position other than zero.
And, if we do that, we add in the starting position.
So, the position at any given later time is equal to the starting position, that's, that's the beginning, plus additional substance.
Well, it's the, once again, it's the average velocity of the ball over the course of its, its fall.
So, it's that average velocity times the time between the start of the fall and now.
So, it's the same product as before, but now the average velocity is more complicated because the velocity didn't start at zero.
It's not very, not very difficult but it's enough, I'll leave it out of this, out of this video.
The final result is that the position of the ball during its fall at, at any given time where, where time zero is the moment the fall began, that position is equal to the initial position of the ball, where you let go of it, plus the ball's initial velocity times time.
So, the three terms that are present in that relationship that give you the ultimate, the position of the ball overall.
The first term adjusts for the fact that you might want to start the fall, the ball's fall, at a position other than zero.
And the third term recognizes that a falling ball is accelerating downward, the acceleration due to gravity.
So, whether you, you care about these quantitative relationships that, that, that actually tell you specifically where the ball is in space, how fast its moving, and, and what its acceleration is, or when you simply want to watch the ball fall, its motion is still very simple.
The ball starts with its initial velocity, and once it's falling, it, it accelerates downward.
If it's heading upward at a given moment, well, it's, it's becoming less and less upward as time goes on.
So, so it makes use of this velocity then to cover distance, and so you see these rises and falls, or simply falls, they're all dictated by this constant downward acceleration, the downward acceleration of a falling ball.
It's time to ask the question I asked you to think about during the introduction to this episode.
The ball moves upward not because of any force pushing it upward, but because of its own inertia.
The ball left my hand with an upward velocity.
And even though it begins to fall the moment I stop supporting it, it takes time for that ball's downward acceleration to change the ball's upward velocity into a downward velocity.
If the only thing you could do in baseball, or basketball, or football, or soccer, or volleyball was make the ball go straight up and down, those would be pretty dull sports.
They still involve falling balls, but those balls have room to move.
And, in the next part of this episode, we'll take a look at motions that aren't strictly vertical.
How does a ball's horizontal motion affect its fall?
The trivial answer to that question is, that it doesn't.
But a more complete answer is that the ball's horizontal coasting motion has no effect on its vertical falling motion.
It's falling vertically, while it's coasting horizontally.
The space we live in is 3-dimensional, and so motion occurs in 3 dimensions.
Up until now, I focused only on the vertical dimension, the balls altitude or it's height above the ground.
In more general cases, the ball can move horizontally as well as vertically.
And if I throw it up at an angle, it does two things at once.
It goes up and down like a falling object, but at the same time it coasts horizontally at a steady pace.
Geometry tells us that in three dimensions, we can describe a ball's position, or any other vector quantity for that matter, in terms of coordinates along three separate directions.
Boxes are made in such a shape that if you put sticks along three sides, you have three mutually perpendicular directions pointed out.
So, here's one direction, a second direction that is at right angles to the first, and a third direction that is also at right angles to both the previous directions.
So, this is a system that is three perpendicular and mutually perpendicular directions.
And any of these is a pretty good choice of coordinates, of coordinate directions, along which to describe any vector quantity you like.
When describing the motion of a falling ball, there is one particularly simple choice of coordinate directions.
I call that direction the down-field direction because if you're playing American football or soccer, then you're trying to make progress along with that down feel direction.
The third coordinate points to one side or the other, and it actually doesn't matter in this situation.
One of them points straight up, one of them points horizontally along the downward direction, and the third points to the side.
If I drop it from rest or toss it straight up, then all of its motion is along that vertical coordinate.
The ball's vertical motion, that is the component of its motion that lies along the vertical coordinate direction, is that of a falling ball.
And the ball's down field motion, that is the component of its motion that lies along the down field coordinate direction, is that of a coasting ball.
And the ball is doing both of these things simultaneously and they have no effect on one another.
To give you an idea of why this works, before I set out and show you that it works, let's look at how the ball accelerates.
The acceleration of the ball is entirely along that vertical core direction, and so the component of the ball's acceleration along that direction is the entire acceleration.
The, therefore, the ball accelerates along the vertical coordinate direction perfectly.
On the other hand, there is no gravitational force component pointing along the down field direction.
That down field direction is horizontal and gravity is a vertical effect.
Gravity has no effect on motion along the down field coordinate direction, and so the ball simply does what it was doing in accordance with Newton's first law.
It, it's, the, the component of its velocity along the downfield coordinate direction is constant.
So, the ball's motion vertically is that of a falling object.
Its motion along the downfield coordinate direction is that of a coasting object.
I need more room so we're going to go up to the third floor again and throw things out the window.
Now, I want to make the, the ball head horizontally fast so that you can see that downfield motion.
And because a bowling ball has a pretty big mass, I can't throw it sideways very fast.
that's an inertia issue, right?
I'm going to throw a basketball out the 3rd floor window of the Physics Building at, at UVA and I'm going to get it going horizontally as fast as I can so that you'll see that down field coasting motion at the same time.
I'm going to throw it as horizontally as possible.
So, it'll start with no vertical component to its velocity.
The basketball's fall and its subsequent bounces took a few seconds but it's still hard to see what happened in real time.
So, I'm going to use the fact that this is video to show you that same arcing descent, but with the images of the basketball lingering on the screen.
So, recall this camera takes 30 frames per second, so the images that you'll see in a moment are separated in time by 1/30th of a second.
So, here again is that, is the, the ball thrown horizontally out the window and arcing downward in the arc of a falling ball.
Now, I'm going to concentrate first on the vertical motion of the ball.
That is, the component of its motion that lies along the vertical coordinate direction.
And I'm going to show you the same video, slowed down to 1/10 of, of normal speed so that you can see what's happening, and I'm going to mark the ball's vertical component of position and vertical component of velocity every fifth of a second as it plummets.
So, here again, same basketball fall, but with slowed down and with the, the vertical components of velocity and position there for you to see.
As you can see, the vertical component of the basketball's motion is that of a falling object.
There's no difference between the vertical component of motion of this basketball, which I threw sideways to start with, and the bowling ball that I dropped previously from rest out the same window.
Its vertical component of velocity is increasing in the downward direction by about 10 meters per second every second.
So, the vertical motion of a falling ball is that of falling regardless of what its horizontal motion is.
So, here's the same video in slow motion, with the, the horizontal component of position marked off every fifth of a second.
As you can see, the downfield component of the ball's motion is that of a coasting object.
So, the ball's doing two things at once.
It's falling vertically, it's coasting horizontally, and that gives you the arc that you saw as the ball descended out this window starting horizontally then arcing downward, until finally it hit the ground.
So, you wanted to see it, I'm sure.
Now, bowling doesn't have much to do with falling balls, but basketball does.
Still, tossing basketballs out the window isn't how the sport is played.
Instead, it's played on a court by people throwing the ball, either between themselves or toward the basket.
And once the ball is free from anybodies hands, it's a falling ball.
So, basketball is all about falling balls.
Once the basketball leaves the hands of the shooter, it's experiencing only one force, its weight straight down.
And the arc that it travels in is the arc of a falling object.
Every time a player takes his shot and the ball leaves his hands, the ball begins to fall and it travels in the arc of a falling object.
I could take any one of these shots, show you the trail of basketball images, and then show you that, that trail is the arc of a falling object.
I will show you the arc that's formed by the basketball images, and then I'll show you both the vertical motion, and the horizontal motion.
So you can see if the vertical motion is that of falling, then the horizontal motion is that of coasting.
And here is a still photograph of that same shot showing you all the basketball images.
And I've marked it up so that you can see the ball's vertical component of motion and it's down field component of motion.
The ball's vertical motion is that of a falling object.
The ball rises quickly at first, then more and more slowly.
It's momentarily neither rising nor descending, and then it descends more and more quickly as it approaches the basket.
The ball is moving steadily downfield at a you, uniform pace.
And, it looks like the, the vertical yellow lines are getting closer and closer together only because the ball is getting farther and farther from us.
And because of our perspective on this shot then, the lines that are far away from us appear closer together because the space out there is compressed.
So, this really is the arc of a falling ball thrown up at an angle and basketball has lots of these arcs, every single shot is like this.
Here's another nice shot through the basket.
And here is that same shot with a trail of basketball images lingering on the screen.
Lastly, here is a still photograph the same shot marked up to show you that the basketball is falling vertically and coasting horizontally.
It's time for a question.
The black ball weighs twice as much as the orange ball, but the orange ball will be moving to your right twice as fast when the two of them leave the table.
The question is, which ball will hit the ground first, and which ball will hit the ground farthest from the table?
Here we go.
Both balls left the table with the same vertical component of velocity, namely zero.
They dropped together, it hit the floor at the same time.
But the orange ball was traveling sideways faster.
It had a greater down field component of velocity than the black ball, and so it used its time to travel farther from the table, it hit the ground farther from the table.
The arcs of falling balls are part of nearly every ball sport, including football, basketball, baseball and soccer.
Effects due to the air modify those arcs somewhat, and we'll deal with those air issues in later episodes.
But even if we continue to ignore air, we can make some interesting observations about how ball sports work.
Whenever you throw or kick or hit a ball, there's usually a limit to how fast you can make that ball move.
For example, I can only throw a baseball so fast.
Let's suppose that you throw the, a ball as fast as you can, what path does that ball take?
Well, that depends on the direction in which you throw it.
I've set that upper speed for the ball but I haven't selected yet its velocity.
So, when you throw the ball, you're choosing not only its speed, and we'll choose the maximum.
But you're choosing the direction of that ball's velocity when it leaves your hand.
Well, when you choose the ball's velocity, and particularly the direction of its velocity, you're choosing both the vertical component of the ball's velocity and its down field component of velocity.
If you throw the ball straight up, you're putting all of that speed into the vertical motion and giving the ball its maximum vertical component of velocity.
At the same time, though, you're giving the ball zero down field component of velocity.
So, straight up, it distributes all of the speed in the vertical direction.
Well, that choice of angle, and we'll measure angle relative to horizontal.
That choice of angle at which to throw the ball has a big effect on the ball's path.
It, it determines both how long the ball stays above the ground and how far it travels down field during its time aloft.
Here is a plot of the ball's position, both its vertical component of position and its downfield component of position at times, at equal times during its travels.
By throwing the ball straight up, you're putting all of the ball's initial speed into its vertical component of velocity and none into the downfield component of velocity.
That ball has the maximum vertical upward speed, and so it rises to its, the greatest height it can go to and takes as long as possible to return to the ground.
Let's try something else.
Let's lower the angle at which we throw the ball to about 70 degrees.
In this case, we're putting the ball speed mostly into its vertical component of velocity, but still somewhat into its down field component of velocity.
At this point then, the ball doesn't stay above the ground as long.
It simply doesn't have as much upward component of velocity, but it uses the time that it's above the ground to make progress down field.
And it lands somewhere down field, this is good, you didn't get hit in the head again.
Let's go down to 45 degrees.
45 degrees is special because at that angle, you're distributing the ball's initial velocity equally.
So that the vertical component of velocity and the down field component of velocity are the same.
So, the ball has a perfect balance between the vertical motion which keeps it above the ground, and the down field motion which causes it to travel in the direction you want it to go.
The ball stays loft long enough and travels down field fast enough to, to travel as far as you can make it go from where you threw it.
So, if you throw it from this height, it will pass through this height again as far as possible down field.
Alright, let's lower the angle still further from 45 down to about 20 degrees.
At this point you're putting most of the ball's initial velocity along the down field direction so that the down field component of velocity is, is, is quite large.
The ball doesn't stay above the ground very long, but it uses what little time it has to travel very fast down field.
But, for baseball for example, it's not bad because you are far enough above the ground that the ball can can stay above the ground by the time it get's to home plate.
All of these possible paths are potentially useful in ball sports.
For example, if you're going for maximum distance with a football, you probably want to throw it about 45 degrees above the horizontal because that gives you the best balance between vertical component of velocity and down field component of velocity to maximize its flight distance down field.
And so, a punter will often kick the ball above 45 degrees, more like 70 or 80 degrees, so that the ball has a longer time above the ground, even if that costs some amount of downfield distance.
On the other hand, if there are players all over the field in football and you want to throw the ball to someone as quickly as possible, and they're not all that far from you, distance isn't the goal, it's speed down field.
In which case you want to throw the ball below 45 degrees, more like 20 degrees or maybe even 10 degrees, to put as much of the speed in the down field component of velocity as possible to get it there fast.
In this episode, we examined what it means to fall and what happens to a falling ball when you drop it from rest, toss it straight up, or throw it upward at an angle.
A ball's weight is the downward force exerted on it by the Earth's gravity.
That weight, it turns out is exactly proportional to the ball's mass.
So that, for every kilogram with the ball's mass there is, the ball acquires a downward weight of about 9.8 Newtons.
That constant proportionality 9.8 Newtons per kilogram is called the acceleration due to gravity because not only does it does, does it describe the proportionality between mass and weight, it also tells you how a ball accelerates if you drop it, if you allow it to experience only its weight, and therefore accelerate in response to that weight.
That 9.8 Newtons/kg has other units, it's also 9.8 m/s^2, which is explicitly an acceleration.
Well, that 9.8 Newtons per kilogram or meters per seconds squared is true here near the Earth's surface, but if you go to the moon, the value changes because the strength of gravity on the moon is different from here near the Earth's surface.
Returning back to the to, to, to the Earth then, we saw how balls move when they're falling.
they accelerate downward at the acceleration of gravity regardless of which way they're going, but that downward acceleration causes their velocities to evolve with time and you see different behaviors, depending on what the balls initial velocity was.
If you drop it from rest, the velocity simply evolves into more and more downward speed.
if you throw it upward the velocity starts upward and so it's accelerating opposite its velocity.
And we saw how a lot of ball sports then make use of this dual behavior.
Go play some sports and watch the balls fall or, or become one yourself by diving off a diving board, into the water, of course, which is nice and safe and, you know, relatively soft.
And we'll be back for another episode of how things work.
People have been using ramps for heavy lifting since long before the Great Pyramids were built.
Whenever something is too heavy to lift straight up, the simplest solution is often a ramp.
As long as the slope of the ramp is gentle enough, and you have something like wheels to keep friction at bay, you can lift almost anything from here to there.
Whenever you drive or bicycle up a hill, you're using a ramp to lift yourself to that hilltop.
Not for everyone.
Ramps are just as useful for lowering things as they are for lifting them.
Suppose, for example, that you have a piano on ledge and you want to lower it to the ground.
Well, you can push the piano off the ledge and it will arrive at the ground, but don't expect it to be in tune when it gets there.
Ramps, also known as inclined planes, are one of the six simple machines.
The other simple machines are levers, wheels, pulleys, wedges, and screws.
In telling the story of ramps, however, I'll be laying the physics groundwork for all the simple machines.
Namely, that they allow you to change the amount and or the direction of the force you're using to do something.
Doing something is of special significance in physics because it often involves the transfer of an important physical quantity, energy.
The term energy is familiar, but people use that term to describe a broad range of concepts, only some of which are the physical quantity.
One of my goals for this episode, then, is to explain what physicists mean when they talk about energy.
For now, you can think of energy as the capacity to do things.
With that in mind, let's return to look at ramps.
And I want to ask you a question to think about.
That is, don't, I'm not going to ask you to answer it yet.
But you should keep it in mind as we continue to look at how things work.
As background, ramps come in all shapes and sizes.
When does this wagon have the most energy?
That is, the most capacity to do things.
When it's at the bottom of a long ramp, the top of a long ramp, the bottom of a high ramp.
And now, I want to end the ramp right around here so it is not long, it's high.
To guide us through the study of ramps, we'll pursue five how and why questions.
Why doesn't a wagon fall through a sidewalk?
Why does the sidewalk perfectly support the wagon's weight?
How does a wagon move as you let it roll freely down a ramp?
Why is it more exhausting to lift a wagon up than to lower it down?
Why is it easier to pull a wagon uphill on a ramp than to lift it up a ladder?
There's a video sequence for each of these questions, and a summary video at the end.
And now, onto the first question.
Why doesn't a wagon fall through the sidewalk?
The answer to that question is that the sidewalk pushes up on the wagon to prevent the two objects from occupying the same space at the same time.
The sidewalk exerts what's known as a support force on the wagon.
Support forces appear whenever two surfaces try to occupy the same space.
My hands, for example.
As I push them together, trying to make them overlap, the atoms, molecules, and materials that are my hands begin to push apart.
Perpendicular is the ex-, sort of universal right angles.
This stick is perpendicular to the surface of this book, meaning it is at right angles at every respect.
And the stick actually is experiencing a support force when I push it against the book.
Again, I am trying to make the two of them occupy the same space and they do not like that.
And the stick is showing you the direction of the book's support force.
There's another kind of force that acts along surfaces.
That type of force is known as a frictional force.
And we're going to leave frictional forces for the episode on wheels.
For now, we're going to ignore friction and look only at support forces.
And so, if we go back to the wagon, the sidewalk is pushing perpendicular to its surface on the wagon.
And since the surface on the sidewalk is horizontal, its support force on the wagon is straight up.
That upward force cancels the wagons downward weight leaving the wagon here inertial and motionless.
If I push on a ball in which direction.
Wherever I touch the ball, the ball pushes on my finger with a support force that's perpendicular to that local patch of ball surface.
And that perpendicular direction, which I'm illustrating now with this stick instead of my finger.
That perpen, perpendicular direction points from the center of the ball, to the place where the stick is touching.
And I'm just continuing that line with the rest of the stick.
So you can see the direction of the support force that the ball exerts on The stick when the two try to overlap in space.
The wagon and sidewalk clearly push on one another with support forces but which one is pushing hardest on the other.
The answer to that question is surprisingly simple.
They push equally hard on each other.
That's an example of what is known as Newton's Third Law of Motion.
And Newton's Third Law of Motion is an observation about our universe, that says that whenever one object pushes on a second object.
The second object pushes back on the first object with a force that's equal in amount.
But opposite in direction, every time.
The second finger pushes back on the first finger, equally hard in the opposite direction.
No matter what I'm doing.
The sidewalk is pushing up on the wagon to support the wagon and keep it from falling through the sidewalk but at the same time the wagon is pushing down on the sidewalk just as hard in exactly the opposite direction.
Well, Newton's Third Law of Motion, which is often just simplified as 'For every action there is an equal but opposite reaction,' is easy to say but not so simple to comprehend.
To show you all the ramifications of Newton's Third Law of Motion I need some help and some more room.
So let's go outside and show you how Newton's Third Law works.
To show you just how general Newton's Third Law is, I've enlisted the help of Arris and Ryan, and they're going to push against each other using these spring scales.
So Arris's spring scale will show you how hard she is pushing against Ryan.
And Ryan's spring scale will show you how hard he is pushing against Arris.
See whether you can make it so that one spring scale reads differently than the other.
If you do, You violated Newton's third law and we have a Noble Prize to go earn.
Okay, alas we're not going to earn it.
Give it a try.
Now you can do better than that.
They can't do it no matter how hard they try.
You can't do it, right.
Now, let's try vertically.
Up and down, okay?
You know, 70 and 70, 50 and 50.
So once again the universe demands that whatever force Arris exerts on Ryan, Ryan exerts the same amount of force on Arris in the opposite direction.
Newton's third law works, not just when people are standing still.
And this isn't all that intuitive.
It sure seems like if you push on something that's moving toward you.
That well, you don't push the same as it pushes on you.
The secret is, though, you do push just as hard on it as it pushes on you.
You can't beat Newton's third law.
And I'll show you that.
It won't work.
So, no matter that Aris is moving and Ryan is pushing her forward.
Here we go.
And how bout if you, Ryan instead of pushing her that direction, come in front.
I'll stop pushing and let, you know, they still push equally.
But no matter what, the two forces in a Newton's third law pair are always exactly equal in amount and in exactly the opposite direction.
Suppose you reach out and push on a passing bus, with a force of five Newtons away from you.
Regardless of what the bus is doing it will always exert an equal but opposite force on you.
So if you push it away from you with a 5 Newton force, it will exert a 5 Newton force on you in the direction opposite to your force namely towards you.
Evidently, the wagon and sidewalk push equally hard on one another.
The sidewalk exerts an upward support force on the wagon, and the wagon pushes back exactly as hard on the sidewalk with a downward support force.
It's not accelerating at all.
So the net force on it must be zero.
So the support force from the wag, from the sidewalk on the wagon must exactly cancel The wagon's weight.
The sidewalk is perfectly supporting the wagon's weight.
Well, before we go on to look at why the sidewalk chooses exactly that amount of force to exert on the wagon, let's take a look at Newton's Third Law, one last look at it, and recognize that so far I've only talked about three forces.
The wagons downward force on the sidewalk, the sidewalks upward force on the wagon, and the wagons downward weight.
That's three forces, that's a odd number.
And Newton's third law says that for every one force, there's a equal but opposite force around.
The missing force is the gravitational attraction of the wagon on the earth.
Recall that the wagon's weight is the earth's gravitational attraction on the wagon.
Lo and behold, the wagon exerts an equal but opposite force.
And that's the fourth force that is missing and we do have two pairs of Newton's Third Law Forces.
The one pair is the wagon's force on the sidewalk and the sidewalk's force on the wagon.
The other pair is the earth's gravitational force on the wagon and the wagon's gravitational force on the earth.
Well, that's enough, then, about just having the wagon and sidewalk push on one another.
Now, in the next segment we'll look at why the sidewalk chooses to push on the wagon with just enough force to support the wagon's weight.
Why does the sidewalk perfectly support the wagon's weight?
W-, we know that the wagon is perfectly supported because it's not accelerating.
Its weight downward must be perfectly canceled by the upward support force that the sidewalk is exerting on the wagon.
But how does a sidewalk know how to exert that amount of force on the wagon?
The answer tot he question is, the wagon and sidewalk negotiate until the sidewalk perfectly supports the wagon's weight.
That negotiation is real and it actually takes some time.
Underlying it is the fact that there's no such thing as a truly rigid object.
Everything dents slightly when you push on it and when it's pushing back on you.
So when I push on the sidewalk, it dents a little as it pushes on my hands.
The more I push on it the more it dents.
Now the denting of a sidewalk is so minuscule it's hard to see.
But it's a lot easier if I pick a softer object like this spring scale not only moves downward noticable When it's pushing, when I'm pushing on it and it's pushing on me but there's the needle that shows you how much it is dented downward.
If I push hard on it it dents a lot.
And you can see everything in between.
Let's watch the negotiation when I set the wagon on the scale, as opposed to on a on the sidewalk.
Here I'm going to actually drop the wagon onto the scale and watch the negotiation occur.
Whenever the wagon is under supported as it is before I, it even touches the scale it's accelerating downward, and therefore tends to move toward the ground, down, down.
Every time the dent is too small it's accelerating down.
It's negotiating with the scale to find just the right amount of dent and the right amount of upward force so that the wagon can be motionless, inertial, and here at rest.
And let's watch that negotiation again.
And when it all settles down, we have a motionless, perfectly supported wagon.
The same negotiation that occurs between the wagon and the spring scale also occurs between the wagon and the sidewalk.
They negotiate briefly and, when the dust settles, the sidewalk is perfectly supporting the wagon's weight and the wagon is therefore inertial and motionless.
Actually that same negotiation occurs whenever you set an object on a horizontal surface.
For example, an egg, if I set the egg on the table, there's a brief negotiation, and then the table is perfectly supporting the egg's weight.
The egg isn't accelerating.
Voila, but that brings us to a question.
Can the table ever exert and upward force on the egg that is greater an amount than the egg's weight?
Although the table is prefectly supporting the egg's weight right now during the negotiation that occured when I set the egg down there were times when the egg was being pushed up harder then it's own weight.
The egg can take a little bit of extra force exerted on its surface, but not a whole lot.
Watch what happens if I make that negotiation extreme by dropping the egg on the table.
That negotiation is an amazing thing.
It ensures that the sidewalk perfectly supports the wagon.
In fact it works when the wagon is motionless, or when the wagon is moving, or even when the wagon is accelerating back and forth.
Actually, if the sidewalk is rough and bumpy, the negotiation is ongoing, and the wagon is still supported on average.
Well, before putting the wagon on a ramp, I have one more question to look at regarding the support of objects by surfaces.
If I put a ball on the sidewalk or on the table here, the ball's pushing down on the table, the table's pushing up on the ball.
Those two forces are equal in amount but opposite in direction.
Do they ever cancel?
Although the two forces are equal in amount in opposite directions, they act on different objects and therefore never cancel.
Only one of those forces acts on the ball, namely the force that the table exerts on the ball.
For example, now, the ball is accelerating.
because the table is pushing up on the ball so hard during that impact that the ball is accelerating upward.
But the bottom line is, the 2 forces in a Newton's Third Law pair never cancel because they're always on different objects.
I asked that question to call attention to an important misconception people have about Newton's Third Law.
While it's true forces always occur in pairs, that are equal in amount but opposite in direction, those forces never cancel because only, each, each of the forces acts on a different object.
For example if I push on this wagon one of the forces acts on the wagon and causes it to accelerate.
The other force in that Newton's third law pair, namely the, the, force that wagon exerts on my finger acts on me.
And in principle it would cause me to accelerate.
In fact, if I were on slippery ice, I would accelerate.
Off I'd go in that direction, the wagon would go off to the right.
Well, that's it for wagons on sidewalks.
Now it's time to tip the sidewalk up to make it a ramp.
The answer to that question, is that the wagon accelerates downhill.
Now, it's tempting to think that the wagon moves downhill.
If I start the wagon heading up hill watch what happens to it.
It comes to a stop and then it rolls downhill.
What you can say, though, is that it's always accelerating downhill.
So if I let go of it from rest it starts from rest and develops more and more downhill speech, and that's indicative of downhill acceleration.
And if I start it from moving uphill It initially is heading uphill, that's its velocity, but its acceleration is still downhill.
It momentarily comes to a stop but it's still accelerating downhill.
So the long and short of it is, a wagon that's rolling freely on a ramp is accelerating down hill, and we can't say anything specific about it's velocity without more information.
Well, that brings us to, to the issue, where does this down hill acceleration come from?
Why does a wagon on a ramp accelerate in that particular direction?
And the answer to that, is, the net force on the wagon, once I let go of it, is downhill.
Why is there a downhill force on the wagon?
That turns out to come from the, the Interaction of two separate forces.
One is the wagon's weight which is straight down as always toward the center of the earth.
The second force acting on the wagon is the support force from the ramp.
I can show you the direction again with my little stick.
So, This is a horizontal surface and it exerts vertical support forces on the things that sit on it, that touch it, that try to penetrate into its surface.
But when we tip this sidewalk into a ramp, it's not horizontal anymore.
So the support force on the wagon is now up and to the right.
It's, it's in this direction.
And a force that's up and to the right can't cancel a s, a force that's straight down the weight of the wagon.
They can't cancel.
Instead the downward weight and up and to the right support force add together to become a very small net force that is downhill.
That is exactly along the surface, parallel to that.
And it's that net force in the downhill direction that causes the wagon to accelerate downhill when I let go of it.
Now, I call the net force on the wagon that points downhill, the ramp force.
It's the sum of two separate forces that don't quite cancel, the wagon's downward weight and the not quite upward force exer-, support force exerted by the ramp on the wagon.
Those two forces, when you sum them together, produce this downhill net force, this ramp force, that causes the wagon to accelerate.
The amount of downhill ramp force depends on the steepness of the ramp.
To show you that I will start with no ramp at all.
Go back to our horizontal surface and now the downhill ramp force is 0.
That's because the cancellation is perfect between the wagon's downward weight.
That number turns out to be the height of the ramp, which in this case is about 10 centimeters, or 4 inches, divided by the length of the ramp, which is 4 feet, or a bit over a meter.
So it's about a 10 to 1 ratio.
And that means that the downhill ramp force on this wagon is about a tenth of the wagon's weight, and aimed along the ramp.
That's because the height's larger, the length is the same.
I can keep going.
I don't have the reflexes to keep going without some help.
In this case the ramp force, which is straight down, is the full weight of the wagon.
It evolves continuously to larger and larger ramp forces all the way to the full weight of the wagon.
The steeper the slope, the bigger the downhill ramp force.
This slope on the grass is a whole lot steeper than a handicap access ramp, so the downhill force will be big and so will my acceleration.
Don't try this at home, professional driver here.
And off we go.
But what if you intervene and you exert an uphill force that is equal an amount to the downhill ramp force.
If you an exert an uphill force on the wagon that exactly cancels the downhill ramp force.
And it moves as an intertial object.
But if it's moving, it keeps moving at constant velocity.
So let me get it moving.
But that's the idea.
Those are all possible situations where you've perfectly canceled the downhill ramp force by exerting your own uphill force.
We've seen that when you pull uphill just enough to cancel the wagon's downhill ramp force that the wagon becomes inertial, and it can be motionless or coasting.
But what if you pull a little too hard or a little too soft?
In that case, the wagon does accelerate.
For example if I pull a little too weakly in the uphill direction.
And if I pull a little too hard in the uphill direction, the wagon accelerates gently uphill.
That allows us to control the wagons motion.
For example, how do I get the wagon from the bottom of the hill to the top of the hill?
The whole process has three parts.
And my goal is to get it to the top of the hill and motionless.
First, I've gotta make the wagon accelerate uphill by pulling it uphill a little extra hard.
So I'm going to do that just a little and get it moving.
A little extra strong pull, a little upward hill acceleration.
I'm simply balancing the downhill force.
Now I've gotta bring the wagon to a stop.
How I do that?
Pull a little less hard, and under support the wagon, so that it accelerates downhill.
Opposite it's uphill velocity and it slows to a stop.
So just to make sure you can follow that let me do it again.
A miracle occurs and we are at the bottom of the hill again.
And now, Ii pull a little extra hard to get it started, now I just pull enough to keep it coasting, and now I pull a little extra weak to let it slow to a stop.
This actually works in reverse to go downhill.
Suppose I got the wagon at the top of the hill?
Which I do and I want to get it to the bottom of the hill.
Well I under support the wagon at first, so that it accelerates in the downhill direction, it gets moving.
You use processes like these to move objects up and down ramps all the time, without even thinking about it.
Most of the time, you simply support the object against its downhill ramp force to let it coast.
But you use subtle adjustments in your uphill force to cause the object.
They sure look similar in terms of physics, up to this point, but they feel very different.
You know from experience that dragging something uphill Is a lot more fatiguing, in many ways, than lowering it downhill.
In the next segment, we'll talk about what distinguishes the trip up from the trip down.
>> Why is it more exhausting to lift a wagon up than to lower a wagon down?
The answer to that question lies in the fact that you transfer energy to the wagon as you lift it and you receive energy from the wagon as you lower it.
Energy is an intangible physical quantity that can move from object to object.
Energy is what's known as a conserved physical quantity.
Meaning, that you can't create it or destroy it.
You can only move it from object to object.
Conserved quantities are very rare in nature and energy is one of them.
It's analogous to money.
In a society with law abiding citizens, money is pretty much a conserved quantity as well.
You can't create it or destroy it.
Usually, without going to jail.
And, it's the conservation of that quantity that makes it so interesting.
If people could print money at will, why, money wouldn't be very interesting anymore.
Similarly, if you could create or destroy energy at will, hm, no one would care about it any more.
Well, society decided to make money and conserve quantity.
Society had no choice in making energy conserve quantity.
That's the way our universe works.
In any civil, civilization that's sophisticated enough to have discovered the laws of physics will have found the concept of energy and will have exactly the same quantity in their minds.
Just as you can learn a lot about how a community or an economy works by watching how money moves through it, you can learn a lot about how something works by watching how energy moves through it.
But first, I need to talk a little bit about what energy is and how it moves between objects.
Since we are going to encounter several other conserved physical quantity in later episode, I want to distinguish energy from those other conservative quantities.
The more energy you have, the more you can do.
The doing that I have in mind is what physicists call work.
Work is a common word that has many meanings, only one of which is what physicists refer to as work.
That, physicist work is the mechanical means of transferring energy.
Doing work is analogous to spending money.
When you spend money, you're transferring money from you to someone else.
The total amount of money present in the world doesn't change, it just moves from one place to another.
When you do work on something, you transfer energy from yourself to something else.
The total amount in the world doesn't change.
It just moves from one thing to another.
Energy, which I've described as the conserved quantity of doing is defined as the capacity to do work.
And work is defined as the mechanical means for transferring energy.
But, as we begin to play with work and energy, it'll all begin to make clearer and clearer sense.
So bear with me.
Even though I've defined energy as a capacity to work, and work, as the means of transferring energy, it's all going to work out in the end.
But first, I've gotta take a look at what work is.
So let me show you, work.
To do work on the wagon, there are two requirements.
I have to push on the wagon and the wagon has to move a distance in the direction of my push.
For example, if I put my hand under the wagon, push up on it, and cause it to move upward, I'm doing work on the wagon.
I'm exerting an upward force on the wagon, you know this from experience, and you saw that the wagon moved a distance in the direction of my force.
Therefore, I did work on the wagon and that means I transferred my energy to the wagon.
Now, this is analogous to what you do when you spend money, right?
Don't spend it in one place.
So, the total amount of money in the world didn't change, but it moved from me, in part, from me to the wagon.
For example, if I don't push on the wagon, I do no work on it.
On the other hand, if I push on the wagon, but it doesn't move a distance in the direction of my push, I do no work again.
So, I am pushing, or let me, hold, don't watch for a second, let me get this up here.
Now, I'm still pushing up on the wagon, but it's not moving, so I'm doing no work on it.
And, actually, I don't have to make sure that it's not moving all together.
I just have to make sure that it's not moving in the direction of my force.
So since my force is upward, if it moves horizontally, that's not in the direction of my force.
But now, now, as it coasts to your right, I'm doing no work on it.
Now let me get it going to the left.
Again, it's coasting to the right, my force is straight up.
I'm doing no work on it.
Now, you wonder, why is it tiring to sit here holding up a wagon?
That's because, human beings are not statues and we burn calories just trying to hold a pose.
So, I'm not transferring any energy to the wagon, but I'm getting tired nonetheless, because I'm turning my own chemical energy into thermal energy.
I'm getting hot, holding this here all day.
That doesn't affect the wagon.
The wagon is just minding its own business with the same amount of energy now, as now, as now.
Because I'm doing no work on it.
Now that you've seen how work works in the context of, of wagons, let's apply it to another situation.
So here is a question for you.
If I hold one end of the rubber band motionless with my left hand, and I take my right hand, and stretch the rubber band outward like this, which of my hands is transferring energy to the rubber band?
Your right hand, the one that holds a piece of rubber band that moves does work on the rubber band.
The other hand, the one that stays still, doesn't move, and therefore, it does no work.
So, as I move the rubber band to, to your left with my right hand, sorry for the complexity here.
It's pushing the rubber band to your left as the rubber band moves to your left.
Goes in the same direction.
My, my hand here is doing work on the rubber band.
The other hand doesn't move, does no work.
We've seen that when you push on an object and it moves in the direction of your push that you do work on it.
But what if it moves in the direction opposite your force?
Like this.
I'm pushing up on the wagon but it's moving downward.
What then?
In that case, you do negative work on the object.
That is, you transfer less than zero energy to it.
And you reduce its overall amount of energy.
So, doing work on the wagon and increasing its energy is analogous to giving money to the wagon and increasing its money.
Okay?
Doing negative work on the wagon is equivalent or analogous to giving the wagon debts.
For example, my car loan, it's, it's weighing me down.
My money just increased.
The wagon suddenly saddled with, with debt it didn't expect, is impoverished.
So, I have passed along negative money to the wagon.
It's poor and I'm richer.
Whenever you do negative work on something, you lower its energy, and amazingly enough, you increase your own.
Well, how did I increase my energy by doing negative work on the wagon?
I'll show you.
The wagon right now has some energy, and as I lower it, and therefore do negative work on it, watch what it does to me.
It's pushing down on my hand and my hand is moving downward.
And that's how the energy moves.
Whenever one object does positive work on the other, the second object does negative work on the, on the first.
There's a perfect transfer of energy from one to the other.
And overall, the total amount of energy doesn't change.
That brings me to one last point.
I've talked about doing work and doing negative work.
Shouldn't the word positive show up in here?
Shouldn't this be positive work and negative work?
But physicists have adopted the convention that if you don't specify negative or positive, we assume positive.
And, that just simplifies the language.
So, doing work always refers to doing a positive amount.
If you're going to do a negative amount of work, say it, use the word negative.
And you might think, well, that's a silly convention, no one ever adopts that convention outside of physicists.
Well, think about charity.
When you give money to charity, we're assuming you're giving a positive amount of money.
Don't you go giving your loans and your mortgages to a charitable organization.
I've been talking a lot about work and letting energy come along for the ride.
And to do that, let's revisit the rubber band problem.
When I stretch a rubber band, the rubber band changes.
When it's unstretched, okay, it can't do anything.
And energy after all, is the conserved quantity of doing.
This rubber band, now that I've stretched it, is capable of doing work and making things happen.
Energy takes two principle forms, kinetic energy and potential energy.
Kinetic energy is the energy associated with the motion of objects.
Now, energy itself is the conserved quantity of doing, not of moving.
So energy isn't inherently about motion, but there is energy in moving objects.
For example, this ball.
When the ball is at rest, it has no energy associated motion, because it's not moving.
But if do work on it, I will push it toward your right, and it will move toward your right.
And during that brief period while it was passing quickly to the right, it was chock full of kinetic energy.
That is, it had energy that was in the form of this energy of motion, kinetic energy.
So the whole act of throwing the ball from one hand to the other, Involves investment of energy in the ball, so I'm transferring energy to the ball by, by way of work.
So, long story, simple action, but there's energy going in and coming out.
So, moving objects have energy associated with their motion, that is called kinetic energy.
But even objects that are at rest can have another form of energy.
Potential energy is energy stored in the forces between, or among, within objects.
For example, there is a gravitational force or traction between this ball and the earth.
You know that because we've talked about dropping.
You drop the ball and it falls.
So, the ball is being attracted to the earth, the earth is being attracted to the ball.
And if I pull them apart, something that takes work to do.
I invest energy in the ball in the form of gravitational potential energy.
That is, an energy stored in the forces of gravity.
In this case, between the ball and the earth.
So, when the ball is down low, it has relatively little of this gravitational potential energy.
And as I lift it upward, and do work on it in the process, I'm pushing it upwards, it moves upward, I'm increasing its, its total energy.
And that energy is going primarily into the form of gravitational potential energy, the energy stored in the forces of gravity.
I tend to identify the forces involved in a potential energy.
But if we can, it, it makes sense to identify the forces that are doing the storing.
So that's gravitational potential energy.
Let me show you elastic potential energy, energy stored in the forces of an el, an elastic object.
I hope you had one of these cans of mixed nuts when you were young and you would go up to your, to your favorite aunt or uncle and say.
You know?
And then you would open the can and out would jump a snake, right?
And five minutes later, Uncle Richard, want some nuts again?
And you would be surprised yet again.
But that energy that caused this snake to leap out of the container and attack my, my magnets down there on the table.
That's energy stored in the elastic forces within this snake and I'm doing work pushing the snake back in as it moves inward.
I'm packing it full of elastic potential energy and it's ready to attack another relative.
Okay.
Another familiar app situation with elastic potential energy is, is an elastic balloon.
If I inflate this balloon with air, an action which requires work, I push the skin outward with, by, by way of my, my air, and it moved outwards so I did work on it.
It now has energy stored in the elastic forces in the balloon surface.
And if I let go, off it goes.
It uses the energy I put in to do something, fly around the room.
The forces between magnets, we can store energy.
It has magnetic potential energy.
They now have it in the forces, the magnetic forces between them.
And if I let them come near each other, off they go.
They release that energy, leap at each other, the energy transforms spontaneously from magnetic potential energy to kinetic energy.
Because suddenly, we had we had some fast moving magnets and then into sound and other forms of energy.
How about the forces between electric charges?
So that's the force between magnets, magnetic poles, something for the future.
How about the forces between electric charges?
Well, this is a device that stores separated positive charge and negative charge.
And I'm going to, right now the charges are not, are, are evenly distributed here.
But I'm going to separate positive and negative charges from one another and if you remember the, the old opposites attract well opposite charges attract.
The batteries are now doing work, pulling apart positive and negative charges, accumulating negative charges on this side, accumulating positive charges on that side.
It's pretty well separated at this point.
And I'm going to stop that process, and I'm going to let them get back together.
They're, the energy is stored as electrostatic potential energy.
So, so frequently this would be called magnet, magnetostatic potential energy.
That's full of electrostatic potential energy.
I'm going to let that get together.
Last form of energy to, to talk about here, because I'm going to leave nuclear potential energy for some other situation.
I can show it to you, but I, then I'd have to do something.
Chemical potential energy.
Okay.
So you get the idea.
Energy can take two principal forms.
And it can take potential energy, that is, energy stored in the forces between, within, among objects.
There are a variety of forces to work with, we've worked with several of them, and, those forces can store energy.
Often, when the energy is being stored in potential form, there's no motion at all.
When there's kinetic energy, of course, there is motion.
And the last observation to say about energy is, energy as a whole, is a conserved quantity.
You cannot create total energy, you cannot destroy total energy.
But the individual types of energy, they're not conserved.
So, kinetic energy can change as long as potential energy changes correspondingly in the opposite direction.
Similarly, you can turn chemical potential energy into kinetic energy.
You can turn kinetic energy into gravitational potential energy, like that and so on.
It's total energy that is truly the conserve quantity in nature.
Like any object, a wagon has kinetic energy when it's moving and it has gravitational potential energy when it's elevated.
In so knowing how much gravitational potential energy the wagon has at various heights is going to be useful to us in understanding what ramps do.
So, let's figure out how much gravitational potential energy the wagon has at various heights.
To do that, I have to start by making sure it's clear exactly how much work you're doing when you lift that wagon.
That is, to do work on this wagon, I have to exert force on it.
It has to move a distance at the direction of my force.
The exact amount of work I do is the product of the force I exert on the wagon times the distance it moves in the direction of that force.
Now, in this case, it's moving exactly in the direction of my force.
My force is straight up and it's moving straight up.
But if I push the wagon upward, and it moves up at an angle, the overall distance the wagon moves isn't the issue.
What matters is the component of its motion, that is in the direction of my force.
Since my force is straight up, the only part of the wagon's motion that counts is its motion in the upward direction.
Its motion horizontally doesn't matter, it doesn't contribute to the work.
So, the amount of work I do in lifting this, this wagon is the force I exert on it, times the distance it travels upward.
That's interesting, because, in order to lift this wagon upward at constant velocity, I have to push up with a force that exactly cancels the wagon's weight.
So as it goes up, steadily, I am pushing up with a force equal in amount to the wagon's weight, although in the upward direction and it's moving upward directly in, in line with my force.
So the work I'm doing is the product of the wagon's weight times the upward distance it moves.
That's very simple.
I'm doing that work and that work is becoming entirely gravitational potential energy in the wagon.
So starting with a, a clear understanding of work, that it is the force you exert on the wagon, times the distance the wagon moves in the direction of your force.
We can then figure out how much gravitational potential energy the wagon has at any given height.
Because, this, we might call this zero, but actually, if I drop the wagon on the floor, I can release a little bit of gravitational potential energy that's even there at zero.
So we choose a zero and if you really want to, you can go into the negative values by coming off the table.
But this is a perfectly good zero right here.
We don't have to worry about going to the floor or going to the basement and so on.
If I increase the height of the wagon by 1 meter, then, and I, and I, suppose I've had to push up on this wagon with the force of, let's say 10 newtons.
Now, the newton meter has a name.
It's got a name to make life simple, it's called the joule.
So in lifting this, this wagon, 1 meter upward using a 10 newton force, I did 10 joules of work on the wagon and they are now present in the wagon as gravitational potential energy.
The gravitational potential energy of the wagon increased by 10 joules going from here to here.
It's time for the question I asked you to think about in the introduction to this episode, when does the wagon have the most energy?
When it's at the bottom of a long ramp?
The top of a long ramp?
By being at the top of a tall ramp, the wagon has as much gravitational potential energy as it can have among the choices I offered.
So by getting here to the top of the tall ramp, it's accumulated as much energy as it can accumulate.
The work you do in lifting a wagon depends only on how much you increase its altitude and not on the specifics of how you did that lifting process.
Whether you go up the ramp or you go straight up, doesn't matter, it's just increase of altitude that matters.
And the work you do is the weight of the wagon times the increase in altitude.
That means that, as you go up the ramp, you must be doing work on the wagon, because you're increasing the wagon's altitude, and therefore, its gravitational potential energy.
We're now in a position to answer the question I asked at the beginning of this video segment.
As you take the wagon up the ramp, you're doing work on it, increasing its gravitational potential energy.
And doing work on a heavy load involves transferring a lot of your energy to the wagon.
You're consuming that.
It fatigues our muscles.
It consumes our energy.
As you lower the wagon down the ramp, it actually requires negative work.
You're taking energy out of the wagon and receiving it yourself, it's coming into you.
Now, human beings, like most animals, cannot store energy well, so the work is really being done on us.
We are receiving energy as we lower the wagon down the, down the ramp, and what we do with that energy is to waste it.
Thermal energy is, we'll deal with in the near future in other episodes, s, is ordinary energy chopped up into little pieces.
And thermal energy is hard to do anything useful with.
So taking the wagon up the ramp involves you transferring energy to the wagon and that's tiring.
Taking the wagon down the ramp involves the wagon transferring energy to you that has some tiring aspects to it, but at least, it's not consuming the same amount of, of, of, your, your stored chemical food energy.
And it's, it's less exhausting, it's a little nerve-racking, cause you can get injured as that energy rushes into you., but it is not as fatiguing.
Why is it easier to pull a wagon up a ramp than it is to lift it up a ladder?
The answer to that question is that the ramp allows you to lift the wagon using a smaller force exerted over a longer distance.
Regardless of how you lift the wagon you have to do work on it, to raise its altitude from this to this.
That increase in altitude comes with an increase in gravitational potential energy in the wagon.
So you have to transfer a specific amount of energy to the wagon.
To pay for that increase in altitude and therefore increase in gravitational potential energy.
Well if you go up the ladder, you do that, that work, you transfer the energy by exerting a large upward force on the wagon as it moves a short distance, the minimum possible distance.
In going up the ramp, however, you increase its altitude, the wagon's altitude gradually.
It goes from the low level, to the high level, while traveling quite a long distance.
Now, the distance it travels is in the direction of your force.
You are pulling the wagon uphill in order to cancel the downhill ramp force.
But that's a gentle uphill force and the wagon moves uphill.
But it takes a much longer travel along that, that ramp to do the work involved in lifting the wagon from low to high.
So while you do the same amount of work whether you go up the ladder or up the ramp, the ramp version of this trip involves a small force exerted over a long distance, whereas the ladder version went, involved a large force exerted over a short distance.
Well, it's all very well to do this in my laboratory with a dinky little wagon.
On the right I can go up to that ledge and lift the wagon straight up.
In a very short distance I can manage to, to elevate the wagon from ground level to entry level.
On the left I can go up the ramp.
It's a much longer trip.
I'll be pulling the wagon up, up the ramp, but I can still do the job of lifting the wagon from ground level to entry level.
Let's start with the first option, the ledge.
I'll roll the wagon out to the ledge.
And now to lift the wagon up I have to support its entire weight so that it can coast upward constant velocity and go from ground level to building entry level.
I did a certain amount of work on the wagon.
That, that amount was the weight of the wagon times the distance upward the wagon moved.
Okay.
Let's try the second option.
Back to the starting point and this time I'm going to go up the ramp.
As I go up the ramp, I have to pull uphill gently just enough to balance the downhill ramp force so the wagon can coast upward.
I am doing work on the wagon though this entire trip because I am pulling it uphill as it moves uphill.
So I have managed to lift the wagon from ground level to building entry level, this time using a small force exerted on the wagon.
I did a certain amount of work on the wagon in that process.
And lo and behold, it's the same amount of work that I did in lifting the wagon from ground to ledge.
All that mattered was the increase in elevation or increase in altitude of the wagon.
That's the increase in the wagon's gravitational potential energy.
The only form of energy that, that increased.
It went from motionless to motionless so It has the same kinetic energy it had at the beginning, zero.
And the only other form of energy that it has is gravitational potential, and that went from the value at ground level to the higher value at building entry level.
And whether I went up the ledge or whether I went up the ramp, makes no difference.
It doesn't matter at all.
But there's a difference to me.
In going up the ledge I had to exert a large force on the wagon as the wagon moved a short distance in the direction of that force.
In going up the ramp I had to exert a gentle force on the wagon as the wagon moved a very long distance in the direction of that force.
The product of those two, force times distance, was the same in each case.
But if this wagon were a little more heavily occupied that it is going up that ledge would have been very difficult if this were full of, of bricks.
There is no way I can lift it up the ledge.
So I could still pull it up the ramp.
The mechanical advantage of a simple machine known as a ramp, or inclined plane.
The amount of force and the direction of force that I need to use to do some particular activity.
Upward force to do the activity in this case.
I was able to use a small uphill force to do that same activity namely lifting the wagon.
Now that the wagon is full of energy I can release that energy by riding it back downhill.
The gravitational potential energy is becoming kinetic energy.
It's time for a question.
Suppose you have two ramps with the same height.
That is, both ramps lift the wagon that rides them vertically upward the same amount, in this case, about that much height.
But one ramp is long, and the other ramp is short.
In fact, the long ramp is twice as long.
The question then is this: If it takes 100 newtons of uphill force to pull the wagon up the longer ramp, how much uphill force does it take to pull the wagon up The steeper, shorter ramp.
If it took 100 newtons of uphill force, to pull the wagon up the long ramp at constant of velocity, when you have the length of the ramp While keeping its height constant, you must do the same amount of work in half for distance.
So now you have to pull uphill with twice the uphill force.
The product of the two, force times distance traveled by the wagon Remains the same.
But now instead of a 100 Newton force exerted over a long ramp, it's a 200 Newton force exerted over the short, half-length ramp.
It's clear that ramps make it easier to lift and lower heavy objects.
For example, when you're moving something, or delivering something, or taking something back out; if you're using a ramp that's gradual enough, you can lift a very heavy load using a relatively gentle force.
One of the most important uses for ramps is for handicap access.
And access ramp allows a disabled person to change elevations, to move up or down with relative ease.
But in order to be usable as an access ramp, the ramp has to be very gradually sloped.
In fact, the United States regulates access ramps and will only approve them If their slope is 1 unit of rise to 12 units of run.
Rise is defined as the vertical movement that occurs in going up a ramp.
And run is defined as the horizontal movement that occurs in going up the ramp.
Now, I've been talking about rise.
That is, after all, the distance moved by an object rolling along the ramp.
Fortunately for these very shallow angle ramps, very gradual ramps, there's almost no difference between the length of the ramps surface and the run, the horizontal extent of the ramp.
This is a trigonometry problem that basically for very small angles the difference between this hypotenuse and this component of horizontal.
It's a simple problem in trigonometry.
You can do it as homework if you like.
So, the bottom line is that ramps, access ramps, can be no steeper than, ramps in which you move up 1 unit for every 12 units you go along the surface of the ramp.
And, if you recall, the uphill force that you, you have to exert on an object coming up this ramp at constant velocity is 1, 1 12th its weight.
If it's a 1 to 12 ramp, 1 unit of rise to 12 units of length, then the force you have to exert in the uphill direction Is 1 12th of the weight of the object.
That means that a disabled person coming up one of these access ramps at the maximum slope, needs an uphill force of approximately 1 12th their weight.
And that was deemed to be All you can expect of the disabled person themselves or of their helpers in going up the ramp, 1 12th their weight is enough.
In addition to limiting the slope of an access ramp, US regulations limit the extent of that ramp as well.
And the extent that they limit Is its vertical extent.
To be approved, an axis ramp may have no uninterrupted inclines that take you through an altitude change of more than about this much.
There's a sound physics basis for that requirement.
And in going from this height to this height, your gravitational potential energy increases by your weight times that distance.
So, in going up an access ramp the, the person responsible for doing the work necessary to increase your gravitational potential energy from this value to this value has to do the work necessary to increase that gravitational potential energy.
And evidently, this much increase in altitude is enough.
The person who's doing the work, whether it's the helper of the disabled person or the disabled person themselves needs a break.
So don't make that person go through an altitude change of more than this without giving them a flat area to regather their energy.
On the way down similar problems are, are, are avoided, by having periodic breaks.
In going from this altitude, to this altitude, the person descending releases gravitational potential energy and that energy takes some other form.
If the, if this occurs in an uncontrolled roll in a wheel chair, it becomes kinetic energy.
So, evidently, this much decrease in altitude and the gravitational potential energy that's released in that process is considered to be enough.
So in, in descending what would otherwise be a very long, uninterrupted ramp, there are periodic flat spots put in to allow the people descending that ramp to pause, get ready for, for the next descent, and then continue on their way.
>> In this episode, we looked at the Physics issues that make ramps so useful.
You exert those forces uphill as the, as the heavy loads move long distances along the ramp.
The story of ramps is also the story of energy and work.
It's the story of energy because energy is a conserved quantity that depends only on the situation.
So that, in this case, the wagon has a certain amount of energy.
And now, it has more energy, the energy increase in going from here to here, is all in the form of gravitational potential energy, the energy stored in the force of gravity.
The story of ramps is also a story of work because in going from this position to this position, you have to do a certain amount of work on the wagon to increase its gravitational potential energy from its low value to its high value.
You're responsible for that increase in energy and you can do that, the work necessary to increase the wagon's energy, either by lifting it straight up with a large force exerted as it moves, as the wagon moves a small distance, or with a gentle force as the wagon moves a long distance.
So, the work you do via either of these two approaches is and has to be the same because the wagon's increasing energy is the same.
In addition to looking at energy and work in this episode, we also looked at a new force, support forces.
Support forces appear whenever two surfaces try to occupy the same space at the same time.
And those support forces are exerted perpendicular to the surfaces involved.
For example, when the surface involved is horizontal as the end of the sidewalk, the support forces that, that a horizontal surface exerts are vertical, as indicated by this stick.
But if the surface that you're looking for looking to, to obtain support forces from, is tilted as it is with our ramp, the support forces are no longer vertical.
That pp and, in this case, to the right support force from a ramp, from this ramp cannot cancel, in this case, the wagon's downward weight.
When the two forces act on the wagon, the residual that is left is the downhill ramp force.
And that ramp force, left unchecked, will cause the wagon to accelerate downhill.
If my, what you see, this hand pushes on this hand, this hand pushes back on this hand equally hard in the opposite direction every time.
It does not depend on whether the hands are accelerating or moving in any way they like.
Do your homework, study hard, and I'll see you next time, as we continue to look at how things work.
Seesaws are a simply toy that consists of a long board mounted on a central pivot.
Two riders get on opposite ends of that board, and adjust their positions until the seesaw balances.
At that point then, they can begin to make the seesaw rock back and forth.
When I was a kid, seesaws were everywhere.
And either at recess or during a birthday party we'd clamber onto the seesaws, one at each end, maybe one big kid, one little kid.
And we'd rock back and forth furiously until our legs wore out, or one of us got hurt.
Or we simply wanted to do something else.
It seems that either they're risky, or perhaps modern children don't enjoy that sort of activity as much.
Whatever the reason, they're missing an opportunity to experiment with rotational motion, balance, levers, and mechanical advantage.
If you have a seesaw nearby, I urge you to experiment with it.
Although be safe, because there are ways in which you can get yourself injured playing with a seesaw.
If you don't have a see-saw, well, you can make one yourself.
All you need is some object to serve as a central pivot and a board to balance on that pivot.
You adjust the spacings just so and.
You can have it rock back and forth, just like the real thing.
Actually, that simplicity.
As I suggested earlier, the story of seesaws is also the story of rotational motion, balance, levers, and mechanical advantage.
We'll study those concepts here in the context of seesaws and then use them repeatedly as we continue to look at how things work.
Before continuing, however, I want to ask you a question to think about.
Not to answer, but something you should have in mind as we work our way through the story of seesaws.
It's a difficult question, one that doesn't have an obvious answer so it's a good prelude to the rest of the story here on seesaws.
To help guide us through the science of see saws, we'll pursue six, how and why questions.
Why does a seesaw need a pivot?
Why do the riders' weights and positions affect the seesaw's motion?
Why do the riders' distances from the pivot affect the seesaw's responsiveness?
How does a balanced seesaw move?
The full answer to that question will require some careful explaining, but a short answer is that a balanced seesaw rotates steadily about a fixed axis.
Now it's tempting to think that I've just asked a trick question, that a balanced seesaw doesn't move at all.
In fact, that it's horizontal and motionless.
But the real answer to that question is more subtle.
Yes, a balanced seesaw can be horizontal, and it can be motionless.
If I set it spinning, it rotates steadily about a fixed axis.
Up until now, I've talked about a type of motion that takes you from place to place.
In this episode on seesaws, we don't go anywhere.
So, the world of motion can divide into two main types.
The motion of translation, of going somewhere and the motion of rotation, spinning in place.
In the episode on skating, we saw that a skater exhibits translational inertia.
And associated with that translational inertia was Newton's first law of translational motion.
Namely, that an object that's free of external forces, moves at constant velocity.
When they're rotating, they continue to rotate.
Associated with rotational inertia is another Newton's first law, but now it's the Newton's first law of rotational motion.
In a draft form Newton's first law of rotational motion states that a rigid object that is wobbling and that is not experiencing any outside influences, rotatates about a fixed axis turning equal amounts in equal times.
That law has a couple of extra words in it.
So Newton's First Law of Rotational Motion has relatively limited applicability.
Rotational motion simply is more complicated than translational motion and therefore the Newton's 1st Law in the world of rotation is fairly limited.
There are lots of things that don't that don't follow Newton's 1st Law of rotational motion.
To perfect the draft of Newton's First Law of Rotational Motion, we need to identify the external influences, and we need better language to describe rotation about a fixed axes turning equal amounts and equal times.
Angular, rotational, it doesn't matter, but there, it's technically called angular position.
And there is a physical quantity describing how angular position changes with time, and it's called angular velocity.
So, those are the 2 quantities I want to introduce.
I'm going to start with a zero of angular position, which is the starting point, the, the zero.
This will be my 0 of angular positioning, the orientation that we all agree is the starting point, facing you.
If I change my angular position, that means that I'm facing some other direction, like this or this or like this and Like that, and so on.
How do you do it?
Actually, you need an amount and a direction.
First, the amount is an angle.
And the angle that I have to rotate through to go from the zero to this is 90 degrees.
From there to there, that's 90 d-, you know what, 90 degrees right?.
So this angle position is 90 degrees.
But that's not enough.
This is 90 degrees.
And so is this, alright?
Of an angular position is the axis about which the rotation occurs.
For example, to, to rotate to this 90 degree angular position, I need to rotate about a vertical axis as though I were a toy top being spun.
So I'm being spun, there I go.
Is 90 degrees about a vertical axis.
This is 90 degrees about a vertical axis.
They're both 90 degrees about a vertical axis.
Well, physicists and mathematicians distinguish them Using a convention known as the right-hand Rule.
And the right-hand rule says that if you take your fingers of your right hand and curl them in the direction in which the rotation occurs.
The thumb of my right hand, points in the official direction of that rotation, downward.
So in going from 0 to this, I rotated 90 degrees.
On the other hand, if I go from this to this, my fingers have to be pointing the other way.
So the ambiguity is solved by the right hand rule.
How about this?
That is 90 degrees toward you.
And this is 90 degrees towards me.
The angle part of anchor position can be measured in various units.
Up until now, I've been using the unit known as the degree.
It's a familiar unit of angle; this is zero degrees, 90 degrees, 180 degrees, 270, 360.
Full rotation: This is zero, quarter rotation, half, three quarters, full rotation.
(End of transcription.) But the unit that mathematicians and physicists normally use to describe angles, is neither of those two.
It's the radian.
And there are two pi radians in a full rotation where pi is the mathematical constant.
And that is the natural unit of angles.
So you can describe this angular position as.
That's angular position, but that by itself doesn't help us Redraft Newton's first law of rotational motion.
We need to look a little deeper.
And we need the next physical quantity which is angular velocity.
Angular velocity is The rate at which angular position is changing with time.
So right now my angular position is not changing with time, so my angular velocity is zero.
But if I begin to spin, then my angular velocity is no longer zero.
And I am, the, the, the same right hand rule applies.
I'm turning such that my fingers curl like this and my thumb points out.
This is an angular velocity.
Of 90 degrees per second down.
90 , yeah 90 degrees per second toward you but that's, I'm going to run out of ability to do this.
That angle velocity describes how an object is rotated, that is how fast it's going through angles, and also the axis about which it's, it's spinning and finally, the right, using the right hand rule, the specific direction of its spin around that axis.
That now, that physical quantity, angle velocity will be useful in redrafting Newton's first law, rotation motion.
If I'm turning 90 degrees per second down and staying that way My angular velocity is constant.
Which is identifying the external influences that show up in Newton's first law of rotational motion.
Technically, they're known as torques.
So I'll grab the see-saw from the front, and I will twist.
And it's now, for the, at present it is a rigid object that's not wobbly, it's obeying Newton's first law of rotational motion.
But if I come in with an external influence of the right type.
While I'm exerting that torque, it is not following Newton's first law of rotational motion.
So, we can now state Newton's first law of rotational motion in all it's glory.
Turning once every, approximately 24 hours.
It's experiencing essentially no torques, and therefore, it rotates according to Newton's 1st Law of Rotational Motion, namely >> It's a rigid object that is not wobbling, it is not experiencing any external torques, so it rotates with constant angular velocity.
That angular velocity is approximately one rotation per 24 hours.
About the north poles so that the rotational axis points from the center of the earth up to the north pole and that's the way the earth rotates.
If it's rotating, it continues to rotate.
Because it's a rigid object that's not wobbling, it exhibits a particularly simple type of rotational motion.
So right now, the con, the angular velocity of this balanced seesaw Is 0.
It's, it's obeying Newton's 1st Law of rotational motion.
The point is, it's rotating right now, not because something is twisting it, but because nothing is twisting it.
So, in, in a normal see-saw that perpetual rotation isn't possible, because during the rotation.
It twists the seesaw and therefore takes it out of the, out of Newton's First Law of Rotational Motion, violates Newton's First Law of Rotational Mo-, and new things happen.
Why does a seesaw need a pivot?
The answer to that question is that the pivot prevents the seesaw from undergoing translational motion, while leaving it free to undergo rotational motion.
Without a pivot to support its weight and that of its riders, the seesaw would fall.
And while two children might find it exciting to jump out of an airplane seated at opposite ends of unsupported seesaw, that idea is unlikely to be popular with their parents.
The physics will be fabulous but I'm not going to film it.
I'm going to leave that for children who enjoy extreme recess.
Instead, I'm going to show you how an unsupported and riderless seesaw moves.
Basically, I'm going to throw the seesaw through the air and we'll watch its motion.
But even so, even with a small seesaw board, or a pretend seesaw board, I need more room, so, let's go outside and have some fun.
I'm going to throw a riderless, unsupported seesaw.
Well that sure was quick.
But this is video so I can show you that throw again.
And this time I can slow it down to one tenth it's original speed.
More over, I can make the images of the seesaw linger on the screen so that you can see all the previous images as the seasaw goes through it's travels.
Now, because the camera takes 30 frames per second, those images will be separated from one another by a thirtieth of a second.
The same throw, slowed down to one tenth its original speed, with all the previous images of the seesaws lingering on the screen.
Seeing all those image of the seesaw is pretty, but how do we make sense of the seesaw's motion?
Well, it's center of mass is traveling in the arc of a falling object as though it were a tiny ball located at the center of mass, that's traveling in the arc that we're familiar with for falling balls.
At the same time, The seesaw, which is an extended object, is rotating about its center of mass, its natural pivot.
And, it's doing these two things at once: the translation motion of a falling object located right at its center of mass, and the rotational object.
So I'm going to show you that same video again, same throw.
Once again, at one tenth normal speed with all the previous images of the seesaw board.
In view, but this time, I'm going to show you the arc of a falling object, and I picked the arc just right so that the seesaw's center of mass will travel along that arc, as the seesaw rotates about it's own center of mass.
So, the motion we saw had the center of the board travelling in the arc of a falling object as the rest of the board rotated about it's geometrical center.
For example, a mallet, nearly all of the mass of this mallet is in its head.
So, when I throw this mallet The head will travel in the arc of a falling object because the center of mass is, is, is almost dead center in that head.
So you'll see that center of mass travel in the arc, and that's the head.
Which is almost an insignificant contribution of mass, will rotate about the center of mass, and the arch'll look a little different.
So, now I'm going to throw the mallet.
This rubber mallet has most of it's mass in it's head.
So I'm going to show you the same throw.
But this time, I'm going to slow it down to one tenth its original speed.
And I'm going to let all the previous images of the mallet linger on the screen.
So you can watch the path the mallet takes.
It's already pretty obvious that the mallet is following the arc of a falling object as it's rotating.
But just to make that crystal clear.
So you see, when you throw something, and it becomes a falling object.
That is, it's experiencing only one force, its weight.
Its motion is actually fairly simple.
The object's center of mass travels in the arc of a falling object.
As though it were a simple thing like a falling ball.
At the same time, the rest of the object may be rotating about that center of mass.
It's translating in the arc of a falling object as it's rotating in the manner of an object that's just simply free to rotate about its own natural pivot.
This may look like an ordinary beach ball, but it's not.
This beach ball has its center of mass located far from its geometrical center.
As a result, the center of mass is here on the surface of the ball.
And when I throw the ball, and it becomes a falling object, it's that center of mass that travels in the arc of a falling object.
The rest of the ball comes along for the ride.
And therefore about one surface, one side of the ball.
So that wobbly motion you're seeing is the ball rotating about the side of the ball, it's natural pivot where the center of mass is located.
You can begin to locate a small object's center of mass by setting it on a surface to support it's weight and then giving it a spin.
It naturally spins about it's center of mass.
So, what I can say in, for this basketball is that the center of mass of the basketball lies somewhere on this rotational axis.
It's spinning about a line, passing from top to bottom of the ball, and the center of mass is located on that line.
That's true of a basketball.
How do you find the center of mass of a knife?
So I can tell you the center of mass is somewhere ...between my two fingers.
To pin it down further, I'd have to spin the knife about another axis.
Can I do it?
It's really right there in the middle of this metal piece.
Well, for a seesaw, you do the same thing.
So here's a seesaw board.
The point that's trying to stay put is right about here.
So that's, that's the center of mass.
Somewhere between my fingers.
And that's where the pivot goes when you make the seesaw into a real rideable seesaw.
The rideable seesaw if you're very, very small.
Is supported right at its center of mass, and therefore pivots naturally about that point.
So we're supporting it right at its center of mass, and allowing it to undergo rotational motion about its own natural pivot.
When examining rotational motion, it's technically necessary to specifiy the center of rotation.
That is, the point about which all the physical quantitites of rotational motion are defined.
We're free to choose that center of rotation.
For example, if I'm rotating like this and we want to describe my rotation as simply as possible using the physical quantities of rotational motion, the most obvious choice for a center of rotation about which to build our language is my center of mass, 'cause that's the point about which I'm pivoting.
So, in this case, we define the center of rotation as located at my center of mass.
So about my center of mass, is pinning down the center of rotation about which our language is built.
But if I'm rotating not about my center of mass, but about my thumb, watch this.
I can pivot about things other than my center of mass.
I need help to do that.
But I can do it, and I'm now pivoting about my thumb.
So, it makes good sense to define that as our center of rotation and to say that I am currently rotating.
My angular velocity is about 90 degrees again, up, about my thumb.
Instead I'm going to assume that the center rotation that we have in mind is obvious, unless it's not, in which case I will say it.
So, for this case of a seesaw mounted with a pivot passing right through its center mass, its own natural pivot, that is an obvious choice.
Right here in the middle of the board where the pivot passes through the center of that board.
That's the obvious choice for the center of rotation.
So, instead of adding language now to all our physical quantities of rotation for the seesaw.
And that's the job for the next video.
The seesaw rotates such that the rider descends toward the ground.
There are several ways of examining this situation.
So I'm going to follow the path that I think is most straightforward.
The rider's weight gives rise to a torque on the seesaw.
And since the seesaw is no longer rotationally inertial, its angular velocity is no longer constant.
Instead, that angular velocity changes with time, and the rider soon plummets to the ground.
When the seesaw is experiencing no outside torques it's covered by Newton's first law of rotational motion.
But once there is a torque acting on the seesaw, the seesaw is no longer covered by angu-, by Newton's First Law of Rotational Motion.
Instead, it's angular velocity begins to change with time.
Angular acceleration is another vector physical quantity of rotational motion, and it is the rate at which angular velocity is changing with time.
Like ordinary acceleration, translational acceleration, it's a subtle quantity.
To see acceleration and it takes three glances to see angle acceleration.
So I'm going to illustrate angle acceleration with my body and hope that you can see.
That is my angle velocity is 0.
If I change my angular velocity, during the time over which that angular velocity's changing, I am undergoing angular acceleration.
So here we go.
I'm going to g-, undergo angular acceleration, and then I'm going to stop undergoing angular acceleration, and watch what happens.
Here goes the angular acceleration; it's going to be...
I'm going to rotate.
Here we go.
I am now coasting rotationally, at constant angular velocity.
But when I first got started I was undergoing angular acceleration.
If I don't go, undergo angular acceleration again, I'm going to keep spinning here forever, and this will make me very dizzy.
So I'm going to undergo angular acceleration downward in a moment.
When I changed my angular velocity I did it by way of angular acceleration.
I'll show it to you again.
I'm going to do A intersection upward for about a quarter of a second and then, I'm going to do A intersection downward for about a quarter of a second and come to stop.
So, the angular acceleration portion of that situation Was during the changes in my angular velocity.
Coming back to the seesaw then, the angular acceleration is absent now.
There were a lot of angualar accelerations there at the bottom, but they initially kicked in, the first angular accelerations Kicked in when the rider got on the seesaw.
So we see, a torque causes a seesaw to undergo an angular acceleration.
So for example if I've got 2 riders hopping on to the seesaw at once, the seesaw can't respond with several separate angular accelerations at the same time, it, it only has 1.
Instead it responds to the net torque, produced by those 2 riders.
Well, if net torque causes angular acceleration, the question comes up is, how much angular acceleration?
It turns out that the seesaw's angular acceleration is proportional to the net torque acting on it.
But there's a second factor involved in determining the seesaw's angular acceleration, the seesaw's rotational mass.
Rotational mass is the measure of an object's rotational inertia, its resistance to undergoing angular acceleration.
Now traditionally that physical quantity is called moment of inertia and it has various complexities to it.
That conveys the characteristic that it's a mass like thing, it's a resistance to acceleration of some form.
So, this seesaw has a certain rotational mass, a certain resistance to angular acceleration.
So if I exert a certain torque on it.
If I put a certain rider on this seesaw and let it undergo angular acceleration, well, it undergoes rather rapid angular acceleration, and down goes the rider.
But I can increase the rotational mass of this seesaw.
When I do this, I'm increasing the rotational inertia of the seesaw.
Try to glue it and tape it in place.
And now, it's less responsive to the same torques as before.
Overall, the seesaw's angular acceleration is proportional to the net torque acting on the seesaw.
For Newton's Second Law of Rotational Motion, which states that an object's angular acceleration is equal to the net torque acting on that object divided by that object's rotational mass.
I'm going to ask a question about angular acceleration, but I'm going to do it in the context of a bicycle wheel that I can hold in my hands.
At present the bicycle wheel is motionless.
And I'm going to do three things to it, in sequence.
Second, I'm going to turn the wheel all the way around like this, so it's spinning in the opposite direction.
The question is, during which of those 3 steps was the bicycle wheel undergoing non zero angular acceleration?
All three steps involved angular acceleration of the wheel.
When I started it spinning it went from having an angullar velocity of zero to having an angular velocity toward you.
Remember the right hand rule here.
I reverse the direction of the wheels angular velocity from toward you to toward me.
That's angular acceleration.
I had to, to make the wheel undergo angular acceleration to reverse its direction of, of rotation.
So, we see that a seesaw responds to a net torque by undergoing angular acceleration.
And If I hold the seesaw in place now, the rider and seesaw are pushing on each other with forces.
The seesaw to support the rider's weight and the rider pushing back on the seesaw in response.
It's all forces out here.
Where does the torque come from?
Well it turns out that forces and torques are related and that a force can produce a torque and a torque can produce a force.
To see how that all works, let's go experiment with a door.
...because doors are a wonderful example of rotational motion and the use of a force to produce a torque.
So here I am outside the physics building, opening and closing doors in a light rain.
Doors are a nice example of rotational motion.
After all, they don't go anywhere.
But that brings us to the issue at hand, which is when you open a door you do it by exerting a force on the door handle.
And yet the door undergoes angular acceleration.
So how is it that a force exerted on the door handle produces a torque On the door.
To show you how that works, I first have to define a center of rotation.
Now, the obvious place to put the center of rotation is somewhere along the hinge line.
'Because that's the line about which all the ro-, door's rotation occurs.
So I'm going to put the center of rotation in line horizontally with the door handle for reasons that we'll come to eventually.
And that's going to be our center rotation right there on the hinge line aligned nicely with the door handle.
Having done that then, let's look at ways in which not to produce a torque about that center rotation.
So, first unsuccessful way to produce a torque, starting the force, is to push the door handle toward.
Instead of pushing toward the center of rotation, let me pull away from the center of rotation.
Doesn't do anything.
How about pushing on the center of rotation.
Let me come over here to the center of rotation and push right on it.
I'll try to pull right on it, all the kids of forces, none of it works.
So you can't move the door by exerting your force toward, away from or on the center of rotation.
So now, I'm going to exert a force out here on the door handle, not toward or away from the center of rotation, but at right angles to a special line.
It's called the lever arm.
The lever arm is going to be the vector that, that extends from the center of rotation to the point at which I'm going to exert my force.
So there is a vector that points along this lineto this point here.
It has a length of about 1 meter like that and it's direction is exactly to your left.
And I'm going to exert my force Not along that vector or, you know, with it or against it, but at right angles to it, perpendicular to that lever arm.
I'm going to exert my force toward you, and watch what happens.
That is how to produce a torque starting with a force.
From the center rotation, that is the vector that extends from a center of rotation to where you exert your force.
And you exert your force at perpendicular to that lever arm.
And then you swepp the index finger of your right hand in the direction of the force which is towards you.
My thumb is pointing up.
That is the direction of the torque I produced in pulling toward you.
The lever arm is that, that direction.
The force is toward you.
The, the torque I exert is up, and so it causes upward angular acceleration in the door which swings open.
So, that's the first observation.
The torque I produce is proportional to the length of that lever arm.
Here I have a lever arm about that long, but if I go inside and I push near the hinges, I can make the lever arm very short; and watch what happens.
So, I'm exerting my force here, very close to the pivot, Pivot.
Therefore at a very short lever arm, and I'm obtaining a very small torque until I really crank up my force.
We can combine these observations to relate the force to the torque it produces, quantitatively.
Where only the component of force that is perpendicular to the lever arm is included.
And where the torque is in the direction determined by the right hand rule.
So in this case if the lever arm is pointing to your left and the force is pointing toward you The torque is up.
Now this door is complicated because it has a closing mechanism, like many doors.
It has a system to try and keep that door closed when you leave it alone.
So it's not free to exhibit rotational inertia and has all kinds of, of its own trouble and I had to overcome that resistance, That, that The mechanism trying to keep the door closed.
That's a lot easier to overcome if I'm out here at a, with a big lever arm.
I can exert relatively gentle force on the door handle and get the door to open despite the closing mechanism.
If I try to push very close to the hinges, that closing mechanism is hard to beat.
If you push near the hinge side of the door, the door doesn't open very easily.
It's very resistant to openeing because you're producing so little torque with your force.
You need to go out to the other side of the door where you have a big lever arm to work with.
To produce a torque with a force then, all we need is a lever arm.
One that can rotate in any possible direction, the options are limitless.
I'm going to choose as our center rotation The seesaw's center of mass just for convenience here, right about there.
And now, let me show you a couple of torques.
If I come out here to a lever arm Towards your left and then I push down with my force, which is at right angles to that lever arm or, in fact I don't have to be perfectly right angles I have to just, just have to have some component that's at right angles to the lever arm.
And I push down, I cause an angular acceleration toward you.
But I push my force towards you.
And if I come out to a level arm toward you, very short one but it's there, and push down, I caused angular acceleration to your right.
I flipped the board like that.
This is exciting, but very complicated.
>> This seesaw board down here cannot do this kind of rotation, or this kind of rotation.
And so, it operates in a more simple fashion, like this.
And it still exhibits the same sorts of behaviors.
To produce a torque on this seesaw, I come out to a lever arm and push at right angles, or partly at right angles to that lever arm down and I cause angular acceleration toward you.
Because my torque was toward you.
We've seen how to produce torques with forces in the context of doors, in the context of seesaws.
You rotate a bolt into place and you rotate it the other direction to take it out of place.
>> That has rusted in place, and you're trying to get it out but it won't turn when you grab it with your hand and try to twist.
You need more torque.
So, in that case you get a wrench.
This is a device that when you put it on the head of the, the bolt.
And by now, you should be thinking about how this works.
But what if this is really, really stuck?
And you need a bigger wrench?
Well, that's already a pretty big wrench, you think.
And you're probably thinking that I'm going to go over and get this wrench.
I have in mind this wrench.
And so we take this wrench, put it on our stuck bolt.
To produce a large torque on that bolt and remove it from wherever it's stuck.
The question then, is this, why is using this larger wrench more effective it, why does it enable you to remove that bolt when this wrench didn't to the job?
This wrench has a longer handle, and it provides a longer lever arm with which to produce a torque using a force.
So when you come out here to the end of the handle and push perpendicular to that handle and therefore perpendicular to the lever arm.
It's got a shorter lever arm and so when you push on the handle of this wrench with that shorter lever arm your force produces less torque.
So we see, whenever a lone rider goes out to a lever arm on the seesaw and sits down, the rider's weight gives rise to a torque on the seesaw that causes it to undergo angular acceleration, such that the rider ends up pretty much sitting on the ground.
Is a force and that weight causes the rider to push on the seesaw with a force, but the force acting at a lever arm from the center rotation produces the torque that causes all this to happen.
Pretty much the only place a, a single low rider can, can sit or stand and not produce a torque.
On the seesaw is exactly on top of the pivot, which is kind of an interesting place to stand.
How do the seesaw's riders affect one another?
The answer to that question is that they support one another and they exchange energy as the seesaw rotates back and forth.
Let's start with the support issue.
And to do this, I'm going to treat the seesaw as a facilitator rather than the object of our main attention.
I'm going to define the center of rotation as lying in the middle of the pivot.
So the axle rotation for this entire story is right here at the pivot of the seesaw.
But, otherwise, the seesaw is just helping the red rider exert a torque on the purple rider about the pivot.
That's because, the purple rider is already experiencing a second torque, a torque due to gravity.
Gravity is pulling downward on that purple rider, at a level arm from the pivot, the axle rotation.
So gravity by itself is exerting a torque on the purple rider, and that torque is towards me, that is away from you.
To keep that purple rider from undergoing angle acceleration and plummeting toward the ground, the red rider comes to the rescue.
The red rider is exerting a second torque on the purple rider, and that torque is toward you.
So the second torque acting on the purple rider cancels gravity's torque on the purple rider.
This is all about that, that pivot, and prevents the purple rider from undergoing angle acceleration.
How about the other way around?
Well, the red rider is also experiencing a gravitational torque, forces down, lever arm is toward your left.
So, the gravitational torque on the red rider is toward you.
By itself, that would cause the poor red rider to undergo angle acceleration, boom, and drop toward the ground.
But once again, the purple rider comes to the rescue.
And now, the purple rider is exerting a torque on the red rider, that is this way, toward me it cancels the gravitational torque on the red rider and saves the red rider.
So the long and short of it is, the red rider is keeping gravity from twisting the poor purple rider to the ground and the purple rider is stopping gravity from twisting the poor red rider to the ground.
So we have two torques between the riders.
How do those two torques compare?
They turn out to be exactly equal in amount, but opposite in direction.
That's an example of Newton's third law of rotational motion, which observes that for every torque one object exerts on a second object, the second object exerts an equal, but oppositely directed torque back on the first object.
That's how our universe works again, it's never violated, it's always there.
And that ultimately allows this whole thing to balance smoothly.
At the same time, the purple rider rescues the red rider from the, from the grips of, of gravity.
The red rider rescues the purple rider from the same clutches, and so, the two, two objects here both reach the balance condition at the same time.
They all end up with no overall torque due to gravity.
This mutual support idea still works when one of the riders weighs far more than the other.
If I replace the red rider with this silver one, I can't put that heavy silver rider all the way at the end of the board.
I have to come in close to balance the seesaw, so right about here.
And look what has happened.
It would turn the purple rider into an astronaut.
So, by pulling the silver rider in closer to the pivot, I have compensated for the silver rider's greater weight by shrinking the lever arm that the silver rider uses to produce a torque about the pivot.
So, that part, part of the balance still works.
Well, it still works there too.
The gravitation torque acting on this silver rider was reduced by bringing the silver rider in close to the pivot.
Gravity is pulling down with a big force on that heavy silver rider, but since that force has only a short level arm with which to work, it doesn't produce all that much torque on the silver rider about the pivot.
The silver rider may be heavier, but because the silver rider is closer to the pivot, it doesn't take as much torque to support this silver rider against the torque produced by gravity itself.
I haven't talked about units in rotational motion, because they're somewhat complicated and they'll distract us from more important issues.
But let me take a moment to mention the units of torque.
In the SI or metric system, the unit of torque is the newton meter.
And it corresponds to a force of 1 newton exerted at a lever arm of 1 meter from the center of rotation.
In the English system of units, the unit of, of torque is the foot pound.
It corresponds to a pound force, exerted one foot from the center rotation.
I introduced the units of torque in part so that I can ask a question.
Here is a wood screw and I will screw it into the wood by exerting a torque on it, using my right hand, that is down towards the wood.
And now, I will unscrew the screw by exerting a torque on it that is up out of the wood.
If in both cases, inward torque and outward torque, I exert a torque in the amount of 1 newton meter.
What torque does the wood screw exert back on me?
If I exert a torque of 1 newton meter on the wood screw, it has to exert a torque of 1 newton meter back on me in the opposite direction.
That's Newton's third law of rotational motion.
So as I exert a torque of 1 newton meter downward into the wood block, it exerts a torque of 1 newton meter up out of the wood block on me.
And if I exert a torque of 1 newton meter out of the block, upward, on the wood screw, it exerts a torque of 1 newton meter downward on me, every time.
Now, let's watch the riders exchange energy as the seesaw rotates.
Speaker 1: I've pretty well balanced the board here, I have the red and purple riders at about the right differences from the pivot, so that the seesaw balances.
It experiences zero net torque and therefore rotates at constant angular velocity.
I'm going to hold the riders in place, so that as the seesaw rotates, they don't slide about and possibly fall to the floor.
But what I want you to do is watch the altitudes of the two riders.
I'm going to make the seesaw rotate at a constant angular velocity toward you, that is, like this, and the red rider descends as the purple rider rises.
That means the red rider's gravitational potential energy is decreasing, while the purple rider's potential energy is increasing.
Hm, I wonder.
As you might suspect, the red rider is transferring energy to the purple rider by way of the seesaw.
There are number of ways of following that energy transfer, so I'm going to pick what I think is the most straightforward path.
It involves the work that the red rider does on the seesaw and the work the seesaw does on the purple rider.
I'm going to make the seesaw rotate very slowly at constant angular velocity toward you, and as I do, I'll tell you how the transfer is occurring.
Okay, it's started.
We're going very slowly so I have time to talk.
The red rider is pushing down on the seesaw as the seesaw moves down in the direction of that downward force.
So the red rider is doing work on the seesaw.
At the same time, the seesaw is pushing up on the purple rider and the purple rider is moving up in the direction of that upward force.
So the seesaw is doing work on the purple rider.
The job is complete, the red rider is, is transferring energy away to the seesaw and the seesaw is transferring energy away to the purple rider.
Hope you could follow that.
So, energy is flowing through the seesaw from the red rider to the purple rider, pretty neat, as the rotation occurs in the opposite direction.
So I'm going to make it rotate a constant angle velocity toward me.
In this case, the purple rider's pushing down on the board as the board moves in the direction of that push.
Therefore, the purple rider is doing work on the seesaw, the seesaw is pushing up on the red rider, as the red rider moves up in the direction of the seesaw's push.
So, the seesaw is doing work on the red rider.
Again, energy is going from the purple rider into the board, and from the board into the red rider.
Because the seesaw is balanced, all of the gravitational potential energy lost by the rider that's moving downward becomes gravitational potential energy in the rider that's moving upward.
The transfer of gravitational potential energy to gravitational potential energy is perfect.
If the seesaw isn't balanced, well then, it undergoes various types of accelerations and kinetic energy becomes part of the equation.
But this arrangement where a balanced seesaw is transferring energy and particularly gravitational potential energy from the descending to the it, to the rising rider works even if the riders have different weights.
If I replace the red rider with the much heavier silver rider and balance the seesaw again, I achieve that balance by putting the heavier silver rider close to the pivot.
Now, it's pretty well balanced.
As the seesaw rotates, at constant angle velocity which is what it normally does, the silver rider who is close to the pivot, doesn't move up or down very much anymore.
Right, they're close to the pivot.
They only move up and down, oh, no, this far, as the purple rider is moving up and down, you know, much farther, more than a hand-width.
Wooh, that is the secret or maybe the, the explanation, behind the perfect transfers of energy again.
It's pushing down on the seesaw board with a large force, because it weighs a lot.
But that seesaw that it's touching isn't moving very far.
A little bit, but not all that far.
So it's doing work of a reasonable amount on the seesaw.
At the same time, the seesaw is pushing up on the purple rider with a more gentle force.
So the work the seesaw is doing on the purple rider is the same as the work the silver rider is doing on the seesaw.
The silver rider is exerting a large downward force on the, on the seesaw as the seesaw is descending a short distance.
At the same time, the seesaw is exerting a small, upward force on the purple rider as the purple rider moves upward a large distance.
The product of force times distance traveled in the direction of that force, the products are the same.
The work done by the descending silver rider on the seesaw is the same as the work done by the seesaw on the rising purple rider.
This arrangement of the seesaw where a heavy rider can lift a light rider or a light rider can lift a heavy rider highlights the fact that the seesaw is an example of a lever.
One of the simple machines.
Like all simple machines, the lever allows you to change the amount and or direction of the force you're using to perform a particular task.
To make that clearer in this case, let me get rid of one riders, purple rider take a rest, and now, I'm going to lift the heavy rider with my hand by exerting a force directly on the seesaw.
I can lift the heavy rider.
And, in this case, the force that I'm exerting on this side of the seesaw was relatively small much less in amount than the weight of the heavy rider.
But as I lift the heavy rider, I have to move the seesaw I'm pushing on much farther than the seesaw moves the heavy rider.
So I'm doing work as I push down on my side of the seesaw.
And I'm doing it by exerting a small force over a large distance.
Whereas, the seesaw is doing work on a heavy rider consisting of a, of a large upward force exerted as the, as the, heavy rider moves a short distance.
So, the work I do on the seesaw is the same as the work the seesaw does on the heavy rider.
But the relationship of force and distance has changed.
And that's typical of many levers in our world, which brings me again to a question.
Let me get out a familiar lever and ask you about it.
It's an all too familiar situation.
And then you change your mind and you want to take the nail back out.
So you grab the nail with your hand, you pull as hard as you can.
Can't get that nail out.
What are you going to do?
You take a claw hammer.
That is, a hammer that has a groove in it, meant for grabbing the heads of nails.
And you grab the head of the nail with that groove.
Tip the hammer and it plucks the nail right out of the wood.
So the question is this, what aspect of what I did to the hammer is the same as what the hammer did to the nail?
The hammer acts as a lever.
And the work I did on my part of the hammer was the same as the work the claw did on the nail, as the whole system rotated about an effective pivot where the, where the top of the hammer touched the wood.
So I was doing my work with a small force exerted over a long distance as the claw was doing its work with a large force exerted over a small distance.
This is why I was able to pull out the nail.
It was stuck tight and it needed a huge force to pluck it out of the wood.
I couldn't provide that big force with my own hands directly.
But with the help of the hammer, I could pull it off, because I have mechanical advantage associated with this lever.
I'm moving the level far from the pivot, so I can use a gentle force and it's moving the nail close to the pivot, so it provides a huge force.
I don't get something for nothing, though.
I have to exert my force over a long distance, whereas the claw exerts its force over a short distance.
Nonetheless, the mechanical advantage provided by this lever allowed me to do something I couldn't normally do, namely pull a nail out of a piece of wood.
As you can see, the rider's interaction on the seesaw is pretty sophisticated.
Not only are they supporting one another, but they're exchanging energy as the seesaw tips back and forth.
The seesaw is just a kid's toy.
And yet, it exhibits all this really amazing rotational behavior.
And in particular, it acts as a lever allowing one rider to lift the other rider.
Wow, pretty much something for everybody.
A seesaw is a pretty amazing toy and a beautiful example of rotational motion.
It rotates about its own center of mass, its own natural pivot so that, the only reason I need this physical pivot passing through it is to prevent the seesaw from falling.
If I could turn off gravity, I wouldn't need that physical pivot to make the seesaw do exactly what it's doing.
Well, there is gravity so you need the central pivot.
And the pivot also constrains the seesaw so it can't do rotations that we don't want.
It can only do what you see it doing at the moment.
Although it can also do that in the, in the other direction.
The seesaw is balanced as well, meaning that it's experiencing no torque due to gravity.
That's because the center of gravity of the seesaw is located right at the pivot as well.
Basically vertically in line with the pivot.
In fact it's on the pivot.
And as a result, that, the force of gravity produces no torque on the seesaw about its pivot.
No torques.
So, the seesaw is turning according to Newton's First Law of Rotational Motion.
It's a rigid object that is not wobbling.
And it's not experiencing any external torques.
So, it rotates at constant angular velocity.
Well, when you put riders on the seesaw, life can get more complicated, which we've seen.
Those riders produce their own torques on the seesaw, and they move in various interesting ways.
If they're not balanced, the seesaw undergoes angular acceleration in various ways.
But once they are balanced, and again there is no gravitational torque on the seesaw and its riders, the seesaw is once again rotationally inertial.
It turns according to Newton's first law of rotational motion.
If they come out of balance, and the seesaw undergoes angular acceleration, it does so according to Newton's second law of rotational motion.
The angular acceleration of the seesaw is equal to the net torque acting on the seesaw divided by its rotational mass.
And depending on where the, the riders sit on the seesaw, they can go from making the, giving the seesaw a small rotational mass to giving it a large rotational mass.
Lots of flexibility.
And as they're tipping back and forth, they're exerting torques on one another, these two riders.
And that's according to Newton's Third Law of Rotational Motion.
If the red rider exerts a torque on the purple rider, the purple rider has to exert an equal but oppositely directed torque back on the red rider, every time.
And as they tip up and down, they do work on each other.
They transfer energy to each other with the help of the seesaw board.
So there's really a, a lot going on here in the seesaw.
And we'll use many of these same concepts later on as we continue to look at how things work.
Hello, I'm Lou Bloomfield and welcome to how things work at the University of Virginia.
Wheels are so common, and have been around so long that we simply take them for granted.
Not only do we avoid reinventing them We avoid even thinking about them, but that may be a mistake.
Their extreme commonness makes wheels more important, not less.
And giving them a little attention may save you time, money and even misfortune.
When they're used to propel a bicycle or car.
Wheels serve as yet another simple machine.
But, wheels are far more than simple machines.
They also save us from the limitations of friction.
Without wheels nothing would just roll along.
There would be no free-wheeling adventures and the wheels of industry would grind to a halt.
In fact, wheels are so inextricably linked to friction that the story of wheels is also the story of friction.
It's also the story of energy, but in a different way from ramps and seesaws.
Ramps transformed energy from one form to another.
Seesaws transferred energy from one person to another, but wheels prevent friction from wasting energy.
That is, from grinding up useful energy into countless tiny, random fragments, that are then very difficult to use.
We'll examine friction and wasted energy here in the context of wheels, and then use our new found understanding as we continue to look at how things work.
At this point, let me have you think about a question.
We won't actually ask this and answer it yet.
But this is something you might have in your mind as we continue on through this episode.
Suppose you're riding a bicycle or a car and you are stopped waiting for something.
And then it's time to accelerate forward.
Will you accelerate forward fastest if you twist your wheels so hard that they begin to skid across the ground, that is slide on the ground, or if you twist them somewhat less hard so that they just barely avoid skidding?
To help guide us through the science of wheels we'll pursue six how and why questions.
Why does a wagon need wheels?
Why is sliding a box across the floor usually hardest at the start?
How do wheels help a wagon coast?
How do powered wheels propel a bicycle or car forward?
How is energy present in a wheel?
There is one video sequence for each of those questions and a summary video at the end, but now on to the first question
How is momentum transferred from one bumper car to another?
The answer to that question is that the first bumper car does an impulse on the second bumper car.
Just as you can transfer energy by doing work.
You can transfer momentum by doing an impulse.
So what exactly is an impulse?
For example, I do an impulse on this bumper car by pushing on it as time passes.
The product of my force on the bumper car.
Times the duration of that force.
And correspondence to the amount of momentum I transfer to the bumper car.
That impulse is also a vector quanity An impulse points in the same direction as the force responsible for it.
So, for example, if I push the bumper car to the right.
The impulse points to the right.
If I push the bumper car to the left.
My force points to the left, the impulse points to the left and I transfer a leftward momentum to the bumper car.
Of course, at an amusement park, people don't usually transfer momentum to bumper cars.
So, here's one bumper car.
And it's going to do an impulse on a second bumper car and I'm going to make it so that this bumper car is going to hit that one, like this and it's going to do a rightward impulse on a second bumper car.
Here we go.
So, this guy transferred momentum to that guy.
But actually, there were two impulses occurring during that collision.
We've seen one.
This one did impulse on that one, it exerted a force on that one over a period of time.
But simultaneously, the second bumper car did an impulse back on the first bumper car in the opposite direction.
It had to, this is Newton's third law.
As this one pushes on that one, that one pushes back on this one equally hard in the opposite direction.
That bumper car did a rightward impulse on the second bumper car, but at the same time, the second bumper car did a leftward impulse on the first bumper car.
Well, that means that the second bumper car transferred leftward momentum to the first bumper car.
But leftward momentum is the same as a negative amount of rightward momentum.
So as this bumper car was transferring rightward momentum to that bumper car, the second bumper car was taking away rightward momentum from the first bumper car.
That's how the transfer works.
The bumper car over here transfers right where momentum the second bumper car and gives it up.
It comes out of this one into that one.
And you can see that where the collision occurs.
The original bumper car basically has lost its rightward momentum, and the second bumper car carries it away.
You can see, this one almost stops, and the second bumper car carries away the rightward momentum that had started in the first bumper car.
The transfers of momentum that are occurring as these two bumper cars collide have to be perfect, because momentum is a conserved quantity.
Whatever momentum the second bumper car receives, the first bumper car has to loose.
Well, let's return to the fact that an impulse is proportional to both the force that, that's responsible for it and the time of which it adds.
That's a rather interesting result.
I'm going to go back to pushing a single bumper car by hand.
Now, of coarse, I can increase the amount of momentum I transfer into that bumper car.
Either by pushing harder or by pushing for longer duration, but that's not surprising.
What is somewhat remarkable is that I can transfer the same amount of momentum to the bumper car with different pairings of my force and its duration.
As long as the product of my force times the duration doesn't change, I'd do the same impulse and transfer the same amount of momentum to the bumper car.
For example, I can start by exerting a medium force for a medium amount of time.
Here we go.
I pushed it medium hard for a medium amount of time and off it goes.
But I can do the same impulse by pushing hard for a short amount of time.
Same thing, or I can go back and transfer the same amount of momentum by using a gentler force for a longer duration.
I have some choices here.
Oh, yeah.
Big forces can break things.
For example, here is a hammer.
And I'm going to invest some downward momentum in that hammer.
Before it encounters a nail on a piece of wood.
And when the hammer reaches the nail, it's going to transfer all of its downward momentum to the nail by way of an impulse.
The hammer will exert what is known as an impact force on the nail as it transfers its momentum to the nail.
And that transfer is going to occur in the blink of an eye, short duration, so the force has to be huge.
The hammer exerts such a large force on the nail.
That it pounds the nail right into the wood.
I'm going to try that again, but this time, I'm going to tape a rubber stopper on to the tip of the hammer before I hit the nail.
Now, there we go.
I'll pull the nail back out.
Now, I'm going to try to pound in the nail again.
Doesn't work.
I'm giving the hammer plenty of downward momentum before it strikes the nail.
The hammer is still.
Transferring all of its downward momentum to the nail, but somehow that doesn't cause the nail to enter the wood.
The problem is that the impulse that's occuring when the hammer hits the nail involves a much longer time now.
The softness of that rubber stopper prolongs the impact.
So, there's a long impact.
The force that develops, the impact force of this rubber hammer hitting the nail is too small to push the nail into the wood.
I occasionally insert what I call public service announcements into my how things work course and here's one of them.
This type of baseball is used in professional sports and that I've mounted here on a handle so that it looks like a hammer is extremely hard.
It's so hard that it transfers its momentum to whatever it hits extremely fast.
Because the duration of that impulse is so short the force of the impulse can be huge.
You could pound a nail in with this kind of baseball.
In contrast, a somewhat softer ball, so this ball has the same mass, carries the same momentum, with the same velocity as a professional ball, but it's got a somewhat softer surface.
And it takes a little longer to transfer it's momentum.
With a longer duration for its impulse.
The force of that impulse is smaller.
So these softer balls are soft strike, or reduced impact force balls, because the longer impulse involves a smaller force.
A smaller impact force.
This type of ball.
In fact, you can hit your own hand with it.
Don't try that with, with a professional sports ball.
My advice is this.
A fast-moving hard ball is effectively a loose hammer, and it can cause serious injury or worse if it hits you in the wrong place.
So the trade-off between forces and durations is also important with bumper cars.
So you've seen these bumper cars with their rubber bumpers, they're called bumper cars.
Because they have bumpers on them.
Without those bumpers, the steel frames of the cars would hit and they would transfer momentum way too fast.
I can show that because the bumpers come off these guys, and I've already removed the bumpers from this pair of bumper cars.
So, if I turn them on And bump them into each other.
This kind of bumper car, like, bumperless bumper cars, wouldn't be very fun.
The transfers of momentum are so fast, involve such big forces, that the cars will get damaged by them.
And you, as a rider in one of these cars, will also experience unpleasantly large forces in rapid accelerations.
It's not going to be good.
So, if you have the option of going and riding bumperless bumper cars.
Or, I guess, just bumperless cars, skip it.
It's time for a question.
We've seen that it's entirely possible to use a hammer to pound a nail into the floor.
So the question is this, can you use a hammer to pound a nail into the ceiling?
You'll have no trouble driving a nail into the ceiling with a hammer.
That's because the impact between hammer and nail occurs over a very short period of time.
And transfers the hammer's momentum, the upper momentum, to the nail so quickly that it involves an enormous force.
A force that's capable of pushing the nail right into the ceiling.
You might worry about gravity during this upside down hammering process, but the force of gravity is so small compared to the force of the hammer on the nail during the impact that it just doesn't amount to anything.
You can pretty much ignore gravity when it comes to hammering.
Bumper cars obtain their initial forward momenta from the floor.
And they use frictional forces between those wheels in the floor to propel themselves forward.
As the floor pushes the bumper car forward, the car gradually accumulates forward momentum.
The impulse that it's experiencing as it picks up speed involves a relatively weak frictional force from the floor exerted for a long period of time.
During collisions however, things happen so fast that there's very little momentum transfer to the floor.
The frictional force between the wheels and the floor are just too weak.
So, when two bumper cars collide, they're pretty much on their own during that collision.
As though there, there's nothing else in the universe.
And for the sake of simplicity, I'm going to assume that they're completely on their own.
Since momentum is conserved quantity, the collision can redistribute their momentum, their total momentum, but it can't change that total.
Their total momentum before, and after the collision has to be the same.
The same is true for energy.
The collision between two bumper cars can redistribute their total energy, but it can't change that total.
Unfortunately, the collision between bumper cars can and does grind up some of their ordered energy into thermal energy.
So that we don't see it after the collision.
But that wasted energy is relatively small for bumper cars and so for simplicity, I'm going to ignore it.
For the experts, perfect collisions, ones that waste no energy.
Elastic collisions are some what simpler to understand then inelastic collisions.
We'll make our lives a little easier, without really changing the story.
So, a collision between two bumper cars has two important constraints: their total momentum can't change, and their total energy can't change before and after the collision.
So together, those two constraints determine how the cars bounce from one another.
The simplest case is two identical bumper cars, and that's what I have here.
These bumper cars have the same mass, they're basically indistinguishable.
And the need for them to have the same total momentum and total energy after the collision as before the collision really constrains how they bounce.
And you get these very interesting effects, like, if they have head-on collisions, that is collisions that are entirely along one line, they exchange motion.
So if I have one of them at rest and I slam the second one into it, they trade, they trade their motion.
The second one continues on as though it were the first one.
And the first one continues on as though it was the second one.
So it works like that.
It works like that.
It works if I slam the both in like that.
All of these variations.
If they hit off center, if they're not riding this rail into each other and apart, then you get more complicated motions, but still they're all related.
Very highly constrained bounces and this is how bumper cars the bumper car arena will behave if they have identical masses.
Actually, you don't even need bumper cars to see some of these effects.
Any objects that are identical and that bounce almost perfectly off one another will work.
For example, coins.
And if I bump one of them into another quarter head on, perfect shot, they'll trade motion.
The first one stops, the second one continues on as though it were the first one.
Actually you can line a whole series of these quarters up and if I hit the first one head on, the last one will go on as though it were the first one.
It's all about conserving momentum and energy during a very complicated collision.
That causes the first one to stop and the last one to continue on.
Actually, people have made toys that use this principle and their called either Newton's cradle or the executive toy, which doesn't say much about executives but that's the name under which it goes.
This has a set of very elastic balls.
They're made of steel and they bounce almost perfectly off one another and if I take the first one and I make it smack into the entire row of, of balls the last will come off.
It's a series of collisions in which energy and momentum have to be conserved, and the only way that can work is if the motion propagates through the entire row of balls and the last one continues on as though it were continuing the work of the first one.
It's time for the full glory of bumper cars, and that means having bumper cars with different masses.
So, I brought the little bumper car arena.
And first I can show you things you've already seen before.
I can take two bumper cars that have identical masses.
They differ in color, but otherwise, they're identical.
And if I smack the green one into the red one, the red one continues on with the green one's motion.
So, so, so far, so good.
That is, ones with substantially different masses like this green one and this little red one.
I'm going to make the green one hit the red one.
It just swats the red one out of the way, and the green one continues on.
Why did that happen?
Well, the physics isn't too hard to understand.
When the green one collides with the motionless red one, it begins to transfer to.
Conserve physical quantities to the right one is transferring momentum by way of an impulse and it is transferring energy by way of work.
It's using the same force to make both transfers but the impulse involves force times time while the work involves force times distance.
The little red one moves easily during the impact.
It's being pushed on, and it's accelerating, and picking up speed, and beginning to move so the green one is able to do a lot of work on it.
It's travelling in the direction of the force.
So, the green one's doing work on it and it turns out that the green one is able to do enough work on the little red one.
To, to set it off in the distance before the green one has had time to transfer all of the green one's momentum.
So, the green one keeps on going it only gives some of it's momentum to the little red one.
The little red one runs away to soon and heads off in the distance.
The reverse is also interesting.
Let me let the little red one collide with the stationary green one.
Watch what happens there.
I'll do it again.
How did that happen?
Well, when the little red one arrives at the green one it's again trying to transfer to conserve quantities to the green one.
Momentum and energy.
Energy by way of work.
So the red one begins to push on the green one.
That force is going to transfer both of these conserved quantities.
But the green one won't move, not very well any way.
It's massive.
It's very hard for the, to get that green one moving.
So it doesn't travel very much distance during a collision, therefore the red one is barely able to give the green one any energy.
Can't do much work on that almost immobile green one.
But there's the right one tries and tries and tries, so a lot of time goes by during the impact.
And the right one manages to transfer all of it's momentum and it transfers more momentum, even than it had.
So it was heading to the right, it gives all it's rightward momentum to the green one an extra.
And it ends up with a deficit of rightward momentum.
And it heads backwards.
It tried to give the green one all its energy and momentum.
And it didn't manage to give the green one much energy.
But it gave it a lot of momentum and off it goes backward.
So all of these impacts, then, are making use of these transfers, energy and momentum, trying to get everything to work out right, because those two quantities have to be conserved.
So this explains then a lot of wht you see or experience in bumper cars.
The really massive cars, the ones carrying a lot of heavy ha, high mass occupants riding in them, they pretty much swap the other cars out of the way when they hit them.
They transfer a lot of energy to those cars, but not all of their momentum.
And so they, so these big, these big massive cars just keep on going.
They, they still have momentum after the impact.
In the same direction they had before the impact.
The little cars, on the other hand, bounce off the other cars when they hit them.
Because they don't manage to transfer much energy to those other cars, but they transfer a lot of momentum and they bounce back.
So let me ask you a question.
To successfully catch a ball, why do you have to let your hands move with the ball as it collides with your hands?
By letting your hands move with the ball as it collides with your hands, you're letting the ball do work on you and transfer its energy to you.
In the process, it transfers its energy and its momentum and comes to rest, and that's how you catch things.
If you hold your hands rigidly in place as the ball hits them, it's going to be able to transfer momentum to you, but no energy.
And it will actually bounce off you like, like the little bumper cars bouncing off the big bumper cars.
So that's it for translational motion in bumper cars.
We see how momentum moves from car to car during the collisions, as they, as they do impulses on one another.
But not all of the motion in bumper cars is in straight lines moving from here to there.
Bumper cars can also spin.
So the next video is about the rotational motion of bumper cars.
And the associated conserve quantity known as angular momentum .
This is the last week of our learning.
The last lesson will be reviewing all and grammars from the past six weeks.
Are you ready to start?
Now the text.
Let's review the key words.
The first one , happy, joyful.
Let's watch the video again.
I'll show you the answers.
Let's see number one.
That's all for today.
The next thing that we're going to be looking at is antibodies, and eventually, T-cells.
So, we'll be looking at adaptive immunity.
So, just before we head on into that, I'd like to do a quick compare and contrast.
So, here we are in section five, and we're going to compare and contrast the innate response and the adaptive response.
So, both of these are responses that a cell uses to fight off pathogens.
Now, the innate response is found in all organisms.
The adaptive response is found in fish, amphibians, reptiles, birds, and mammals.
I would like to say, parenthetically, at this point, is that it doesn't work the same way in all of these guys.
They have evolved, again, their own special tricks and ways of doing things.
But in general, in all of these, we're going to find compounds that are produced from rearranged genes.
So, these guys rearrange genes.
So, then, when we look at TLRs, we're going to look at things that recognize the general pattern of a molecule that's common to a class of pathogens.
Like most bacteria have bacterial cell walls with a particular flagellar protein, we do that.
We look at things that recognize certain peptidoglycans and things that recognize certain bacterial lipids.
Because in their form, they're essential to their function so that when we look at the specific recognition that we employ when we look at adaptive responses, we're looking at something that in many or most cases, involved a very specific sequence of amino acids that produces a very specific shape.
So, in this case, a virus or a bacterium can change the details of a protein and essentially, fool the system.
So, these two systems have to work together.
The other important element to remember is that this thing is ever ready.
But from day one, if you get a cold or a flu, these will recognize aspects of that flu and begin to fight it off.
That's a good thing because if it's a new version of the flu, it's going to take two weeks before your adaptive system is ready to go to work on it.
You could be dead by then, in fact, often are, which is why we give you vaccinations, because if you have a previous exposure to something, you can begin to make antibodies and T-cell recognition molecules within three days.
Now, you might want to say, well, why wasn't that enough?
If you have an infection that hangs on, you may need an adaptive response, an additional layer of second round protection, something that actually helps a lot of your innate responses to do their thing.
So, as we go through the rest of this course, there will be times when we are talking specifically about adaptive responses, making antibodies, but we will also see that those antibodies can help the innate responses in particular.
They'll help phagocytosis of neutrophils and macrophages.
We're going to look at specific classes and categories of antibodies, and just bear in mind that the information that tells you which one of these things to make often comes from innate input that you had at the onset of the infection
So, this is it, this is the last video for this lecture.
We're going to wrap up a few issues and kind of, sort of summarize a little bit of what we've done.
One of the things I wanted to wrap up first was how the developmental processes wind up leading to a B-cell.
So, let's go back again to hematopoiesis, where we had a hematopoietic stem cell and we use GATA2 to tell it to begin to differentiate.
Now, it turns out that to determine a B-cell, we need something called BSAP.
So, if this lymphoid cell receives BSAP, then I will go into a B-lineage development.
The ironic thing is that if this turns into a plasma cell, that is one that secretes the antibodies, then it stops making the BSAP.
If however is becomes a memory cell, then it continues to make the BSAP.
So, that we have in the B-lineage something that keeps it dividing, developing, and keeps its options open but still means it's a B cell that's going to be the BSAP.
Once a cell becomes a plasma cell it is committed.
So, it's something that actually kind of think about when you're looking at lymphoid or other kinds of blood cancers.
So, anyway hematopoietic stem cell gata two gives you Lin plus, ikaros makes you lymphoid, BSAP means you're a developing B cell and once you become a plasma cell and you're terminally differentiated you then turn it off.
Well, okay, we are at the end of this lecture and the last thing I want to bring up again is a reminder that here we have my favorite antibody molecule and here we have the parts, the CDRs that recognize antigen.
What we really want to make sure we do is have antibodies were the CDR's recognize foreign antigen but not self-antigen and that isn't necessarily as easy as you might think.
I don't think so.
So, there is an ongoing process to make sure that these cells do not produce antibodies that will attack your own self-tissues.
One, not the only but one element of this is surveillance by the T regulatory cell which will down regulate the activity of adaptive cells especially if it thinks they're attacking the wrong thing.
So, if the FC stems bind to the B cell, the B cell says, "Oh there's plenty of antibodies around maybe I should lower my production." Maybe if it's a cell that hasn't started yet making antibodies, it might say, "Oh well maybe what I need to do is become a memory cell".
One reason for having the measles mumps rubella vaccine in the United States not given until one year, is that during the first year, infants often have antibodies from their mothers against these antigens.
So, if you give them a vaccine, mom's antibodies tie up the antigens before baby has a chance to make antibodies against it.
In other parts of the world where measles is more endemic and more likely to kill a child, they will give the first vaccine at nine months and hope for the best and maybe they can follow up with a booster later on or not but at least maybe the kid will survive.
So, this was kind of an academic lecture but it is of all the lectures I do things that have some of the most important supporting information you can have to do something practical to improve the health of everyone.
Hi, I'm Gary Burton, welcome to my course Introduction to Improvisation.
And it's one of the mallet instruments like xylophone and marimba, only the vibraphone has metal keys.
And it was invented around 1930, so it's a fairly new instrument.
When I first started playing music, I wasn't too serious about it.
But when I discovered jazz at about age 13, I became very passionate about it.
And as you continue working on improvisation yourself I'm sure you will come to agree that it's a wonderful experience to make up the music as you go along and play it spontaneously.
I've had a wonderful career.
I travel around the world playing concerts and make records and I'm very grateful for the opportunities that have come my way.
I've also been very involved in music education.
And when it first became technically possible to teach music online, I was a very enthusiastic supporter of that as well.
And in fact, I created my own improvisation course for Berkeley College for their continuing education division.
It's called Gary Burton Jazz Improvisation.
I've been doing it for a while now, and I've learned a lot about how online teaching works.
I'll bring my experience and my knowledge to anyone who is interested here at Coursera.
If you haven't taken an online course before, you're in for some surprises.
The first thing you'll notice is there's a lot of individual choice and flexibility on your part.
And you can take days off when you need to and catch up a few days later.
And you also can go back and watch the instruction over and over again as much as you would like in order to feel you fully understand it.
It's a lot more flexible and personalized than a typical, traditional classroom setting.
In addition, there will be a whole new experience in how you interact with your fellow students.
I found teaching traditionally that the students often didn't talk to each other much at all unless they were just close friends with someone else in the class.
But in an online class, there's a lot of interaction for one thing, all the students get to see the homework and assignments of the other students.
So everybody can comment and share and communicate with each other about what they're learning and how they're going about doing the assignments.
And this interaction is one of the most important parts of online education.
And you will learn as much from your fellow students as you do from me, and that's a very healthy thing.
We are going to be critiquing each others work, we're gonna be talking about how to do things and how others have done them.
A lot of respect is appropriate, is called for in this kind of learning environment, and so keep that in mind.
Well, let's discuss how my course works and the kind of resources that you're going to need to complete the assignments.
And of course, the assignment will be directly related to that concept.
And a chance for you to show that you understand how it works and can incorporate it into your playing.
So, in some cases, homework may involve things that you do right on the computer screen.
And, in that case, when you're finished with it you'll have to scan it and send it back to the site as a PDF file.
So, you will need a scanner.
You will also need to record yourself playing, creating MP3 files of your playing.
And it doesn't have to be anything elaborate.
we are not looking for studio audio quality here, just so it's clear to listen to.
the simplest thing is to have a microphone and some basic recording software on your computer and you're in business.
And you will need to play along with it and record both.
And you can experiment a little bit to see where to place the mic.
Again, great audio is not a requirement as long as the music can be heard relatively clearly, that will be perfectly fine.
Some students are very technical and, equipped, and have much more sophisticated setups to do this.
It's not necessary.
I always get asked also about Notation Software.
you do not need Sibelius or the other kinds of music notation software to complete the assignments for the course.
You can use it if you wish, if you are very conversant in it and prefer writing that way, that's perfectly all right.
And again, don't feel like you have to go out, buy a new software, and learn how to use it, and so on.
these are the most universal.
Virtually, everybody's computer can open up those files.
If you record something in a wav file or a garage band file, a lot of students won't be able to see your work including me as well.
So, my advice is to stick the most universal files.
That's MP3 and MP4 when recording music.
That's all you need to do the assignment for this course.
Hi, and welcome again.
This is week two and the topic for this week is scales.
now, the first thing we see when we look at a piece of music is a cord symbol.
And we know usually most of us at this stage in our learning, know the basic notes of that chord.
So we know we know the, the triad and the, the seventh that makes up the basic sound.
And what you do in that case is you feature the chord tones and then you take a guess at filling in some other notes.
The problem is you can't play a whole melody with just the four notes of an arpeggio.
You need more notes to make melodies.
Good at doing this.
In fact, a great musician I played with for several years who was a wonderful player, Stan Getz the saxophone player.
That's how he functioned as an improviser.
He had never really studied music theory much, didn't know much about chords.
He just knew the basic triad for each chord symbol that he saw.
And he would start with those notes.
But we don't want to settle for that.
We want to have a full knowledge of the available notes during any given harmony.
So, for that we need a scale rather than just a chord outline.
The topic today is scales, specifically what we call chord scales in the jazz world.
And, if you've looked at some books on improvisation you might have come across some that included page after page after page of scales with exotic sounding names.
the truth is, there is a small number of scales that cover most situations.
there are ten of them, in fact, that are the most commonly used scales.
And 90% of the chords and scales that you come across in a tune, a standard tune or a jazz tune will use one of those ten scales.
So, they're the ones that you really need to have under your fingers, that you have to have memorized and are able to play on them.
And we're going to look at each of those ten scales today, and what their characteristics are and how to organize them and think of them.
The goal is to have them memorized to the point that you have instant recall.
Now you probably already have instant recall on a few scales.
And you don't have to stop and think what the notes are in that scale as you play it on your instrument you're just used to playing it.
We can memorize scales in two ways.
There are two characteristics that our memory uses.
One is the shape that the scale makes in terms of the pattern.
And it doesn't matter whether you play a keyboard instrument like mine, or the piano.
But on any instrument, there's kind of a, a kind of a shape and pattern to a scale run.
And we also recognize the sound of it when we hear it.
when it, you know, we associate the sound and the shape of the scale and that's what allows us to have instant recall of it.
Chords change every couple of seconds there is not time for conscious, you know, study of arguing with yourself about can I use the B flat or not and so on.
I mean, if you have to think at all about the scale as you're playing, you won't be able to keep up with the music.
So that's the goal is to get instant recall.
Now, in the classical world, ♪ ♪ the way you practice scales is usually going up and down.
But that's not much help to a jazz musician, to an improvisor.
We need to make melodies out of that scale.
♪ ♪ Which means moving to different intervals, and different groupings of notes within that scale.
So we want to have flexibility, and be, be very facile with the notes in the scale.
So instead of practicing ♪ ♪, we want to change the intervals.
Use most of the range of your instrument.
Don't do it all within one octave.
♪ ♪ So you can see I'm rambling around.
And I'm seeing the shape of the scale, the C Minor scale, called the Dorian.
And I'm using different combinations of notes from that scale ♪ ♪.
I'm getting used to the sound of this scale.
As I mentioned before, there are ten scales that are the most commonly used.
And they're the ones that you really have to be ready to play, and have instant recall of, and be comfortable on.
So, that's a total of 120.
Now that sounds like a lot, but in fact many of these scales are closely related, so it's really not like learning 120 totally separate things.
So it goes quicker then you think.
There's sort of two ways to approach it.
One way is to be methodical about it, and say, well, I have 120 scales, so if I work on two scales a day in 60 days, I'll have gone through all of them.
I don't know anyone who's done it that way, to be honest, but it's certainly logical.
That is, every time they learn a new song, they look through the tune and see what chords, what chord scales are called for, and if there's going to be some new ones, in almost every new song you learn at first.
And so, you add a few more each time you learn a new song.
And eventually, you've pretty much covered all of them just by learning 25, 30, 40 songs over the next few months, or however long it takes you.
when you come to a chord symbol in a song, and you're not sure, you don't get an instant recall of what scale goes with it, remember that.
I mean here's a situation that happens to everybody when they're learning.
And I'm sure it's happened to you.
you're playing a new song, and the first chord is fine, it's a B flat chord, I know that one.
Then a C chord, I know what to do there.
And you see the problem coming up on the next page.
And this tempo is moving along, and you're getting closer and closer, and finally you're there.
And now what do you do?
There's this chord that you don't know the scale for.
You're not sure what to play.
Well, there's a couple of options, and it's sort of funny.
one option is you don't play that measure.
Take that moment to adjust the horn, or pause and rest.
and listen to the rest of the musicians, and see what notes they're playing, see if you can recognize notes and what it should sound like.
Alright and, again, listen to what the other players are playing, and the chords, and the support notes, and so on.
And find, you'll hear it maybe, oh I notice a C works.
When you recognize a chord as being unfamiliar, just make a mental note, the next time I practice, find the scale that goes with that chord.
And then, try to memorize it.
Now, let's talk a little more about how to do that.
We're going to play around on it in random combinations.
So that your brain remembers the, this combination of shape and sound.
So, that's what we're going to be doing.
Now, as I said, there are 120 theoretically possibilities, if you're talking about all 12 keys.
But you'll learn them fast enough once you start doing this with each new tune that you learn.
figure out the right scales, and then make sure that you've played them before, or make sure that you have the time to stop and learn them now.
There are three more scales that are very commonly used in jazz music and popular music.
And all three of them are used on dominant seven type harmonies.
So let's take a look at each one of these.
It's a Lydian scale, but instead of having the natural 7, it has a flat 7.
Well, that ninth, has been altered, been made half step lower, in order to make it sound more dissonant, and have a richer color.
So, think of it this way, I'm gonna walk you through each note of the scale.
Along with the basic chord outline, 1, 3, and 7th.
I'm gonna come to it in a minute and tell you one little oddity about the altered scale that you need to keep in mind.
But the third, of these additional scales and the last of the ten Is the Symmetrical Diminished.
As you might expect, it sounds like the diminished chord.
And in fact, it's made up, you could say, of two diminished scales combined.
It's almost the same.
We have the 5 and 6, so the bottom of the diminished scale, the symmetrical diminished scale is the same as the altered but the top notes are slightly different.
So those are the three and all three of these scales are used on dominant seven type harmonies.
Now, as I said, there's one more thing to point out about the altered scale.
That's what I call it.
As it turns out, the fifth of a chord is perfectly usable during an altered chord harmony and an altered scale.
It's not included because we have a complete sounding scale without the fifth.
So if we added it, It would just be an extra chromatic note in there.
And so, it was left out in terms of describing the official altered scale.
But the reason you need to know about the fifth being possibly included, is that you'll run into altered harmonies in songs.
And that'll be the fifth in the melody.
Obviously, called for by the composer and sounds good and it works.
So keep in mind, when in an altered harmony situation that, even though it isn't officially in the scale, it is also a perfectly usable note on an altered scale.
Okay, that's all ten scales, these commonly occurring scales that we need to know really well.
So, let's review what we're supposed to be doing with them.
We want to assimilate them using their two characteristics, the pattern that they make and the sound that they make.
Now, when I say pattern, It's the shape of the scale.
I play the saxophone.
Has a way of picturing groups of notes, whether it's a chord outline or a scale.
And I've often asked players of other instruments, in fact, how do they picture a scale or a group of notes?
And I'll tell you that most of them answer, they picture them on the piano keyboard, even if they don't really play the piano.
That seems to be a common way of thinking about them.
And some people, saxophone players for instance, tend to say I picture the fingering of running the scale, when I think of how do I picture a seven, eight note run of notes of scale.
However you do it, you will have some way of visualizing the scales and the shape that they have.
And you'll hear the sound of the scales.
So, with any new scale, Ramble around, make different combinations.
Speed is not an issue.
It doesn't matter if you can play them faster and faster and faster.
What matters is are you assimilating the memory of this group of notes and different ways to combine the notes in to different combinations.
So that's what you should be doing with every new song that you learn or practice.
Check out the chord symbols and make sure that you are familiar with the chord scale that goes with each one.
In addition, if you're playing, let's say this chord is an E flat minor seven, and the scale is the Dorian and you're playing around on it.
Be aware that it is an E-flat minor seven chord even though you're playing around on the scale cuz we have to actually be using not only the chord tones but the chord scale as we play it to a harmony.
Play the basic scale, and then start, Bouncing around playing different combinations.
So record that and upload it to the site.
And I'll see you next week.
This is week three and we're going to be talking about chord scales again, a kind of continuation of what we covered last week.
And especially how to go about memorizing them and learning them so that you can use as improvisers.
And that is choosing the right chord scale to fit each harmony as you come to it.
Now, normally you might think well, that, that's something I'll have to study for a bit.
I'll have to take the so, song home and play it for a while and work out what the right scales are.
But we don't want to have to do that.
We want to be able to play the song and solo on it if it's put in front of us, at a rehearsal or at a session or whatever.
Hi, I'm Gary Burton, welcome to my course Introduction to Improvisation.
And it's one of the mallet instruments like xylophone and marimba, only the vibraphone has metal keys.
And it was invented around 1930, so it's a fairly new instrument.
When I first started playing music, I wasn't too serious about it.
But when I discovered jazz at about age 13, I became very passionate about it.
And as you continue working on improvisation yourself I'm sure you will come to agree that it's a wonderful experience to make up the music as you go along and play it spontaneously.
I've had a wonderful career.
I travel around the world playing concerts and make records and I'm very grateful for the opportunities that have come my way.
I've also been very involved in music education.
And when it first became technically possible to teach music online, I was a very enthusiastic supporter of that as well.
And in fact, I created my own improvisation course for Berkeley College for their continuing education division.
It's called Gary Burton Jazz Improvisation.
I've been doing it for a while now, and I've learned a lot about how online teaching works.
I'll bring my experience and my knowledge to anyone who is interested here at Coursera.
Well, let's discuss how my course works and the kind of resources that you're going to need to complete the assignments.
And of course, the assignment will be directly related to that concept.
And a chance for you to show that you understand how it works and can incorporate it into your playing.
So, in some cases, homework may involve things that you do right on the computer screen.
And, in that case, when you're finished with it you'll have to scan it and send it back to the site as a PDF file.
So, you will need a scanner.
You will also need to record yourself playing, creating MP3 files of your playing.
And it doesn't have to be anything elaborate.
we are not looking for studio audio quality here, just so it's clear to listen to.
the simplest thing is to have a microphone and some basic recording software on your computer and you're in business.
And you will need to play along with it and record both.
And you can experiment a little bit to see where to place the mic.
Again, great audio is not a requirement as long as the music can be heard relatively clearly, that will be perfectly fine.
Some students are very technical and, equipped, and have much more sophisticated setups to do this.
It's not necessary.
I always get asked also about Notation Software.
you do not need Sibelius or the other kinds of music notation software to complete the assignments for the course.
You can use it if you wish, if you are very conversant in it and prefer writing that way, that's perfectly all right.
And again, don't feel like you have to go out, buy a new software, and learn how to use it, and so on.
these are the most universal.
Virtually, everybody's computer can open up those files.
If you record something in a wav file or a garage band file, a lot of students won't be able to see your work including me as well.
So, my advice is to stick the most universal files.
That's MP3 and MP4 when recording music.
That's all you need to do the assignment for this course.
If you haven't taken an online course before, you're in for some surprises.
The first thing you'll notice is there's a lot of individual choice and flexibility on your part.
And you can take days off when you need to and catch up a few days later.
And you also can go back and watch the instruction over and over again as much as you would like in order to feel you fully understand it.
It's a lot more flexible and personalized than a typical, traditional classroom setting.
In addition, there will be a whole new experience in how you interact with your fellow students.
I found teaching traditionally that the students often didn't talk to each other much at all unless they were just close friends with someone else in the class.
But in an online class, there's a lot of interaction for one thing, all the students get to see the homework and assignments of the other students.
So everybody can comment and share and communicate with each other about what they're learning and how they're going about doing the assignments.
And this interaction is one of the most important parts of online education.
And you will learn as much from your fellow students as you do from me, and that's a very healthy thing.
We are going to be critiquing each others work, we're gonna be talking about how to do things and how others have done them.
A lot of respect is appropriate, is called for in this kind of learning environment, and so keep that in mind.
Hi, and welcome again.
This is week two and the topic for this week is scales.
now, the first thing we see when we look at a piece of music is a cord symbol.
And we know usually most of us at this stage in our learning, know the basic notes of that chord.
So we know we know the, the triad and the, the seventh that makes up the basic sound.
And what you do in that case is you feature the chord tones and then you take a guess at filling in some other notes.
The problem is you can't play a whole melody with just the four notes of an arpeggio.
You need more notes to make melodies.
Good at doing this.
In fact, a great musician I played with for several years who was a wonderful player, Stan Getz the saxophone player.
That's how he functioned as an improviser.
He had never really studied music theory much, didn't know much about chords.
He just knew the basic triad for each chord symbol that he saw.
And he would start with those notes.
But we don't want to settle for that.
We want to have a full knowledge of the available notes during any given harmony.
So, for that we need a scale rather than just a chord outline.
The topic today is scales, specifically what we call chord scales in the jazz world.
And, if you've looked at some books on improvisation you might have come across some that included page after page after page of scales with exotic sounding names.
the truth is, there is a small number of scales that cover most situations.
there are ten of them, in fact, that are the most commonly used scales.
And 90% of the chords and scales that you come across in a tune, a standard tune or a jazz tune will use one of those ten scales.
So, they're the ones that you really need to have under your fingers, that you have to have memorized and are able to play on them.
And we're going to look at each of those ten scales today, and what their characteristics are and how to organize them and think of them.
The goal is to have them memorized to the point that you have instant recall.
Now you probably already have instant recall on a few scales.
And you don't have to stop and think what the notes are in that scale as you play it on your instrument you're just used to playing it.
We can memorize scales in two ways.
There are two characteristics that our memory uses.
One is the shape that the scale makes in terms of the pattern.
And it doesn't matter whether you play a keyboard instrument like mine, or the piano.
But on any instrument, there's kind of a, a kind of a shape and pattern to a scale run.
And we also recognize the sound of it when we hear it.
when it, you know, we associate the sound and the shape of the scale and that's what allows us to have instant recall of it.
Chords change every couple of seconds there is not time for conscious, you know, study of arguing with yourself about can I use the B flat or not and so on.
I mean, if you have to think at all about the scale as you're playing, you won't be able to keep up with the music.
So that's the goal is to get instant recall.
Now, in the classical world, ♪ ♪ the way you practice scales is usually going up and down.
But that's not much help to a jazz musician, to an improvisor.
We need to make melodies out of that scale.
♪ ♪ Which means moving to different intervals, and different groupings of notes within that scale.
So we want to have flexibility, and be, be very facile with the notes in the scale.
So instead of practicing ♪ ♪, we want to change the intervals.
Use most of the range of your instrument.
Don't do it all within one octave.
♪ ♪ So you can see I'm rambling around.
And I'm seeing the shape of the scale, the C Minor scale, called the Dorian.
And I'm using different combinations of notes from that scale ♪ ♪.
I'm getting used to the sound of this scale.
As I mentioned before, there are ten scales that are the most commonly used.
And they're the ones that you really have to be ready to play, and have instant recall of, and be comfortable on.
So, that's a total of 120.
Now that sounds like a lot, but in fact many of these scales are closely related, so it's really not like learning 120 totally separate things.
So it goes quicker then you think.
There's sort of two ways to approach it.
One way is to be methodical about it, and say, well, I have 120 scales, so if I work on two scales a day in 60 days, I'll have gone through all of them.
I don't know anyone who's done it that way, to be honest, but it's certainly logical.
That is, every time they learn a new song, they look through the tune and see what chords, what chord scales are called for, and if there's going to be some new ones, in almost every new song you learn at first.
And so, you add a few more each time you learn a new song.
And eventually, you've pretty much covered all of them just by learning 25, 30, 40 songs over the next few months, or however long it takes you.
when you come to a chord symbol in a song, and you're not sure, you don't get an instant recall of what scale goes with it, remember that.
I mean here's a situation that happens to everybody when they're learning.
And I'm sure it's happened to you.
you're playing a new song, and the first chord is fine, it's a B flat chord, I know that one.
Then a C chord, I know what to do there.
And you see the problem coming up on the next page.
And this tempo is moving along, and you're getting closer and closer, and finally you're there.
And now what do you do?
There's this chord that you don't know the scale for.
You're not sure what to play.
Well, there's a couple of options, and it's sort of funny.
one option is you don't play that measure.
Take that moment to adjust the horn, or pause and rest.
and listen to the rest of the musicians, and see what notes they're playing, see if you can recognize notes and what it should sound like.
Alright and, again, listen to what the other players are playing, and the chords, and the support notes, and so on.
And find, you'll hear it maybe, oh I notice a C works.
When you recognize a chord as being unfamiliar, just make a mental note, the next time I practice, find the scale that goes with that chord.
And then, try to memorize it.
Now, let's talk a little more about how to do that.
We're going to play around on it in random combinations.
So that your brain remembers the, this combination of shape and sound.
So, that's what we're going to be doing.
Now, as I said, there are 120 theoretically possibilities, if you're talking about all 12 keys.
But you'll learn them fast enough once you start doing this with each new tune that you learn.
figure out the right scales, and then make sure that you've played them before, or make sure that you have the time to stop and learn them now.
There are three more scales that are very commonly used in jazz music and popular music.
And all three of them are used on dominant seven type harmonies.
So let's take a look at each one of these.
It's a Lydian scale, but instead of having the natural 7, it has a flat 7.
Well, that ninth, has been altered, been made half step lower, in order to make it sound more dissonant, and have a richer color.
So, think of it this way, I'm gonna walk you through each note of the scale.
Along with the basic chord outline, 1, 3, and 7th.
I'm gonna come to it in a minute and tell you one little oddity about the altered scale that you need to keep in mind.
But the third, of these additional scales and the last of the ten Is the Symmetrical Diminished.
As you might expect, it sounds like the diminished chord.
And in fact, it's made up, you could say, of two diminished scales combined.
It's almost the same.
We have the 5 and 6, so the bottom of the diminished scale, the symmetrical diminished scale is the same as the altered but the top notes are slightly different.
So those are the three and all three of these scales are used on dominant seven type harmonies.
Now, as I said, there's one more thing to point out about the altered scale.
That's what I call it.
As it turns out, the fifth of a chord is perfectly usable during an altered chord harmony and an altered scale.
It's not included because we have a complete sounding scale without the fifth.
So if we added it, It would just be an extra chromatic note in there.
And so, it was left out in terms of describing the official altered scale.
But the reason you need to know about the fifth being possibly included, is that you'll run into altered harmonies in songs.
And that'll be the fifth in the melody.
Obviously, called for by the composer and sounds good and it works.
So keep in mind, when in an altered harmony situation that, even though it isn't officially in the scale, it is also a perfectly usable note on an altered scale.
Okay, that's all ten scales, these commonly occurring scales that we need to know really well.
So, let's review what we're supposed to be doing with them.
We want to assimilate them using their two characteristics, the pattern that they make and the sound that they make.
Now, when I say pattern, It's the shape of the scale.
I play the saxophone.
Has a way of picturing groups of notes, whether it's a chord outline or a scale.
And I've often asked players of other instruments, in fact, how do they picture a scale or a group of notes?
And I'll tell you that most of them answer, they picture them on the piano keyboard, even if they don't really play the piano.
That seems to be a common way of thinking about them.
And some people, saxophone players for instance, tend to say I picture the fingering of running the scale, when I think of how do I picture a seven, eight note run of notes of scale.
However you do it, you will have some way of visualizing the scales and the shape that they have.
And you'll hear the sound of the scales.
So, with any new scale, Ramble around, make different combinations.
Speed is not an issue.
It doesn't matter if you can play them faster and faster and faster.
What matters is are you assimilating the memory of this group of notes and different ways to combine the notes in to different combinations.
So that's what you should be doing with every new song that you learn or practice.
Check out the chord symbols and make sure that you are familiar with the chord scale that goes with each one.
In addition, if you're playing, let's say this chord is an E flat minor seven, and the scale is the Dorian and you're playing around on it.
Be aware that it is an E-flat minor seven chord even though you're playing around on the scale cuz we have to actually be using not only the chord tones but the chord scale as we play it to a harmony.
Play the basic scale, and then start, Bouncing around playing different combinations.
So record that and upload it to the site.
And I'll see you next week.
This is week three and we're going to be talking about chord scales again, a kind of continuation of what we covered last week.
And especially how to go about memorizing them and learning them so that you can use as improvisers.
And that is choosing the right chord scale to fit each harmony as you come to it.
Now, normally you might think well, that, that's something I'll have to study for a bit.
I'll have to take the so, song home and play it for a while and work out what the right scales are.
But we don't want to have to do that.
We want to be able to play the song and solo on it if it's put in front of us, at a rehearsal or at a session or whatever.
Over the next few months we will take a closer look at the collection, processing and communication of accounting information via financial statements, and their related disclosures.
This course is the first course in a two course sequence that focus on the accounting concepts, principles and theory with an emphasis on the issues that arise in the application of these concepts.
I'm excited to share this knowledge with you, so let's get started.
To start off, let's briefly review our Learning Objectives for this week's module.
First thing would be for me to introduce myself.
My name is Greg Davis, I'll be your instructor for this specialization over the next few months.
Based on my experience of over three decades, I plan to share lots of real world examples with you.
Particularly from my over 20 years experience of working at Hershey's Entertainment Resorts in iconic Hershey, Pennsylvania.
Next, we will discuss the concepts of GAAP, generally accepted accounting principles, versus IFRS, which is International Financial Reporting Standards, and their related convergence issues.
And in our final lesson for this week's module, we're going to talk about some of the most important accounting standard or GAAP assumptions.
Welcome to our second week with Coursera, on developing innovative ideas from new companies.
We're excited to explore with you this week entrepreneur motivations and behaviors.
And we're coming to you from the Hinman CEOs Program at the University of Maryland.
Hinman CEOs is a living-learning entrepreneurship program, where we have a host of student from many different majors that have come together to learn about entrepreneurial mind set as well as the motivations, behaviors.
Looking at customers in industries, developing their financial plans, much like you are.
And what we do with these students is we take them through a program, whereby they're able to develop ideas.
They're able to do prototyping and they're able to attain to develop, and launch new ventures.
Within the Hinman CEOs residence, it is as much a technology incubator as it is a residential community.
And what we mean by that, students are working together with room mates, with hall mates and with class mates, on developing their innovative ideas for new companies.
So this is the typical classroom environment for us, it's very different than the theater style seating that you may see elsewhere.
And we as faculty are circulating throughout the class working with them, providing feedback and helping them develop their ideas.
We also work with them in providing some prototyping facilities.
And so via this 3-D printer, you can see that they are really bringing their ideas into action and are making their dreams a reality.
Students are working a variety of different areas to include engineering and education concepts.
They're working in entertainment and building software platforms to teach music theory and music practice.
They're also working in the healthcare industry and developing a host of different solutions in those areas, to provide more affordable and more accessible health care.
And communications, is also a strong element that is well represented within our program as well.
Welcome to our second week with Coursera, on developing innovative ideas from new companies.
We're excited to explore with you this week entrepreneur motivations and behaviors.
And we're coming to you from the Hinman CEOs Program at the University of Maryland.
Hinman CEOs is a living-learning entrepreneurship program, where we have a host of student from many different majors that have come together to learn about entrepreneurial mind set as well as the motivations, behaviors.
Looking at customers in industries, developing their financial plans, much like you are.
And what we do with these students is we take them through a program, whereby they're able to develop ideas.
They're able to do prototyping and they're able to attain to develop, and launch new ventures.
Within the Hinman CEOs residence, it is as much a technology incubator as it is a residential community.
And what we mean by that, students are working together with room mates, with hall mates and with class mates, on developing their innovative ideas for new companies.
So this is the typical classroom environment for us, it's very different than the theater style seating that you may see elsewhere.
And we as faculty are circulating throughout the class working with them, providing feedback and helping them develop their ideas.
We also work with them in providing some prototyping facilities.
And so via this 3-D printer, you can see that they are really bringing their ideas into action and are making their dreams a reality.
Students are working a variety of different areas to include engineering and education concepts.
They're working in entertainment and building software platforms to teach music theory and music practice.
They're also working in the healthcare industry and developing a host of different solutions in those areas, to provide more affordable and more accessible health care.
And communications, is also a strong element that is well represented within our program as well.
Hello, everyone, my name's Eunjung Grace.
I'm a faculty member at the College of Education, at the University of Illinois at Urbana Champaign.
I would like to welcome all of you to the exciting world of instructional design.
I've studied learning design and technology in both South Korea and United States before working in academia.
This course is the first course of the instructional design Master Track Certificate, MTC, offered by the College of Education at the University of Illinois at Urbana-Champaign.
This certificate is created for those who would like to learn more about how to tackle real world performance challenges with innovative and creative educational solutions.
In the first course we will learn how to design instruction and training, and in the second course, we'll learn learning technologies.
What you will be learning in the full version of the course.
In addition to myself, we have a number of contributors from the University of Illinois, who will share their expertise relevant to instructional design in the video lectures.
You will get to meet them each week in different videos.
I'm going to show you the use of the Michigan Terminal System, a large computing system at the University of Michigan Computing Center, using the IBM Model 36067.
This system can be used by a telephone system anywhere in the world, as long as we can dial directly into the computer.
We start by pushing the Originate button, which turns on the teletype.
Now, there is a handset which is available with every teletype system.
You can dial this number, if you like, with the handset.
Either one works, but as soon as you are connected to the computer, do not use the handset for any purpose at all.
Now, I'll push the Originate button.
I can control the speaker volume with this little knob, and so you can hear it.
Now, I will dial a number, 763-0300, or in a Centrex system just 30300.
The response from the computer is the identification of the system.
Now I must sign on to the computer and identify myself.
The number sign at the beginning of the line is the indication that the Michigan Terminal System is waiting for me to communicate something to it.
The first thing I must do is issue the sign on command.
All commands in the system start with a dollar sign.
Now, the keyboard on the teletype is very much like the keyboard of a typewriter, including a Shift key for the characters on the top of the key.
We do not have upper and lower case letters, however.
So the Shift key is only used to get an additional set of characters, and in this case the dollar sign is the character above the number four.
Now, I will use the word SIGN ON, which is the official command.
There must be a space, at least one, after every command.
And now I will give my own personal computing center number, which happens to be W010.
Each user of this system is issued a computing center identification number, through his instructor if he's a student, or through the department for faculty.
But I can, if I see any errors in it, do some editing and correcting.
I am satisfied with this line and now I will give the end-of-line character, which must be given after every line and I will remind you each time that I am doing it for a while.
The character for ending a line uses the Control key on the keyboard which is a special key which indicates that I want to use even additional characters besides those that are added by the use of the Shift key.
And while I hold it down, I can hit one of a number of other keys.
And in this case, I will use the Control with the letter Q.
It's possible to use the letter S also, but that's right next to another key which disconnects the teletype.
I will use Control and Q to terminate the line.
And now, I'm asked to give my private password.
I'll give an incorrect password, just some nonsense characters, and of course end of line because I must indicate that I am satisfied with that.
To turn off printing we use this switch which is labeled HDX and FDX, for Half Duplex and Full Duplex.
If I push it to Full Duplex, printing is suppressed.
And now I will give my correct password, push the Half Duplex again, and end-of-line character Control-Q, and it is accepted by the system.
The information that's coming out here is time and date of the previous sign on and time and date of this sign on.
So, I can check if anyone did use my number since I myself did use it.
Now, one of the first things I will do is to change my password having signed on correctly, I may be concerned that someone may have acquired my password and I will issue a command that says $ SET.
Which is used for setting various things in the system, but in this case, I want to set my password to something else.
At least one blank after each command.
PW is the name of my password, equals and no blank spaces in here, and now I will turn off printing again, give my new password, and terminate the line.
Well now suppose we wish to start using the computer and we wish to enter some information into a file.
I can have a number of private files, each one with a name that I invent, that's useful to me.
And I will attempt to create a new file in this case by issuing a command, Create.
And I think I will illustrate here the fact that only the first three letters of every command are necessary.
So, CREATE, space, let's use the name EX.
To show what names I do have, in case I've forgotten, let us run a special program that is available from the Computing Center Library, called Catalog.
So, I will say, run that program.
I'll explain the asterisk in a moment.
Now, it is listing out all the files that I have under my private number.
Now, the internal form of a name like EX, is really W010EX.
He can't do that without knowing my password.
Thus, I'm protected as long as I protect my password, which I do by changing it often.
Now we see the names of the various files that I had, including VIDEOTAPE, which was used to print out the titles to this tape.
And I did want to create a file.
I'd better think of a name that isn't in there.
So I'll say CREATE X1.
Now space has to be found on the disk storage of the computer for this.
It has to be entered into the system catalog of files.
The blank spaces after X1 remind me that I could have up to twelve characters in a name.
I didn't choose to in this case.
Now I would like to enter some lines into this file, and the lines will be numbered.
So we'll give a command Number, $ N-U-M, and if I terminated the line at this point, it would number them starting with one in steps of one.
But I will indicate in this case starting with line one but will use steps of three.
Let's look at how we might make corrections here.
One way is to delete the whole line and start over.
This inserts a delete line character into the line.
If I like I can continue with with the new line that I would like to have go in at that point, and I'll do that in this case.
And end of line.
Notice that since I asked for steps of three, it is now asking for line four.
Let me put some more information in here.
And I made another mistake.
Well, again I could use Control-N if I like, and this time I'll terminate the line at that point.
And I get an indication that the line was deleted.
I didn't get the indication in the previous case because I just continued with the new form of the line.
Well, let me put the line in again.
And I made another mistake.
Now in this case I really need to only backspace a character and continue.
Let me backspace two characters to show how that could work.
If I give two of them, I have now back spaced twice.
And I can start the word come again.
Notice that the teletype does not physically backspace as a typewriter does.
The backspace character is inserted in the line, and when the line is processed by the computer, it is interpreted to delete the previous characters.
We don't see that on the teletype itself.
All right, and now, let me turn off the numbering, so that I can begin to do some other things with it.
That turns off the numbering and it's waiting for me to do something.
To protect myself from doing something inadvertently and damaging the information in the file, I will release it from being the active file by giving the command RELEASE.
Now, for instance, if I chose to put a line in like two, I am protected because I don't have any active files.
Now, since we did do a fair amount of modification for the information in X1, let us print out or list the information in the file to see what actually got in.
Now, let me show how we can put a line in if we want to make a modification.
I can put a line in with a number like two, which will go in the right place.
I could even use 2.5.
So, let us make X1 the active file again and put a line 2.5 into that file.
X1 was active the first time because it was created with the CREATE command.
I can't do that now.
But I can make it the active file by using a command GET.
It's acknowledged, and now X1 is probably the active file.
Now let's verify that it actually got in there.
I don't want to list the whole file X1, it could be a very long file.
What I'd like to do is list a part of the file.
Let's say, all the lines in the number range one through five.
Notice that the line 2.5 was inserted in the proper place according to its line number.
And the end of file comment here, even though we didn't get line seven, has to do with the fact that the name X1(1,5) named a new file which was in fact made up of parts of an old file.
And when it came to the end of that file, it indicated end of file.
There are other ways to make new files out of old files.
We can use a process called Explicit Concatenation.
To do that, let me, for example, list a file made up of pieces of old files.
I will say, LIST.
I have a long file whose name is EX.
Oh, that's too long.
Let's back, cancel that out, 27.
Now, with the plus sign, I explicitly append to the end of those lines or concatenate to them.
Let's say, lines 53 and 54.
Notice that if it's the same file again, I don't need the name EX again.
Now, I will concatenate some lines directly from my terminal.
So, I need a name of my terminal as a file.
That is the name of my terminal as an input file.
And then I will, maybe, take some more lines from file EX.
If I just give one number, it means all the lines from 100 on.
And that's a long file, and so in fact, we will see a fair amount of typing at that point.
There is a special button on the teletype called the Break button.
It is located in various places on different models of the teletype.
In this case, it is right here.
Now when I want to interrupt, as we will see, whatever is going on, I will push the Break button.
At that point, because of the way the teletype is built, the keyboard locks.
And I must, then, push a button which occurs in another part of the teletype, called the Break Release button.
This button will light, and when I push it, it will then unlock the keyboard.
Now, let's do it and we'll see how the break process works.
Line 25, 26, and 27.
It is now waiting for lines from the file called SOURCE.
And so I must give a line.
And since I'm listing things on this terminal, when I give a line as input, it'll come right back out and be listed, as if it were in that file.
It's the first line in that file.
And then I will get an acknowledgement that it's gone in the file.
And now it continues to line 100 of that old file, EX.
That's an interesting line.
I get a response from the computer that attention was indicated.
Now, I will hit the Break Release button to free up the keyboard.
When I push it, it goes out, and now I can do something from the keyboard again.
The number sign indicates that after an interruption by the Break button, the system is ready to have me tell it what to do again.
Now, I'm going to illustrate the use of one of our language processors in the system, a language called PIL, P-I-L, for Pittsburgh Interpretive Language.
And PIL is stored, the processor for the language is stored, in a file whose name is asterisk P-I-L.
I will run that program, that is the PIL program itself, by using the RUN command and the name of the file in which the program is found.
I could indicate that the source of input for PIL is from some other file and have it read that file directly.
We will see the comment "execution begins" when the loader finds that program and loads it and begins it, and now PIL itself is identifying itself as ready to go.
I will only introduce some of the features of the language.
A full description of the language, as well as information about using the teletype, is available at the bookstores in a small booklet called Introduction to PIL in MTS, written by Professor Larry Flanagan of the Computing Center.
Now let me illustrate some of the features of the PIL language, but only a few of them.
Three plus four minus two should come out five.
I can say type the square root of 4.12345.
I can ask for certain trigonometric functions like the sine of the square root of, notice I have a different way of writing square root here.
It's not completely free English however.
And these are the only two ways.
Now I can ask for, for instance, the value of X plus one.
And so I can set, there's another PIL language command, SET X equal to three.
Okay.
And for that we give a line number, which consists of a number in front of a decimal point, that's called a Part Number, and then the Step Number.
I might say Step 1.2, which I might give as DEMAND Y and Z.
Now that line was not executed immediately, because with a line number, it indicates it to be put away to become part of a packaged program.
So now, we have a program which will start off by demanding two numbers from me, it will type out their sum and each of them, and go back and demand two numbers again.
Now in order to actually carry out this computation, I have to say DO that set of instructions.
Since all these began with one, this is called Part 1.
We could have Part 2, etc.
So I will say, DO Part 1.
Seven, nine, and we see we can do various things.
Now, how do I stop this, because it's always coming back to ask for more?
Well, in PIL, I could give a break.
End of line, and that indicates to PIL that I interrupted the program at step 1.2 where it was asking for input.
Incidentally, if I wanted to see what step 1.2 was out of some large program I could say TYPE Part 1, and it'll tell me what Part 1 was.
Well, there are various things we can do in this language.
I can say FOR, and without a line number it'll be executed immediately.
If it goes from one to five by twos, it'll go in one, three, and five.
I plus one should be two, four, six.
So let's see if it is.
And now PIL is waiting for something else.
Well, at this point, I will stop illustrating PIL and go back to the MTS system.
Be careful to distinguish that I have been running a particular program in the system.
All of the file manipulation and editing and correction were at the level of the system itself.
If I am talking now to PIL, if I want to return to the system to, for example, sign off, I must go back up to level of the system itself.
I do that by telling PIL the command SYSTEM.
Let us review the commands we have had so far.
I have a file which has the various commands in them.
And if I copy that file, we should see some that we've seen, and there will be a couple that we have not yet seen.
SIGN ON.
We have seen SET and RUN.
But the main use of COPY is to make a copy of one file into another one, perhaps a temporary file to be able to make changes in it.
So, for example, I will make a copy of the file X1.
I will copy it to a temporary file, whose name will be minus something, minus J.
Now, the minus sign indicates that this file is to be created just because I've mentioned this now.
Permanent files, whose names don't begin with minus, such as X1, are not destroyed.
I could come back next week and find X1 still intact.
It takes a little while to create a temporary file because there is checking to make sure that I don't have one already by that name.
Now, -J will be destroyed automatically but, well, before we get to that, let's copy -J back into X1.
Any old lines will still be there.
If I don't want to have a mixture of old and new I will do well to empty out the contents of X1 before I copy the new form of it back in.
And so I will use a new command called EMPTY X1.
This doesn't destroy the file, it only erases any contents that it has.
And now, this is a very important point.
We don't like to destroy information unless we are sure that it is the right information to be destroyed.
I'm being asked to confirm that it is X1 that I want to empty, in this case.
An exclamation mark would do, or O period, K period will work.
But anything else will not.
So now X1 is, in fact, emptied.
If I wanted to completely get rid of the file, I would say DESTROY, as I will after we Copy -J back into it.
And now I would have a new copy if I had made modifications to -J.
Now, I will say DESTROY X1.
As soon as it comes back, I will sign off from the computer.
I will say CANCEL in this case.
Now, I will sign off from the computer by issuing the command SIGN OFF.
We have used thirteen seconds in this case of computer time.
And then there's various other information.
This presentation has been designed to make your work on the teletype terminals easier.
If you have any questions, ask your instructor, or someone in the counseling room at the computing center.
Since this film was produced, some changes have been made in the MTS system, three of which we now call to your attention.
Second, while Control-Q may still be used to signal the end of the input line, the Return key on the right side of the keyboard may also be used and it is usually more convenient.
Use the Return key to end the line.
Third, when dialing in, if nothing prints on the teletype within a few seconds after the telephone connection has been made, type the word GO.
The word GO, and the Return key.
Thank you.
Hi, I'm Paul Bloom, and I'm delighted to welcome you to Introduction to Psychology.
It is one of my favorite courses to teach.
But I'm particularly thrilled to be able now to present the material of intro psych to a broader audience.
Now, there's all different ways you could take this course.
Electrodes can be listened to or watched out of order.
But what I would suggest if you can is treat it like a course.
Exams are not meant to be difficult, but they are meant to sort of tap your understanding of the material as you go through it.
Then, if you want to move it up one level, you can do the associated readings.
If you do lectures and you do the readings, then you can legitimately say you took intro to psych and you'll have a tremendous background.
The course covers every important aspect of the science of the mind.
I start off with the brain asking the question of how this physical lump of me gives rise to mental life.
We talk about Freud and Skinner looking at the historical foundations of psychology.
We talk about how children develop including some research I've done on that building over there.
We talk about how we learn to speak.
We target the emotions, love, lust, anger, kindness, and hatred.
We explore how we interact socially, how prejudices form, what we like about one another.
We'll talk about differences, how we're different, why we're different, what this means for us, and we'll talk about clinical disorders like depression and anxiety.
What disorders many of you suffer from and what causes them and what can cure them, and we'll end with an overview about happiness.
What the scientific study of psychology tells us about how to be happy.
I'm admittedly biased, but I think psychology is most interesting topic around.
So, I'm delighted to have you take this course.
I said before that if you've heard of one psychologist, it's going to be Sigmund Freud.
But if you've heard of developmental psychologists, it's probably going to be Jean Piaget.
Jean Piaget was the founder of the modern study of developmental psychology.
A lot of the methods and observations and rich theories that we now build from came out from his work.
He had a vibrant school.
He had many students, and he had a really interesting influence on our field.
And his research program was genetic epistemology.
And one way to put it, which I think is admittedly too crude, but we'll try this out, is that Jean Piaget ultimately wasn't interested that much in children.
Rather, he was interested in the development of knowledge in the human species.
And the way he pursued that interest, though, because you can't study the human species, it's not in front of you, you have to infer it through other sources, is to look at it in individual children.
The idea that John Piaget believed is that, well, to put it in a very snooty phrase, ontogeny recapitulates phylogeny.
And you can forget the phrase, but what the idea would mean is that you can see the development of the species is repeated, recapitulated, in the development of every individual.
So what did Jean Piaget have to say?
Well, he thought of children as active thinkers.
He may call them little scientists trying to make sense of the world.
So you could already see that although Piaget was in some way had views congenial to those of empiricists with his emphasis on learning, he is already departing from them in his believe that there could be mental structures in the head.
And for Piaget, there were two psychological mechanisms that lead to the transformation of these schemas.
And to sometimes to the creation of new schemas.
One is assimilation.
So assimilation is the process of taking in new information and new experiences and matching it up with an already existing schema.
And accommodation is the process by which existing schemas are changed, or new schemas are created, in order to fit the new information and new experience.
So a child who has to suck on his rattle or his toes is going to do so in a somewhat different way than sucking on his mother's breast.
And that's a very concrete, maybe not so interesting example.
So that there are schemas having to do with objects or number or people.
And the baby's understanding, ultimately the child's understanding, get transformed as a result of the process of assimilation and accommodation.
Now, Piaget's method was to ask children, was to talk to children.
He has wonderful interviews with children where he would ask them to solve problems, or deal with different situations.
So he's like a nativist suggesting that children know it all from the start.
But nor is he like an empiricist or a behaviorist who viewed learning simply as the accumulation of new knowledge.
Or for the behaviorist, new conditioning and new responses.
Rather, Piaget believed that children have theories of the world, and so do we.
And children's theories are very different from ours.
And so, he proposed that theories transform, and that you could capture development in terms of a series of stages.
Each stage corresponding to a different style of thinking, a different way of making sense of how the world works.
But Freud theory was psychosexual.
Piaget's theory is sort of far more intellectual, far more having to do with styles of reasoning.
And in my view, has far more scientific grounding.
Welcome to this new MOOC, an Intuitive Introduction to Probability, from the University of Zurich and Coursera.
My name is Karl Schmedders, I'm your instructor in this class.
I'm a Professor of Quantitative Business Administration at the University of Zurich.
And I really want to get you excited about probabilistic thinking in this MOOC, I hate probability.
You won't believe how often I've heard those words from my students in the past.
And interestingly, if you Google I Hate Probability you will be surprised by the number of hits you find and the number of blogs on this particular topic.
Now, all of us have had bad experience in probabilistic, or statistical, classes.
Another student said, I don't need probability, I have a good gut feeling to make decisions.
Now instead, I really want you to get excited about probabilistic thinking.
And I want to show you many cool applications of probability and other applications of probability in everyday life.
Let's think about this.
How often do you see probabilities in your life?
How should I think about it?
Should I trust that probability?
How should I react on this probability?
Last year I had a surgery, and afterwards, my surgeon told me, Karl, as a result of your condition, your probability of getting cancer is tenfold.
But don't worry, it's still small.
How should I feel about this?
How should this affect my lifestyle?
This past summer, 2016, there was an infamous Brexit vote in the United Kingdom.
Brexit is becoming more likely, it's less likely, the stock market thinks the probability is this much.
Or the opinion post says the probability of Brexit is shrinking.
Another very important public policy issue where probabilities were talked about over and over in the weeks running up to the vote.
Those of you who, have flown in the past or have been on airplanes, you may have noticed that the airlines overbook their flights.
They sell 400 tickets even though there are only 300 seats on an airplane.
Why are they doing it?
I will explain to you how simple, probabilistic thinking is behind the airline's behavior.
Those of you who invest money in the stock or bond market, or in new ventures, may have thought about how risky is this investment?
Again, that's a probabilistic concept of riskiness, or volatility.
Why are they sending you this particular advertisement?
Again, it goes back to probability, and we will talk about this.
Even in the court, we all have heard in movies, beyond any reasonable level of doubt, what is that?
Another probabilistic statement, and I will show you some interesting thought provoking examples of using probability in the course.
So, we really see that probability is everywhere in our daily lives.
Now, if you decide to take this class, I have a favor to ask from you.
I realize many of us, me included Had very frustrating experiences with probability in the past.
Give me a chance to get you exciting, and to show you my enthusiasm about probability.
So please, have an open mind.
My TA, Jose, and I, will show you various little examples.
So, that's important to me try to have some fun.
And finally, contact us with questions into the forum, there are many people here who want to help you, Jose and me included, and so that we have a fun and fruitful experience here in this new MOOC.
So we want to talk about probabilities.
Before we get into formulas and calculations, it's really worthwhile to think about what is a probability and how do we define probability.
Interestingly, there's not just one definition of probability.
There are three widely accepted definitions of probability.
And so before we look at some slides and examples, let's talk about the three definitions.
It's the one that we use when we play games with cards or with dice or if you go to the casino.
We see there are three black cards and then there's the ace of hearts.
And now, if I asked you what's the question, if I shuffle those cards and pull a card, what's the probability this is the ace of hearts?
This particular definition is very limited.
It's very simple, intuitive, maybe that's what you saw in high school or college or other classes.
And we like it because it's so easy.
But frankly, in everyday decision making, it's utterly useless.
The reason is it's very limited, it requires that all outcomes like in these cards, all four cards are equally likely and we can easily agree on the probabilities.
It's called the empirical definition of probability, also the definition according to relative frequencies.
What's that?
In those situations, we look at past data.
For example, before a pharmaceutical company can bring a new drug to market, it has to do a lot of tests.
The idea behind these tests is now to assess the probability that this new drug will help a patient with a particular condition.
We also want to assess the probability that there will be side effects.
So what does a pharmaceutical company do?
It gives the drug in some test to patients and then it checks out, do the patients feel better?
And based on this data, it then determines probabilities, empirical frequencies that it has seen in the past in the trials, to assess the probability of side effects.
Similarly, when we look at stock market data, past data, to say something about the future performance of a particular investment, then we also essentially talk about the relative frequency definition.
We look at past data, and from those past data points, we derive assessments for the probabilities.
That's the second definition.
Again, the empirical probability definition or relative frequency definition.
But even that definition is not always helpful.
What do you do when there is no past data, when you're in an utterly new situation?
For example, when Apple came out with the iPad, they didn't have past data on iPad sales.
So the company couldn't look at past data.
And it wasn't just a one in four chance, because it was unclear what could happen in the market.
At this point they needed the third definition, the subjective probability definition.
The company had to assess the likelihood of success, the likelihood of failure, and based on that, make the decision whether to bring the product to market or not.
And that's the third definition that occasionally we have to use.
Based on perhaps my gut feeling or my life experience, I assess uncertain situation without data, and without the easy counting that I can do with cards.
To summarize, the key takeaways of this first lesson.
There are three very different definitions of probability.
One, the first one, the easiest one, the exact definition that we use when we play cards.
Second, if we have lots of data available and we think this past data is relevant for a probabilistic assessment, we use the relative frequency definition.
And finally, the third definition, if I don't even have data, the subjective probability definition.
In the next lesson, we will define these three concepts more precisely using some mathematical language.
Thank you, and please come back to the next classs.
Hi, I'm Gary Burton, welcome to my course Introduction to Improvisation.
And it's one of the mallet instruments like xylophone and marimba, only the vibraphone has metal keys.
And it was invented around 1930, so it's a fairly new instrument.
When I first started playing music, I wasn't too serious about it.
But when I discovered jazz at about age 13, I became very passionate about it.
And as you continue working on improvisation yourself I'm sure you will come to agree that it's a wonderful experience to make up the music as you go along and play it spontaneously.
I've had a wonderful career.
I travel around the world playing concerts and make records and I'm very grateful for the opportunities that have come my way.
I've also been very involved in music education.
And when it first became technically possible to teach music online, I was a very enthusiastic supporter of that as well.
And in fact, I created my own improvisation course for Berkeley College for their continuing education division.
It's called Gary Burton Jazz Improvisation.
I've been doing it for a while now, and I've learned a lot about how online teaching works.
I'll bring my experience and my knowledge to anyone who is interested here at Coursera.
If you haven't taken an online course before, you're in for some surprises.
The first thing you'll notice is there's a lot of individual choice and flexibility on your part.
And you can take days off when you need to and catch up a few days later.
And you also can go back and watch the instruction over and over again as much as you would like in order to feel you fully understand it.
It's a lot more flexible and personalized than a typical, traditional classroom setting.
In addition, there will be a whole new experience in how you interact with your fellow students.
I found teaching traditionally that the students often didn't talk to each other much at all unless they were just close friends with someone else in the class.
But in an online class, there's a lot of interaction for one thing, all the students get to see the homework and assignments of the other students.
So everybody can comment and share and communicate with each other about what they're learning and how they're going about doing the assignments.
And this interaction is one of the most important parts of online education.
And you will learn as much from your fellow students as you do from me, and that's a very healthy thing.
We are going to be critiquing each others work, we're gonna be talking about how to do things and how others have done them.
A lot of respect is appropriate, is called for in this kind of learning environment, and so keep that in mind.
Well, let's discuss how my course works and the kind of resources that you're going to need to complete the assignments.
And of course, the assignment will be directly related to that concept.
And a chance for you to show that you understand how it works and can incorporate it into your playing.
So, in some cases, homework may involve things that you do right on the computer screen.
And, in that case, when you're finished with it you'll have to scan it and send it back to the site as a PDF file.
So, you will need a scanner.
You will also need to record yourself playing, creating MP3 files of your playing.
And it doesn't have to be anything elaborate.
we are not looking for studio audio quality here, just so it's clear to listen to.
the simplest thing is to have a microphone and some basic recording software on your computer and you're in business.
And you will need to play along with it and record both.
And you can experiment a little bit to see where to place the mic.
Again, great audio is not a requirement as long as the music can be heard relatively clearly, that will be perfectly fine.
Some students are very technical and, equipped, and have much more sophisticated setups to do this.
It's not necessary.
I always get asked also about Notation Software.
you do not need Sibelius or the other kinds of music notation software to complete the assignments for the course.
You can use it if you wish, if you are very conversant in it and prefer writing that way, that's perfectly all right.
And again, don't feel like you have to go out, buy a new software, and learn how to use it, and so on.
these are the most universal.
Virtually, everybody's computer can open up those files.
If you record something in a wav file or a garage band file, a lot of students won't be able to see your work including me as well.
So, my advice is to stick the most universal files.
That's MP3 and MP4 when recording music.
That's all you need to do the assignment for this course.
Hi, and welcome again.
This is week two and the topic for this week is scales.
now, the first thing we see when we look at a piece of music is a cord symbol.
And we know usually most of us at this stage in our learning, know the basic notes of that chord.
So we know we know the, the triad and the, the seventh that makes up the basic sound.
And what you do in that case is you feature the chord tones and then you take a guess at filling in some other notes.
The problem is you can't play a whole melody with just the four notes of an arpeggio.
You need more notes to make melodies.
Good at doing this.
In fact, a great musician I played with for several years who was a wonderful player, Stan Getz the saxophone player.
That's how he functioned as an improviser.
He had never really studied music theory much, didn't know much about chords.
He just knew the basic triad for each chord symbol that he saw.
And he would start with those notes.
But we don't want to settle for that.
We want to have a full knowledge of the available notes during any given harmony.
So, for that we need a scale rather than just a chord outline.
The topic today is scales, specifically what we call chord scales in the jazz world.
And, if you've looked at some books on improvisation you might have come across some that included page after page after page of scales with exotic sounding names.
the truth is, there is a small number of scales that cover most situations.
there are ten of them, in fact, that are the most commonly used scales.
And 90% of the chords and scales that you come across in a tune, a standard tune or a jazz tune will use one of those ten scales.
So, they're the ones that you really need to have under your fingers, that you have to have memorized and are able to play on them.
And we're going to look at each of those ten scales today, and what their characteristics are and how to organize them and think of them.
The goal is to have them memorized to the point that you have instant recall.
Now you probably already have instant recall on a few scales.
And you don't have to stop and think what the notes are in that scale as you play it on your instrument you're just used to playing it.
We can memorize scales in two ways.
There are two characteristics that our memory uses.
One is the shape that the scale makes in terms of the pattern.
And it doesn't matter whether you play a keyboard instrument like mine, or the piano.
But on any instrument, there's kind of a, a kind of a shape and pattern to a scale run.
And we also recognize the sound of it when we hear it.
when it, you know, we associate the sound and the shape of the scale and that's what allows us to have instant recall of it.
Chords change every couple of seconds there is not time for conscious, you know, study of arguing with yourself about can I use the B flat or not and so on.
I mean, if you have to think at all about the scale as you're playing, you won't be able to keep up with the music.
So that's the goal is to get instant recall.
Now, in the classical world, ♪ ♪ the way you practice scales is usually going up and down.
But that's not much help to a jazz musician, to an improvisor.
We need to make melodies out of that scale.
♪ ♪ Which means moving to different intervals, and different groupings of notes within that scale.
So we want to have flexibility, and be, be very facile with the notes in the scale.
So instead of practicing ♪ ♪, we want to change the intervals.
Use most of the range of your instrument.
Don't do it all within one octave.
♪ ♪ So you can see I'm rambling around.
And I'm seeing the shape of the scale, the C Minor scale, called the Dorian.
And I'm using different combinations of notes from that scale ♪ ♪.
I'm getting used to the sound of this scale.
As I mentioned before, there are ten scales that are the most commonly used.
And they're the ones that you really have to be ready to play, and have instant recall of, and be comfortable on.
So, that's a total of 120.
Now that sounds like a lot, but in fact many of these scales are closely related, so it's really not like learning 120 totally separate things.
So it goes quicker then you think.
There's sort of two ways to approach it.
One way is to be methodical about it, and say, well, I have 120 scales, so if I work on two scales a day in 60 days, I'll have gone through all of them.
I don't know anyone who's done it that way, to be honest, but it's certainly logical.
That is, every time they learn a new song, they look through the tune and see what chords, what chord scales are called for, and if there's going to be some new ones, in almost every new song you learn at first.
And so, you add a few more each time you learn a new song.
And eventually, you've pretty much covered all of them just by learning 25, 30, 40 songs over the next few months, or however long it takes you.
when you come to a chord symbol in a song, and you're not sure, you don't get an instant recall of what scale goes with it, remember that.
I mean here's a situation that happens to everybody when they're learning.
And I'm sure it's happened to you.
you're playing a new song, and the first chord is fine, it's a B flat chord, I know that one.
Then a C chord, I know what to do there.
And you see the problem coming up on the next page.
And this tempo is moving along, and you're getting closer and closer, and finally you're there.
And now what do you do?
There's this chord that you don't know the scale for.
You're not sure what to play.
Well, there's a couple of options, and it's sort of funny.
one option is you don't play that measure.
Take that moment to adjust the horn, or pause and rest.
and listen to the rest of the musicians, and see what notes they're playing, see if you can recognize notes and what it should sound like.
Alright and, again, listen to what the other players are playing, and the chords, and the support notes, and so on.
And find, you'll hear it maybe, oh I notice a C works.
When you recognize a chord as being unfamiliar, just make a mental note, the next time I practice, find the scale that goes with that chord.
And then, try to memorize it.
Now, let's talk a little more about how to do that.
We're going to play around on it in random combinations.
So that your brain remembers the, this combination of shape and sound.
So, that's what we're going to be doing.
Now, as I said, there are 120 theoretically possibilities, if you're talking about all 12 keys.
But you'll learn them fast enough once you start doing this with each new tune that you learn.
figure out the right scales, and then make sure that you've played them before, or make sure that you have the time to stop and learn them now.
There are three more scales that are very commonly used in jazz music and popular music.
And all three of them are used on dominant seven type harmonies.
So let's take a look at each one of these.
It's a Lydian scale, but instead of having the natural 7, it has a flat 7.
Well, that ninth, has been altered, been made half step lower, in order to make it sound more dissonant, and have a richer color.
So, think of it this way, I'm gonna walk you through each note of the scale.
Along with the basic chord outline, 1, 3, and 7th.
I'm gonna come to it in a minute and tell you one little oddity about the altered scale that you need to keep in mind.
But the third, of these additional scales and the last of the ten Is the Symmetrical Diminished.
As you might expect, it sounds like the diminished chord.
And in fact, it's made up, you could say, of two diminished scales combined.
It's almost the same.
We have the 5 and 6, so the bottom of the diminished scale, the symmetrical diminished scale is the same as the altered but the top notes are slightly different.
So those are the three and all three of these scales are used on dominant seven type harmonies.
Now, as I said, there's one more thing to point out about the altered scale.
That's what I call it.
As it turns out, the fifth of a chord is perfectly usable during an altered chord harmony and an altered scale.
It's not included because we have a complete sounding scale without the fifth.
So if we added it, It would just be an extra chromatic note in there.
And so, it was left out in terms of describing the official altered scale.
But the reason you need to know about the fifth being possibly included, is that you'll run into altered harmonies in songs.
And that'll be the fifth in the melody.
Obviously, called for by the composer and sounds good and it works.
So keep in mind, when in an altered harmony situation that, even though it isn't officially in the scale, it is also a perfectly usable note on an altered scale.
Okay, that's all ten scales, these commonly occurring scales that we need to know really well.
So, let's review what we're supposed to be doing with them.
We want to assimilate them using their two characteristics, the pattern that they make and the sound that they make.
Now, when I say pattern, It's the shape of the scale.
I play the saxophone.
Has a way of picturing groups of notes, whether it's a chord outline or a scale.
And I've often asked players of other instruments, in fact, how do they picture a scale or a group of notes?
And I'll tell you that most of them answer, they picture them on the piano keyboard, even if they don't really play the piano.
That seems to be a common way of thinking about them.
And some people, saxophone players for instance, tend to say I picture the fingering of running the scale, when I think of how do I picture a seven, eight note run of notes of scale.
However you do it, you will have some way of visualizing the scales and the shape that they have.
And you'll hear the sound of the scales.
So, with any new scale, Ramble around, make different combinations.
Speed is not an issue.
It doesn't matter if you can play them faster and faster and faster.
What matters is are you assimilating the memory of this group of notes and different ways to combine the notes in to different combinations.
So that's what you should be doing with every new song that you learn or practice.
Check out the chord symbols and make sure that you are familiar with the chord scale that goes with each one.
In addition, if you're playing, let's say this chord is an E flat minor seven, and the scale is the Dorian and you're playing around on it.
Be aware that it is an E-flat minor seven chord even though you're playing around on the scale cuz we have to actually be using not only the chord tones but the chord scale as we play it to a harmony.
Play the basic scale, and then start, Bouncing around playing different combinations.
So record that and upload it to the site.
And I'll see you next week.
This is week three and we're going to be talking about chord scales again, a kind of continuation of what we covered last week.
And especially how to go about memorizing them and learning them so that you can use as improvisers.
And that is choosing the right chord scale to fit each harmony as you come to it.
Now, normally you might think well, that, that's something I'll have to study for a bit.
I'll have to take the so, song home and play it for a while and work out what the right scales are.
But we don't want to have to do that.
We want to be able to play the song and solo on it if it's put in front of us, at a rehearsal or at a session or whatever.
Welcome to Julia Scientific Programming.
This course is an introduction to programming with Julia.
I will introduce you to Julia programming.
I teach Applied Mathematics at the University of Cape Town.
I do research in Mathematical Biology.
I first used Julia after being faced with solving sets of differential equations that took days to run.
I then started programming in Julia and within a couple of weeks I had rewritten my code and took the run time down to just a few minutes.
That convinced me of the value of Julia.
I'm Juan Klopper a surgeon in academic practice and head of the Acute Care Surgery Unit at Groote Schuur Hospital.
I introduced Julia to students needing to analyze healthcare data.
They are able to quickly learn to perform statistical analysis and generate stunning plots, which I look forward to introducing to you in week four.
And I present these Honors lessons in weeks three and four.
Because of its design, it is also good as a first programming language.
It's effective for general purpose programming and suited for computing over networks.
Now Julia is a modern dynamic programming language designed to address the requirements of high performance numerical and scientific computing.
The best way to start learning Julia is to write code and practice.
This course takes us through several lectures showing how to use Julia and start you on the process of writing your own code.
For each Julia programming video lecture there is Jupyter Notebook which is the source code file for that lecture.
And you can download that file and use it to follow alongside and reproduce the code results.
This course is for beginners, but if you have some experience with other languages, I'm talking Python, Mathlab, R, Fortran or C, you will have an advantage.
As a new and evolving language, Julia has a vibrant online development community or rather several communities.
And we hope you will join and and contribute to this online family.
Join us on this course and start learning to program in Julia.
These are very exciting times in the world of Julia.
We've reached Julia version 1.0, the future stable version of Julia.
Now, while that is fantastic, it makes it a bit difficult for us to create this course, because we use packages and libraries that aren't quite ready for version 1.0.
But as these become available, we're going to put out new resources and new video, new material for you to use.
That's just another program in which you can write your Julia code, so that you can use either the Jupyter Notebooks or the Juno IDE.
In this video, we'll discuss exceptions.
Kotlin doesn't differentiate checked and unchecked exceptions.
In Kotlin, you may or may not handle any exception.
And your function doesn't need to specify which exception it can throw.
The experience shown as that in Java, Java rules for checked exceptions often require you to write a lot of meaningless code to rethrow or ignore exceptions.
And these rules doesn't really help you to prevent possible errors.
That's why in Kotlin this design decision was made which is shared among many other modern JVM languages.
That means that you can assign the result of 'throw' to a variable.
In this case, if the number is in a range, we assign it to the result of 'if' expression.
Otherwise, we throw an exception.
It's really convenient to use 'throw' in an 'else' branch like in this example, or in 'when' branches, or in other different situations.
That means you can assign the result of 'try' to a variable.
In this case, we assign the result of 'parseInt()' function to a 'number' variable if everything is okay.
And we return from the outer function if the exception was throw.
In a similar fashion, instead of returning from this 'catch' block, we can, for instance, return 'null'.
In this case, this 'null' will be assigned to a 'number' variable as a result.
'try' is an expression where you can specify different result values for different (types of) exceptions.
There is no checked exceptions in Kotlin so there is no need to specify "this function throws this exception" specification.
And to better understand it, there is the question to you.
What do you think: Is there a difference between calling the following 'foo' and 'bar' functions from Java?
And the only difference is this '@Throws' annotation.
Java code simply tries to surround this function call with a try-catch block and catch this IOException.
The possible options are: there is no difference, the Java code that calls 'foo' compiles but the Java code which calls 'bar' doesn't compile, and vice versa.
Let's look at our Java example.
Here when we try to call 'foo' function from Java and catch this IOException, Java compiler complains that exception is never thrown in the corresponding try-block.
In Java you cannot catch an exception if it wasn't thrown.
Especially for this reason, when you throw a checked exception (from Java point of view) in Kotlin, you need to add this annotation.
If you simply use it in Kotlin, then you don't need '@Throws'.
Next, we're going to discuss the feature that has no direct analogs in Java but is crucial for providing good interoperability with existing Java libraries.
Hi, everyone.
And each week, there will be about one hour of video for you to watch.
>> Throughout the course, there will be homework exercises and programming assignments.
These will give you the opportunity to practice.
Practice is key for learning to program, much like it's important for learning how to play a musical instrument.
>> We're excited to be teaching tens of thousands of people from around the world.
Thank you for joining us.
What do you do when you just can't figure something out?
For zombies, it's pretty simple.
They can just keep bashing their brains against the wall.
But living brains are a lot more complex.
It turns out, though, that if you understand just a little bit of some of the basics about how your brain works, you can learn more easily and be less frustrated.
Researchers have found that we have two fundamentally different modes of thinking.
Here, I'll call them the Focused and the Diffuse modes.
It's when you concentrate intently on something you're trying to learn or to understand.
But we're not so familiar with diffuse thinking.
Turns out that this more relaxed thinking style is related to a set of neural resting states.
We're going to use an analogy of the game of pinball to help us understand these two thinking modes.
Incidentally, both metaphor and analogy are really helpful when you're trying to learn something new.
If you remember, a pinball game works by, you pull back on the plunger, release it, and a ball goes boinking out, bouncing around on the rubber bumpers, and that's how you get points.
So, here's your brain, with the ears right here, and the eyes looking upwards.
And we can lay that pinball machine right down inside it.
There's the analogy for the focused mode.
It represents a familiar thought pattern.
Maybe involving something simple like adding some numbers, or more advanced ideas like literary criticism or calculating electromagnetic flows.
You think a thought, boom, it takes off, moves smoothly along.
And then, as it's bouncing around on the bumpers, you're able to figure out the problem you're trying to solve, or.
So look at how that thought moves smoothly around on the fuzzy underlying orange neural pathway.
In some sense it's as if it's traveling along a familiar, nicely paved road.
But what if the problem you're working on needs new ideas or approaches?
Concepts you haven't thought of before.
That's symbolized here by this neural pattern towards the bottom of the pinball machine area.
But if you haven't thought that thought before, you don't even know how that pattern feels or where it is.
So how are you going to develop that new thought in the first place?
Not only do you not know where the pattern is or what the pattern looks like, but see all the rubber bumpers that are blocking your access whatever direction you do decide to move in?
To get to this new thought pattern, you need a different way of thinking.
And that's represented here, by the diffuse mode.
It could travel a long way before being interrupted by hitting a bumper.
In this diffuse mode of thinking, you can look at things broadly from a very different, big-picture perspective.
You can make new neural connections traveling along new pathways.
You can't focus in as tightly as you often need to, to finalize any kind of problem solving.
But you can at least get to the initial place you need to be in to home in on a solution.
Now as far as neuroscientists know right now, you're either in the focused mode or the diffuse mode of thinking.
It seems you can't be in both thinking modes at the same time.
It's kind of like a coin.
We can see either one side, or the other side of the coin.
But not both sides at the same time.
Being in one mode seems to limit your access to the other mode's way of thinking.
In our next video we're going to see how some extraordinary people access their diffuse ways of thinking to do great things.
Perhaps the greatest gift that our brains give us is the ability to learn new things every day.
On my way here, I thought about the journey that will take us to the last day of the course, and how much we will learn along the way.
Our goal is to give you a better understanding of how we learn, so that your brain becomes a better learner.
These insights are based on solid research from neuroscience, from cognitive psychology, and also from dozens of leading instructors and practitioners in difficult-to-learn subjects.
Whether you're a novice or an expert, you will find great new ways to improve your skills and techniques for learning, especially related to math and science.
This course is meant to help you reframe how you think about learning, to help reduce your frustration, and increase your understanding.
We approach things a little differently.
You're not expected to have an in-depth background in any particular subject.
Instead, you're expected to take these ideas and apply them to whatever subject you're trying to learn or improve in, to help you learn more deeply, effectively, and with less frustration.
You'll hear experts from a variety of different disciplines talking about their best tips for learning more effectively.
You can benefit from these ideas whether you're struggling in high school or soaring through math and science at graduate levels at a university.
I'm a co-director of a Science and Learning Center that is sponsored by the National Science Foundation based here in La Hoya.
In recent years, we've made great strides from research and discovering how to learn most effectively.
Finding a way to simply and effectively share these ideas with you has been a big undertaking, but we feel it's well worth doing.
You will see that many of these ideas, although simple, are incredibly powerful.
And along the way, we will also learn a lot in the process of teaching you.
You'll see how you can fool yourself about whether you actually know the material.
You'll discover new ways to hold your focus and embed the material more deeply and powerfully in your mind, and you'll learn to condense key ideas you're learning about, so you can grasp them more easily.
Master the simple practical approaches outlined here, including simple tips to help prevent procrastination, and you'll be able to learn more effectively and with less frustration.
This course is meant to enrich both your learning and your life.
You'll be able to get what you want from this material.
So, welcome to the course and happy learning
So, let's take a look at some famous people from history who used their different thinking modes to help them with their problem solving.
He was the very definition of a wild and crazy guy.
Dalí used to have an interesting technique to help him come up with his fantastically creative Surrealist paintings.
He'd relax in a chair and let his mind go free, often still vaguely thinking about what he had previously been focusing on.
Now, you might think, well, you know that's okay for an artist.
But what does it have to do with more scientific or mathematical kinds of thinking?
Well, if you look down here, this guy was Thomas Edison, one of the most brilliant inventors ever.
According to legend, what Edison used to do was he'd sit and relax in his chair, holding ball bearings in his hand.
Although, it would often noodle back in a much more relaxed way to what he'd been focusing on previously.
When Edison would fall asleep, the ball bearings would drop and clatter to the ground just as with Dalí, and it would wake Edison up, and off he'd go with his ideas from the diffuse mode ready to take them into the focus mode and build on them.
So, the bottom line is, when you're learning something new, especially something that's a little more difficult, your mind needs to be able to go back and forth between the two different learning modes.
You might think of it as a bit analogous to building your strength by lifting weights.
You would never plan to compete in a weightlifting competition by waiting until the very day before a meet and then spending the entire day working out like a fiend.
I mean, it just doesn't happen that way.
To gain muscular structure, you need to do a little work every day, gradually allowing your muscles to grow.
Similarly, to build neural structure, you need to do a little work every day, gradually allowing yourself to grow a neuro-scaffold to hang your thinking on a little bit, every day, and that's the trick.
In summary then, we learned that analogies provide powerful techniques for learning.
We learned about how the brain's two different thinking modes focused and diffuse, each helps us learn but in very different ways.
Finally, we learned that learning something difficult can take time.
Your brain needs to alternate it's ways of learning as it grapples with and assimilates the new material.
Everybody has some issues with procrastination.
Because if you're working on something, it means you're not working, on a lot of other things.
But some people have more issues with procrastination than others.
In this video, we're going to give you a little insight into procrastination.
Why it arises, and a powerful little tool to help you address it.
When you look at something that you really rather not do, it seems that you activate the areas of your brain associated with pain.
Your brain, naturally enough, looks for a way to stop that negative stimulation by switching your attention to something else.
But here's the trick.
Researchers discovered that not long after people might start actually working out what they didn't like, that neurodiscomfort disappeared.
So it seems what happens when you procrastinate, is something like this.
First, you observe, and get a cue about something that causes a tiny bit of unease.
You don't like it, so to make the sensation go away you turn your attention from whatever caused that unease.
The result, you feel happier, temporarily.
But in the mean, time I'm going to let you in on a handy little mental tool.
It was invented by Francesco Cirillo, in the early 1980's.
All you need to do, is set a timer to 25 minutes, turn off all interruptions, and then focus.
That's it!
Most anybody can focus for 25 minutes.
The only last important thing is to give yourself a little reward when you're done.
A few minutes of web surfing, a cup of coffee, or a bite of chocolate, even just stretching or chatting mindlessly, allowing your brain to enjoyably change its focus for a while.
You'll find that using the Pomodoro technique is very effective.
It's a little like doing an intense 25 minute workout at a mental gym.
Give it a try.
Next, we're going to see how one very shy ten year old, changed her brain.
This week, we're going to be talking about chunks, compact packages of information that your mind can easily access.
How you can use them to improve your understanding of, and creativity with the material, and how chunks can help you do better on tests.
We will also talk about illusions of competence in learning.
We'll cover what those less effective study methods are and tell you what methods research has shown will work better to help you in your studies.
You can make your study time more valuable by interleaving, providing intelligent variety in your studies.
This week, we're going to be talking about two seemingly different ideas: procrastination and memory.
But the two topics are intimately related, why?
Because building solid council long-term memory, chunks that are easily accessible by your short term memory takes time.
It's not the kind of thing you want to be putting off until the last minute.
Then we'll move on to talking about some of the best ways to access your brain's most powerful long-term memory systems.
>> In this course we will present some of the fundamental building blocks for designing lessons in your classroom.
We will discuss how to create sound learning objectives, lesson plans that consider the end from the very beginning, and give you a general view of how lesson plans are designed.
>> We will also give you a little background into theories of instructional design, and give you an overview of ways in which to engage your learners at each step of the learning process.
During several videos we will spend time trying to share not only how to plan and teach a lesson, but we will spend time showing you how not to plan and teach.
Our hope is that you will avoid some of the common pitfalls of language instruction.
We are doing this so that you don't fall victim to the same mistakes that many of us have committed on our way to becoming language teaching professionals.
>> I sure made a lot of mistakes when I was a young teacher.
You know, what you said reminds me of a saying.
Smart people learn from their own experiences, but super smart people learn from other people's experiences.
And I guess you can say that our greatest hope in giving you this third course is that you can learn from both of us, both the good and the bad, so you can truly be not just smart, but super smart.
In today's lesson, we want to provide an overview of instructional design principles, and a theory from an American educational psychologist named Robert Gagne.
Who gained a lot of insight in the 1940s and 50s by helping pilots learn how to quickly and accurately fly planes for the United States Air Force.
But before we do that, let's talk about teachers in general.
All of these are essential roles at varying times and in varying degrees.
You are walking around a class, you are sharing and listening, you are giving feedback, you are using teacher talk and having a great time with your students.
However, one of the most significant roles that a teacher can have is when they aren't with students at all.
The role of lesson designer, lesson planner is a role that is often done in the quiet of your office.
For me, it often requires a degree of solitude, so I can think clearly about my learners, my objectives, and how to bridge the gap between the material I want to present and how to most clearly convey that material so that learners will acquire it.
Other times I need to surround myself with teachers so I can get ideas about how to present material, especially challenging material.
But in either case how does someone design these lessons.
And what are the elements of a good lesson design.
Let's go back to our discussion of Robert Gagne and discuss his basic theory of instructional design.
This theory was influenced by both behaviorists and cognitive scientists, perhaps especially information processing theorists.
With what you know about behaviorism and cognitive science, from our second course, you can probably guess that Gagne created a rather systematic approach to instruction.
Please remember that when you are dealing with human behavior there is no such thing as a hard fast rule.
In a real learning environment, you might skip one of these nine events entirely, put them in a different order, or even repeat an event multiple times in a single lesson.
But what is great about Gagne's design is that it considers the fact that learners don't just receive information passively.
Students are not empty vessels that you fill.
But rather, there are ways to stimulate a learner and make the learning process easier.
In our first course, we called all of this making meaning clear.
You remember?
Language is cake, right?
All right, so back to Gagne.
Since nine events is a bit much for our needs right now, let's discuss the first three events.
First, when presenting material, Gagne said that teachers must gain the attention and interest of the audience.
Let's look at these three steps a little more closely.
And let me ask you a few questions to get you thinking.
When you start a class, you have to get, grab the students' attention somehow.
It wouldn't make sense to just start a lesson without somehow bringing everyone in the class to attention.
But what does it mean to gain attention?
What do you think about that?
But how do you give learners objectives?
Isn't enough just to share them?
Do you have to give objectives at the beginning or might be appropriate sometimes to have students discover objectives inductively and ultimately?
We'll, definitely talk about that.
What is that mean?
I supposed you could interpret it to mean that you help learners think about or recall past lessons, information that they have from past experiences.
Obviously it is important to know what students know before you teach them what you think is new information.
I hate teaching concepts that have already been given, and students hate even more when they receive information they already know.
So definitely make sure you know what students know.
Two more things, first, it's wonderful to get students right from the beginning to share what they know and engage them in the learning process.
Don't you hate when a teacher immediately turns students off by just talking without drawing you in?
Helpers are, as you can probably guess from the word, the students who already know the material and can help others on a particular subject.
Do you stimulate recall in every single lesson?
Is it something you do just at the beginning of a lesson?
And do you stimulate recall by just asking questions?
These three steps are crucial to any lesson.
But we are left with a lot of questions on how to actually get it done and we will be spending a lot of time in our future modules answering these important questions.
But perhaps, we can begin by having you answer some of these questions on your own by observing actual teachers in practice.
To help you begin thinking about these three events, in the next video we will turn our attention to a few different teachers.
So you can see precisely how they put these three principles and practice.
We'll see you then.
In the last video, we discussed Robert Gagne's first three events of instruction and discussed the need to gain attention, create clear objectives and stimulate the recall of prior learning.
While these three events can happen at anytime, they are often presented at the beginning of a lesson plan.
With that in mind, let's turn our attention to a few different teachers and see how they begin a classroom lesson.
These teachers are all instructors of high intermediate high school aged ESL students.
I also want to introduce you to Jack P.
They will help to break down the instruction and provide their own analysis.
Jack and Jill?
I'm sure I'll tell you all that I know.
And together, we will do our best to give you insights that should help clarify each teaching moment.
I want you to turn to page 23 in your book and we will learn more about some people in Australia.
Looks like this teacher hasn't got the guts to turn up the volume.
If the teacher doesn't turn up the volume, the students are sure to turn off the lights.
Now, I don't mind that she begins the lesson right away.
But it seems there could be a little more work to gain attention and stimulate the recall of the previous lesson.
All she said was that we will learn more about some people in Australia.
Hm, let's keep watching.
Then we will take a test about Australia.
What do you think?
What do I think?
It seems to me that those objectives aren't really about the vocabulary, grammar, or language skills the students will gain.
Get your faces out of your smartphones, open books to pages 23, 24.
Today, you're going to be reading a story.
You're going to notice that there are some vocabulary that you've already learned.
By the end of the week, you will have learned 25 new vocabulary words, and you will have gained better control over the past tense.
You remember the past tense, don't you?
But to me, it just looks like the teacher thinks that gaining attention means drawing attention to yourself.
That was a bit scary, no doubt.
>> To be fair, he does go on to explain that there will be a story and mentions that the story is connected to a past lesson.
But doesn't really go into detail about which words or vocabulary are similar or different.
There are language objectives, and they are specific, 25 words, better control over the past tense.
I like it!
Thanks for your opinion, but I still think it could have been a little better.
Let's go to teacher three.
Let me introduce you to some words and raise your hand if you know these words.
School bus, hiking, stranded, dingo, signal, dangerous, compass, outback.
Yes, some of these words come from our lesson yesterday.
What do they mean?
What do these words mean?
Yes, it's a compass.
Can someone tell me what a compass is and what it is used for?
Very good way of bringing students into the Australian reading.
>> And don't forget the technique she uses of inviting students to raise their hands for simple questions and then inviting students to respond out loud for more difficult questions.
Jill, did you notice that the simple questions help students demonstrate their recall of prior learning?
It was as gorgeous as my hair.
You see, we're going to read a story to build up your vocabulary for today and help you learn words to express feelings.
We're also going to help you to present, by the end of the week, a speech about an emotional time in your life.
Notice that the teacher shares a short term daily goal, building vocabulary, and ties it to the weekly goal, presenting about feelings.
Teachers who don't take command of the classroom.
Teachers who do all of the steps but maybe without detail or clarity.
Notice how our last teacher attempted to make the readers think about and want to know more about the story they will read.
In the next video, we will share the next three events from Gagne's events of instruction and discuss how a teacher has to put on different hats in a single lesson from instructor to coach to evaluator.
In the previous lesson, we watched three teachers in action as they began a class and successfully or unsuccessfully managed to perform Gagne's first three events of instruction.
Now let's discuss the next three events, and discuss how and when these events should be implemented.
The next three events from Gagne's nine events of instruction are, present the content, provide learner guidance, and elicit performance, or practice.
Presenting the content refers to the idea of demonstrating, and sharing, speaking, and presenting, carefully constructing a lesson by explicitly giving information that will help learners understand material.
In our first course, foundational principles, a lot of time was spent on discussing the use of teacher talk.
Here is where you would do a lot of teacher talk, explaining, breaking down, scaffolding and well, to be honest, being front and center.
If you remember, we shared the 80 / 20 rule which informed us of the goal of presenting information only 20% of the time, while allowing students practice 80% of the time.
But don't let this ideal goal make you undervalue the instruction because that 20% of instruction is truly vital to the success of your class.
Let me add one more thing, use warm language when you present content.
Well, in an extensive study of the best college teachers in America, Ken Bain discovered that one of the most powerful shared attributes of the best teachers, was the ability to use warm language.
Do you want to be the best?
Of course you do and warm language may be a key.
So, what is warm language?
It is the ability to communicate from the inside out, to share ideas that excite and help students anticipate a future conclusion.
For example, maybe you've heard this one before.
>> There was a story about this little girl and three bears, and how she went to their house, and when they were gone, she tried and tasted everything and then they came home and discovered her.
Yes, it is Goldilocks and the three bears.
But did you feel like you were inside the story?
No, the language was cool and detached.
It was informational, but feels irrelevant, like a user's manual, or an online terms and conditions that you just go down to the bottom of the page and accept.
Now consider the same story, but told using warm language.
>> Once upon a time there was a girl named Goldilocks.
She had fine golden hair and was dancing through the forest when suddenly she stopped.
What did she see?
It brings you in, helps you feel like you are there in the story.
In other words, warm language is a bit like story telling and it can be done even when you aren't telling stories.
When you're explaining grammar, punctuation, vocabulary or any kind of principle, think about how to use warm language.
When you present content, make sure you do so in a lively engaging manner.
A way that draws students in, and makes them motivated to learn more.
Clear explanations, warm language that invites students to problem solve with you, the use of story and metaphor.
All of these techniques can help you to present language in a pleasing manor.
After all, like we keep on saying, language is cake.
And your job at this stage is to provide assistance as learners attempt to recall, use, or apply the information you have given them.
In course one of teach English now, we call this guided practice.
Benjamin Bloom, another learning theorist, suggest that there are different ways to get students to interact with learning and that a good instructor is able to get students to think and examine critically.
In some sense, this is the time for students to play with language, make mistakes, figure out how certain rules work and the words work and interact with each other in order to acquire language.
At this stage students may not be able to do things on their own, but in pairs or in groups or with you as a teacher, they are able to work together and accomplish a task.
This, for some teachers, represents the final stage of a lesson.
This part of the lesson is actually a mixture of practice and evaluation.
In course one of teach English now, we mentioned independent practice, and this part of the lesson is where students would be given time to practice independently, and show you that they understand what you've taught them.
It is also your opportunity as a teacher to evaluate your learners, and determine if they have learned anything, or not.
Now, a performance can be a test, a presentation, a group activity, a question and answer session, there are all kinds of ways to do it.
But the point is that when you illicit a performance, you move away from being a presenter, presenting the content or a coach providing learning guidance and now you become an evaluator.
In this new capacity you are allowing students to present their knowledge and or competence of the contents you have perviously presented and worked on together.
So what ties all three of these events together?
Well, at least a couple of things.
First, these three events involve direct interaction with the material you are trying to present.
Presentation and practice of material when done well can encourage long term learning and acquisition and inspire students to do their best.
Second, these events all involve the exchange of information from teacher to student.
Think of it as the passing of a baton.
First, you are in charge of the information.
And finally, you let go of the information and give it to students alone.
All right, so now that we understand these three events, let's watch teachers in action.
In the next video, you'll see three fearless teachers attempt to teach a small lesson.
In the last video, we discussed three more of Robert Gagne's Events of Instruction.
This time, discussing events that might be more clearly aligned to the instructional portion of lesson planning.
With these three events in mind, let's turn now to three teachers and see how they might instruct during a lesson.
Once again, we'll have Jack and Jill give us some immediate feedback.
Remember, this horizontal line shows time and this vertical line means right now.
When we talk about the future, it means some time in the future.
Remember, we could be talking about tonight, tomorrow, next week or next year.
Any other words?
There are many words that help us know we are talking about the future and there are two ways to express the future.
We will learn the differences a little bit later.
How is this different from the past or the present tense?
Let's look.
If we have the sentence c, Sam is in his office.
Now, how about sentence d?
Raise your hand if you know.
Sam was in his office.
It's the past tense.
So, how would we change this sentence to the future?
Let's do it together.
Let's use will this time.
Will be in his office.
Now, I'm going to read about something I wrote when I was younger.
I was 12 years old when I wrote this and it has a lot of my hopes for the future.
Remember that I will be asking each of you to write about your dream job, your dream house and your dream family.
While you listen, see if you can hear from my dream job, my dream house and my dream family.
In ten years, I will be a writer.
I will write many books.
I'm going to have a great, big house.
>> Wow, I love the use of diagrams and examples, Jack.
I like that the teacher has been asking questions all throughout the instruction.
What's your take?
So I think you'd agree that I'm not very good at subtle touches, but there were some nice subtle touches here.
The teacher gave instruction, then modeled the instruction with something she wrote when she was younger.
Excellently done and even more impressive, the teacher mentioned the objectives again to help them realize that what she was modeling is something they will be required to do later.
>> I'll say and speaking of subtle touches, the teacher also stimulated recall of prior learning by mentioning the present and past tenses they have worked on in previous lessons.
This teacher is a star.
Let's look at teacher two.
Let's turn in your books to page 55.
Who can tell me what the two kinds of future are?
Anyone?
Yes, there is going to and will.
Now, I'll read you five sentences and I want you to tell me after each sentence if it is future tense or not.
If it is future tense, it had going to or will.
Now, raise your hands if you think the sentence is future.
It seemed like this teacher moved too quickly from presenting content to providing guided practice.
>> Now let's work in pairs and I will go around the room as you complete activities four, five and six.
Exercise five, requires you to take turns asking questions to each other and exercise six is an interview.
But really, I wonder what the final performance might be.
If so, I would have loved to have had a model of what a good interview might look like.
Or maybe they did show it, I don't know.
And if you have any questions, raise your hand.
We're going to be checking the answers at the very end of class.
This teacher believes that the books is in charge of the instruction rather than the teacher.
There is no instruction, no modeling of the content and no real group or pair work, so.
Well, I guess it reminds me of the good old days spent with my economics teacher soccer coach.
Sitting a desk and getting paid, he was living the good life, I tell you.
While you didn't see these three teachers present their full lessons, we hope this gives you a taste of some of the different ways teachers interpret these three events and how lesson planning often goes within a classroom.
In the next video, we're going to review Gagne's theory so far in preparation for our final quiz.
By the way, have you noticed in our video the use of any of the six events we have been discussing?
Do we in our videos, try to gain your attention, state objectives, stimulate prior learning?
Do we attempt to present content clearly, provide you guidance and lead you to perform the material we have taught you?
I sure hope so.
Whether online or in person, these learning events can give your class structure and substance and help learners to engage with the material you are presenting.
You'll probably notice we didn't discuss Gagne's last three stages of development.
But since his last three events are closely related to assessment and evaluation, we're going to speak more about them in an upcoming module.
>> For now, let's review what we have learned so far by discussing some of the information we have shared with you in this module.
Robert Gagne's Instructional Design Principles, which came from both behaviorists and information processing theory.
In general, his theory assumes that in order for instruction to be received well that there is more to it than simply pouring information directly into the brain, an assumption that we strongly agree with.
While not all of his instructional events may be necessary for every lesson we find them useful to discuss as a sort of ideal lesson plan.
>> Gagne's first three events of instruction are gaining attention, informing students of objectives and stimulating prior recall of instruction.
Remember that gaining the attention refers to more than just telling students, hey let's go, it's time to start class.
Rather, gaining attention refers to helping shine a spotlight on a theme or information you wish to share as you begin a lesson.
And can give students an important insight into not only what you're teaching but why you're teaching it.
And finally, stimulating prior recall of instruction is a tool for both student and teacher.
For a student, it allows them to strengthen neural pathways and become more ready to connect new information with information you've previously shared.
As a teacher it allows you to know what students know, what students remember, and perhaps what needs to be reviewed again.
>> In Gagne's next three events of instruction, we learn about events that are related to both instruction and practice.
The events are presenting the content, providing learner guidance, and eliciting performance.
When presenting content, your job will be to find ways to present information clearly.
Helping break down concepts so that students can acquire language.
No doubt you will use teacher talk, stories, diagrams, visual aids, and all of those things you have seen from dynamic, engaging instructors.
Remember the tip, to present in the present, meaning you shouldn't just talk about language whether you should talk to students in way that draws them into the instruction.
To help you understand a little bit more about the concept of presenting in the present.
After you present the content, the next event is to give guidance to students.
This is often done by creating activities that can be done in pairs, groups or as an entire class.
The point of providing guidance is to help students practice with the new information, struggle with it, and receive help as they get things wrong and attempt to get it right.
Mistakes at this stage of the game are highly encouraged.
To share their knowledge and demonstrate their ability to do what they have been taught.
>> In the next modules, we will go into even more depth about lesson planning and ask you to create a lesson plan yourself.
For this module however our writing prompt will be a bit different.
I think all of these are essential elements to lesson design.
It's a tough question.
As we get into more detail about lesson design, one thing should become very apparent, students are not empty vessels.
In other words, there is a sort of layman's theory that would suggest that students are cups without water.
A teacher is a sort of pitcher full water and that all a teacher needs to do is nothing more than fill that empty glass until it is full.
Makes sense, but it just happens to be terribly wrong.
The truth is that the human brain is not an empty cup or a blank slate or anything that might suggest that it isn't already packed full of information.
Even for young learners of language, there are countless ways in which you can use the information they already have to great advantage.
Thus, language learning is not something wherein a teacher simply has to teach new information while students obediently learn it.
So, how do you engage all your learners right from the beginning?
And how do you use their current knowledge to your own advantage?
Now that can be a trick, but at least you are thinking about it.
You see, one of the biggest problems in education is that teachers don't recognize the importance of engaging students and firing up those neural receptors and introducing them to a theme that they will connect to already formed neural pathways.
Jeone Brunner, another instructional designer and cognitive learning theorist suggests that when curriculum is built in a spiral with many iterations from simple to complex, learners can get better and better at what they do.
Think of it this way.
Now each of these are different from the other, but wouldn't you say that there is a since of relying on past skills in order to gain new skills?
That there are similarities, even between your very first tricycle and a jet fighter plane?
In other words, when you write your lesson plans, keep in mind that knowledge and skills in language is not a one and done proposition.
Students who learn how to give a five-minute speech are not simply done and have no need to speak ever again.
Students who learn vocabulary in your class don't simply keep that vocabulary in their heads, because they got an A on that last test.
In fact, it is quite the opposite.
Students are very likely to forget information that isn't constantly brought up again and again.
I guess this is all just a fancy way of stating an obvious point.
When you write your lesson plans, connect them to each other.
Your lessons aren't little chunks of knowledge on an island, they should be interconnected and reliant upon each other and they should help students practice again and again, previous material already covered.
Now, why am I bringing this up in a lesson about warm-ups?
You see, a warm-up is a perfect opportunity to accomplish two things.
First, it is an opportunity to bring up and introduce new ideas.
In other words, one of the most important things you can do as a teacher is to engage students's background knowledge by having those synapses fire and providing connections between new information and the neural pathways they have already formed.
Students have already traveled some distance and you as a teacher can help them to go a bit farther.
In the next video, we will discuss some of the elements of a proper warm up and have our three teachers give examples of ways in which a warm up might be performed in the TESOL context.
We just reviewed three teachers giving us examples of warm-ups.
I hope it gave you some insight into the importance of beginning a lesson plan.
Now, we're going to discuss another important concept, something called an objective discussion.
Now, when we talk about an objective discussion, perhaps we should first ask ourselves a couple of questions.
All right, let's talk.
First, objectives, for purposes of this module, are specific end goals tied to a lesson plan.
A target that you, as a teacher, have in mind.
And lesson plan objectives matter, because we want to get somewhere as teachers.
We're not just saying stuff, we're trying to achieve stuff.
We're trying to help students learn English.
Now English is a very big goal.
So to be clear, lesson plan objectives are much smaller than that massive target, but they are related.
In fact, you might say that they are clear competencies that we want students to acquire.
Competencies that will ultimately help us understand how close the students are in achieving this bigger goal of learning English.
Certainly as you are beginning, you might be tempted to simply follow already published curriculum guides, or even just follow a book and the book's objectives.
You may have noticed that we spent a lot of time in the second course discussing how different teachers over different time periods had different objectives, because they had different purposes.
Teachers, even professional ones, may have different objectives than you do.
Please do not suppose that everyone in our field is on the same page.
Knowing your objectives is important, because it allows you to recognize how you will instruct, and what you will instruct.
So, while it may be appropriate for beginning teachers to follow a book's objectives, I think you will quickly realize that writing your own objectives is a fundamental part of lesson planning.
Now, let's talk about that second primary question.
Imagine that you know your objectives, why have a discussion with students about them?
Well to put it simply, students like to know what the heck they're doing.
And so students are more likely to achieve success when there are clear target goals.
Now, do you always have to give students clear target goals?
Well, learning English of course is the overall goal, and telling students every day these minor goals may or may not be so important.
But throughout a course, helping students realize how these many goals fit into the larger scope of their main goal, can be very useful and motivating.
On a related side note, did any of you know that we have a major goal here at Teach English Now?
The goal is to put in your hands, each and every one of you, a major product.
Of course you know we are trying to give you a TESOL certificate, but that's not the product I am talking about.
You see, by the end of our two specializations, we want you to have a professional teaching portfolio.
A portfolio that shows your philosophy of teaching, which we discussed in courses one and two.
Observations, in future courses, and write ups detailing your practicum experience.
Yes, you see, we are asking you at each point in the process, to think of different pieces that will be useful to you later on.
We will ask you to write up a teaching philosophy, ask you to do observations, and ask you to do a one day and one week lesson plan.
We will put all of these elements into one big great hole, and that hole, that project, that product, is a professional teaching portfolio.
Something that hopefully, you'll be proud of.
Our hope is that a professional portfolio like this will help you get a job.
Will help you to improve and demonstrate your skills, and can be used as a resource wherever you may teach English all over the world.
I've just have an objective discussion with you.
We definitely have big plans for Teach English Now.
By the way, this kind of instructional design, this idea of having something big at the end of an entire course, comes from a learning theory that I love.
Two theorists, Blumenfeld and Krajcik, introduce this concept by stating that objectives should start with a driving question, and end with a concrete artifact.
In other words, good curriculum often starts with some great question you are trying to solve, and has some goal at the end of it.
Some product or thing that will show off the answer to the great question.
Now, a meaningful project might take the shape of a final class presentation, a portfolio, a dramatization, a final test that demonstrates knowledge of a lot of individual activities.
Whatever it might be, think of it as your measurable and tangible target.
What are you driving at?
I'll tell you the question, the driving question that keeps me awake at night as we designed this course.
How can I prepare teachers all over the world to teach English now, and what product will be proof of their excellence as teachers?
All right, so now we have answered our two questions in brief.
An objective is a goal with specific tasks that can be measured, and an objective discussion allows students to understand the goal or target they are aiming for.
Objectives are often incorrectly written and incorrectly understood.
And it has been my experience that even intelligent and seasoned teachers create improper objectives.
Since that is the case, we are going to spend an extra bit of time discussing not only what objectives are, but what they are not.
In our next video, we will show you some of the pitfalls of objective writing.
In this module, we discussed two concepts, the concept of presenting information and the concept of modeling.
When we spoke about presenting information, we shared the idea that good presenters tend to make information sticky.
When curriculum or content is memorable, it stands out and it's easy to recall.
When we say that content is usable, that means that students can use the information as a vital life skill.
When we say content is durable, we mean that even over a long period of time, the information still has a way of sticking around.
The first bit of advice was to use teacher talk and the second bit of advice was to keep things conversational.
Keeping things conversational refers not only to your conversational tones, but also your ability to stop and have students respond, work together, and find solutions to problems that you pose.
It also refers to your ability to think carefully ahead of time, so that you can anticipate the kinds of problems your students are likely to have in learning the new material.
Don't forget to personalize your instruction with stories and warm language.
When talking about presenting material, we also discussed different methods of delivery.
Teach, Model, an example or series of examples that show the rule in action, and Question, an attempt by the teacher to know and amend what students understood by what was taught and modeled.
Finally, a teacher asks students to elaborate on these rules, so that the teacher can clarify or amend the student's understanding.
The model is often what sticks in someone's head even more than the instruction.
First, give more than one model and second give models later in the process.
We hope you noticed that there are different methods that can all be viable options for you in a classroom.
Now, it will be your turn to think about how you might present and model information to a classroom.
Think about one of the objectives you wrote in our last module and imagine how you would present the information and model for your students.
The importance of guided practice is to allow students a hands on practice with the information learned and modeled in class, before asking them to try the concept on their own.
But also, let's then have a safety net, the safety net of the teacher or other students, to help out and answer any remaining questions they might have.
A teacher can do this by starting a sentence, and allowing the class to fill in the information at the end of the sentence.
>> Less guided practice happens when the teacher puts students in pairs or small groups and asks them to practice the information from a lesson together.
The teacher is still present, but the students themselves focus on producing work.
Independent practice provides the students an opportunity to show the teacher that they truly understand the lesson.
Tests, quizzes, essays, and presentations can be used as independent practice.
If a teacher notices the entire class struggles with the independent practice, the teacher can choose to spend a little extra time going back over the information, probably using a different method than before so that the students can better comprehend.
For in-class independent practice activities, the teacher should be sure to go over the directions and make sure students clearly understand what is being asked of them.
We hope you noticed that there are different methods that can all be viable options for you in the classroom.
Now, it will be your turn to think about how you might handle guided and independent practice activities in your classroom.
What independent practice activities could you use to find out how much the students learned, and if they can complete the task on their own?
Don't be afraid to think outside the box and try something new.
Of course, be sure to have fun.
In this module, what we're looking at, is the sorts of things we can do with vectors.
We can look at a way to combine vectors together to get a number called the dot product.
It will take us on to find the scalar and vector projections.
Now, it will then takes on to looking at the vectors that we use to define the space, the basis vectors, and a linear independence and linear combinations, and that will wrap up module two.
This is hopefully going to be a good work.
This is the main module on vectors.
After this, in the next modules, we'll move over to matrices.
Let's get started with the next video on the modulus and the dot product.
Welcome to module five of the linear algebra course.
Finally, we'll be applying this new tool to recreate Google's famous method for taking internet search results, and ordering them by relevance, known as the page rank algorithm.
I hope you enjoyed this module, and make use of the forums to let us know how you're getting on.
This brings us to the end of the fifth module and also, to the end of this course on linear algebra for machine learning.
We've covered a lot of ground in the past five modules, but I hope that we've managed to balance, the speed with the level of detail to ensure that you've stayed with us throughout.
There is a tension at the heart of mathematics teaching in the computer age.
This can mean that, despite doing lots of work, students can come away from a classical education missing both the detailed view of the computational methods, but also the high level view of what each method is really doing.
The concepts that you've been exposed to over the last five modules cover the core of linear algebra.
That you will need as you progress your study of machine learning.
And we hope that at the very least, when you get stuck in the future, you'll know the appropriate language.
So that you can quickly look up some help when you need it.
Which, after all, is the most important skill of a professional coder.
And I teach mechanical engineering here at the Georgia Institute of Technology.
This course will cover the fundamental of static and fatigue failure analysis methodologies.
That can be applied to a wide variety of engineering components.
From simple designs such as a screwdriver, to more complex designs like a Zimmer total hip implant.
Prior to Georgia Tech, I worked for a number of years at Northrop Grumman Aerospace Systems as a mechanical engineer.
Where I helped with the design, material selection, and manufacturing of a number of satellites for the United States Air Force.
After my time at Northrop Grumman, I returned to school and received a PhD in mechanical engineering form the University of Colorado at Boulder.
Where I studied novel biomaterials and design of prosthetic arteries.
One of the most exciting fields in engineering is design.
Where the Engineer gets to create something that's never existed before.
In the design of complex components and systems, it's critical to use robust analysis techniques to validate and predict design performance and like.
In this course, you'll learn some of these techniques.
We'll then transition into static failure theories, such as the distortion energy theory.
Which can be utilized to predict failure in the beams of a building.
Such as the input shaft of a transmission in a car.
Throughout this course, I will tie the fundamental engineering principles into real life engineering applications.
Such as the design of a Zimmer total hip implant, the steel selection in an automobile, or the static wing test of a Boeing triple seven aircraft.
Top engineers from Boeing, GM, Zimmer, and Ingenium Technologies have contributed to the content of this course.
This is going to be a great course.
I look forward to teaching you these essential principles in engineering, design, and analysis.
In this video, I'm going to define what is probably the most common type of Machine Learning problem, which is Supervised Learning.
I'll define Supervised Learning more formally later, but it's probably best to explain or start with an example of what it is, and we'll do the formal definition later.
Let's say you want to predict housing prices.
Here on the horizontal axis, the size of different houses in square feet, and on the vertical axis, the price of different houses in thousands of dollars.
So, given this data, let's say you have a friend who owns a house that is say 750 square feet, and they are hoping to sell the house, and they want to know how much they can get for the house.
So, how can the learning algorithm help you?
One thing a learning algorithm might be want to do is put a straight line through the data, also fit a straight line to the data.
Based on that, it looks like maybe their house can be sold for maybe about $150,000.
But maybe this isn't the only learning algorithm you can use, and there might be a better one.
For example, instead of fitting a straight line to the data, we might decide that it's better to fit a quadratic function, or a second-order polynomial to this data.
If you do that and make a prediction here, then it looks like, well, maybe they can sell the house for closer to $200,000.
One of the things we'll talk about later is how to choose, and how to decide, do you want to fit a straight line to the data?
There's no fair picking whichever one gives your friend the better house to sell.
So, this is an example of a Supervised Learning algorithm.
The term Supervised Learning refers to the fact that we gave the algorithm a data set in which the, called, "right answers" were given.
So, what was the actual price that that house sold for, and the task of the algorithm was to just produce more of these right answers such as for this new house that your friend may be trying to sell.
To define a bit more terminology, this is also called a regression problem.
By regression problem, I mean we're trying to predict a continuous valued output.
So technically, I guess prices can be rounded off to the nearest cent.
But usually, we think of the price of a house as a real number, as a scalar value, as a continuous value number, and the term regression refers to the fact that we're trying to predict the sort of continuous values attribute.
Here's another Supervised Learning examples.
Some friends and I were actually working on this earlier.
Let's say you want to look at medical records and try to predict of a breast cancer as malignant or benign.
If someone discovers a breast tumor, a lump in their breast, a malignant tumor is a tumor that is harmful and dangerous, and a benign tumor is a tumor that is harmless.
So obviously, people care a lot about this.
Suppose you are in your dataset, you have on your horizontal axis the size of the tumor, and on the vertical axis, I'm going to plot one or zero, yes or no, whether or not these are examples of tumors we've seen before are malignant, which is one, or zero or not malignant or benign.
Sadly, we also saw a few malignant tumors cell, one of that size, one of that size, one of that size, so on.
So in this example, I have five examples of benign tumors shown down here, and five examples of malignant tumors shown with a vertical axis value of one.
Let's say a friend who tragically has a breast tumor, and let's say her breast tumor size is maybe somewhere around this value, the Machine Learning question is, can you estimate what is the probability, what's the chance that a tumor as malignant versus benign?
To introduce a bit more terminology, this is an example of a classification problem.
The term classification refers to the fact, that here, we're trying to predict a discrete value output zero or one, malignant or benign.
It turns out that in classification problems, sometimes you can have more than two possible values for the output.
As a concrete example, maybe there are three types of breast cancers.
So, you may try to predict a discrete value output zero, one, two, or three, where zero may mean benign, benign tumor, so no cancer, and one may mean type one cancer, maybe three types of cancer, whatever type one means, and two mean a second type of cancer, and three may mean a third type of cancer.
In classification problems, there is another way to plot this data.
Let me show you what I mean.
I'm going to use a slightly different set of symbols to plot this data.
So, if tumor size is going to be the attribute that I'm going to use to predict malignancy or benignness, I can also draw my data like this.
I'm going to use different symbols to denote my benign and malignant, or my negative and positive examples.
So, instead of drawing crosses, I'm now going to draw O's for the benign tumors, like so, and I'm going to keep using X's to denote my malignant tumors.
All I did was I took my data set on top, and I just mapped it down to this real line like so, and started to use different symbols, circles and crosses to denote malignant versus benign examples.
Now, in this example, we use only one feature or one attribute, namely the tumor size in order to predict whether a tumor is malignant or benign.
Here's an example, let's say that instead of just knowing the tumor size, we know both the age of the patients and the tumor size.
In that case, maybe your data set would look like this, where I may have a set of patients with those ages, and that tumor size, and they look like this, and different set of patients that look a little different, whose tumors turn out to be malignant as denoted by the crosses.
So, let's say you have a friend who tragically has a tumor, and maybe their tumor size and age falls around there.
In this example, we had two features namely, the age of the patient and the size of the tumor.
It turns out one of the most interesting learning algorithms that we'll see in this course, as the learning algorithm that can deal with not just two, or three, or five features, but an infinite number of features.
On this slide, I've listed a total of five different features.
Two on the axis and three more up here.
But it turns out that for some learning problems what you really want is not to use like three or five features, but instead you want to use an infinite number of features, an infinite number of attributes, so that your learning algorithm has lots of attributes, or features, or cues with which to make those predictions.
So, how do you deal with an infinite number of features?
How do you even store an infinite number of things in the computer when your computer is going to run out of memory?
It turns out that when we talk about an algorithm called the Support Vector Machine, there will be a neat mathematical trick that will allow a computer to deal with an infinite number of features.
I just kept writing more and more features, like an infinitely long list of features.
It turns out we will come up with an algorithm that can deal with that.
So, just to recap, in this course, we'll talk about Supervised Learning, and the idea is that in Supervised Learning, in every example in our data set, we are told what is the correct answer that we would have quite liked the algorithms have predicted on that example.
Such as the price of the house, or whether a tumor is malignant or benign.
We also talked about the regression problem, and by regression that means that our goal is to predict a continuous valued output.
Suppose you're running a company and you want to develop learning algorithms to address each of two problems.
In the first problem, you have a large inventory of identical items.
So, imagine that you have thousands of copies of some identical items to sell, and you want to predict how many of these items you sell over the next three months.
In the second problem, problem two, you have lots of users, and you want to write software to examine each individual of your customer's accounts, so each one of your customer's accounts.
For each account, decide whether or not the account has been hacked or compromised.
So, for each of these problems, should they be treated as a classification problem or as a regression problem?
When the video pauses, please use your mouse to select whichever of these four options on the left you think is the correct answer.
Therefore, the number of items I sell as a continuous value.
So, just like your breast cancers where zero is benign, one is malignant.
So, I might set this be zero or one depending on whether it's been hacked, and have an algorithm try to predict each one of these two discrete values.
Because there's a small number of discrete values, I would therefore treat it as a classification problem.
In the next video, I'll talk about Unsupervised Learning, which is the other major category of learning algorithm.
In this video, we'll talk about the second major type of machine learning problem, called Unsupervised Learning.
In the last video, we talked about Supervised Learning.
So for each example in Supervised Learning, we were told explicitly what is the so-called right answer, whether it's benign or malignant.
In Unsupervised Learning, we're given data that looks different than data that looks like this that doesn't have any labels or that all has the same label or really no labels.
So we're given the data set and we're not told what to do with it and we're not told what each data point is.
Instead we're just told, here is a data set.
Can you find some structure in the data?
Given this data set, an Unsupervised Learning algorithm might decide that the data lives in two different clusters.
And yes, Supervised Learning algorithm may break these data into these two separate clusters.
So this is called a clustering algorithm.
And this turns out to be used in many places.
One example where clustering is used is in Google News and if you have not seen this before, you can actually go to this URL news.google.com to take a look.
What Google News does is everyday it goes and looks at tens of thousands or hundreds of thousands of new stories on the web and it groups them into cohesive news stories.
For example, let's look here.
The URLs here link to different news stories about the BP Oil Well story.
So, let's click on one of these URL's and we'll click on one of these URL's.
What I'll get to is a web page like this.
Here's a Wall Street Journal article about, you know, the BP Oil Well Spill stories of "BP Kills Macondo", which is a name of the spill and if you click on a different URL from that group then you might get the different story.
Here's the CNN story about a game, the BP Oil Spill, and if you click on yet a third link, then you might get a different story.
Here's the UK Guardian story about the BP Oil Spill.
So what Google News has done is look for tens of thousands of news stories and automatically cluster them together.
So, the news stories that are all about the same topic get displayed together.
It turns out that clustering algorithms and Unsupervised Learning algorithms are used in many other problems as well.
Here's an example of DNA microarray data.
The idea is put a group of different individuals and for each of them, you measure how much they do or do not have a certain gene.
Technically you measure how much certain genes are expressed.
So these colors, red, green, gray and so on, they show the degree to which different individuals do or do not have a specific gene.
And what you can do is then run a clustering algorithm to group individuals into different categories or into different types of people.
So this is Unsupervised Learning because we're not telling the algorithm in advance that these are type 1 people, those are type 2 persons, those are type 3 persons and so on and instead what were saying is yeah here's a bunch of data.
I don't even know what the different types of people are, but can you automatically find structure in the data from the you automatically cluster the individuals into these types that I don't know in advance?
Because we're not giving the algorithm the right answer for the examples in my data set, this is Unsupervised Learning.
Unsupervised Learning or clustering is used for a bunch of other applications.
It's used to organize large computer clusters.
I had some friends looking at large data centers, that is large computer clusters and trying to figure out which machines tend to work together and if you can put those machines together, you can make your data center work more efficiently.
This second application is on social network analysis.
So given knowledge about which friends you email the most or given your Facebook friends or your Google+ circles, can we automatically identify which are cohesive groups of friends, also which are groups of people that all know each other?
Many companies have huge databases of customer information.
So, can you look at this customer data set and automatically discover market segments and automatically group your customers into different market segments so that you can automatically and more efficiently sell or market your different market segments together?
Again, this is Unsupervised Learning because we have all this customer data, but we don't know in advance what are the market segments and for the customers in our data set, you know, we don't know in advance who is in market segment one, who is in market segment two, and so on.
But we have to let the algorithm discover all this just from the data.
Finally, it turns out that Unsupervised Learning is also used for surprisingly astronomical data analysis and these clustering algorithms gives surprisingly interesting useful theories of how galaxies are formed.
All of these are examples of clustering, which is just one type of Unsupervised Learning.
I'm gonna tell you about the cocktail party problem.
So, you've been to cocktail parties before, right?
Well, you can imagine there's a party, room full of people, all sitting around, all talking at the same time and there are all these overlapping voices because everyone is talking at the same time, and it is almost hard to hear the person in front of you.
So maybe at a cocktail party with two people, two people talking at the same time, and it's a somewhat small cocktail party.
And we're going to put two microphones in the room so there are microphones, and because these microphones are at two different distances from the speakers, each microphone records a different combination of these two speaker voices.
Maybe speaker one is a little louder in microphone one and maybe speaker two is a little bit louder on microphone 2 because the 2 microphones are at different positions relative to the 2 speakers, but each microphone would cause an overlapping combination of both speakers' voices.
So here's an actual recording of two speakers recorded by a researcher.
Let me play for you the first, what the first microphone sounds like.
What you just heard was the first microphone recording, here's the second recording.
Uno (one), dos (two), tres (three), cuatro (four), cinco (five), seis (six), siete (seven), ocho (eight), nueve (nine) y diez (ten).
And what the algorithm will do is listen to these audio recordings and say, you know it sounds like the two audio recordings are being added together or that have being summed together to produce these recordings that we had.
Moreover, what the cocktail party algorithm will do is separate out these two audio sources that were being added or being summed together to form other recordings and, in fact, here's the first output of the cocktail party algorithm.
One, two, three, four, five, six, seven, eight, nine, ten.
And here's the second of it.
Uno, dos, tres, quatro, cinco, seis, siete, ocho, nueve y diez.
Not too bad, to give you one more example, here's another recording of another similar situation, here's the first microphone : One, two, three, four, five, six, seven, eight, nine, ten.
Here's the second microphone recording.
One, two, three, four, five, six, seven, eight, nine, ten.
One, two, three, four, five, six, seven, eight, nine, ten.
So that wasn't perfect, it got the voice, but it also got a little bit of the music in there.
Then here's the second output to the algorithm.
Not too bad, in that second output it managed to get rid of the voice entirely.
And just, you know, cleaned up the music, got rid of the counting from one to ten.
So you might look at an Unsupervised Learning algorithm like this and ask how complicated this is to implement this, right?
It seems like in order to, you know, build this application, it seems like to do this audio processing you need to write a ton of code or maybe link into like a bunch of synthesizer Java libraries that process audio, seems like a really complicated program, to do this audio, separating out audio and so on.
It turns out the algorithm, to do what you just heard, that can be done with one line of code - shown right here.
It take researchers a long time to come up with this line of code.
I'm not saying this is an easy problem, But it turns out that when you use the right programming environment, many learning algorithms can be really short programs.
So this is also why in this class we're going to use the Octave programming environment.
Octave, is free open source software, and using a tool like Octave or Matlab, many learning algorithms become just a few lines of code to implement.
Later in this class, I'll just teach you a little bit about how to use Octave and you'll be implementing some of these algorithms in Octave.
Or if you have Matlab you can use that too.
It turns out the Silicon Valley, for a lot of machine learning algorithms, what we do is first prototype our software in Octave because software in Octave makes it incredibly fast to implement these learning algorithms.
Here each of these functions like for example the SVD function that stands for singular value decomposition; but that turns out to be a linear algebra routine, that is just built into Octave.
If you were trying to do this in C++ or Java, this would be many many lines of code linking complex C++ or Java libraries.
So, you can implement this stuff as C++ or Java or Python, it's just much more complicated to do so in those languages.
And in fact what many people will do to in the large Silicon Valley companies is in fact, use an algorithm like Octave to first prototype the learning algorithm, and only after you've gotten it to work, then you migrate it to C++ or Java or whatever.
It turns out that by doing things this way, you can often get your algorithm to work much faster than if you were starting out in C++.
So, I know that as an instructor, I get to say "trust me on this one" only a finite number of times, but for those of you who've never used these Octave type programming environments before, I am going to ask you to trust me on this one, and say that you, you will, I think your time, your development time is one of the most valuable resources.
And having seen lots of people do this, I think you as a machine learning researcher, or machine learning developer will be much more productive if you learn to start in prototype, to start in Octave, in some other language.
We talked about Unsupervised Learning, which is a learning setting where you give the algorithm a ton of data and just ask it to find structure in the data for us.
Of the following four examples, which ones, which of these four do you think would will be an Unsupervised Learning algorithm as opposed to Supervised Learning problem.
For each of the four check boxes on the left, check the ones for which you think Unsupervised Learning algorithm would be appropriate and then click the button on the lower right to check your answer.
So when the video pauses, please answer the question on the slide.
If you have labeled data, you know, with spam and non-spam e-mail, we'd treat this as a Supervised Learning problem.
The news story example, that's exactly the Google News example that we saw in this video, we saw how you can use a clustering algorithm to cluster these articles together so that's Unsupervised Learning.
The market segmentation example I talked a little bit earlier, you can do that as an Unsupervised Learning problem because I am just gonna get my algorithm data and ask it to discover market segments automatically.
And the final example, diabetes, well, that's actually just like our breast cancer example from the last video.
Only instead of, you know, good and bad cancer tumors or benign or malignant tumors we instead have diabetes or not and so we will use that as a supervised, we will solve that as a Supervised Learning problem just like we did for the breast tumor data.
So, that's it for Unsupervised Learning and in the next video, we'll delve more into specific learning algorithms and start to talk about just how these algorithms work and how we can, how you can go about implementing them.
Our first learning algorithm will be linear regression.
In this video, you'll see what the model looks like and more importantly you'll see what the overall process of supervised learning looks like.
Let's use some motivating example of predicting housing prices.
We're going to use a data set of housing prices from the city of Portland, Oregon.
Let's say that given this data set, you have a friend that's trying to sell a house and let's see if friend's house is size of 1250 square feet and you want to tell them how much they might be able to sell the house for.
Well one thing you could do is fit a model.
Maybe fit a straight line to this data.
Looks something like that and based on that, maybe you could tell your friend that let's say maybe he can sell the house for around $220,000.
So this is an example of a supervised learning algorithm.
And it's supervised learning because we're given the, quotes, "right answer" for each of our examples.
And just to remind you the other most common type of supervised learning problem is called the classification problem where we predict discrete-valued outputs such as if we are looking at cancer tumors and trying to decide if a tumor is malignant or benign.
So that's a zero-one valued discrete output.
More formally, in supervised learning, we have a data set and this data set is called a training set.
So for housing prices example, we have a training set of different housing prices and our job is to learn from this data how to predict prices of the houses.
Let's define some notation that we're using throughout this course.
We're going to define quite a lot of symbols.
It's okay if you don't remember all the symbols right now but as the course progresses it will be useful convenient notation.
So I'm gonna use lower case m throughout this course to denote the number of training examples.
So in this data set, if I have, you know, let's say 47 rows in this table.
Then I have 47 training examples and m equals 47.
notation, I'm going to use (x, y) to denote a single training example.
So, a single row in this table corresponds to a single training example and to refer to a specific training example, I'm going to use this notation x(i) comma gives me y(i) And, we're going to use this to refer to the ith training example.
This (x(i), y(i)), the superscript i in parentheses that's just an index into my training set and refers to the ith row in this table, okay?
So this is not x to the power of i, y to the power of i.
Instead (x(i), y(i)) just refers to the ith row of this table.
So for example, x(1) refers to the input value for the first training example so that's 2104.
That's this x in the first row.
The first, the y value for my first training example, that's what that (1) refers to.
So as mentioned, occasionally I'll ask you a question to let you check your understanding and a few seconds in this video a multiple-choice question will pop up in the video.
When it does, please use your mouse to select what you think is the right answer.
What defined by the training set is.
So here's how this supervised learning algorithm works.
We saw that with the training set like our training set of housing prices and we feed that to our learning algorithm.
Is the job of a learning algorithm to then output a function which by convention is usually denoted lowercase h and h stands for hypothesis And what the job of the hypothesis is, is, is a function that takes as input the size of a house like maybe the size of the new house your friend's trying to sell so it takes in the value of x and it tries to output the estimated value of y for the corresponding house.
So h is a function that maps from x's to y's.
People often ask me, you know, why is this function called hypothesis.
It turns out that in machine learning, this is a name that was used in the early days of machine learning and it kinda stuck.
So don't worry too much about why people call it that.
When designing a learning algorithm, the next thing we need to decide is how do we represent this hypothesis h.
For this and the next few videos, I'm going to choose our initial choice , for representing the hypothesis, will be the following.
We're going to represent h as follows.
And as a shorthand, sometimes instead of writing, you know, h subscript theta of x, sometimes there's a shorthand, I'll just write as a h of x.
But more often I'll write it as a subscript theta over there.
And plotting this in the pictures, all this means is that, we are going to predict that y is a linear function of x.
Right, so that's the data set and what this function is doing, is predicting that y is some straight line function of x.
And why a linear function?
Well, sometimes we'll want to fit more complicated, perhaps non-linear functions as well.
But since this linear case is the simple building block, we will start with this example first of fitting linear functions, and we will build on this to eventually have more complex models, and more complex learning algorithms.
Let me also give this particular model a name.
This model is called linear regression or this, for example, is actually linear regression with one variable, with the variable being x.
Predicting all the prices as functions of one variable X.
And univariate is just a fancy way of saying one variable.
So, that's linear regression.
In the next video we'll start to talk about just how we go about implementing this model.
In this video we'll define something called the cost function, this will let us figure out how to fit the best possible straight line to our data.
And the form of our hypothesis, which we use to make predictions is this linear function.
To introduce a little bit more terminology, these theta zero and theta one, they stabilize what I call the parameters of the model.
And what we're going to do in this video is talk about how to go about choosing these two parameter values, theta 0 and theta 1.
With different choices of the parameter's theta 0 and theta 1, we get different hypothesis, different hypothesis functions.
I know some of you will probably be already familiar with what I am going to do on the slide, but just for review, here are a few examples.
If theta 0 is 1.5 and theta 1 is 0, then the hypothesis function will look like this.
Because your hypothesis function will be h of x equals 1.5 plus 0 times x which is this constant value function which is phat at 1.5.
Or really h of theta(x), but sometimes I'll just omit theta for brevity.
So h(x) will be equal to just 0.5 times x, which looks like that.
And finally, if theta zero equals one, and theta one equals 0.5, then we end up with a hypothesis that looks like this.
Let's see, it should pass through the two-two point.
Whatever way you remember, I said that this is h subscript theta of x, but that's a shorthand, sometimes I'll just write this as h of x.
In linear regression, we have a training set, like maybe the one I've plotted here.
So, how do we come up with values, theta zero, theta one, that corresponds to a good fit to the data?
The idea is we get to choose our parameters theta 0, theta 1 so that h of x, meaning the value we predict on input x, that this is at least close to the values y for the examples in our training set, for our training examples.
So in our training set, we've given a number of examples where we know X decides the wholes and we know the actual price is was sold for.
So, let's try to choose values for the parameters so that, at least in the training set, given the X in the training set we make reason of the active predictions for the Y values.
Let's formalize this.
So linear regression, what we're going to do is, I'm going to want to solve a minimization problem.
And I want this to be small, right?
I want the difference between h(x) and y to be small.
And one thing I might do is try to minimize the square difference between the output of the hypothesis and the actual price of a house.
You remember that I was using the notation (x(i),y(i)) to represent the ith training example.
So what I want really is to sum over my training set, something i = 1 to m, of the square difference between, this is the prediction of my hypothesis when it is input to size of house number i.
Minus the actual price that house number I was sold for, and I want to minimize the sum of my training set, sum from I equals one through M, of the difference of this squared error, the square difference between the predicted price of a house, and the price that it was actually sold for.
And just remind you of notation, m here was the size of my training set right?
So my m there is my number of training examples.
Putting the 2 at the constant one half in front, it may just sound the math probably easier so minimizing one-half of something, right, should give you the same values of the process, theta 0 theta 1, as minimizing that function.
And just to be sure, this equation is clear, right?
This expression in here, h subscript theta(x), this is our usual, right?
So this is going to be my overall objective function for linear regression.
And just to rewrite this out a little bit more cleanly, what I'm going to do is, by convention we usually define a cost function, which is going to be exactly this, that formula I have up here.
Just write this out.
So, this cost function is also called the squared error function.
It turns out that these squared error cost function is a reasonable choice and works well for problems for most regression programs.
But the square cost function is probably the most commonly used one for regression problems.
Later in this class we'll talk about alternative cost functions as well, but this choice that we just had should be a pretty reasonable thing to try for most linear regression problems.
So that's the cost function.
In case this function seems a little bit abstract, and you still don't have a good sense of what it's doing, in the next video, in the next couple videos, I'm actually going to go a little bit deeper into what the cause function "J" is doing and try to give you better intuition about what is computing and why we want to use it...
In the previous video, we gave the mathematical definition of the cost function.
In this video, let's look at some examples, to get back to intuition about what the cost function is doing, and why we want to use it.
To recap, here's what we had last time.
We want to fit a straight line to our data, so we had this formed as a hypothesis with these parameters theta zero and theta one, and with different choices of the parameters we end up with different straight line fits.
So the data which are fit like so, and there's a cost function, and that was our optimization objective.
So this video, in order to better visualize the cost function J, I'm going to work with a simplified hypothesis function, like that shown on the right.
We can, if you want, think of this as setting the parameter theta zero equal to 0.
So I have only one parameter theta one and my cost function is similar to before except that now H of X that is now equal to just theta one times X.
And I have only one parameter theta one and so my optimization objective is to minimize j of theta one.
In pictures what this means is that if theta zero equals zero that corresponds to choosing only hypothesis functions that pass through the origin, that pass through the point (0, 0).
Using this simplified definition of a hypothesizing cost function let's try to understand the cost function concept better.
It turns out that two key functions we want to understand.
The first is the hypothesis function, and the second is a cost function.
For a face value of theta one, this is a function of X.
So the hypothesis is a function of, what is the size of the house X.
In contrast, the cost function, J, that's a function of the parameter, theta one, which controls the slope of the straight line.
Let's plot these functions and try to understand them both better.
Let's start with the hypothesis.
Let's pick a value theta one, so when theta one equals one, and if that's my choice for theta one, then my hypothesis is going to look like this straight line over here.
X-axis, my horizontal axis is labeled X, is labeled you know, size of the house over here.
Now, of temporary, set theta one equals one, what I want to do is figure out what is j of theta one, when theta one equals one.
So let's go ahead and compute what the cost function has for.
Well, as usual, my cost function is defined as follows, right?
And, this is therefore equal to.
Of theta one x I minus y I and if you simplify this turns out to be.
It turns out each of these terms here is equal to zero.
Because for the specific training set I have or my 3 training examples are (1, 1), (2, 2), (3,3).
So, we now know that j of one Is equal to zero.
What I'm gonna do on the right is plot my cost function j.
And notice, because my cost function is a function of my parameter theta one, when I plot my cost function, the horizontal axis is now labeled with theta one.
So I have j of one zero zero so let's go ahead and plot that.
Now lets look at some other examples.
Theta-1 can take on a range of different values.
So theta-1 can take on the negative values, zero, positive values.
What happens then?
Let's go ahead and plot that.
I'm now going to set theta-1 equals 0.5, and in that case my hypothesis now looks like this.
As a line with slope equals to 0.5, and, lets compute J, of 0.5.
It turns out that the cost function is going to be the sum of square values of the height of this line.
Plus the sum of square of the height of that line, plus the sum of square of the height of that line, right?
Whereas, the actual value was one.
For my second example, I get, one minus two squared, because my hypothesis predicted one, but the actual housing price was two.
Because, M when trading set size, right, have three training examples.
In that, that's times simplifying for the parentheses it's 3.5.
So that's 3.5 over six which is about 0.68.
So now we know that j of 0.5 is about 0.68. Lets go and plot that.
Okay?
Now, let's do one more.
It turns out that if theta one is equal to zero, then H of X is just equal to, you know, this flat line, right, that just goes horizontally like this.
So it ends up with a value around 2.3 and of course we can keep on doing this for other values of theta one.
This turns out to be, you know, for 0.5, it turns out to have really high error.
It works out to be something, like, 5.25.
And so on, and the different values of theta one, you can compute these things, right?
And it turns out that you, your computed range of values, you get something like that.
And by computing the range of values, you can actually slowly create out.
Each value of theta one corresponds to a different hypothesis, or to a different straight line fit on the left.
And for each value of theta one, we could then derive a different value of j of theta one.
And for example, you know, theta one=1, corresponded to this straight line straight through the data.
And this point shown in magenta corresponded to maybe that line, and theta one=zero which is shown in blue that corresponds to this horizontal line.
Right, so for each value of theta one we wound up with a different value of J of theta one and we could then use this to trace out this plot on the right.
Now you remember, the optimization objective for our learning algorithm is we want to choose the value of theta one.
This was our objective function for the linear regression.
Well, looking at this curve, the value that minimizes j of theta one is, you know, theta one equals to one.
And low and behold, that is indeed the best possible straight line fit through our data, by setting theta one equals one.
And just, for this particular training set, we actually end up fitting it perfectly.
And that's why minimizing j of theta one corresponds to finding a straight line that fits the data well.
In this video, we looked up some plots.
To understand the cost function.
And we set the parameter theta zero to be only zero.
We'll go back to the original problem formulation and look at some visualizations involving both theta zero and theta one.
And hopefully that will give you, an even better sense of what the cost function j is doing in the original linear regression formulation.
In this video, lets delve deeper and get even better intuition about what the cost function is doing.
This video assumes that you're familiar with contour plots.
If you are not familiar with contour plots or contour figures some of the illustrations in this video may or may not make sense to you but is okay and if you end up skipping this video or some of it does not quite make sense because you haven't seen contour plots before.
That's okay and you will still understand the rest of this course without those parts of this.
Here's our problem formulation as usual, with the hypothesis parameters, cost function, and our optimization objective.
Unlike before, unlike the last video, I'm going to keep both of my parameters, theta zero, and theta one, as we generate our visualizations for the cost function.
So, same as last time, we want to understand the hypothesis H and the cost function J.
So, here's my training set of housing prices and let's make some hypothesis.
But, if I set theta zero=50 and theta one=0.06, then I end up with this hypothesis down here and that corresponds to that straight line.
Now given these value of theta zero and theta one, we want to plot the corresponding, you know, cost function on the right.
What we did last time was, right, when we only had theta one.
In other words, drawing plots that look like this as a function of theta one.
It turns out that when we have only one parameter, that the parts we drew had this sort of bow shaped function.
Now, when we have two parameters, it turns out the cost function also has a similar sort of bow shape.
And, in fact, depending on your training set, you might get a cost function that maybe looks something like this.
So as you vary theta zero and theta one, the two parameters, you get different values of the cost function J (theta zero, theta one) and the height of this surface above a particular point of theta zero, theta one.
Right, that's, that's the vertical axis.
And you can see it sort of has this bow like shape.
Let me show you the same plot in 3D.
You kinda of a get a sense, I hope, of this bowl shaped surface as that's what the cost function J looks like.
Now for the purpose of illustration in the rest of this video I'm not actually going to use these sort of 3D surfaces to show you the cost function J, instead I'm going to use contour plots.
So here's an example of a contour figure, shown on the right, where the axis are theta zero and theta one.
And what each of these ovals, what each of these ellipsis shows is a set of points that takes on the same value for J(theta zero, theta one).
So concretely, for example this, you'll take that point and that point and that point.
All three of these points that I just drew in magenta, they have the same value for J (theta zero, theta one).
So that the minimum, so the bottom of the bow is this point right there, right?
This middle, the middle of these concentric ellipses.
And the minimum with the bow, right, is right down there.
And so the contour figures is a, is way to, is maybe a more convenient way to visualize my function J.
So, let's look at some examples.
Over here, I have a particular point, right?
Now this line is really not such a good fit to the data, right.
This hypothesis, h(x), with these values of theta zero, theta one, it's really not such a good fit to the data.
And so you find that, it's cost.
Is a value that's out here that's you know pretty far from the minimum right it's pretty far this is a pretty high cost because this is just not that good a fit to the data.
Is equal to zero.
And this pair of parameters corresponds to that hypothesis, corresponds to flat line, that is, h(x) equals 360 plus zero times x.
So that's the hypothesis.
And this hypothesis again has some cost, and that cost is, you know, plotted as the height of the J function at that point.
Last example, this is actually not quite at the minimum, but it's pretty close to the minimum.
So this is not such a bad fit to the, to the data, where, for a particular value, of, theta zero.
Which, one of them has value, as in for a particular value for theta one.
And this is, this is not quite at the minimum, but it's pretty close.
And so the sum of squares errors is sum of squares distances between my, training samples and my hypothesis.
Really, that's a sum of square distances, right?
Of all of these errors.
This is pretty close to the minimum even though it's not quite the minimum.
So with these figures I hope that gives you a better understanding of what values of the cost function J, how they are and how that corresponds to different hypothesis and so as how better hypotheses may corresponds to points that are closer to the minimum of this cost function J.
Now of course what we really want is an efficient algorithm, right, a efficient piece of software for automatically finding The value of theta zero and theta one, that minimizes the cost function J, right?
And, in fact, we'll see it later, that when we look at more complicated examples, we'll have high dimensional figures with more parameters, that, it turns out, we'll see in a few, we'll see later in this course, examples where this figure, you know, cannot really be plotted, and this becomes much harder to visualize.
And so, what we want is to have software to find the value of theta zero, theta one that minimizes this function and in the next video we start to talk about an algorithm for automatically finding that value of theta zero and theta one that minimizes the cost function J.
We previously defined the cost function J.
In this video, I want to tell you about an algorithm called gradient descent for minimizing the cost function J.
It turns out gradient descent is a more general algorithm, and is used not only in linear regression.
It's actually used all over the place in machine learning.
And later in the class, we'll use gradient descent to minimize other functions as well, not just the cost function J for the linear regression.
So in this video, we'll talk about gradient descent for minimizing some arbitrary function J and then in later videos, we'll take this algorithm and apply it specifically to the cost function J that we have defined for linear regression.
So here's the problem setup.
And we want to come up with an algorithm for minimizing that as a function of J(theta 0, theta 1).
Just as an aside it turns out that gradient descent actually applies to more general functions.
But for the sake of brevity, for the sake of succinctness of notation, I'm just going to pretend I have only two parameters throughout the rest of this video.
Here's the idea for gradient descent.
What we're going to do is we're going to start off with some initial guesses for theta 0 and theta 1.
What we're going to do in gradient descent is we'll keep changing theta 0 and theta 1 a little bit to try to reduce J(theta 0, theta 1), until hopefully, we wind at a minimum, or maybe at a local minimum.
So let's see in pictures what gradient descent does.
Let's say you're trying to minimize this function.
So we're going to start off with theta 0, theta 1 at some point.
So imagine picking some value for theta 0, theta 1, and that corresponds to starting at some point on the surface of this function.
I did initialize them to 0, 0 but sometimes you initialize it to other values as well.
Now, I want you to imagine that this figure shows a hole.
In gradient descent, what we're going to do is we're going to spin 360 degrees around, just look all around us, and ask, if I were to take a little baby step in some direction, and I want to go downhill as quickly as possible, what direction do I take that little baby step in?
Turns out, that if you're standing at that point on the hill, you look all around and you find that the best direction is to take a little step downhill is roughly that direction.
Okay, and now you're at this new point on your hill.
And if you do that and take another step, you take a step in that direction.
And then you keep going.
Take another step, another step, and so on until you converge to this local minimum down here.
Gradient descent has an interesting property.
This first time we ran gradient descent we were starting at this point over here, right?
Started at that point over here.
Now imagine we had initialized gradient descent just a couple steps to the right.
Imagine we'd initialized gradient descent with that point on the upper right.
If you were to repeat this process, so start from that point, look all around, take a little step in the direction of steepest descent, you would do that.
Then look around, take another step, and so on.
And if you started just a couple of steps to the right, gradient descent would've taken you to this second local optimum over on the right.
And this is a property of gradient descent that we'll say a little bit more about later.
Let's look at the math.
This is the definition of the gradient descent algorithm.
So let's see, there's lot of details in this equation so let me unpack some of it.
So briefly, if I write a := b, what this means is, it means in a computer, this means take the value in b and use it overwrite whatever value is a.
So this means set a to be equal to the value of b, which is assignment.
And I can also do a := a + 1.
Whereas in contrast, if I use the equal sign and I write a equals b, then this is a truth assertion.
So if I write a equals b, then I'll asserting that the value of a equals to the value of b, right?
So the left hand side, that's the computer operation, where we set the value of a to a new value.
a and a + 1 can never be equal to the same values.
So this is first part of the definition.
This alpha here is a number that is called the learning rate.
And what alpha does is it basically controls how big a step we take downhill with creating descent.
So if alpha is very large, then that corresponds to a very aggressive gradient descent procedure where we're trying take huge steps downhill and if alpha is very small, then we're taking little, little baby steps downhill.
And I'll come back and say more about this later, about how to set alpha and so on.
I don't wanna talk about it right now, but I will derive this derivative term and tell you exactly what this is later, okay?
And some of you will be more familiar with calculus than others, but even if you aren't familiar with calculus, don't worry about it.
I'll tell you what you need to know about this term here.
Now, there's one more subtlety about gradient descent which is in gradient descent we're going to update, you know, theta 0 and theta 1, right?
And the subtlety of how you implement gradient descent is for this expression, for this update equation, you want to simultaneously update theta 0 and theta 1.
And the way to implement is you should compute the right hand side, right?
So let me say what I mean by that.
This is a correct implementation of gradient descent meaning simultaneous update.
So I'm gonna set temp0 equals that, set temp1 equals that so basic compute the right-hand sides, and then having computed the right-hand sides and stored them into variables temp0 and temp1, I'm gonna update theta 0 and theta 1 simultaneously because that's the correct implementation.
In contrast, here's an incorrect implementation that does not do a simultaneous update.
So in this incorrect implementation, we compute temp0, and then we update theta 0, and then we compute temp1, and then we update temp1.
And the difference between the right hand side and the left hand side implementations is that If you look down here, you look at this step, if by this time you've already updated theta 0, then you would be using the new value of theta 0 to compute this derivative term.
Because you've now plugged in the new value of theta 0 into this equation.
And so, this on the right-hand side is not a correct implementation of gradient descent, okay?
So I don't wanna say why you need to do the simultaneous updates.
And when people talk about gradient descent, they always mean simultaneous update.
If you implement the non simultaneous update, it turns out it will probably work anyway.
It's not what people refer to as gradient descent, and this is some other algorithm with different properties.
And for various reasons this can behave in slightly stranger ways, and so what you should do is really implement the simultaneous update of gradient descent.
So, that's the outline of the gradient descent algorithm.
In the next video, we're going to go into the details of the derivative term, which I wrote up but didn't really define.
And if you've taken a calculus class before and if you're familiar with partial derivatives and derivatives, it turns out that's exactly what that derivative term is, but in case you aren't familiar with calculus, don't worry about it.
The next video will give you all the intuitions and will tell you everything you need to know to compute that derivative term, even if you haven't seen calculus, or even if you haven't seen partial derivatives before.
And with that, with the next video, hopefully we'll be able to give you all the intuitions you need to apply gradient descent.
In the previous video, we gave a mathematical definition of gradient descent.
Let's delve deeper and in this video get better intuition about what the algorithm is doing and why the steps of the gradient descent algorithm might make sense.
Here's a gradient descent algorithm that we saw last time and just to remind you this parameter, or this term alpha is called the learning rate.
And it controls how big a step we take when updating my parameter theory j.
In order to convey these intuitions, what I want to do is use a slightly simpler example, where we want to minimize the function of just one parameter.
So we can have one d plots, which are a little bit simpler to look at.
So let's say, here's my function, J of theta 1.
And where theta 1 is a real number.
So imagine that we start off at that point on my function.
And as an aside, this derivative term, right, if you're wondering why I changed the notation from these partial derivative symbols.
If you don't know what the difference is between these partial derivative symbols and the dd theta, don't worry about it.
Technically in mathematics you call this a partial derivative and call this a derivative, depending on the number of parameters in the function J.
And so for the purpose of this lecture, think of these partial symbols and d, d theta 1, as exactly the same thing.
I'm gonna try to use the mathematically precise notation, but for our purposes these two notations are really the same thing.
And so let's see what this equation will do.
So we're going to compute this derivative, not sure if you've seen derivatives in calculus before, but what the derivative at this point does, is basically saying, now let's take the tangent to that point, like that straight line, that red line, is just touching this function, and let's look at the slope of this red line.
Okay, the slope of a line is just this height divided by this horizontal thing.
Now, this line has a positive slope, so it has a positive derivative.
Alpha the the learning, is always a positive number.
And, so we're going to take theta one is updated as theta one minus something.
So, gradient descent so far says we're going the right thing.
Let's look at another example.
So let's take my same function J, let's try to draw from the same function, J of theta 1.
And now, let's say I had to say initialize my parameter over there on the left.
Now my derivative term DV theta one J of theta one when you value into that this point, we're gonna look at right the slope of that line, so this derivative term is a slope of this line.
But this line is slanting down, so this line has negative slope.
Or alternatively, I say that this function has negative derivative, just means negative slope at that point.
And so I have theta 1 minus a negative number which means I'm actually going to increase theta, because it's minus of a negative number, means I'm adding something to theta.
So this whole theory of intuition behind what a derivative is doing, let's take a look at the rate term alpha and see what that's doing.
And let's look at what could happen if alpha is either too small or if alpha is too large.
So this first example, what happens if alpha is too small?
So here's my function J, J of theta.
Let's all start here.
Okay, so this one step.
Then from this new point, I'm gonna have to take another step.
And I'm gonna need a lot of steps to get to the minimum and so if alpha is too small gradient descent can be slow because it's gonna take these tiny tiny baby steps and so it's gonna need a lot of steps before it gets anywhere close to the global minimum.
So the derivative points to the right, but if alpha is too big, I want to take a huge step.
So it ends up taking a huge step, and now my cost functions have strong roots.
Cuz it starts off with this value, and now, my values are strong in verse.
Now my derivative points to the left, it says I should decrease data.
But if my learning is too big, I may take a huge step going from here all the way to out there.
So we end up being over there, right?
And if my is too big, we can take another huge step on the next elevation and kind of overshoot and overshoot and so on, until you already notice I'm actually getting further and further away from the minimum.
So if alpha is to large, it can fail to converge or even diverge.
Now, I have another question for you.
So this a tricky one and when I was first learning this stuff it actually took me a long time to figure this out.
What if your parameter theta 1 is already at a local minimum, what do you think one step of gradient descent will do?
So let's suppose you initialize theta 1 at a local minimum.
So, suppose this is your initial value of theta 1 over here and is already at a local optimum or the local minimum.
So for that slope, that tangent point, so the slope of this line will be equal to zero and thus this derivative term is equal to zero.
So if your parameters are already at a local minimum one step with gradient descent does absolutely nothing it doesn't your parameter which is what you want because it keeps your solution at the local optimum.
This also explains why gradient descent can converse the local minimum even with the learning rate alpha fixed.
Here's what I mean by that let's look in the example.
If I take one step in gradient descent, maybe it will take me to that point, because my derivative's pretty steep out there.
Now, I'm at this green point, and if I take another step in gradient descent, you notice that my derivative, meaning the slope, is less steep at the green point than compared to at the magenta point out there.
Because as I approach the minimum, my derivative gets closer and closer to zero, as I approach the minimum.
So after one step of descent, my new derivative is a little bit smaller.
I will naturally take a somewhat smaller step from this green point right there from the magenta point.
Now with a new point, a red point, and I'm even closer to global minimum so the derivative here will be even smaller than it was at the green point.
Now, my derivative term is even smaller and so the magnitude of the update to theta one is even smaller, so take a small step like so.
And as gradient descent runs, you will automatically take smaller and smaller steps.
Until eventually you're taking very small steps, you know, and you finally converge to the to the local minimum.
So just to recap, in gradient descent as we approach a local minimum, gradient descent will automatically take smaller steps.
And that's because as we approach the local minimum, by definition the local minimum is when the derivative is equal to zero.
As we approach local minimum, this derivative term will automatically get smaller, and so gradient descent will automatically take smaller steps.
This is what so no need to decrease alpha or the time.
In the next video, we're going to take the function J and set that back to be exactly linear regression's cost function, the square cost function that we came up with earlier.
And taking gradient descent and this great cause function and putting them together.
That will give us our first learning algorithm, that'll give us a linear regression algorithm.
In previous videos, we talked about the gradient descent algorithm and we talked about the linear regression model and the squared error cost function.
In this video we're gonna put together gradient descent with our cost function, and that will give us an algorithm for linear regression or putting a straight line to our data.
So this was what we worked out in the previous videos.
This gradient descent algorithm which you should be familiar and here's the linear regression model with our linear hypothesis and our squared error cost function.
What we're going to do is apply gradient descent to minimize our squared error cost function.
Now in order to apply gradient descent, in order to, you know, write this piece of code, the key term we need is this derivative term over here.
So you need to figure out what is this partial derivative term and plugging in the definition of the cause function j.
And all I did here was I just, you know plug in the definition of the cost function there.
And all I did there was I took the definition for my hypothesis and plugged it in there.
So we want to figure out what is this partial derivative for both the theta 0 case and the theta 1 case.
And I'm just going to write out the answers.
It turns out this first term is, simplifies to 1/M sum from over my training step of just that of X(i)- Y(i) and for this term partial derivative let's write the theta 1, it turns out I get this term.
Minus Y(i) times X(i).
If you know calculus, feel free to work through the derivations yourself and check that if you take the derivatives, you actually get the answers that I got.
But if you're less familiar with calculus, don't worry about it and it's fine to just take these equations that were worked out and you won't need to know calculus or anything like that, in order to do the homework so let's implement gradient descent and get back to work.
So armed with these definitions or armed with what we worked out to be the derivatives which is really just the slope of the cost function j we can now plug them back in to our gradient descent algorithm.
So here's our linear regression algorithm.
That term is of course just the partial derivative with respect to theta zero, that we worked out on a previous slide.
And this second term here, that term is just a partial derivative in respect to theta 1, that we worked out on the previous line.
There's actually this detail that you should be implementing it so the update theta 0 and theta 1 simultaneously.
Let's see how gradient descent works.
One of the issues we saw with gradient descent is that it can be susceptible to local optima.
So when I first explained gradient descent I showed you this picture of it going downhill on the surface, and we saw how depending on where you initialize it, you can end up at different local optima.
But, it turns out that that the cost function for linear regression is always going to be a bow shaped function like this.
The technical term for this is that this is called a convex function.
But informally a convex function means a bowl shaped function and so this function doesn't have any local optima except for the one global optimum.
And does gradient descent on this type of cost function which you get whenever you're using linear regression it will always converge to the global optimum.
So now let's see this algorithm in action.
As usual, here are plots of the hypothesis function and of my cost function j.
And so this corresponds to h(x)=-900-0.1x, is this line, out here on the cost function.
Let's get started with our linear algebra review.
In this video I want to tell you what are matrices and what are vectors.
A matrix is a rectangular array of numbers written between square brackets.
These could be features from a learning problem or it could be data from somewhere else, but the specific values don't matter, and then I'm going to close it with another right bracket on the right.
And so that's one matrix.
So matrix is just another way for saying, is a 2D or a two dimensional array.
And the other piece of knowledge that we need is that the dimension of the matrix is going to be written as the number of row times the number of columns in the matrix.
So, four rows, two columns.
This one on the right, this matrix has two rows.
That's the first row, that's the second row, and it has three columns.
So we say that the dimension of this matrix is 2 by 3.
So, this thing here, this just means the set of all matrices that of dimension 4 by 2 and this thing on the right, sometimes this is written out as a matrix that is an R 2 by 3.
So if you ever see something like this are 4 by 2 or are 2 by 3, people are just referring to matrices of a specific dimension.
Next, let's talk about how to refer to specific elements of the matrix.
And by matrix elements, other than the matrix I just mean the entries, so the numbers inside the matrix.
So, in the standard notation, if A is this matrix here, then A sub-strip IJ is going to refer to the i, j entry, meaning the entry in the matrix in the ith row and jth column.
So for example a1-1 is going to refer to the entry in the 1st row and the 1st column, so that's the first row and the first column and so a1-1 is going to be equal to 1, 4, 0, 2.
Another example, 8 1 2 is going to refer to the entry in the first row and the second column and so A 1 2 is going to be equal to one nine one.
And finally, 8 4 1 is going to refer to this one right, fourth row, first column is equal to 1 4 7 and if, hopefully you won't, but if you were to write and say well this A 4 3, well, that refers to the fourth row, and the third column that, you know, this matrix has no third column so this is undefined, you know, or you can think of this as an error.
So, the matrix gets you a way of letting you quickly organize, index and access lots of data.
In case I seem to be tossing up a lot of concepts, a lot of new notations very rapidly, you don't need to memorize all of this, but on the course website where we have posted the lecture notes, we also have all of these definitions written down.
Don't worry about memorizing everything now.
You can always refer back to the written materials on the course website, and use that as a reference.
So that's what a matrix is.
Next, let's talk about what is a vector.
A vector turns out to be a special case of a matrix.
A vector is a matrix that has only 1 column so you have an N x 1 matrix, then that's a remember, right?
N is the number of rows, and 1 here is the number of columns, so, so matrix with just one column is what we call a vector.
so we also call this thing, another term for this is a four dmensional vector, just means that this is a vector with four elements, with four numbers in it.
So this R4 means a set of four-dimensional vectors.
Next let's talk about how to refer to the elements of the vector.
We are going to use the notation yi to refer to the ith element of the vector y.
So y1 is the first element,four sixty, y2 is equal to the second element, two thirty two -there's the first.
Y3 is equal to 315 and so on, and only y1 through y4 are defined consistency 4-dimensional vector.
So this example on the left is a one in that specter where the element we write is y1, y2, y3, y4.
And this example in the right is an example of a zero index factor where we start the indexing of the elements from zero.
And this is a bit like the arrays of some primary languages where the arrays can either be indexed starting from one.
The first element of an array is sometimes a Y1, this is sequence notation I guess, and sometimes it's zero index depending on what programming language you use.
So it turns out that in most of math, the one index version is more common For a lot of machine learning applications, zero index vectors gives us a more convenient notation.
In fact, throughout the rest of these videos on linear algebra review, I will be using one index vectors.
But just be aware that when we are talking about machine learning applications, sometimes I will explicitly say when we need to switch to, when we need to use the zero index vectors as well.
Finally, by convention, usually when writing matrices and vectors, most people will use upper case to refer to matrices.
So we're going to use capital letters like A, B, C, you know, X, to refer to matrices, and usually we'll use lowercase, like a, b, x, y, to refer to either numbers, or just raw numbers or scalars or to vectors.
This isn't always true but this is the more common notation where we use lower case "Y" for referring to vector and we usually use upper case to refer to a matrix.
So, you now know what are matrices and vectors.
Next, we'll talk about some of the things you can do with them
In this video we'll talk about matrix addition and subtraction, as well as how to multiply a matrix by a number, also called Scalar Multiplication.
Let's start an example.
Given two matrices like these, let's say I want to add them together.
And so, what does addition of matrices mean?
It turns out that if you want to add two matrices, what you do is you just add up the elements of these matrices one at a time.
So, my result of adding two matrices is going to be itself another matrix and the first element again just by taking one and four and multiplying them and adding them together, so I get five.
The second element I get by taking two and two and adding them, so I get four; three plus three plus zero is three, and so on.
And, on the right is open five, ten and two.
And it turns out you can add only two matrices that are of the same dimensions.
This is also a 3 by 2 matrix, and the result of adding these two matrices is a 3 by 2 matrix again.
So you can only add matrices of the same dimension, and the result will be another matrix that's of the same dimension as the ones you just added.
Where as in contrast, if you were to take these two matrices, so this one is a 3 by 2 matrix, okay, 3 rows, 2 columns.
Next, let's talk about multiplying matrices by a scalar number.
And the scalar is just a, maybe a overly fancy term for, you know, a number or a real number.
Alright, this means real number.
So let's take the number 3 and multiply it by this matrix.
And if you do that, the result is pretty much what you'll expect.
You just take your elements of the matrix and multiply them by 3, one at a time.
So, you know, one times three is three.
And so this matrix is the result of multiplying that matrix on the left by 3.
And you notice, again, this is a 3 by 2 matrix and the result is a matrix of the same dimension.
And by the way, you can write multiplication, you know, either way.
I can also take this matrix and multiply this by three.
So whether it's you know, 3 times the matrix or the matrix times three is the same thing and this thing here in the middle is the result.
You can also take a matrix and divide it by a number.
So, turns out taking this matrix and dividing it by four, this is actually the same as taking the number one quarter, and multiplying it by this matrix.
And so that's the results of computing this matrix divided by four.
Finally, for a slightly more complicated example, you can also take these operations and combine them together.
So in this calculation, I have three times a vector plus a vector minus another vector divided by three.
So just make sure we know where these are, right.
This is an example of scalar multiplication because I am taking three and multiplying it.
And this is, you know, another scalar multiplication.
And again, just to make sure we understand what is going on here, this plus symbol, that is matrix addition, right?
This, you can also call this vector addition This minus sign here, this is again a matrix subtraction, but because this is an n by 1, really a three by one matrix, that this is actually a vector, so this is also vector, this column.
We call this matrix a vector subtraction, as well.
OK?
This therefore gives me a vector, whose first element is going to be 3+0-1, so that's 3-1, which is 2.
The second element is 12+0-0, which is 12.
And so this gives me a 3 by 1 matrix, which is also just called a 3 dimensional vector, which is the outcome of this calculation over here.
So that's how you add and subtract matrices and vectors and multiply them by scalars or by row numbers.
So far I have only talked about how to multiply matrices and vectors by scalars, by row numbers.
In the next video we will talk about a much more interesting step, of taking 2 matrices and multiplying 2 matrices together.
In this video, I'd like to start talking about how to multiply together two matrices.
We'll start with a special case of that, of matrix vector multiplication - multiplying a matrix together with a vector.
Let's start with an example.
Here is a matrix, and here is a vector, and let's say we want to multiply together this matrix with this vector, what's the result?
Let me just work through this example and then we can step back and look at just what the steps were.
It turns out the result of this multiplication process is going to be, itself, a vector.
And I'm just going work with this first and later we'll come back and see just what I did here.
To get the first element of this vector I am going to take these two numbers and multiply them with the first row of the matrix and add up the corresponding numbers.
Take one multiplied by one, and take three and multiply it by five, and that's what, that's one plus fifteen so that gives me sixteen.
It turns out that the results of multiplying that's a 3x2 matrix by a 2x1 matrix is also just a two-dimensional vector.
The result of this is going to be a 3x1 matrix, so that's why three by one 3x1 matrix, in other words a 3x1 matrix is just a three dimensional vector.
Here's the details of how to multiply a matrix by a vector.
Let's say I have a matrix A and want to multiply it by a vector x.
The result is going to be some vector y.
So the matrix A is a m by n dimensional matrix, so m rows and n columns and we are going to multiply that by a n by 1 matrix, in other words an n dimensional vector.
In other words, the number of columns in this matrix, so it's the number of n columns.
It has to match the dimension of this vector.
And the result of this product is going to be an n-dimensional vector y.
So how do you actually compute this vector "Y"?
So here's what I mean.
In order to get the first element of "Y", that first number--whatever that turns out to be--we're gonna take the first row of the matrix "A" and multiply them one at a time with the elements of this vector "X".
So I take this first number multiply it by this first number.
Then take the second number multiply it by this second number.
Take this third number whatever that is, multiply it the third number and so on until you get to the end.
So we take the second row of A, and multiply it elements-wise, so the elements of X and add up the results of the products and that would give me the second element of Y.
And you keep going to get and we going to take the third row of A, multiply element Ys with the vector x, sum up the results and then I get the third element and so on, until I get down to the last row like so, okay?
Here's the example: So let's look at the dimensions.
Here, this is a three by four dimensional matrix.
This is a four-dimensional vector, or a 4 x 1 matrix, and so the result of this, the result of this product is going to be a three-dimensional vector.
So for the first element, I'm going to take these four numbers and multiply them with the vector X.
And then for the second element, I'm going to take this row now and multiply it with this vector (0x1)+3.
And finally, for the last element, I'm going to take this last row, so I have minus one times one.
So my final answer is this vector fourteen, just to write to that without the colors, fourteen, thirteen, negative seven.
And as promised, the result here is a three by one matrix.
So that's how you multiply a matrix and a vector.
I know that a lot just happened on this slide, so if you're not quite sure where all these numbers went, you know, feel free to pause the video you know, and so take a slow careful look at this big calculation that we just did and try to make sure that you understand the steps of what just happened to get us these numbers,fourteen, thirteen and eleven.
Let's say we have a set of four houses so 4 houses with 4 sizes like these.
It turns out there's neat way of posing this, applying this hypothesis to all of my houses at the same time.
It turns out there's a neat way to pose this as a Matrix Vector multiplication.
I am going to construct a matrix as follows.
And what I am going to do is to take matrix and that vector and multiply them together, that times is that multiplication symbol.
So what do I get?
Well this is a four by two matrix.
This is a two by one matrix.
So the outcome is going to be a four by one vector, all right.
Now it turns out and so this first element of this result, the way I am going to get that is, I am going to take this and multiply it by the vector.
And so this is going to be -40 x 1 + 4.25 x 2104.
By the way, on the earlier slides I was writing 1 x -40 and 2104 x 0.25, but the order doesn't matter, right?
-40 x 1 is the same as 1 x -40.
And this first element, of course, is "H" applied to 2104.
So it's really the predicted price of my first house.
Well, how about the second element?
Hope you can see where I am going to get the second element.
And so on for the third and the fourth elements of this 4 x 1 vector.
This thing here that I just drew the green box around, that's a real number, OK?
That's a single real number, and this thing here that I drew the magenta box around--the purple, magenta color box around--that's a real number, right?
And so this thing on the right--this thing on the right overall, this is a 4 by 1 dimensional matrix, was a 4 dimensional vector.
And, the neat thing about this is that when you're actually implementing this in software--so when you have four houses and when you want to use your hypothesis to predict the prices, predict the price "Y" of all of these four houses.
What this means is that, you know, you can write this in one line of code.
When we talk about octave and program languages later, you can actually, you'll actually write this in one line of code.
Where data matrix is this thing here, and parameters is this thing here, and this times is a matrix vector multiplication.
If you just do this, then prediction becomes this 4 by 1 dimensional vector, on the right, that just gives you all the predicted prices.
And your alternative to doing this as a matrix vector multiplication would be to write eomething like , you know, for I equals 1 to 4, right?
And you have say a thousand houses it would be for I equals 1 to a thousand or whatever.
and then do a bunch more work over there and it turns out that When you have a large number of houses, if you're trying to predict the prices of not just four but maybe of a thousand houses then it turns out that when you implement this in the computer, implementing it like this, in any of the various languages.
This is not only true for Octave, but for Supra Server Java or Python, other high-level, other languages as well.
It turns out, that, by writing code in this style on the left, it allows you to not only simplify the code, because, now, you're just writing one line of code rather than the form of a bunch of things inside.
I'll say more about this later when we talk about vectorization, but, so, by posing a prediction this way, you get not only a simpler piece of code, but a more efficient one.
So, that's it for matrix vector multiplication and we'll make good use of these sorts of operations as we develop the living regression in other models further.
But, in the next video we're going to take this and generalize this to the case of matrix matrix multiplication.
In this video we'll talk about matrix-matrix multiplication, or how to multiply two matrices together.
When we talk about the method in linear regression for how to solve for the parameters theta 0 and theta 1 all in one shot, without needing an iterative algorithm like gradient descent.
So let's, as usual, start with an example.
So the first thing I'm gonna do is I'm going to pull out the first column of this matrix on the right.
And I'm going to take this matrix on the left and multiply it by a vector that is just this first column.
So this is the same matrix-vector multiplication as you saw in the last video.
I worked this out in advance, so I know it's 11, 9.
And I'm then going to take this matrix on the left, so take that matrix, and multiply it by that second column on the right.
So again, this is a matrix-vector multiplication step which you saw from the previous video.
And by the way, if you want to practice your matrix-vector multiplication, feel free to pause the video and check this product yourself.
Then I'm just gonna take these two results and put them together, and that'll be my answer.
So it turns out the outcome of this product is gonna be a two by two matrix.
And taking 10, 14 and plugging them into the second column, okay?
So that was the mechanics of how to multiply a matrix by another matrix.
You basically look at the second matrix one column at a time and you assemble the answers.
But I just want to point out also, this first example is a 2x3 matrix.
Multiply that by a 3x2 matrix, and the outcome of this product turns out to be a 2x2 matrix.
And again, we'll see in a second why this was the case.
Let's actually look at the details and look at what exactly happened.
It turns out you can only multiply together matrices whose dimensions match.
So the number of columns in the first matrix must equal to the number of rows in the second matrix.
And in the previous video everything we did corresponded to the special case of o being equal to 1.
That was to the case of B being a vector.
But now we're gonna deal with the case of values of o larger than 1.
So here's how you multiply together the two matrices.
What I'm going to do is I'm going to take the first column of B and treat that as a vector, and multiply the matrix A by the first column of B.
Then I'm gonna take the second column of B, right?
So this is another n by 1 vector.
The result will be a m-dimensional vector, which we'll put there, and so on.
And so on, until you get to the last column.
The matrix times the last column gives you the last column of C.
Just to say that again, the ith column of the matrix C is obtained by taking the matrix A and multiplying the matrix A with the ith column of the matrix B for the values of i = 1, 2, up through o.
So this is just a summary of what we did up there in order to compute the matrix C.
Let's look at just one more example.
Let's say I want to multiply together these two matrices.
Matrix multiplication is really useful, since you can pack a lot of computation into just one matrix multiplication operation.
In this video, I wanna tell you about a few properties of matrix multiplication.
When working with just real numbers or when working with scalars, multiplication is commutative.
And this is called the commutative property of multiplication of real numbers.
It turns out this property, they can reverse the order in which you multiply things.
Then in general, A times B is not equal to B times A.
Its not okay to arbitrarily reverse the order in which you multiply matrices.
Matrix multiplication in not commutative, is the fancy way of saying it.
As a concrete example, here are two matrices.
Now let's swap around the order of these two matrices.
It turns out if you multiply these two matrices, you get the second answer on the right.
And well clearly, right, these two matrices are not equal to each other.
So, in fact, in general if you have a matrix operation like A times B, if A is an m by n matrix, and B is an n by m matrix, just as an example.
Then, it turns out that the matrix A times B, right, is going to be an m by m matrix.
In the example on the left, I have all two by two matrices.
So the dimensions were the same, but in general, reversing the order of the matrices can even change the dimension of the outcome.
So, matrix multiplication is not commutative.
Here's the next property I want to talk about.
And both of these give you the same answer, right?
Both of these is equal to 30.
And this is called the associative property of real number multiplication.
So concretely, let's say I have a product of three matrices A x B x C.
I'm not gonna prove this but you can just take my word for it I guess.
So just be clear, what I mean by these two cases.
Let's look at the first one, right.
And this is then the same as A x B x C, and it turns out that both of these options will give you this guarantee to give you the same answer.
When dealing with real numbers or scalar numbers, the number 1, you can think of it as the identity of multiplication.
Because this m has the match up that m, and in either case, the outcome of this process is you get back the matrix A which is m by n.
For most matrices A and B, this is not true.
In this video, I want to tell you about a couple of special matrix operations, called the matrix inverse and the matrix transpose operation.
Let's start by talking about matrix inverse, and as usual we'll start by thinking about how it relates to real numbers.
In the last video, I said that the number one plays the role of the identity in the space of real numbers because one times anything is equal to itself.
It turns out that real numbers have this property that very number have an, that each number has an inverse, for example, given the number three, there exists some number, which happens to be three inverse so that that number times gives you back the identity element one.
And so to me, inverse of course this is just one third.
And given some other number, maybe twelve there is some number which is the inverse of twelve written as twelve to the minus one, or really this is just one twelve.
So that when you multiply these two things together.
Now it turns out that in the space of real numbers, not everything has an inverse.
Because zero's a zero inverse, one over zero that's undefined.
And what we want to do, in the rest of this slide, is figure out what does it mean to compute the inverse of a matrix.
Here's the idea: If A is a n by n matrix, and it has an inverse, I will say a bit more about that later, then the inverse is going to be written A to the minus one and A times this inverse, A to the minus one, is going to equal to A inverse times A, is going to give us back the identity matrix.
Only matrices that are m by m for some the idea of M having inverse.
So, a matrix is M by M, this is also called a square matrix and it's called square because the number of rows is equal to the number of columns.
Right and it turns out only square matrices have inverses, so A is a square matrix, is m by m, on inverse this equation over here.
Let's look at a concrete example, so let's say I have a matrix, three, four, two, sixteen.
So this is a two by two matrix, so it's a square matrix and so this may just could have an and it turns out that I happen to know the inverse of this matrix is zero point four, minus zero point one, minus zero point zero five, zero zero seven five.
And if I take this matrix and multiply these together it turns out what I get is the two by two identity matrix, I, this is I two by two.
And so on this slide, you know this matrix is the matrix A, and this matrix is the matrix A-inverse.
And it turns out if that you are computing A times A-inverse, it turns out if you compute A-inverse times A you also get back the identity matrix.
It turns out that sometimes you can compute inverses by hand but almost no one does that these days.
And it turns out there is very good numerical software for taking a matrix and computing its inverse.
So again, this is one of those things where there are lots of open source libraries that you can link to from any of the popular programming languages to compute inverses of matrices.
How I actually computed this inverse, and what I did was I used software called Optive.
Let me just quickly show you an example.
Set my matrix A to be equal to that matrix on the left, type three four two sixteen, so that's my matrix A right.
This is matrix 34, 216 that I have down here on the left.
And, the software lets me compute the inverse of A very easily.
This given the numerical solution to what is the inverse of A.
Can also verify the inverse of A times A is also equal to the identity, ones on the diagonals and values that are essentially zero except for a little bit of round dot error on the off diagonals.
But it turns out that in this review I don't want to go too deeply into what it means matrix have an inverse but it turns out for our machine learning application this shouldn't be an issue or more precisely for the learning algorithms where this may be an to namely whether or not an inverse matrix appears and I will tell when we get to those learning algorithms just what it means for an algorithm to have or not have an inverse and how to fix it in case.
But the intuition if you want is that you can think of matrices as not have an inverse that is somehow too close to zero in some sense.
So, just to wrap up the terminology, matrix that don't have an inverse Sometimes called a singular matrix or degenerate matrix and so this matrix over here is an example zero zero zero matrix.
Finally, the last special matrix operation I want to tell you about is to do matrix transpose.
So suppose I have matrix A, if I compute the transpose of A, that's what I get here on the right.
This is a transpose which is written and A superscript T, and the way you compute the transpose of a matrix is as follows.
To get a transpose I am going to first take the first row of A one to zero.
And then I'm going to take the second row of A, 3 5 9, and that becomes the second column.
And another way of thinking about how the computer transposes is as if you're taking this sort of 45 degree axis and you are mirroring or you are flipping the matrix along that 45 degree axis.
so here's the more formal definition of a matrix transpose.
Let's say A is a m by n matrix.
Then B is going to be a n by m matrix with the dimensions reversed so here we have a 2x3 matrix.
So the IJ element of this matrix B is going to be the JI element of that earlier matrix A.
So for example, B 1 2 is going to be equal to, look at this matrix, B 1 2 is going to be equal to this element 3 1st row, 2nd column.
And so that wraps up the definition of what it means to take the transpose of a matrix and that in fact concludes our linear algebra review.
So by now hopefully you know how to add and subtract matrices as well as multiply them and you also know how, what are the definitions of the inverses and transposes of a matrix and these are the main operations used in linear algebra for this course.
In case this is the first time you are seeing this material.
I know this was a lot of linear algebra material all presented very quickly and it's a lot to absorb but if you there's no need to memorize all the definitions we just went through and if you download the copy of either these slides or of the lecture notes from the course website.
and use either the slides or the lecture notes as a reference then you can always refer back to the definitions and to figure out what are these matrix multiplications, transposes and so on definitions.
And the lecture notes on the course website also has pointers to additional resources linear algebra which you can use to learn more about linear algebra by yourself.
in this video we will start to talk about a new version of linear regression that's more powerful.
One that works with multiple variables or with multiple features.
In the original version of linear regression that we developed, we have a single feature x, the size of the house, and we wanted to use that to predict why the price of the house and this was our form of our hypothesis.
But now imagine, what if we had not only the size of the house as a feature or as a variable of which to try to predict the price, but that we also knew the number of bedrooms, the number of house and the age of the home and years.
It seems like this would give us a lot more information with which to predict the price.
Let's introduce a little bit more notation.
Now that we have four features I'm going to use lowercase "n" to denote the number of features.
So in this example we have n4 because we have, you know, one, two, three, four features.
And "n" is different from our earlier notation where we were using "n" to denote the number of examples.
So if you have 47 rows "M" is the number of rows on this table or the number of training examples.
As a concrete example let say X2 is going to be a vector of the features for my second training example.
And so X2 here is going to be a vector 1416, 3, 2, 40 since those are my four features that I have to try to predict the price of the second house.
This is not X to the power of 2.
Instead, this is, you know, an index that says look at the second row of this table.
This refers to my second training example.
With this notation X2 is a four dimensional vector.
With this notation, X2 is now a vector and so, I'm going to use also Xi subscript J to denote the value of the J, of feature number J and the training example.
So concretely X2 subscript 3, will refer to feature number three in the x factor which is equal to 2,right?
Now that we have multiple features, let's talk about what the form of our hypothesis should be.
Previously this was the form of our hypothesis, where x was our single feature, but now that we have multiple features, we aren't going to use the simple representation any more.
And if we have N features then rather than summing up over our four features, we would have a sum over our N features.
X two is the number of floors, and it goes up further for each additional bedroom the house has, because X three was the number of bedrooms, and the price goes down a little bit with each additional age of the house.
With each additional year of the age of the house.
Here's the form of a hypothesis rewritten on the slide.
And what I'm gonna do is introduce a little bit of notation to simplify this equation.
So whereas previously I had n features because x1, x2 through xn, I'm now defining an additional sort of zero feature vector that always takes on the value of one.
So now my feature vector X becomes this N+1 dimensional vector that is zero index.
This is another zero index vector.
It's of index signed from zero.
That is another n plus 1 dimensional vector.
And this equation is the same as this on top because, you know, eight zero is equal to one.
Underneath and I now take this form of the hypothesis and write this as either transpose x, depending on how familiar you are with inner products of vectors if you write what theta transfers x is what theta transfer and this is theta zero, theta one, up to theta N.
So this thing here is theta transpose and this is actually a N plus one by one matrix.
It's also called a row vector and you take that and multiply it with the vector X which is X zero, X one, and so on, down to X n.
And so, the inner product that is theta transpose X is just equal to this.
This gives us a convenient way to write the form of the hypothesis as just the inner product between our parameter vector theta and our theta vector X.
And it is this little bit of notation, this little excerpt of the notation convention that let us write this in this compact form.
So that's the form of a hypthesis when we have multiple features.
And, just to give this another name, this is also called multivariate linear regression.
And the term multivariable that's just maybe a fancy term for saying we have multiple features, or multivariables with which to try to predict the value Y.
In the previous video, we talked about the form of the hypothesis for linear regression with multiple features or with multiple variables.
In this video, let's talk about how to fit the parameters of that hypothesis.
In particular let's talk about how to use gradient descent for linear regression with multiple features.
To quickly summarize our notation, this is our formal hypothesis in multivariable linear regression where we've adopted the convention that x0=1.
The parameters of this model are theta0 through theta n, but instead of thinking of this as n separate parameters, which is valid, I'm instead going to think of the parameters as theta where theta here is a n+1-dimensional vector.
Our cost function is J of theta0 through theta n which is given by this usual sum of square of error term.
But again instead of thinking of J as a function of these n+1 numbers, I'm going to more commonly write J as just a function of the parameter vector theta so that theta here is a vector.
We're going to repeatedly update each parameter theta j according to theta j minus alpha times this derivative term.
And once again we just write this as J of theta, so theta j is updated as theta j minus the learning rate alpha times the derivative, a partial derivative of the cost function with respect to the parameter theta j.
Let's see what this looks like when we implement gradient descent and, in particular, let's go see what that partial derivative term looks like.
Here's what we have for gradient descent for the case of when we had N=1 feature.
And this term here was of course the partial derivative of the cost function with respect to the parameter of theta0, and similarly we had a different update rule for the parameter theta1.
There's one little difference which is that when we previously had only one feature, we would call that feature x(i) but now in our new notation we would of course call this x(i) So that was for when we had only one feature.
Let's look at the new algorithm for we have more than one feature, where the number of features n may be much larger than one.
We get this update rule for gradient descent and, maybe for those of you that know calculus, if you take the definition of the cost function and take the partial derivative of the cost function J with respect to the parameter theta j, you'll find that that partial derivative is exactly that term that I've drawn the blue box around.
And if you implement this you will get a working implementation of gradient descent for multivariate linear regression.
The last thing I want to do on this slide is give you a sense of why these new and old algorithms are sort of the same thing or why they're both similar algorithms or why they're both gradient descent algorithms.
Let's consider a case where we have two features or maybe more than two features, so we have three update rules for the parameters theta0, theta1, theta2 and maybe other values of theta as well.
If you look at the update rule for theta0, what you find is that this update rule here is the same as the update rule that we had previously for the case of n = 1.
And the reason that they are equivalent is, of course, because in our notational convention we had this x(i) why these two term that I've drawn the magenta boxes around are equivalent.
There's a lot going on on this slide so I definitely encourage you if you need to to pause the video and look at all the math on this slide slowly to make sure you understand everything that's going on here.
But if you implement the algorithm written up here then you have a working implementation of linear regression with multiple features.
In this video and in the video after this one, I wanna tell you about some of the practical tricks for making gradient descent work well.
In this video, I want to tell you about an idea called feature skill.
If you have a problem where you have multiple features, if you make sure that the features are on a similar scale, by which I mean make sure that the different features take on similar ranges of values, then gradient descents can converge more quickly.
If you plot the contours of the cos function J of theta, then the contours may look like this, where, let's see, J of theta is a function of parameters theta zero, theta one and theta two.
So, this is very, very tall and skinny ellipses, or these very tall skinny ovals, can form the contours of the cause function J of theta.
And if you run gradient descents on this cos-function, your gradients may end up taking a long time and can oscillate back and forth and take a long time before it can finally find its way to the global minimum.
In fact, you can imagine if these contours are exaggerated even more when you draw incredibly skinny, tall skinny contours, and it can be even more extreme than, then, gradient descent just have a much harder time taking it's way, meandering around, it can take a long time to find this way to the global minimum.
In these settings, a useful thing to do is to scale the features.
Concretely if you instead define the feature X one to be the size of the house divided by two thousand, and define X two to be maybe the number of bedrooms divided by five, then the count well as of the cost function J can become much more, much less skewed so the contours may look more like circles.
And if you run gradient descent on a cost function like this, then gradient descent, you can show mathematically, you can find a much more direct path to the global minimum rather than taking a much more convoluted path where you're sort of trying to follow a much more complicated trajectory to get to the global minimum.
In this example, we end up with both features, X one and X two, between zero and one.
More generally, when we're performing feature scaling, what we often want to do is get every feature into approximately a -1 to +1 range and concretely, your feature x0 is always equal to 1.
So, that's already in that range, but you may end up dividing other features by different numbers to get them to this range.
The numbers -1 and +1 aren't too important.
So, if you have a feature, x1 that winds up being between zero and three, that's not a problem.
If you end up having a different feature that winds being between -2 and + 0.5, again, this is close enough to minus one and plus one that, you know, that's fine, and that's fine.
It's only if you have a different feature, say X 3 that is between, that ranges from -100 tp +100 , then, this is a very different values than minus 1 and plus 1.
So, this might be a less well-skilled feature and similarly, if your features take on a very, very small range of values so if X 4 takes on values between minus 0.0001 and positive 0.0001, then again this takes on a much smaller range of values than the minus one to plus one range.
And again I would consider this feature poorly scaled.
So you want the range of values, you know, can be bigger than plus or smaller than plus one, but just not much bigger, like plus 100 here, or too much smaller like 0.00 one over there.
You know, I think that's fine too or 0 to one-third or minus one-third to 0.
But it will take on a much tinier range of values like x4 here than gain on mine not to worry.
So, the take-home message is don't worry if your features are not exactly on the same scale or exactly in the same range of values.
But so long as they're all close enough to this gradient descent it should work okay.
In addition to dividing by so that the maximum value when performing feature scaling sometimes people will also do what's called mean normalization.
And what I mean by that is that you want to take a feature Xi and replace it with Xi minus new i to make your features have approximately 0 mean.
But it concretely for other features if the range of sizes of the house takes on values between 0 to 2000 and if you know, the average size of a house is equal to 1000 then you might use this formula.
Size, set the feature X1 to the size minus the average value divided by 2000 and similarly, on average if your houses have one to five bedrooms and if on average a house has two bedrooms then you might use this formula to mean normalize your second feature x2.
In both of these cases, you therefore wind up with features x1 and x2.
Exactly not true - X2 can actually be slightly larger than .5 but, close enough.
And similarly for the second feature, x2, you replace x2 with this sort of subtract the mean of the feature and divide it by the range of values meaning the max minus min.
So if max is 5 minus 1 then the range of their own values is actually equal to 4, but all of these are approximate and any value that gets the features into anything close to these sorts of ranges will do fine.
So, now you know about feature scaling and if you apply this simple trick, it and make gradient descent run much faster and converge in a lot fewer other iterations.
That was feature scaling.
In this video, I want to give you more practical tips for getting gradient descent to work.
The ideas in this video will center around the learning rate alpha.
And what I want to do in this video is tell you about what I think of as debugging, and some tips for making sure that gradient descent is working correctly.
And second, I wanna tell you how to choose the learning rate alpha or at least how I go about choosing it.
Here's something that I often do to make sure that gradient descent is working correctly.
The job of gradient descent is to find the value of theta for you that hopefully minimizes the cost function J(theta).
What I often do is therefore plot the cost function J(theta) as gradient descent runs.
So the x axis here is a number of iterations of gradient descent and as gradient descent runs you hopefully get a plot that maybe looks like this.
Previously we where looking at plots of J(theta) where the x axis, where the horizontal axis, was the parameter vector theta but this is not what this is.
And whatever value I get for theta after 100 iterations, I'm going to get some value of theta after 100 iterations.
For the value of theta I get after 100 iterations, and this vertical height is the value of J(theta).
For the value of theta I got after 100 iterations of gradient descent.
And this point here that corresponds to the value of J(theta) for the theta that I get after I've run gradient descent for 200 iterations.
So what this plot is showing is, is it's showing the value of your cost function after each iteration of gradient decent.
And if gradient is working properly then J(theta) should decrease after every iteration.
And one useful thing that this sort of plot can tell you also is that if you look at the specific figure that I've drawn, it looks like by the time you've gotten out to maybe 300 iterations, between 300 and 400 iterations, in this segment it looks like J(theta) hasn't gone down much more.
So by the time you get to 400 iterations, it looks like this curve has flattened out here.
And so way out here 400 iterations, it looks like gradient descent has more or less converged because your cost function isn't going down much more.
So looking at this figure can also help you judge whether or not gradient descent has converged.
By the way, the number of iterations the gradient descent takes to converge for a physical application can vary a lot, so maybe for one application, gradient descent may converge after just thirty iterations.
For a different application, gradient descent may take 3,000 iterations, for another learning algorithm, it may take 3 million iterations.
It turns out to be very difficult to tell in advance how many iterations gradient descent needs to converge.
But I try to tell if gradient descent has converged.
It's also possible to come up with automatic convergence test, namely to have a algorithm try to tell you if gradient descent has converged.
And here's maybe a pretty typical example of an automatic convergence test.
And such a test may declare convergence if your cost function J(theta) decreases by less than some small value epsilon, some small value 10 to the minus 3 in one iteration.
But I find that usually choosing what this threshold is is pretty difficult.
And so in order to check your gradient descent's converge I actually tend to look at plots like these, like this figure on the left, rather than rely on an automatic convergence test.
Looking at this sort of figure can also tell you, or give you an advance warning, if maybe gradient descent is not working correctly.
So you end up with a plot like this and if you see a plot like this, the fix is usually just to use a smaller value of alpha.
You now know about linear regression with multiple variables.
And in particular I also want to tell you about polynomial regression allows you to use the machinery of linear regression to fit very complicated, even very non-linear functions.
Let's take the example of predicting the price of the house.
Suppose you have two features, the frontage of house and the depth of the house.
So, here's the picture of the house we're trying to sell.
called frontage and depth.
You might build a linear regression model like this where frontage is your first feature x1 and and depth is your second feature x2, but when you're applying linear regression, you don't necessarily have to use just the features x1 and x2 that you're given.
So, if I want to predict the price of a house, what I might do instead is decide that what really determines the size of the house is the area or the land area that I own.
So, I might create a new feature.
This is a multiplication symbol.
It's a frontage x depth because this is the land area that I own and I might then select my hypothesis as that using just one feature which is my land area, right?
Because the area of a rectangle is you know, the product of the length of the size So, depending on what insight you might have into a particular problem, rather than just taking the features that we happen to have started off with, sometimes by defining new features you might actually get a better model.
Closely related to the idea of choosing your features is this idea called polynomial regression.
Let's say you have a housing price data set that looks like this.
Then there are a few different models you might fit to this.
One thing you could do is fit a quadratic model like this.
It doesn't look like a straight line fits this data very well.
So maybe you want to fit a quadratic model like this where you think the size, where you think the price is a quadratic function and maybe that'll give you, you know, a fit to the data that looks like that.
So how do we actually fit a model like this to our data?
Using the machinery of multivariant linear regression, we can do this with a pretty simple modification to our algorithm.
And if we want to fit this cubic model that I have boxed in green, what we're saying is that to predict the price of a house, it's theta 0 plus theta 1 times the size of the house plus theta 2 times the square size of the house.
And then plus theta 3 times the cube of the size of the house raises that third term.
In order to map these two definitions to each other, well, the natural way to do that is to set the first feature x one to be the size of the house, and set the second feature x two to be the square of the size of the house, and set the third feature x three to be the cube of the size of the house.
And, just by choosing my three features this way and applying the machinery of linear regression, I can fit this model and end up with a cubic fit to my data.
I just want to point out one more thing, which is that if you choose your features like this, then feature scaling becomes increasingly important.
Finally, here's one last example of how you really have broad choices in the features you use.
But rather than going to a cubic model there, you have, maybe, other choices of features and there are many possible choices.
But just to give you another example of a reasonable choice, another reasonable choice might be to say that the price of a house is theta zero plus theta one times the size, and then plus theta two times the square root of the size, right?
And, so, by having insight into, in this case, the shape of a square root function, and, into the shape of the data, by choosing different features, you can sometimes get better models.
In this video, we talked about polynomial regression.
That is, how to fit a polynomial, like a quadratic function, or a cubic function, to your data.
Was also throw out this idea, that you have a choice in what features to use, such as that instead of using the frontish and the depth of the house, maybe, you can multiply them together to get a feature that captures the land area of a house.
In case this seems a little bit bewildering, that with all these different feature choices, so how do I decide what features to use.
Later in this class, we'll talk about some algorithms were automatically choosing what features are used, so you can have an algorithm look at the data and automatically choose for you whether you want to fit a quadratic function, or a cubic function, or something else.
But, until we get to those algorithms now I just want you to be aware that you have a choice in what features to use, and by designing different features you can fit more complex functions your data then just fitting a straight line to the data and in particular you can put polynomial functions as well and sometimes by appropriate insight into the feature simply get a much better model for your data.
Concretely, so far the algorithm that we've been using for linear regression is gradient descent where in order to minimize the cost function J of Theta, we would take this iterative algorithm that takes many steps, multiple iterations of gradient descent to converge to the global minimum.
In contrast, the normal equation would give us a method to solve for theta analytically, so that rather than needing to run this iterative algorithm, we can instead just solve for the optimal value for theta all at one go, so that in basically one step you get to the optimal value right there.
It turns out the normal equation that has some advantages and some disadvantages, but before we get to that and talk about when you should use it, let's get some intuition about what this method does.
For this week's planetary example, let's imagine, let's take a very simplified cost function J of Theta, that's just the function of a real number Theta.
So, for now, imagine that Theta is just a scalar value or that Theta is just a row value.
It's just a number, rather than a vector.
Imagine that we have a cost function J that's a quadratic function of this real value parameter Theta, so J of Theta looks like that.
Well, how do you minimize a quadratic function?
For those of you that know a little bit of calculus, you may know that the way to minimize a function is to take derivatives and to set derivatives equal to zero.
So, you take the derivative of J with respect to the parameter of Theta.
You get some formula which I am not going to derive, you set that derivative equal to zero, and this allows you to solve for the value of Theda that minimizes J of Theta.
That was a simpler case of when data was just real number.
How do we minimize this cost function J?
Calculus actually tells us that, if you, that one way to do so, is to take the partial derivative of J, with respect to every parameter of Theta J in turn, and then, to set all of these to 0.
If you do that, and you solve for the values of Theta 0, Theta 1, up to Theta N, then, this would give you that values of Theta to minimize the cost function J.
Where, if you actually work through the calculus and work through the solution to the parameters Theta 0 through Theta N, the derivation ends up being somewhat involved.
Or alternatively, or equivalently, the values of Theta is that minimize the cost function J of Theta.
I realize that some of the comments I made that made more sense only to those of you that are normally familiar with calculus.
So, but if you don't know, if you're less familiar with calculus, don't worry about it.
For the example that I want to use as a running example let's say that I have m = 4 training examples.
In order to implement this normal equation at big, what I'm going to do is the following.
In this case let's assume that, you know, these four examples is all the data I have.
What I am going to do is take my data set and add an extra column that corresponds to my extra feature, x0, that is always takes on this value of 1.
So just, you know, copy the data over one column at a time and then I am going to do something similar for y's.
I am going to take the values that I'm trying to predict and construct now a vector, like so and call that a vector y.
So X is going to be a m by (n+1) - dimensional matrix, and Y is going to be a m-dimensional vector where m is the number of training examples and n is, n is a number of features, n+1, because of this extra feature X0 that I had.
There was a lot that happened on the slides and I work through it using one specific example of one dataset.
Let me just write this out in a slightly more general form and then let me just, and later on in this video let me explain this equation a little bit more.
It is not yet entirely clear how to do this.
In a general case, let us say we have M training examples so X1, Y1 up to Xn, Yn and n features.
So, each of the training example x(i) may looks like a vector like this, that is a n+1 dimensional feature vector.
The way I'm going to construct the matrix "X", this is also called the design matrix is as follows.
Each training example gives me a feature vector like this.
say, sort of n+1 dimensional vector.
The way I am going to construct my design matrix x is only construct the matrix like this.
and what I'm going to do is take the first training example, so that's a vector, take its transpose so it ends up being this, you know, long flat thing and make x1 transpose the first row of my design matrix.
Take the transpose of that, and that's my last row of my matrix X.
As a concrete example, let's say I have only one feature, really, only one feature other than X zero, which is always equal to 1.
So if my feature vectors X-i are equal to this 1, which is X-0, then some real feature, like maybe the size of the house, then my design matrix, X, would be equal to this.
So, that's how to construct the matrix X.
And, the vector Y--sometimes I might write an arrow on top to denote that it is a vector, but very often I'll just write this as Y, either way.
The vector Y is obtained by taking all all the labels, all the correct prices of houses in my training set, and just stacking them up into an M-dimensional vector, and that's Y.
Finally, having constructed the matrix X and the vector Y, we then just compute theta as X'(1/X) x X'Y.
I just want to make I just want to make sure that this equation makes sense to you and that you know how to implement it.
So, you know, concretely, what is this X'(1/X)?
Well, X'(1/X) is the inverse of the matrix X'X.
And so that's how you compute this thing.
We haven't yet talked about Octave.
We'll do so in the later set of videos, but in the Octave programming language or a similar view, and also the matlab programming language is very similar.
And so, this expression that's boxed in red, that's computing X transpose times X.
pinv is a function for computing the inverse of a matrix, so this computes X transpose X inverse, and then you multiply that by X transpose, and you multiply that by Y.
I talked about the feature skill and the idea of getting features to be on similar ranges of Scales of similar ranges of values of each other.
Finally, where should you use the gradient descent and when should you use the normal equation method.
One disadvantage of gradient descent is that, you need to choose the learning rate Alpha.
And, often, this means running it few times with different learning rate alphas and then seeing what works best.
Another disadvantage with gradient descent is it needs many more iterations.
As for the normal equation, you don't need to choose any learning rate alpha.
So that, you know, makes it really convenient, makes it simple to implement.
You just run it and it usually just works.
So far, the balance seems to favor normal the normal equation.
Here are some disadvantages of the normal equation, and some advantages of gradient descent.
Gradient descent works pretty well, even when you have a very large number of features.
So, even if you have millions of features you can run gradient descent and it will be reasonably efficient.
In contrast to normal equation, In, in order to solve for the parameters data, we need to solve for this term.
We need to compute this term, X transpose, X inverse.
Because, if you look at the dimensions of X transpose the dimension of X, you multiply, figure out what the dimension of the product is, the matrix X transpose X is an n by n matrix where n is the number of features, and for almost computed implementations the cost of inverting the matrix, rose roughly as the cube of the dimension of the matrix.
So, computing this inverse costs, roughly order, and cube time.
Sometimes, it's slightly faster than N cube but, it's, you know, close enough for our purposes.
So if n the number of features is very large, then computing this quantity can be slow and the normal equation method can actually be much slower.
But, if n is relatively small, then the normal equation might give you a better way to solve the parameters.
What does small and large mean?
Well, if n is on the order of a hundred, then inverting a hundred-by-hundred matrix is no problem by modern computing standards.
If n is a thousand, I would still use the normal equation method.
Inverting a thousand-by-thousand matrix is actually really fast on a modern computer.
Inverting a ten-thousand- by-ten-thousand matrix starts to get kind of slow, and I might then start to maybe lean in the direction of gradient descent, but maybe not quite.
But if it gets much bigger than that, then, I would probably use gradient descent.
So, if n equals ten to the sixth with a million features, then inverting a million-by-million matrix is going to be very expensive, and I would definitely favor gradient descent if you have that many features.
So exactly how large set of features has to be before you convert a gradient descent, it's hard to give a strict number.
But, for me, it is usually around ten thousand that I might start to consider switching over to gradient descents or maybe, some other algorithms that we'll talk about later in this class.
To summarize, so long as the number of features is not too large, the normal equation gives us a great alternative method to solve for the parameter theta.
Concretely, so long as the number of features is less than 1000, you know, I would use, I would usually is used in normal equation method rather than, gradient descent.
To preview some ideas that we'll talk about later in this course, as we get to the more complex learning algorithm, for example, when we talk about classification algorithm, like a logistic regression algorithm, We'll see that those algorithm actually...
So, gradient descent is a very useful algorithm to know.
The linear regression will have a large number of features and for some of the other algorithms that we'll see in this course, because, for them, the normal equation method just doesn't apply and doesn't work.
But for this specific model of linear regression, the normal equation can give you a alternative that can be much faster, than gradient descent.
So, depending on the detail of your algortithm, depending of the detail of the problems and how many features that you have, both of these algorithms are well worth knowing about.
In this video I want to talk about the Normal equation and non-invertibility.
This is a somewhat more advanced concept, but it's something that I've often been asked about.
And so I want to talk it here and address it here.
But this is a somewhat more advanced concept, so feel free to consider this optional material.
And there's a phenomenon that you may run into that may be somewhat useful to understand, but even if you don't understand the normal equation and linear progression, you should really get that to work okay.
For those of you there are, maybe some are more familiar with linear algebra, what some students have asked me is, when computing this Theta equals X transpose X inverse X transpose Y.
So for those of you that know a bit more linear algebra you may know that only some matrices are invertible and some matrices do not have an inverse we call those non-invertible matrices.
The issue or the problem of x transpose x being non invertible should happen pretty rarely.
And in Octave if you implement this to compute theta, it turns out that this will actually do the right thing.
I'm getting a little technical now, and I don't want to go into the details, but Octave hast two functions for inverting matrices.
One is called pinv, and the other is called inv.
And the differences between these two are somewhat technical.
But I thought in this optional video, I'll try to give you little bit of intuition about what it means for X transpose X to be non-invertible.
For those of you that know a bit more linear Algebra might be interested.
I'm not gonna prove this mathematically but if X transpose X is non-invertible, there usually two most common causes for this.
Concretely, if you're trying to predict housing prices and if x1 is the size of the house in feet, in square feet and x2 is the size of the house in square meters, then you know 1 meter is equal to 3.28 feet Rounded to two decimals.
And you can show for those of you that are somewhat advanced in linear Algebra, but if you're explaining the algebra you can actually show that if your two features are related, are a linear equation like this.
The second thing that can cause X transpose X to be non-invertable is if you are training, if you are trying to run the learning algorithm with a lot of features.
Concretely, if m is less than or equal to n.
For example, if you imagine that you have m = 10 training examples that you have n equals 100 features then you're trying to fit a parameter back to theta which is, you know, n plus one dimensional.
So this is 101 dimensional, you're trying to fit 101 parameters from just 10 training examples.
This turns out to sometimes work but not always be a good idea.
Because as we'll see later, you might not have enough data if you only have 10 examples to fit you know, 100 or 101 parameters.
We'll see later in this course why this might be too little data to fit this many parameters.
But this regularization will be a later topic in this course.
But to summarize if ever you find that x transpose x is singular or alternatively you find it non-invertable, what I would recommend you do is first look at your features and see if you have redundant features like this x1, x2.
You're being linearly dependent or being a linear function of each other like so.
And if you do have redundant features and if you just delete one of these features, you really don't need both of these features.
If you just delete one of these features, that would solve your non-invertibility problem.
And if your features are not redundant, I would check if I may have too many features.
Here's my Octave window and let's first go to my desktop.
I saved the files for my first exercise, some of the files on my desktop: in this directory, 'ml-class-ex1'.
And we provide a number files and ask you to edit some of them.
So the first file should meet the details in the pdf file for this programming exercise.
But one of the files we ask you to edit is this file called warmUpExercise.m, where the exercise is really just to make sure that you're familiar with the submission system.
And all you need to do is return the 5x5 identity matrix.
So the solution to this exercise I just showed you is to write A = eye(5).
So that modifies this function to generate the 5x5 identity matrix.
And I'm just going to save it.
So I've done the first part of this homework.
Going back to my Octave window, let's now go to my directory, 'C:\Users\ang\Desktop\ml-class-ex1'.
And if I want to make sure that I've implemented this, type 'warmUpExercise()' like so.
And yup, it returns the 5x5 identity matrix that we just wrote the code to create.
And I can now submit the code as follows.
I'm going to type 'submit()' in this directory and I'm ready to submit part 1 so I'm going to enter choice '1'.
So it asks me for my email address.
This is an internal testing site, so your version of the website may look a little bit different.
But that's my email address and this is my submission password, and I'm just going to type them in here.
So I have ang@cs.stanford.edu and my submission password is 9yC75USsGf.
I'm going to hit enter; it connects to the server and submits it, and right away it tells you "Congratulations!
You have successfully completed Homework 1 Part 1".
And this gives you a verification that you got this part right.
And if you don't submit the right answer, then it will give you a message indicating that you haven't quite gotten it right yet.
And you can use this submission password and you can generate new passwords; it doesn't matter.
But you can also use your regular website login password, but because this password here is typed in clear text on your monitor, we gave you this extra submission password in case you don't want to type in your website's normal password onto a window that, depending on your operating system, may or may not appear as text when you type it into the Octave submission script.
So, that's how you submit the homeworks after you've done it.
Good luck, and, when you get around to homeworks, I hope you get all of them right.
And finally, in the next and final Octave tutorial video, I want to tell you about vectorization, which is a way to get your Octave code to run much more efficiently.
You now know a bunch about machine learning.
In this video, I like to teach you a programing language, Octave, in which you'll be able to very quickly implement the the learning algorithms we've seen already, and the learning algorithms we'll see later in this course.
In the past, I've tried to teach machine learning using a large variety of different programming languages including C++ Java, Python, NumPy, and also Octave, and what I found was that students were able to learn the most productively learn the most quickly and prototype your algorithms most quickly using a relatively high level language like octave.
If you want to build a large scale deployment of a learning algorithm, what people will often do is prototype and the language is Octave.
Because all the lessons we've learned is that a time or develop a time.
Then overall you have a huge time savings by first developing the algorithms in Octave, and then implementing and maybe C++ Java, only after we have the ideas working.
The most common prototyping language I see people use for machine learning are: Octave, MATLAB, Python, NumPy, and R.
And MATLAB works well too, but it is expensive for to many people.
You can also use MATLAB with this class.
If you know Python, NumPy, or if you know R.
But, what I see is that people usually end up developing somewhat more slowly, and you know, these languages.
Because the Python, NumPy syntax is just slightly clunkier than the Octave syntax.
But that I do recommend that you instead do the programming exercises for this class in octave instead.
What I'm going to do in this video is go through a list of commands very, very quickly, and its goal is to quickly show you the range of commands and the range of things you can do in Octave.
The course website will have a transcript of everything I do, and so after watching this video you can refer to the transcript posted on the course website when you want find a command.
And finally, it goes to the course website, download the transcripts of the things you see in the session, and type in whatever commands seem interesting to you into Octave, so that it's running on your own computer, so you can see it run for yourself.
And with that let's get started.
Here's my Windows desktop, and I'm going to start up Octave.
Let me first show the elementary operations you can do in Octave.
That gives you the answer of 11.
So those are the elementary math operations.
So, one equals two, evaluates to false.
One not equals to two.
This is true.
Which is what some other programming languages use.
And I can XOR one and zero, and that evaluates to one.
This thing over on the left, this Octave 324.x equals 11, this is the default Octave prompt.
It shows the, what, the version in Octave and so on.
If you don't want that prompt, there's a somewhat cryptic command PF quote, greater than, greater than and so on, that you can use to change the prompt.
Now my Octave prompt has changed to the greater than, greater than sign.Which, you know, looks quite a bit better.
Next let's talk about Octave variables.
I can take the variable A and assign it to 3.
And now A is equal to 3.
You want to assign a variable, but you don't want to print out the result.
B equals hi Now if I just enter B it prints out the variable B.
If you want to print out or display a variable, here's how you go about it.
For more complex printing there is also the DISP command which stands for Display.
Display A just prints out A like so.
You can also display strings so: DISP, sprintf, two decimals, percent 0.2, F, comma, A.
For those of you that have programmed C before, this is essentially the syntax you use to print screen.
And DISP takes the string DISP generates it by the Sprintf command.
Finally, I was saying, a like so, looks like this.
And format short is a command that restores the default of just printing a small number of digits.
Okay, that's how you work with variables.
Now let's look at vectors and matrices.
There are other ways to type this in.
Type A 1, 2 semicolon 3, 4, semicolon, 5, 6, like so.
Similarly you can assign vectors.
So V equals 1, 2, 3.
Where that is a fat Y vector, excuse me, not, this is a 1 by 3 matrix, right.
If I want to assign this to a column vector, what I would do instead is do v 1;2;3.
So this will be a column vector.
So if I do this, V is going to be this, you know, row vector.
This is what one by eleven matrix really.
That's 1, 1.1, 1.2, 1.3 and so on until we get up to two.
Now here are some other ways to generate matrices.
Ones 2.3 is a command that generates a matrix that is a two by three matrix that is the matrix of all ones.
So if I set that c2 times ones two by three this generates a two by three matrix that is all two's.
You can think of this as a shorter way of writing this and c2,2,2's and you can call them 2,2,2, which would also give you the same result.
Let's say W equals one's, one by three, so this is going to be a row vector or a row of three one's and similarly you can also say w equals zeroes, one by three, and this generates a matrix.
Just a couple more ways to generate matrices .
If I do W equals Rand one by three, this gives me a one by three matrix of all random numbers.
This gives me a three by three matrix of all random numbers drawn from the uniform distribution between zero and one.
So every time I do this, I get a different set of random numbers drawn uniformly between zero and one.
For those of you that know what a Gaussian random variable is or for those of you that know what a normal random variable is, you can also set W equals Rand N, one by three.
And so these are going to be three values drawn from a Gaussian distribution with mean zero and variance or standard deviation equal to one.
And you can set more complex things like W equals minus six, plus the square root ten, times, lets say Rand N, one by ten thousand.
Well, it's going to be a vector of, with a hundred thousand, excuse me, ten thousand elements.
And Octave's print hist command, you know, takes a couple seconds to bring this up, but this is a histogram of my random variable for W.
There was minus 6 plus zero ten times this Gaussian random variable.
And I can plot a histogram with more buckets, with more bins, with say, 50 bins.
Because I have a minus 6 there plus square root 10 times this.
So the variance of this Gaussian random variable is 10 on the standard deviation is square root of 10, which is about what?
Finally, one special command for generator matrix, which is the I command.
Lastly, to wrap up this video, there's one more useful command.
Which is the help command.
So you can type help i and this brings up the help function for the identity matrix.
Brings up documentation for the rand or the random number generation function.
Or even help help, which shows you, you know help on the help function.
So, those are the basic operations in Octave.
And with this you should be able to generate a few matrices, multiply, add things.
In this second tutorial video on Octave, I'd like to start to tell you how to move data around in Octave.
So, if you have data for a machine learning problem, how do you load that data in Octave?
How do you put it into matrix?
How do you manipulate these matrices?
How do you move data around and operate with data?
Here's my Octave window as before, picking up from where we left off in the last video.
The size command in Octave lets you, tells you what is the size of a matrix.
So size A returns three, two.
It turns out that this size command itself is actually returning a one by two matrix.
So you can actually set SZ equals size of A and SZ is now a one by two matrix where the first element of this is three, and the second element of this is two.
Does SZ is a one by two matrix whose two elements contain the dimensions of the matrix A.
You can also type size A one to give you back the first dimension of A, size of the first dimension of A.
If you have a vector V, so let's say V equals one, two, three, four, and you type length V.
What this does is it gives you the size of the longest dimension.
So you can also type length A and because A is a three by two matrix, the longer dimension is of size three, so this should print out three.
So you know, length one, two, three, four, five, rather than apply length to matrices because that's a little more confusing.
Now, let's look at how the load data and find data on the file system.
When we start an Octave we're usually, we're often in a path that is, you know, the location of where the Octave location is.
So the PWD command shows the current directory, or the current path that Octave is in.
So right now we're in this maybe somewhat off scale directory.
The CD command stands for change directory, so I can go to C:/Users/Ang/Desktop, and now I'm in, you know, in my Desktop and if I type ls, ls is, it comes from a Unix or a Linux command.
So, here's my desktop.
Here's Features X, and Features X is this window, excuse me, is this file with two columns of data.
So I think, you know, I think I have forty-seven rows in this data set.
And Price Y is this file that has the prices of the data in my training set.
So, Features X and Price Y are just text files with my data.
How do I load this data into Octave?
Well, I just type the command load Features X dot dat and if I do that, I load the Features X and can load Price Y dot dat.
So you can, this way I'm just putting the file name of the string in the founding in a string and in an Octave use single quotes to represent strings, like so.
So that's a string, and we can load the file whose name is given by that string.
Now the WHO command now shows me what variables I have in my Octave workspace.
So Who shows me whether the variables that Octave has in memory currently.
Features X and Price Y are among them, as well as the variables that, you know, we created earlier in this session.
So I can type Features X to display features X.
And there's my data.
And I can type size features X and that's my 47 by two matrix.
And some of these size, press Y, that gives me my 47 by one vector.
This is a 47 dimensional vector.
This is all common vector that has all the prices Y in my training set.
Now the who function shows you one of the variables that, in the current workspace.
There's also the who S variable that gives you the detailed view.
And so this also, with an S at the end this also lists my variables except that it now lists the sizes as well.
So A is a three by two matrix and features X as a 47 by 2 matrix.
And it shows, you know, how many bytes of memory it's taking up.
Now if you want to get rid of a variable you can use the clear command.
You notice that the features X variable has now disappeared.
And how do we save data?
Let's see.
Let's take the variable V and say that it's a price Y 1 colon 10.
This sets V to be the first 10 elements of vector Y.
B equals price Y, one column ten that sets it to the just the first ten elements of Y.
This will save the variable V into a file called hello.mat.
So let's do that.
I happen to have MATLAB installed in this window, which is why, you know, this icon looks like this because Windows is recognized as it's a MATLAB file,but don't worry about it if this file looks like it has a different icon on your machine and let's say I clear all my variables.
So, if you type clear without anything then this actually deletes all of the variables in your workspace.
So there's now nothing left in the workspace.
And if I load hello.mat, I can now load back my variable v, which is the data that I previously saved into the hello.mat file.
So, hello.mat, what we did just now to save hello.mat to view, this save the data in a binary format, a somewhat more compressed binary format.
So if v is a lot of data, this, you know, will be somewhat more compressing.
If you want to save your data in a human readable format then you type save hello.text the variable v and then -ascii.
So, this will save it as a text or as ascii format of text.
And now, once I've done that, I have this file.
Hello.text has just appeared on my desktop, and if I open this up, we see that this is a text file with my data saved away.
Now let's talk a bit about how to manipulate data.
Let's set a equals to that matrix again so is my three by two matrix.
So, this is what, you know, in normally, we will write this as a subscript 3, 2 or A subscript, you know, 3, 2 and so that's the element and third row and second column of A which is the element of six.
And similarly, if I do a colon comma 2 then this means get everything in the second column of A.
Right this means of A.
This means get all of the elements of A who's first indexes one or three.
So, this was the matrix A and so A 1 3 comma colon means get everything from the first row and from the second row and from the third row and the colon means, you know, one both of first and the second columns and so this gives me this 1 2 5 6.
Although, you use the source of more subscript index operations maybe somewhat less often.
To show you what else we can do.
Here's the A matrix and this source A colon, to give me the second column.
So I can take the second column of A and assign that to 10, 11, 12, and if I do that I'm now, you know, taking the second column of a and I'm assigning this column vector 10, 11, 12 to it.
And the second column has been replaced by 10, 11, 12.
And here's another operation.
Let's set A to be equal to A comma 100, 101, 102 like so and what this will do is depend another column vector to the right.
Should have put semicolons there and now A is equals to this.
This is a column vector and what we did was we set A, take A and set it to the original definition.
And then we put that column vector to the right and so, we ended up taking the matrix A and--which was these six elements on the left.
And finally, one neat trick that I sometimes use if you do just a and just a colon like so.
This is a somewhat special case syntax.
What this means is that put all elements with A into a single column vector and this gives me a 9 by 1 vector.
And let's say I set a B to B equal to 11, 12, 13, 14, 15, 16.
I can create a new matrix C as A B.
What I'm doing is I'm taking these two matrices and just concatenating onto each other.
And that's how I formed this matrix C by putting them together.
The semi colon notation means that I go put the next thing at the bottom.
So, I'll do is a equals semicolon B.
It also puts the matrices A and B together except that it now puts them on top of each other.
so now I have A on top and B at the bottom and C here is now in 6 by 2 matrix.
So, just say the semicolon thing usually means, you know, go to the next line.
So, with that, hopefully you now know how to construct matrices and hopefully starts to show you some of the commands that you use to quickly put together matrices and take matrices and, you know, slam them together to form bigger matrices, and with just a few lines of code, Octave is very convenient in terms of how quickly we can assemble complex matrices and move data around.
So that's it for moving data around.
In the next video we'll start to talk about how to actually do complex computations on this, on our data.
You know, you load and save vectors and matrices, load and save data, put together matrices to create bigger matrices, index into or select specific elements on the matrices.
Look at the coursework site and download the transcript of the session from there and look through the transcript and type some of those commands into Octave yourself and start to play with these commands and get it to work.
So that when later on when you are trying to program a learning algorithms yourself, if you are trying to find a specific command that maybe you think Octave can do because you think you might have seen it here, you should refer to the transcript of the session and look through that in order to find the commands you wanna use.
So, that's it for moving data around and in the next video what I'd like to do is start to tell you how to actually do complex computations on our data, and how to compute on the data, and actually start to implement learning algorithms.
And later on, we'll be using these source of computational operations to implement our learning algorithms.
Let's get started.
Here's my Octave window.
Now let's say I want to multiply two of my matrices.
So let's say I want to compute A*C, I just type A*C, so it's a three by two matrix times a two by two matrix, this gives me this three by two matrix.
You can also do element wise operations and do A.* B and what this will do is it'll take each element of A and multiply it by the corresponding elements B, so that's A, that's B, that's A .* B.
So this is element-wise multiplication of two matrices.
And in general, the period tends to, is usually used to denote element-wise operations in Octave.
So here's a matrix A, and if I do A .^ 2, this gives me the element wise squaring of A.
Let's set v as a vector.
Let's set v as one, two, three as a column vector.
You can also do one dot over v to do the element-wise reciprocal of v, so this gives me one over one, one over two, and one over three, and this is where I do the matrices, so one dot over a gives me the element wise inverse of a.
And once again, the period here gives us a clue that this an element-wise operation.
We can also do things like log(v), this is a element-wise logarithm of the v E to the V is base E exponentiation of these elements, so this is E, this is E squared EQ, because this was V, and I can also do abs V to take the element-wise absolute value of V.
So here, V was our positive, abs, minus one, two minus 3, the element-wise absolute value gives me back these non-negative values.
And negative v gives me the minus of v.
Here's another neat trick.
So, let's see.
Let's say I want to take v an increment each of its elements by one.
Well one way to do it is by constructing a three by one vector that's all ones and adding that to v.
The third and fourth elements of A are less than three, so that's just 1 1.
So that's the element-wise comparison of all four elements of the variable a < 3.
Now, if I do find(a < 3), this will tell me which are the elements of a, the variable a, that are less than 3, and in this case, the first, third and fourth elements are less than 3.
For our next example, let me set a to be equal to magic(3).
They have this, you know, mathematical property that all of their rows and columns and diagonals sum up to the same thing.
So, you know, it's not actually useful for machine learning as far as I know, but I'm just using this as a convenient way to generate a three by three matrix.
And these magic squares have the property that each row, each column, and the diagonals all add up to the same thing, so it's kind of a mathematical construct.
The 2,3 element, for example, is A(2,3), is 7 is this element out here, and that is indeed greater than equal seven.
One is the sum function, so here's my a, and then type sum(a).
This adds up all the elements of a, and if I want to multiply them together, I type prod(a) prod sends the product, and this returns the product of these four elements of A.
So the max of the first column is 8, max of second column is 9, the max of the third column is 7.
In contrast, if I were to type max A, this funny notation, two, then this takes the per row maximum.
So if you want to find the maximum element in the entire matrix A, you can type max(max(A)) like so, which is 9.
So remember the magic square has this property that every column and every row sums the same thing, and also the diagonals, so just a nine by nine matrix square.
So this does a per column sum, so we'll take each column of A and add them up and this is verified that indeed for a nine by nine matrix square, every column adds up to 369, adds up to the same thing.
What this will do is take the element wise product of these two matrices, and so this should Wipe out everything in A, except for the diagonal entries.
And now, I'm gonna do sum sum of A of that and this gives me the sum of these diagonal elements, and indeed that is 369.
Just one last command and then that's it, and then that'll be it for this video.
And so I can set temp = pinv(A) and temp times A, this is indeed the identity matrix, where it's essentially ones on the diagonals, and zeroes on the off-diagonals, up to a numeric round off.
And after running a learning algorithm, often one of the most useful things is to be able to look at your results, so to plot or visualize your result.
When developing learning algorithms, very often a few simple plots can give you a better sense of what the algorithm is doing and just sanity check that everything is going okay and the algorithms doing what is supposed to.
For example, in an earlier video, I talked about how plotting the cost function J of theta can help you make sure that gradient descent is converging.
Often, plots of the data or of all the learning algorithm outputs will also give you ideas for how to improve your learning algorithm.
Here's my Octave window.
So I'm going to set T to be equal to, you know, this array of numbers.
Let's set y1 equals sine of 2 pie 40 and if I want to plot the sine function, it's very easy.
And up comes this plot where the horizontal axis is the T variable and the vertical axis is y1, which is the sine you saw in the function that we just computed.
And if I plot T comma y2, what octave will I do is I'll take my sine plot and it will replace with this cosine function and now, you know, cosine of xi of 1.
Now, what if I want to have both the sine and the cosine plots on top of each other?
So here's my sine function, and then I'm going to use the function hold on.
I'm going to plot the cosine function in a different color.
So, let me put there r in quotation marks there and instead of replacing the current figure, I'll plot the cosine function on top and the r indicates the what is an event color.
And here additional commands - x label times, to label the X axis, or the horizontal axis.
And Y label values A, to label the vertical axis value, and I can also label my two lines with this command: legend sine cosine and this puts this legend up on the upper right showing what the 2 lines are, and finally title my plot is the title at the top of this figure.
Lastly, if you want to save this figure, you type print -dpng myplot .png.
So PNG is a graphics file format, and if you do this it will let you save this as a file.
If I do that, let me actually change directory to, let's see, like that, and then I will print that out.
If I now go to my desktop, Let's hide these windows.
Here's myplot.png which Octave has saved, and you know, there's the figure saved as the PNG file.
So, you can type help plot, if you want to see the other file formats, rather than PNG, that you can save figures in.
And lastly, if you want to get rid of the plot, the close command causes the figure to go away.
Octave also lets you specify a figure and numbers.
And then if you want a second figure, you specify a different figure number.
So figure two, plot t, y2 like so, and now on my desktop, I actually have 2 figures.
So, figure 1 and figure 2 thus 1 plotting the sine function, 1 plotting the cosine function.
What it does it sub-divides the plot into a one-by-two grid with the first 2 parameters are, and it starts to access the first element.
So, divide my figure into a one by two grid, and I want to access the first element right now.
And so, if I type that in, this product, this figure, is on the left.
And if I plot t, y1, it now fills up this first element.
Well, throw in y2 in the right hand side, or in the second element.
And, you know, you don't need to memorize all these commands.
If you ever need to change the access or you need to know is that, you know, there's an access command and you can already get the details from the usual octave help command.
Finally, just a couple last commands CLF clear is a figure and here's one unique trait.
where the different colors correspond to the different values in the A matrix.
So concretely, I can also do color bar.
Let me use a more sophisticated command, and image sc A color bar color map gray.
This is actually running three commands at a time.
And what this does, is it sets a color map, so a gray color map, and on the right it also puts in this color bar.
And so this color bar shows what the different shades of color correspond to.
Concretely, the upper left element of the A matrix is 17, and so that corresponds to kind of a mint shade of gray.
Whereas in contrast the second element of A--sort of the 1 2 element of A--is 24.
Right, so it's A 1 2 is 24.
So that corresponds to this square out here, which is nearly a shade of white.
And the small value, say A--what is that?
A 4 5, you know, is a value 3 over here that corresponds-- you can see on my color bar that it corresponds to a much darker shade in this image.
And finally to wrap up this video, what you've seen me do here is use comma chaining of function calls.
Here's how you actually do this.
If I type A equals 1, B equals 2, C equals 3, and hit Enter, then this is actually carrying out three commands at the same time.
And this is a lot like A equals 1, B equals 2, C equals 3, except that if I use semicolons instead of a comma, it doesn't print out anything.
And, it's just another convenient way in Octave to put multiple commands like image sc color bar, colon map to put multi-commands on the same line.
So, that's it.
You now know how to plot different figures and octave, and in next video the next main piece that I want to tell you about is how to write control statements like if, while, for statements and octave as well as hard to define and use functions
In this video, I'd like to tell you how to write control statements for your Octave programs, so things like "for", "while" and "if" statements and also how to define and use functions.
Here's my Octave window.
Let me first show you how to use a "for" loop.
I'm going to start by setting v to be a 10 by 1 vector 0.
And let's see, I'm going to set V of I equals two to the power of I, and finally end.
But if I do this, then the result is that V gets set to, you know, two to the power one, two to the power two, and so on.
So this is syntax for I equals one colon 10 that makes I loop through the values one through 10.
And by the way, you can also do this by setting your indices equals one to 10, and so the indices in the array from one to 10.
And this is actually the same as if I equals one to 10.
You can do, you know, display I and this would do the same thing.
So, here's my vector V.
Let's write the while loop.
I equals 1, while I is less than or equal to 5, let's set V I equals one hundred and increment I by one, end.
And as a result of that, whereas previously V was this powers of two vector.
So that's a syntax for a while loop.
Let's do another example.
Y equals one while true and here I wanted to show you how to use a break statement.
And this is also our first use of an if statement, so I hope the logic of this makes sense.
While repeatedly set V I equals 1 and increment i by 1, and then when 1 i gets up to 6, do a break which breaks here although the while do and so, the effective is should be to take the first five elements of this vector V and set them to 999.
And yes, indeed, we're taking V and overwritten the first five elements with 999.
This ends here ends the if statement and the second end here ends the while statement.
Now let me show you the more general syntax for how to use an if-else statement.
So, let's see, V 1 is equal to 999, let's type V1 equals to 2 for this example.
This is, if in case that's true in our example, display the value as 2, else display, the value is not one or two.
And of course, here we've just set v 1 equals 2, so hopefully, yup, displays that the value is 2.
And finally, I don't think I talked about this earlier, but if you ever need to exit Octave, you can type the exit command and you hit enter that will cause Octave to quit or the 'q'--quits command also works.
Finally, let's talk about functions and how to define them and how to use them.
This is how you define functions in Octave.
You create a file called, you know, with your function name and then ending in .m, and when Octave finds this file, it knows that this where it should look for the definition of the function "squarethisnumber.m".
Let's open up this file.
Notice that I'm using the Microsoft program Wordpad to open up this file.
I just want to encourage you, if your using Microsoft Windows, to use Wordpad rather than Notepad to open up these files, if you have a different text editor that's fine too, but notepad sometimes messes up the spacing.
If you only have Notepad, that should work too, that could work too, but if you have Wordpad as well, I would rather use that or some other text editor, if you have a different text editor for editing your functions.
So, here's how you define the function in Octave.
And this file has just three lines in it.
The first line says function Y equals square root number of X, this tells Octave that I'm gonna return the value Y, I'm gonna return one value and that the value is going to be saved in the variable Y and moreover, it tells Octave that this function has one argument, which is the argument X, and the way the function body is defined, if Y equals X squared.
So, let's try to call this function "square", this number 5, and this actually isn't going to work, and Octave says square this number it's undefined.
That's because Octave doesn't know where to find this file.
So as usual, let's use PWD, or not in my directory, so let's see this c:\users\ang\desktop.
That's where my desktop is.
Oops, a little typo there.
Users ANG desktop and if I now type square root number 5, it returns the answer 25.
As kind of an advanced feature, this is only for those of you that know what the term search path means.
But so if you want to modify the Octave search path and you could, you just think of this next part as advanced or optional material.
But if you're not familiar with the concept of search path, don't worry about it.
Just make sure as you use the CD command to go to the directory of your function before you run it and that actually works just fine.
One concept that Octave has that many other programming languages don't is that it can also let you define functions that return multiple values or multiple arguments.
So here's an example of that.
Define the function called square and cube this number X and what this says is this function returns 2 values, y1 and y2.
So, some of you depending on what programming language you use, if you're familiar with, you know, CC++ your offer.
But just so the syntax in Octave that should return multiple values.
If I type, you know, a, b equals square and cube this number 5 then a is now equal to 25 and b is equal to the cube of 5 equal to 125.
So, this is often convenient if you needed to define a function that returns multiple values.
Finally, I'm going to show you just one more sophisticated example of a function.
And what I'd like to do is to define an octave function to compute the cost function J of theta for different values of theta.
So, this is my design matrix x with x0, the first column being the said term and the second term being you know, my the x-values of my three training examples.
Here at my desktop, I've predefined does cost function j and if I bring up the definition of that function it looks as follows.
So function j equals cost function j equals x y theta, some commons, specifying the inputs and then vary few steps set m to be the number trading examples thus the number of rows in x.
Compute the predictions, predictions equals x times theta and so this is a common that's wrapped around, so this is probably the preceding comment line.
Computer script errors by, you know, taking the difference between your predictions and the y values and taking the element of y squaring and then finally computing the cost function J.
And Octave knows that J is a value I want to return because J appeared here in the function definition.
Feel free by the way to pause this video if you want to look at this function definition for longer and kind of make sure that you understand the different steps.
And so that sanity tracks that the cost function J, as defined here, that it is indeed, you know, seeming to compute the correct cost function, at least on our simple training set that we had here with X and Y being this simple training example that we solved.
So, now you know how to right control statements like for loops, while loops and if statements in octave as well as how to define and use functions.
In the next video, I'm going to just very quickly step you through the logistics of working on and submitting problem sets for this class and how to use our submission system.
So, whether you using Octave or a similar language like MATLAB or whether you're using Python , R, Java, C++, all of these languages have either built into them or have regularly and easily accessible difference in numerical linear algebra libraries.
They're usually very well written, highly optimized, often sort of developed by people that have PhDs in numerical computing or they're really specialized in numerical computing.
And when you're implementing machine learning algorithms, if you're able to take advantage of these linear algebra libraries or these numerical linear algebra libraries, and make some routine calls to them rather than sort of write code yourself to do things that these libraries could be doing.
If you do that, then often you get code that, first, is more efficient, so you just run more quickly and take better advantage of any parallel hardware your computer may have and so on.
And as a concrete example, rather than writing code yourself to multiply matrices, if you let Octave do it by typing a times b, that would use a very efficient routine to multiply the two matrices.
And there's a bunch of examples like these, where if you use appropriate vectorization implementations you get much simpler code and much more efficient code.
Let's look at some examples.
Here's our usual hypothesis for linear regression, and if you want to compute h(x), notice that there's a sum on the right.
And so one thing you could do is, compute the sum from j = 0 to j = n yourself.
If you have two features, if n equals two, and if you think x as this vector, x0, x1, x2, and these two views can give you two different implementations.
We might first initialize prediction just to be 0.0.
The prediction's going to eventually be h(x), and then I'm going to have a for loop for j=1 through n+1, prediction gets incremented by theta(j) * x(j).
j goes from 1 through n+1 rather than j goes through 0 up to n, right?
But so this is an unvectorized implementation in that we have for loop that is summing up the n elements of the sum.
In contrast, here's how you would write a vectorized implementation, which is that you would think of a x and theta as vectors.
So instead of writing all these lines of code with a for loop, you instead just have one line of code.
And what this line of code on the right will do is, it will use Octaves highly optimized numerical linear algebra routines to compute this inner product between the two vectors, theta and X, and not only is the vectorized implementation simpler, it will also run much more efficiently.
So that was octave, but the issue of vectorization applies to other programming language as well.
Lets look on the example in C++.
We again initialize prediction to 0.0 and then we now how a for loop for j = 0 up to n.
Prediction += theta j * x, where again, you have this explicit for loop that you write yourself.
In contrast, using a good numerical linear algebra library in C++, you could write a function like, or rather.
In contrast, using a good numerical linear algebra library in C++, you can instead write code that might look like this.
And depending on the details of your numerical linear algebra library, you might end up using a slightly different syntax, but by relying on the library to do this inner product, you can get a much simpler piece of code and a much more efficient one.
Let's now look at a more sophisticated example.
Just to remind you, here's our update rule for a gradient descent of a linear regression.
So, let's see if we can come up with a vectorizing notation of this.
Let's see if we can take these three steps and compress them into one line of vectorized code.
Well this vector delta, looks like this, and what it's meant to be is really meant to be this thing over here.
So, let's just make sure we're on this same page about how delta really is computed.
And the meaning of these terms, this is a lot like if you remember actually from the earlier quiz in this, right, you saw this equation.
And if it's still not clear, one insight is that, this thing over here, that's exactly the vector x, and so we're just taking all three of these computations, and compressing them into one step with this vector delta, which is why we can come up with a vectorized implementation of this step of the new refresh in this way.
So, even if you didn't quite understand equivalence, if you just implement it this way, you'll be able to get linear regression to work.
And finally, if you are implementing linear regression using more than one or two features, so sometimes we use linear regression with 10's or 100's or 1,000's of features.
In this and the next few videos, I want to start to talk about classification problems, where the variable y that you want to predict is valued.
We'll develop an algorithm called logistic regression, which is one of the most popular and most widely used learning algorithms today.
Earlier we talked about email spam classification as an example of a classification problem.
So if you have a website that sells stuff and if you want to know if a particular transaction is fraudulent or not, whether someone is using a stolen credit card or has stolen the user's password.
There's another classification problem.
And earlier we also talked about the example of classifying tumors as cancerous, malignant or as benign tumors.
In all of these problems the variable that we're trying to predict is a variable y that we can think of as taking on two values either zero or one, either spam or not spam, fraudulent or not fraudulent, related malignant or benign.
Another name for the class that we denote with zero is the negative class, and another name for the class that we denote with one is the positive class.
So zero we denote as the benign tumor, and one, positive class we denote a malignant tumor.
The assignment of the two classes to positive and negative to zero and one is somewhat arbitrary and it doesn't really matter but often there is this intuition that a negative class is conveying the absence of something like the absence of a malignant tumor.
Whereas one the positive class is conveying the presence of something that we may be looking for, but the definition of which is negative and which is positive is somewhat arbitrary and it doesn't matter that much.
For now we're going to start with classification problems with just two classes zero and one.
Later one we'll talk about multi class problems as well where therefore y may take on four values zero, one, two, and three.
This is called a multiclass classification problem.
But for the next few videos, let's start with the two class or the binary classification problem and we'll worry about the multiclass setting later.
So how do we develop a classification algorithm?
Here's an example of a training set for a classification task for classifying a tumor as malignant or benign.
And notice that malignancy takes on only two values, zero or no, one or yes.
So if you take this training set and fill a straight line to it, maybe you get a hypothesis that looks like that, right.
So that's my hypothesis.
If you want to make predictions one thing you could try doing is then threshold the classifier outputs at 0.5 that is at a vertical axis value 0.5 and if the hypothesis outputs a value that is greater than equal to 0.5 you can take y = 1.
So 0.5 and so that's where the threshold is and that's using linear regression this way.
Everything to the right of this point we will end up predicting as the positive cross.
In this particular example, it looks like linear regression is actually doing something reasonable.
But now let's try changing the problem a bit.
Let me extend out the horizontal access a little bit and let's say we got one more training example way out there on the right.
That is, what is the function we're going to use to represent our hypothesis when we have a classification problem?
Earlier, we said that we would like our classifier to output values that are between 0 and 1.
When we were using linear regression, this was the form of a hypothesis, where h(x) is theta transpose x.
For logistic regression, I'm going to modify this a little bit and make the hypothesis g of theta transpose x.
This is called the sigmoid function, or the logistic function, and the term logistic function, that's what gives rise to the name logistic regression.
And by the way, the terms sigmoid function and logistic function are basically synonyms and mean the same thing.
So the two terms are basically interchangeable, and either term can be used to refer to this function g.
And if we take these two equations and put them together, then here's just an alternative way of writing out the form of my hypothesis.
I'm saying that h(x) Is 1 over 1 plus e to the negative theta transpose x.
And all I've do is I've taken this variable z, z here is a real number, and plugged in theta transpose x.
So I end up with theta transpose x in place of z there.
Lastly, let me show you what the sigmoid function looks like.
The sigmoid function, g(z), also called the logistic function, it looks like this.
It starts off near 0 and then it rises until it crosses 0.5 and the origin, and then it flattens out again like so.
So that's what the sigmoid function looks like.
And you notice that the sigmoid function, while it asymptotes at one and asymptotes at zero, as a z axis, the horizontal axis is z.
As z goes to minus infinity, g(z) approaches zero.
And as g(z) approaches infinity, g(z) approaches one.
Finally, given this hypothesis representation, what we need to do, as before, is fit the parameters theta to our data.
So given a training set we need to a pick a value for the parameters theta and this hypothesis will then let us make predictions.
We'll talk about a learning algorithm later for fitting the parameters theta, but first let's talk a bit about the interpretation of this model.
When my hypothesis outputs some number, I am going to treat that number as the estimated probability that y is equal to one on a new input, example x.
And then one feature is the size of the tumor.
I'm gonna say that this hypothesis is telling me that for a patient with features x, the probability that y equals 1 is 0.7.
In other words, I'm going to tell my patient that the tumor, sadly, has a 70 percent chance, or a 0.7 chance of being malignant.
To write this out slightly more formally, or to write this out in math, I'm going to interpret my hypothesis output as.
So for those of you that are familiar with probability, this equation may make sense.
If you're a little less familiar with probability, then here's how I read this expression.
This is the probability that y is equal to one.
Given x, given that my patient has features x, so given my patient has a particular tumor size represented by my features x.
So I'm basically going to count on my hypothesis to give me estimates of the probability that y is equal to 1.
Now, since this is a classification task, we know that y must be either 0 or 1, right?
Those are the only two values that y could possibly take on, either in the training set or for new patients that may walk into my office, or into the doctor's office in the future.
So given h(x), we can therefore compute the probability that y = 0 as well, completely because y must be either 0 or 1.
It's basically saying that probability of y=0 for a particular patient with features x, and given our parameters theta.
If this equation looks a little bit complicated, feel free to mentally imagine it without that x and theta.
And this is just saying that the product of y equals zero plus the product of y equals one, must be equal to one.
And we know this to be true because y has to be either zero or one, and so the chance of y equals zero, plus the chance that y is one.
And so if you just take this term and move it to the right hand side, then you end up with this equation.
That says probability that y equals zero is 1 minus probability of y equals 1, and thus if our hypothesis feature of x gives us that term.
So, you now know what the hypothesis representation is for logistic regression and we're seeing what the mathematical formula is, defining the hypothesis for logistic regression.
In the next video, I'd like to try to give you better intuition about what the hypothesis function looks like.
And we'll look at some visualizations together to try to get a better sense of what this hypothesis function of logistic regression really looks like.
In the last video, we talked about the hypothesis representation for logistic regression.
What Id like to do now is tell you about something called the decision boundary, and this will give us a better sense of what the logistic regressions hypothesis function is computing.
To recap, this is what we wrote out last time, where we said that the hypothesis is represented as h of x equals g of theta transpose x, where g is this function called the sigmoid function, which looks like this.
It slowly increases from zero to one, asymptoting at one.
What I want to do now is try to understand better when this hypothesis will make predictions that y is equal to 1 versus when it might make predictions that y is equal to 0.
Concretely, this hypothesis is outputting estimates of the probability that y is equal to one, given x and parameterized by theta.
So if we wanted to predict is y equal to one or is y equal to zero, here's something we might do.
Whenever the hypothesis outputs that the probability of y being one is greater than or equal to 0.5, so this means that if there is more likely to be y equals 1 than y equals 0, then let's predict y equals 1.
And otherwise, if the probability, the estimated probability of y being over 1 is less than 0.5, then let's predict y equals 0.
What I want to do is understand better when is it exactly that h of x will be greater than or equal to 0.5, so that we'll end up predicting y is equal to 1.
If we look at this plot of the sigmoid function, we'll notice that the sigmoid function, g of z is greater than or equal to 0.5 whenever z is greater than or equal to zero.
So is in this half of the figure that g takes on values that are 0.5 and higher.
This notch here, that's 0.5, and so when z is positive, g of z, the sigmoid function is greater than or equal to 0.5.
Since the hypothesis for logistic regression is h of x equals g of theta and transpose x, this is therefore going to be greater than or equal to 0.5, whenever theta transpose x is greater than or equal to 0.
So what we're shown, right, because here theta transpose x takes the role of z.
So what we're shown is that a hypothesis is gonna predict y equals 1 whenever theta transpose x is greater than or equal to 0.
Let's now consider the other case of when a hypothesis will predict y is equal to 0.
So when g(z) is less than 0.5, a hypothesis will predict that y is equal to 0.
And by similar argument to what we had earlier, h(x) is equal to g of theta transpose x and so we'll predict y equals 0 whenever this quantity theta transpose x is less than 0.
To summarize what we just worked out, we saw that if we decide to predict whether y=1 or y=0 depending on whether the estimated probability is greater than or equal to 0.5, or whether less than 0.5, then that's the same as saying that when we predict y=1 whenever theta transpose x is greater than or equal to 0.
And we'll predict y is equal to 0 whenever theta transpose x is less than 0.
Let's use this to better understand how the hypothesis of logistic regression makes those predictions.
Now, let's suppose we have a training set like that shown on the slide.
And suppose a hypothesis is h of x equals g of theta zero plus theta one x one plus theta two x two.
We haven't talked yet about how to fit the parameters of this model.
We end up choosing the following values for the parameters.
So this means that my parameter vector is going to be theta equals minus 3, 1, 1.
So, when given this choice of my hypothesis parameters, let's try to figure out where a hypothesis would end up predicting y equals one and where it would end up predicting y equals zero.
Using the formulas that we were taught on the previous slide, we know that y equals one is more likely, that is the probability that y equals one is greater than or equal to 0.5, whenever theta transpose x is greater than zero.
And this formula that I just underlined, -3 + x1 + x2, is, of course, theta transpose x when theta is equal to this value of the parameters that we just chose.
We can also take -3 and bring this to the right and rewrite this as x1+x2 is greater than or equal to 3, so equivalently, we found that this hypothesis would predict y=1 whenever x1+x2 is greater than or equal to 3.
Let's see what that means on the figure, if I write down the equation, X1 + X2 = 3, this defines the equation of a straight line and if I draw what that straight line looks like, it gives me the following line which passes through 3 and 3 on the x1 and the x2 axis.
And so, the region where our hypothesis will predict y = 1, is this region, just really this huge region, this half space over to the upper right.
And that corresponds to this region.
And there's really a half plane, but that region on the left is the region where our hypothesis will predict y = 0.
I wanna give this line, this magenta line that I drew a name.
This line, there, is called the decision boundary.
And just to be clear, the decision boundary is a property of the hypothesis including the parameters theta zero, theta one, theta two.
And in the figure I drew a training set, I drew a data set, in order to help the visualization.
But even if we take away the data set this decision boundary and the region where we predict y =1 versus y = 0, that's a property of the hypothesis and of the parameters of the hypothesis and not a property of the data set.
But once we have particular values for the parameters theta0, theta1, theta2 then that completely defines the decision boundary and we don't actually need to plot a training set in order to plot the decision boundary.
Given a training set like this, how can I get logistic regression to fit the sort of data?
Earlier when we were talking about polynomial regression or when we're talking about linear regression, we talked about how we could add extra higher order polynomial terms to the features.
And we can do the same for logistic regression.
As before, we'll defer to the next video, our discussion on how to automatically choose values for the parameters theta zero through theta four.
What this means is that with this particular choose of parameters, my parameter effect theta theta looks like minus one, zero, zero, one, one.
Following our earlier discussion, this means that my hypothesis will predict that y=1 whenever -1 + x1 squared + x2 squared is greater than or equal to 0.
And if I take minus 1 and just bring this to the right, I'm saying that my hypothesis will predict that y is equal to 1 whenever x1 squared plus x2 squared is greater than or equal to 1.
So what does this decision boundary look like?
Well, if you were to plot the curve for x1 squared plus x2 squared equals 1 Some of you will recognize that, that is the equation for circle of radius one, centered around the origin.
So that is my decision boundary.
And everything outside the circle, I'm going to predict as y=1.
So by adding these more complex, or these polynomial terms to my features as well, I can get more complex decision boundaries that don't just try to separate the positive and negative examples in a straight line that I can get in this example, a decision boundary that's a circle.
Once again, the decision boundary is a property, not of the trading set, but of the hypothesis under the parameters.
So, so long as we're given my parameter vector theta, that defines the decision boundary, which is the circle.
But the training set is not what we use to define the decision boundary.
The training set may be used to fit the parameters theta.
We'll talk about how to do that later.
But, once you have the parameters theta, that is what defines the decisions boundary.
And finally let's look at a more complex example.
So can we come up with even more complex decision boundaries then this?
So this higher autopolynomial features you can a very complex decision boundaries.
So, with these visualizations, I hope that gives you a sense of what's the range of hypothesis functions we can represent using the representation that we have for logistic regression.
Now that we know what h(x) can represent, what I'd like to do next in the following video is talk about how to automatically choose the parameters theta so that given a training set we can automatically fit the parameters to our data.
In this video, we'll talk about how to fit the parameters of theta for the logistic compression.
In particular, I'd like to define the optimization objective, or the cost function that we'll use to fit the parameters.
First feature or a zero feature is always equal to one.
And because this is a computation problem, our training set has the property that every label y is either 0 or 1.
This is a hypothesis, and the parameters of a hypothesis is this theta over here.
And the question that I want to talk about is given this training set, how do we choose, or how do we fit the parameter's theta?
Back when we were developing the linear regression model, we used the following cost function.
I've written this slightly differently where instead of 1 over 2m, I've taken a one-half and put it inside the summation instead.
Which is that instead of writing out this square of return here, let's write in here costs of h of x, y and I'm going to define that total cost of h of x, y to be equal to this.
Just equal to this one-half of the squared error.
So now we can see more clearly that the cost function is a sum over my training set, which is 1 over n times the sum of my training set of this cost term here.
And to simplify this equation a little bit more, it's going to be convenient to get rid of those superscripts.
So just define cost of h of x comma y to be equal to one half of this squared error.
And interpretation of this cost function is that, this is the cost I want my learning algorithm to have to pay if it outputs that value, if its prediction is h of x, and the actual label was y.
So just cross off the superscripts, right, and no surprise for linear regression the cost we've defined is that or the cost of this is that is one-half times the square difference between what I predicted and the actual value that we have, 0 for y.
If we could minimize this cost function that is plugged into J here, that will work okay.
But it turns out that if we use this particular cost function, this would be a non-convex function of the parameter's data.
Have some cross function j of theta and for logistic regression, this function h here has a nonlinearity that is one over one plus e to the negative theta transpose.
So this is a pretty complicated nonlinear function.
And you can kind of tell, if you were to run gradient descent on this sort of function It is not guaranteed to converge to the global minimum.
Whereas in contrast what we would like is to have a cost function j of theta that is convex, that is a single bow-shaped function that looks like this so that if you run theta in the we would be guaranteed that would converge to the global minimum.
And the problem with using this great cost function is that because of this very nonlinear function that appears in the middle here, J of theta ends up being a nonconvex function if you were to define it as a square cost function.
So what we'd like to do is, instead of come up with a different cost function, that is convex, and so that we can apply a great algorithm, like gradient descent and be guaranteed to find the global minimum.
Here's the cost function that we're going to use for logistic regression.
And the actual cost label turns out to be y.
The cost is going to be -log(h(x)) if y = 1 and -log(1- h(x)) if y = 0.
This looks like a pretty complicated function, but let's plot this function to gain some intuition about what it's doing.
Let's start off with the case of y = 1.
And if we plot that, so let's say that the horizontal axis is h(x), so we know that a hypothesis is going to output a value between 0 and 1.
Right, so h(x), that varies between 0 and 1.
If you plot what this cost function looks like, you find that it looks like this.
One way to see why the plot looks like this is because if you were to plot log z with z on the horizontal axis, then that looks like that.
And it approaches minus infinity, right?
So this is what the log function looks like.
Here, z is of course playing the role of h of x.
Now, this cost function has a few interesting and desirable properties.
First, you notice that if y is equal to 1 and h(x) is equal to 1, in other words, if the hypothesis exactly predicts h equals 1 and y is exactly equal to what it predicted, then the cost = 0 right?
That corresponds to the curve doesn't actually flatten out.
First, notice that if h(x) = 1, if that hypothesis predicts that y = 1 and if indeed y = 1 then the cost = 0.
That corresponds to this point down here, right?
If h(x) = 1 and we're only considering the case of y = 1 here.
But if h(x) = 1 then the cost is down here, is equal to 0.
And that's where we'd like it to be because if we correctly predict the output y, then the cost is 0.
But now notice also that as h(x) approaches 0, so as the output of a hypothesis approaches 0, the cost blows up and it goes to infinity.
And what this does is this captures the intuition that if a hypothesis of 0, that's like saying a hypothesis saying the chance of y equals 1 is equal to 0.
It's kinda like our going to our medical patients and saying the probability that you have a malignant tumor, the probability that y=1, is zero.
But if it turns out that the tumor, the patient's tumor, actually is malignant, so if y is equal to one, even after we told them, that the probability of it happening is zero.
But if we told them this with that level of certainty and we turn out to be wrong, then we penalize the learning algorithm by a very, very large cost.
Let's look at what the cost function looks like for y equals 0.
If y is equal to 0, then the cost looks like this, it looks like this expression over here, and if you plot the function, -log(1-z), what you get is the cost function actually looks like this.
So it goes from 0 to 1, something like that and so if you plot the cost function for the case of y equals 0, you find that it looks like this.
And what this curve does is it now goes up and it goes to plus infinity as h of x goes to 1 because as I was saying, that if y turns out to be equal to 0.
But we predicted that y is equal to 1 with almost certainly, probably 1, then we end up paying a very large cost.
And conversely, if h of x is equal to 0 and y equals 0, then the hypothesis melted.
The protected y of z is equal to 0, and it turns out y is equal to 0, so at this point, the cost function is going to be 0.
In this video, we will define the cost function for a single train example.
The topic of convexity analysis is now beyond the scope of this course, but it is possible to show that with a particular choice of cost function, this will give a convex optimization problem.
In the next video we're gonna take these ideas of the cost function for a single training example and develop that further, and define the cost function for the entire training set.
In the last video, we talked about gradient descent for minimizing the cost function J of theta for logistic regression.
In this video, I'd like to tell you about some advanced optimization algorithms and some advanced optimization concepts.
Using some of these ideas, we'll be able to get logistic regression to run much more quickly than it's possible with gradient descent.
Here's an alternative view of what gradient descent is doing.
We have some cost function J and we want to minimize it.
So what we need to is, we need to write code that can take as input the parameters theta and they can compute two things: J of theta and these partial derivative terms for, you know, J equals 0, 1 up to N.
Given code that can do these two things, what gradient descent does is it repeatedly performs the following update.
Right?
So given the code that we wrote to compute these partial derivatives, gradient descent plugs in here and uses that to update our parameters theta.
So another way of thinking about gradient descent is that we need to supply code to compute J of theta and these derivatives, and then these get plugged into gradient descents, which can then try to minimize the function for us.
You only need code to compute the derivative terms.
But if you think of your code as also monitoring convergence of some such, we'll just think of ourselves as providing code to compute both the cost function and the derivative terms.
So, having written code to compute these two things, one algorithm we can use is gradient descent.
But gradient descent isn't the only algorithm we can use.
So conjugate gradient BFGS and L-BFGS are examples of more sophisticated optimization algorithms that need a way to compute J of theta, and need a way to compute the derivatives, and can then use more sophisticated strategies than gradient descent to minimize the cost function.
The details of exactly what these three algorithms is well beyond the scope of this course.
And in fact you often end up spending, you know, many days, or a small number of weeks studying these algorithms.
If you take a class and advance the numerical computing.
These three algorithms have a number of advantages.
One is that, with any of this algorithms you usually do not need to manually pick the learning rate alpha.
So one way to think of these algorithms is that given is the way to compute the derivative and a cost function.
And, in fact, they have a clever inter-loop called a line search algorithm that automatically tries out different values for the learning rate alpha and automatically picks a good learning rate alpha so that it can even pick a different learning rate for every iteration.
These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent.
These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent, but detailed discussion of exactly what they do is beyond the scope of this course.
In fact, I actually used to have used these algorithms for a long time, like maybe over a decade, quite frequently, and it was only, you know, a few years ago that I actually figured out for myself the details of what conjugate gradient, BFGS and O-BFGS do.
So it is actually entirely possible to use these algorithms successfully and apply to lots of different learning problems without actually understanding the inter-loop of what these algorithms do.
If these algorithms have a disadvantage, I'd say that the main disadvantage is that they're quite a lot more complex than gradient descent.
And in particular, you probably should not implement these algorithms - conjugate gradient, L-BGFS, BFGS - yourself unless you're an expert in numerical computing.
Instead, just as I wouldn't recommend that you write your own code to compute square roots of numbers or to compute inverses of matrices, for these algorithms also what I would recommend you do is just use a software library.
So, you know, to take a square root what all of us do is use some function that someone else has written to compute the square roots of our numbers.
And fortunately, Octave and the closely related language MATLAB - we'll be using that - Octave has a very good.
And so if you just use the built-in library, you know, you get pretty good results.
I should say that there is a difference between good and bad implementations of these algorithms.
And so, if you're using a different language for your machine learning application, if you're using C, C++, Java, and so on, you might want to try out a couple of different libraries to make sure that you find a good library for implementing these algorithms.
Because there is a difference in performance between a good implementation of, you know, contour gradient or LPFGS versus less good implementation of contour gradient or LPFGS.
You know the value for theta 1 and theta 2.
If you want to minimize J of theta as a function of theta.
The value that minimizes it is going to be theta 1 equals 5, theta 2 equals equals five.
Now, again, I know some of you know more calculus than others, but the derivatives of the cost function J turn out to be these two expressions.
So it's just computing this cost function over here.
And the second argument that this function returns is gradient.
So gradient is going to be a two by one vector, and the two elements of the gradient vector correspond to the two partial derivative terms over here.
Having implemented this cost function, you would, you can then call the advanced optimization function called the fminunc - it stands for function minimization unconstrained in Octave -and the way you call this is as follows.
This is a options as a data structure that stores the options you want.
So grant up on, this sets the gradient objective parameter to on.
It just means you are indeed going to provide a gradient to this algorithm.
And then this command calls fminunc.
This at symbol presents a pointer to the cost function that we just defined up there.
And if you call this, this will compute, you know, will use one of the more advanced optimization algorithms.
And if you want to think it as just like gradient descent.
But automatically choosing the learning rate alpha for so you don't have to do so yourself.
But it will then attempt to use the sort of advanced optimization algorithms.
To try to find the optimal value of theta for you.
Let me actually show you what this looks like in Octave.
So I've written this cost function of theta function exactly as we had it on the previous line.
And it computes the gradient with the two elements being the partial derivatives of the cost function with respect to, you know, the two parameters, theta one and theta two.
Now let's switch to my Octave window.
Grant option on, maxIter, 100 so that says 100 iterations, and I am going to provide the gradient to my algorithm.
And it returns pretty quickly.
So, this funny thing is just because my command line had wrapped around.
But what this says is that numerically renders, you know, think of it as gradient descent on steroids, they found the optimal value of a theta is theta 1 equals 5, theta 2 equals 5, exactly as we're hoping for.
So that's essentially zero, which is also what we're hoping for.
And the exit flag is 1, and this shows what the convergence status of this.
So that's how you run these algorithms in Octave.
I should mention, by the way, that for the Octave implementation, this value of theta, your parameter vector of theta, must be in rd for d greater than or equal to 2.
So, that's how we optimize our trial example of this simple quick driving cost function.
In logistic regression we have a parameter vector theta, and I'm going to use a mix of octave notation and sort of math notation.
So, if theta 2 in octave and that's gonna be a written theta n+1, right?
So what we need to do then is write a cost function that captures the cost function for logistic regression.
Concretely, the cost function needs to return J-val, which is, you know, J-val as you need some codes to compute J of theta and we also need to give it the gradient.
So, gradient 1 is going to be some code to compute the partial derivative in respect to theta 0, the next partial derivative respect to theta 1 and so on.
Once again, this is gradient 1, gradient 2 and so on, rather than gradient 0, gradient 1 because octave indexes is vectors starting from one rather than from zero.
But the main concept I hope you take away from this slide is, that what you need to do, is write a function that returns the cost function and returns the gradient.
And so in order to apply this to logistic regression or even to linear regression, if you want to use these optimization algorithms for linear regression.
So, now you know how to use these advanced optimization algorithms.
Because, using, because for these algorithms, you're using a sophisticated optimization library, it makes the just a little bit more opaque and so just maybe a little bit harder to debug.
But because these algorithms often run much faster than gradient descent, often quite typically whenever I have a large machine learning problem, I will use these algorithms instead of using gradient descent.
And with these ideas, hopefully, you'll be able to get logistic progression and also linear regression to work on much larger problems.
So, that's it for advanced optimization concepts.
And in the next and final video on Logistic Regression, I want to tell you how to take the logistic regression algorithm that you already know about and make it work also on multi-class classification problems.
And in particular I want to tell you about an algorithm called one-versus-all classification.
What's a multiclass classification problem?
Lets say you want a learning algorithm to automatically put your email into different folders or to automatically tag your emails so you might have different folders or different tags for work email, email from your friends, email from your family, and emails about your hobby.
And another example, for medical diagnosis, if a patient comes into your office with maybe a stuffy nose, the possible diagnosis could be that they're not ill.
Or they have a flu.
I tend to index my classes starting from 1 rather than starting from 0, but either way we're off and it really doesn't matter.
Whereas previously for a binary classification problem, our data sets look like this.
For a multi-class classification problem our data sets may look like this where here I'm using three different symbols to represent our three classes.
So the question is given the data set with three classes where this is an example of one class, that's an example of a different class, and that's an example of yet a third class.
How do we get a learning algorithm to work for the setting?
We already know how to do binary classification using a regression.
We know how to you know maybe fit a straight line to set for the positive and negative classes.
We can then take this and make it work for multi-class classification as well.
What we're going to do is take our training set and turn this into three separate binary classification problems.
I'll turn this into three separate two class classification problems.
So let's start with class one which is the triangle.
And class one gets assigned to the positive class.
So think of the triangles being assigned the value of one and the circles assigned the value of zero.
Okay?
This superscript one here stands for class one, so we're doing this for the triangles of class one.
Next we do the same thing for class two.
Gonna take the squares and assign the squares as the positive class, and assign everything else, the triangles and the crosses, as a negative class.
And finally, we do the same thing for the third class and fit a third classifier h super script three of x, and maybe this will give us a decision bounty of the visible cross fire.
So to summarize, what we've done is, we've fit three classifiers.
Thus trying to estimate what is the probability that y is equal to class i, given x and parametrized by theta.
So in the first instance for this first one up here, this classifier was learning to recognize the triangles.
So it's thinking of the triangles as a positive clause, so x superscript one is essentially trying to estimate what is the probability that the y is equal to one, given that x is parametrized by theta.
And similarly, this is treating the square class as a positive class and so it's trying to estimate the probability that y = 2 and so on.
So we now have three classifiers, each of which was trained to recognize one of the three classes.
Just to summarize, what we've done is we want to train a logistic regression classifier h superscript i of x for each class i to predict the probability that y is equal to i.
What we do is we just run all three of our classifiers on the input x and we then pick the class i that maximizes the three.
So we just basically pick the classifier, I think whichever one of the three classifiers is most confident and so the most enthusiastically says that it thinks it has the right clause.
So whichever value of i gives us the highest probability we then predict y to be that value.
And with this little method you can now take the logistic regression classifier and make it work on multi-class classification problems as well
They work well for many problems, but when you apply them to certain machine learning applications, they can run into a problem called overfitting that can cause them to perform very poorly.
What I'd like to do in this video is explain to you what is this overfitting problem, and in the next few videos after this, we'll talk about a technique called regularization, that will allow us to ameliorate or to reduce this overfitting problem and get these learning algorithms to maybe work much better.
So what is overfitting?
Let's keep using our running example of predicting housing prices with linear regression where we want to predict the price as a function of the size of the house.
But this isn't a very good model.
Looking at the data, it seems pretty clear that as the size of the housing increases, the housing prices plateau, or kind of flattens out as we move to the right and so this algorithm does not fit the training and we call this problem underfitting, and another term for this is that this algorithm has high bias.
Both of these roughly mean that it's just not even fitting the training data very well.
The term is kind of a historical or technical one, but the idea is that if a fitting a straight line to the data, then, it's as if the algorithm has a very strong preconception, or a very strong bias that housing prices are going to vary linearly with their size and despite the data to the contrary.
Despite the evidence of the contrary is preconceptions still are bias, still closes it to fit a straight line and this ends up being a poor fit to the data.
And, at the other extreme, would be if we were to fit, say a fourth other polynomial to the data.
That, on the one hand, seems to do a very good job fitting the training set and, that is processed through all of my data, at least.
But, this is still a very wiggly curve, right?
So, it's going up and down all over the place, and, we don't actually think that's such a good model for predicting housing prices.
So, this problem we call overfitting, and, another term for this is that this algorithm has high variance..
The term high variance is another historical or technical one.
But, the intuition is that, if we're fitting such a high order polynomial, then, the hypothesis can fit, you know, it's almost as if it can fit almost any function and this face of possible hypothesis is just too large, it's too variable.
And we don't have enough data to constrain it to give us a good hypothesis so that's called overfitting.
And in the middle, there isn't really a name but I'm just going to write, you know, just right.
Where a second degree polynomial, quadratic function seems to be just right for fitting this data.
To recap a bit the problem of over fitting comes when if we have too many features, then to learn hypothesis may fit the training side very well.
That is to data to houses that it has not seen in the training set.
On this slide, we looked at over fitting for the case of linear regression.
Here is a logistic regression example with two features X1 and x2.
And if you do that, you end up with a hypothesis, trying to use, maybe, just a straight line to separate the positive and the negative examples.
And this doesn't look like a very good fit to the hypothesis.
So, once again, this is an example of underfitting or of the hypothesis having high bias.
In contrast, if you were to add to your features these quadratic terms, then, you could get a decision boundary that might look more like this.
And, you know, that's a pretty good fit to the data.
Probably, about as good as we could get, on this training set.
And, finally, at the other extreme, if you were to fit a very high-order polynomial, if you were to generate lots of high-order polynomial terms of speeches, then, logistical regression may contort itself, may try really hard to find a decision boundary that fits your training data or go to great lengths to contort itself, to fit every single training example well.
And, you know, if the features X1 and X2 offer predicting, maybe, the cancer to the, you know, cancer is a malignant, benign breast tumors.
And so, once again, this is an instance of overfitting and, of a hypothesis having high variance and not really, and, being unlikely to generalize well to new examples.
Later, in this course, when we talk about debugging and diagnosing things that can go wrong with learning algorithms, we'll give you specific tools to recognize when overfitting and, also, when underfitting may be occurring.
But, for now, lets talk about the problem of, if we think overfitting is occurring, what can we do to address it?
In the previous examples, we had one or two dimensional data so, we could just plot the hypothesis and see what was going on and select the appropriate degree polynomial.
So, earlier for the housing prices example, we could just plot the hypothesis and, you know, maybe see that it was fitting the sort of very wiggly function that goes all over the place to predict housing prices.
And we could then use figures like these to select an appropriate degree polynomial.
So plotting the hypothesis, could be one way to try to decide what degree polynomial to use.
And, in fact more often we may have learning problems that where we just have a lot of features.
And there is not just a matter of selecting what degree polynomial.
And, in fact, when we have so many features, it also becomes much harder to plot the data and it becomes much harder to visualize it, to decide what features to keep or not.
So concretely, if we're trying predict housing prices sometimes we can just have a lot of different features.
And all of these features seem, you know, maybe they seem kind of useful.
But, if we have a lot of features, and, very little training data, then, over fitting can become a problem.
The first option is, to try to reduce the number of features.
Concretely, one thing we could do is manually look through the list of features, and, use that to try to decide which are the more important features, and, therefore, which are the features we should keep, and, which are the features we should throw out.
Later in this course, where also talk about model selection algorithms.
Which are algorithms for automatically deciding which features to keep and, which features to throw out.
This idea of reducing the number of features can work well, and, can reduce over fitting.
And, when we talk about model selection, we'll go into this in much greater depth.
But, the disadvantage is that, by throwing away some of the features, is also throwing away some of the information you have about the problem.
For example, maybe, all of those features are actually useful for predicting the price of a house, so, maybe, we don't actually want to throw some of our information or throw some of our features away.
The second option, which we'll talk about in the next few videos, is regularization.
Here, we're going to keep all the features, but we're going to reduce the magnitude or the values of the parameters theta J.
And, this method works well, we'll see, when we have a lot of features, each of which contributes a little bit to predicting the value of Y, like we saw in the housing price prediction example.
Where we could have a lot of features, each of which are, you know, somewhat useful, so, maybe, we don't want to throw them away.
So, this subscribes the idea of regularization at a very high level.
And, I realize that, all of these details probably don't make sense to you yet.
But, in the next video, we'll start to formulate exactly how to apply regularization and, exactly what regularization means.
And, then we'll start to figure out, how to use this, to make how learning algorithms work well and avoid overfitting.
In this video, I'd like to convey to you, the main intuitions behind how regularization works.
And, we'll also write down the cost function that we'll use, when we were using regularization.
With the hand drawn examples that we have on these slides, I think I'll be able to convey part of the intuition.
But, an even better way to see for yourself, how regularization works, is if you implement it, and, see it work for yourself.
And, if you do the appropriate exercises after this, you get the chance to self see regularization in action for yourself.
So, here is the intuition.
In the previous video, we saw that, if we were to fit a quadratic function to this data, it gives us a pretty good fit to the data.
Whereas, if we were to fit an overly high order degree polynomial, we end up with a curve that may fit the training set very well, but, really not be a, but overfit the data poorly, and, not generalize well.
Consider the following, suppose we were to penalize, and, make the parameters theta 3 and theta 4 really small.
Now, if we were to minimize this function, the only way to make this new cost function small is if theta 3 and data 4 are small, right?
Because otherwise, if you have a thousand times theta 3, this new cost functions gonna be big.
So when we minimize this new function we are going to end up with theta 3 close to 0 and theta 4 close to 0, and as if we're getting rid of these two terms over there.
And, so, we end up with essentially, a quadratic function, which is good.
Because this is a much better hypothesis.
In this particular example, we looked at the effect of penalizing two of the parameter values being large.
More generally, here is the idea behind regularization.
The idea is that, if we have small values for the parameters, then, having small values for the parameters, will somehow, will usually correspond to having a simpler hypothesis.
So, for our last example, we penalize just theta 3 and theta 4 and when both of these were close to zero, we wound up with a much simpler hypothesis that was essentially a quadratic function.
But more generally, it is possible to show that having smaller values of the parameters corresponds to usually smoother functions as well for the simpler.
And which are therefore, also, less prone to overfitting.
I realize that the reasoning for why having all the parameters be small.
And it is kind of hard to explain unless you implement yourself and see it for yourself.
But I hope that the example of having theta 3 and theta 4 be small and how that gave us a simpler hypothesis, I hope that helps explain why, at least give some intuition as to why this might be true.
For housing price prediction we may have our hundred features that we talked about where may be x1 is the size, x2 is the number of bedrooms, x3 is the number of floors and so on.
And unlike the polynomial example, we don't know, right, we don't know that theta 3, theta 4, are the high order polynomial terms.
So, if we have just a bag, if we have just a set of a hundred features, it's hard to pick in advance which are the ones that are less likely to be relevant.
And we don't know which ones to pick, we don't know which parameters to try to pick, to try to shrink.
So, in regularization, what we're going to do, is take our cost function, here's my cost function for linear regression.
So I am going to modify my cost function to add a term at the end.
When I add an extra regularization term at the end to shrink every single parameter and so this term we tend to shrink all of my parameters theta 1, theta 2, theta 3 up to theta 100.
By the way, by convention the summation here starts from one so I am not actually going penalize theta zero being large.
But in practice, it makes very little difference, and, whether you include, you know, theta zero or not, in practice, make very little difference to the results.
But by convention, usually, we regularize only theta through theta 100.
Writing down our regularized optimization objective, our regularized cost function again.
Here's J of theta where, this term on the right is a regularization term and lambda here is called the regularization parameter and what lambda does, is it controls a trade off between two different goals.
The first goal, capture it by the first goal objective, is that we would like to train, is that we would like to fit the training data well.
We would like to fit the training set well.
And the second goal is, we want to keep the parameters small, and that's captured by the second term, by the regularization objective.
And what lambda, the regularization parameter does is the controls the trade of between these two goals, between the goal of fitting the training set well and the goal of keeping the parameter plan small and therefore keeping the hypothesis relatively simple to avoid overfitting.
For our housing price prediction example, whereas, previously, if we had fit a very high order polynomial, we may have wound up with a very, sort of wiggly or curvy function like this.
Once again, I realize it can be a bit difficult to see why strengthening the parameters can have this effect, but if you implement yourselves with regularization you will be able to see this effect firsthand.
In regularized linear regression, if the regularization parameter monitor is set to be very large, then what will happen is we will end up penalizing the parameters theta 1, theta 2, theta 3, theta 4 very highly.
And if we end up penalizing theta 1, theta 2, theta 3, theta 4 very heavily, then we end up with all of these parameters close to zero, right?
It says that, well, housing prices are equal to theta zero, and that is akin to fitting a flat horizontal straight line to the data.
And this is an example of underfitting, and in particular this hypothesis, this straight line it just fails to fit the training set well.
It doesn't go anywhere near most of the training examples.
And another way of saying this is that this hypothesis has too strong a preconception or too high bias that housing prices are just equal to theta zero, and despite the clear data to the contrary, you know chooses to fit a sort of, flat line, just a flat horizontal line.
This just a horizontal flat line to the data.
So for regularization to work well, some care should be taken, to choose a good choice for the regularization parameter lambda as well.
And when we talk about multi-selection later in this course, we'll talk about a way, a variety of ways for automatically choosing the regularization parameter lambda as well.
For linear regression, we have previously worked out two learning algorithms.
One based on gradient descent and one based on the normal equation.
In this video, we'll take those two algorithms and generalize them to the case of regularized linear regression.
This first part is our usual objective for linear regression.
Previously, we were using gradient descent for the original cost function without the regularization term.
Let me take this and just write the case for theta 0 separately.
So I'm just going to write the update for theta 0 separately than for the update for the parameters 1, 2, 3, and so on up to n.
And so this is, I haven't changed anything yet, right.
This is just writing the update for theta 0 separately from the updates for theta 1, theta 2, theta 3, up to theta n.
And the reason I want to do this is you may remember that for our regularized linear regression, we penalize the parameters theta 1, theta 2, and so on up to theta n.
So, when we modify this algorithm for regularized linear regression, we're going to end up treating theta zero slightly differently.
Concretely, if we want to take this algorithm and modify it to use the regular rise objective, all we need to do is take this term at the bottom and modify it as follows.
We'll take this term and add minus lambda over m times theta j.
And if you implement this, then you have gradient descent for trying to minimize the regularized cost function, j of theta.
And concretely, I'm not gonna do the calculus to prove it, but concretely if you look at this term, this term hat I've written in square brackets, if you know calculus it's possible to prove that that term is the partial derivative with respect to J of theta using the new definition of J of theta with the regularization term.
And similarly, this term up on top which I'm drawing the cyan box, that's still the partial derivative respect of theta zero of J of theta.
If you look at the update for theta j, it's possible to show something very interesting.
Concretely, theta j gets updated as theta j minus alpha times, and then you have this other term here that depends on theta J.
So if you group all the terms together that depend on theta j, you can show that this update can be written equivalently as follows.
And this term is, right, lambda over m, there's also an alpha here, so you end up with alpha lambda over m multiplied into theta j.
And this term here, 1 minus alpha times lambda m, is a pretty interesting term.
It has a pretty interesting effect.
So this term here is gonna be a number that's usually a little bit less than 1, so think of it as a number like 0.99, let's say.
And so the effect of our update to theta j is, we're going to say that theta j gets replaced by theta j times 0.99, right?
So theta j times 0.99 has the effect of shrinking theta j a little bit towards zero.
So this makes theta j a bit smaller.
And more formally, this makes the square norm of theta j a little bit smaller.
And then after that, the second term here, that's actually exactly the same as the original gradient descent update that we had, before we added all this regularization stuff.
Of course that's just the intuition behind what this particular update is doing.
Mathematically what it's doing is it's exactly gradient descent on the cost function J of theta that we defined on the previous slide that uses the regularization term.
Gradient descent was just one of our two algorithms for fitting a linear regression model.
The second algorithm was the one based on the normal equation, where what we did was we created the design matrix X where each row corresponded to a separate training example.
And we created a vector y, so this is a vector, that's an m dimensional vector.
And in order to minimize the cost function J, we found that one way to do so is to set theta to be equal to this.
And what this value for theta does is this minimizes the cost function J of theta, when we were not using regularization.
Now that we are using regularization, if you were to derive what the minimum is, and just to give you a sense of how to derive the minimum, the way you derive it is you take partial derivatives with respect to each parameter.
Set this to zero, and then do a bunch of math and you can then show that it's a formula like this that minimizes the cost function.
0, 1, 1, 1, and so on, 1, until the bottom.
There are ones on the diagonals, and then zeros everywhere else in this matrix.
But as a example, if n = 2, then this matrix is going to be a three by three matrix.
More generally, this matrix is an (n+1) by (n+1) dimensional matrix.
So if n = 2, then that matrix becomes something that looks like this.
It would be 0, and then 1s on the diagonals, and then 0s on the rest of the diagonals.
So finally I want to just quickly describe the issue of non-invertibility.
And feel free to skip it, or if you listen to it and positive it doesn't really make sense, don't worry about it either.
But earlier when I talked about the normal equation method, we also had an optional video on the non-invertibility issue.
So this is another optional part to this, sort of an add-on to that earlier optional video on non-invertibility.
Now, consider a setting where m, the number of examples, is less than or equal to n, the number of features.
If you have fewer examples than features, than this matrix, X transpose X will be non-invertible, or singular.
And if you implement this in Octave anyway and you use the pinv function to take the pseudo inverse, it will kind of do the right thing, but it's not clear that it would give you a very good hypothesis, even though numerically the Octave pinv function will give you a result that kinda makes sense.
Then in this setting, you find that X transpose X is singular, is non-invertible, and if you're doing this in different program language and using some linear algebra library to try to take the inverse of this matrix, it just might not work because that matrix is non-invertible or singular.
And concretely, so long as the regularization parameter lambda is strictly greater than 0, it is actually possible to prove that this matrix, X transpose X plus lambda times this funny matrix here, it is possible to prove that this matrix will not be singular and that this matrix will be invertible.
Using this you'll be able to avoid overfitting even if you have lots of features in a relatively small training set.
And this should let you get linear regression to work much better for many problems.
In the next video we'll take this regularization idea and apply it to logistic regression.
So that you'd be able to get logistic regression to avoid overfitting and perform much better as well.
For logistic regression, we previously talked about two types of optimization algorithms.
We talked about how to use gradient descent to optimize as cost function J of theta.
And we also talked about advanced optimization methods.
Ones that require that you provide a way to compute your cost function J of theta and that you provide a way to compute the derivatives.
In this video, we'll show how you can adapt both of those techniques, both gradient descent and the more advanced optimization techniques in order to have them work for regularized logistic regression.
So, here's the idea.
We saw earlier that Logistic Regression can also be prone to overfitting if you fit it with a very, sort of, high order polynomial features like this.
Not necessarily polynomial ones, but just with a lot of features you can end up with overfitting.
This was our cost function for logistic regression.
And if we want to modify it to use regularization, all we need to do is add to it the following term plus londer over 2M, sum from J equals 1, and as usual sum from J equals 1.
And this has to effect therefore, of penalizing the parameters theta 1 theta 2 and so on up to theta N from being too large.
And if you do this, then it will the have the effect that even though you're fitting a very high order polynomial with a lot of parameters.
It looks more reasonable for separating the positive and the negative examples.
So, when using regularization even when you have a lot of features, the regularization can help take care of the overfitting problem.
How do we actually implement this?
Well, for the original gradient descent algorithm, this was the update we had.
We will repeatedly perform the following update to theta J.
This slide looks a lot like the previous one for linear regression.
But what I'm going to do is write the update for theta 0 separately.
So, the first line is for update for theta 0 and a second line is now my update for theta 1 up to theta N.
And in order to modify this algorithm, to use a regularized cos function, all I need to do is pretty similar to what we did for linear regression is actually to just modify this second update rule as follows.
And, once again, this, you know, cosmetically looks identical what we had for linear regression.
But of course is not the same algorithm as we had, because now the hypothesis is defined using this.
So this is not the same algorithm as regularized linear regression.
Because the hypothesis is different.
It actually looks cosmetically the same as what we had earlier.
And of course, just to wrap up this discussion, this term here in the square brackets, so this term here, this term is, of course, the new partial derivative for respect of theta J of the new cost function J of theta.
Where J of theta here is the cost function we defined on a previous slide that does use regularization.
And just to remind you for those methods what we needed to do was to define the function that's called the cost function, that takes us input the parameter vector theta and once again in the equations we've been writing here we used 0 index vectors.
So we had theta 0 up to theta N.
And what we needed to do was provide a function.
Let's provide a function called cost function that we would then pass in to what we have, what we saw earlier.
We will use the fminunc and then you know at cost function, and so on, right.
So the two main things that the cost function needed to return were first J-val.
And for that, we need to write code to compute the cost function J of theta.
Now, when we're using regularized logistic regression, of course the cost function j of theta changes and, in particular, now a cost function needs to include this additional regularization term at the end as well.
So, when you compute j of theta be sure to include that term at the end.
And then, the other thing that this cost function thing needs to derive with a gradient.
Once again, the index is off by one.
We actually worked this out on a previous slide is actually equal to this.
And the other terms do change.
Is equal to, you know, the original term and then minus londer M times theta 1.
Just so we make sure we pass this correctly.
And similarly, you know, this other term here looks like this, with this additional term that we had on the previous slide, that corresponds to the gradient from their regularization objective.
So if you implement this cost function and pass this into fminunc or to one of those advanced optimization techniques, that will minimize the new regularized cost function J of theta.
And the parameters you get out will be the ones that correspond to logistic regression with regularization.
So, now you know how to implement regularized logistic regression.
When I walk around Silicon Valley, I live here in Silicon Valley, there are a lot of engineers that are frankly, making a ton of money for their companies using machine learning algorithms.
But if you understand linear regression, the advanced optimization algorithms and regularization, by now, frankly, you probably know quite a lot more machine learning than many, certainly now, but you probably know quite a lot more machine learning right now than frankly, many of the Silicon Valley engineers out there having very successful careers.
You've actually come a long ways.
And you can actually, you actually know enough to apply this stuff and get to work for many problems.
And in the next set of videos after this one, I'll start telling you about them.
In this and in the next set of videos, I'd like to tell you about a learning algorithm called a Neural Network.
We're going to first talk about the representation and then in the next set of videos talk about learning algorithms for it.
Neutral networks is actually a pretty old idea, but had fallen out of favor for a while.
But today, it is the state of the art technique for many different machine learning problems.
So why do we need yet another learning algorithm?
In order to motivate the discussion of neural networks, let me start by showing you a few examples of machine learning problems where we need to learn complex non-linear hypotheses.
Consider a supervised learning classification problem where you have a training set like this.
If you want to apply logistic regression to this problem, one thing you could do is apply logistic regression with a lot of nonlinear features like that.
So here, g as usual is the sigmoid function, and we can include lots of polynomial terms like these.
And, if you include enough polynomial terms then, you know, maybe you can get a hypotheses that separates the positive and negative examples.
This particular method works well when you have only, say, two features - x1 and x2 - because you can then include all those polynomial terms of x1 and x2.
But for many interesting machine learning problems would have a lot more features than just two.
We've been talking for a while about housing prediction, and suppose you have a housing classification problem rather than a regression problem, like maybe if you have different features of a house, and you want to predict what are the odds that your house will be sold within the next six months, so that will be a classification problem.
And as we saw we can come up with quite a lot of features, maybe a hundred different features of different houses.
For a problem like this, if you were to include all the quadratic terms, all of these, even all of the quadratic that is the second or the polynomial terms, there would be a lot of them.
And if you include just the second order terms, that is, the terms that are a product of, you know, two of these terms, x1 times x1 and so on, then, for the case of n equals 100, you end up with about five thousand features.
And, asymptotically, the number of quadratic features grows roughly as order n squared, where n is the number of the original features, like x1 through x100 that we had.
Here you have only 100 such quadratic features, but this is not enough features and certainly won't let you fit the data set like that on the upper left.
In fact, if you include only these quadratic features together with the original x1, and so on, up to x100 features, then you can actually fit very interesting hypotheses.
So, you can fit things like, you know, access a line of the ellipses like these, but you certainly cannot fit a more complex data set like that shown here.
So 5000 features seems like a lot, if you were to include the cubic, or third order known of each others, the x1, x2, x3.
You can imagine there are gonna be a lot of these features.
For many machine learning problems, n will be pretty large.
Let's consider the problem of computer vision.
And suppose you want to use machine learning to train a classifier to examine an image and tell us whether or not the image is a car.
Many people wonder why computer vision could be difficult.
I mean when you and I look at this picture it is so obvious what this is.
You wonder how is it that a learning algorithm could possibly fail to know what this picture is.
To understand why computer vision is hard let's zoom into a small part of the image like that area where the little red rectangle is.
It turns out that where you and I see a car, the computer sees that.
What it sees is this matrix, or this grid, of pixel intensity values that tells us the brightness of each pixel in the image.
So the computer vision problem is to look at this matrix of pixel intensity values, and tell us that these numbers represent the door handle of a car.
And hopefully it will recognize that that is a car.
To understand why we need nonlinear hypotheses, let's take a look at some of the images of cars and maybe non-cars that we might feed to our learning algorithm.
And let's do this with a few other images.
So let's take a different example of the car and you know, look at the same two pixel locations and that image has a different intensity for pixel one and a different intensity for pixel two.
So, it ends up at a different location on the figure.
And then let's plot some negative examples as well.
That's a non-car, that's a non-car .
And if we do this for more and more examples using the pluses to denote cars and minuses to denote non-cars, what we'll find is that the cars and non-cars end up lying in different regions of the space, and what we need therefore is some sort of non-linear hypotheses to try to separate out the two classes.
Suppose we were to use just 50 by 50 pixel images.
Now that suppose our images were pretty small ones, just 50 pixels on the side.
Then we would have 2500 pixels, and so the dimension of our feature size will be N equals 2500 where our feature vector x is a list of all the pixel testings, you know, the pixel brightness of pixel one, the brightness of pixel two, and so on down to the pixel brightness of the last pixel where, you know, in a typical computer representation, each of these may be values between say 0 to 255 if it gives us the grayscale value.
If we were using RGB images with separate red, green and blue values, we would have n equals 7500.
So, if we were to try to learn a nonlinear hypothesis by including all the quadratic features, that is all the terms of the form, you know, Xi times Xj, while with the 2500 pixels we would end up with a total of three million features.
And that's just too large to be reasonable; the computation would be very expensive to find and to represent all of these three million features per training example.
So, simple logistic regression together with adding in maybe the quadratic or the cubic features - that's just not a good way to learn complex nonlinear hypotheses when n is large because you just end up with too many features.
Neural Networks are a pretty old algorithm that was originally motivated by the goal of having machines that can mimic the brain.
Now in this class, of course I'm teaching Neural Networks to you because they work really well for different machine learning problems and not, certainly not because they're logically motivated.
In this video, I'd like to give you some of the background on Neural Networks.
Both in the sense of applying them to modern day machinery problems, as well as for those of you that might be interested in maybe the big AI dream of someday building truly intelligent machines.
Also, how Neural Networks might pertain to that.
The origins of Neural Networks was as algorithms that try to mimic the brain and those a sense that if we want to build learning systems while why not mimic perhaps the most amazing learning machine we know about, which is perhaps the brain.
Neural Networks came to be very widely used throughout the 1980's and 1990's and for various reasons as popularity diminished in the late 90's.
But more recently, Neural Networks have had a major recent resurgence.
So, when you think about mimicking the brain while one of the human brain does tell me same things, right?
The brain can learn to see process images than to hear, learn to process our sense of touch.
We can, you know, learn to do math, learn to do calculus, and the brain does so many different and amazing things.
This is just a hypothesis but let me share with you some of the evidence for this.
This part of the brain, that little red part of the brain, is your auditory cortex and the way you're understanding my voice now is your ear is taking the sound signal and routing the sound signal to your auditory cortex and that's what's allowing you to understand my words.
Neuroscientists have done the following fascinating experiments where you cut the wire from the ears to the auditory cortex and you re-wire, in this case an animal's brain, so that the signal from the eyes to the optic nerve eventually gets routed to the auditory cortex.
If you do this it turns out, the auditory cortex will learn to see.
So, if you do this to the animals, the animals can perform visual discrimination task and as they can look at images and make appropriate decisions based on the images and they're doing it with that piece of brain tissue.
Here's another example.
That red piece of brain tissue is your somatosensory cortex.
There's this sense that if the same piece of physical brain tissue can process sight or sound or touch then maybe there is one learning algorithm that can process sight or sound or touch.
And instead of needing to implement a thousand different programs or a thousand different algorithms to do, you know, the thousand wonderful things that the brain does, maybe what we need to do is figure out some approximation or to whatever the brain's learning algorithm is and implement that and that the brain learned by itself how to process these different types of data.
To a surprisingly large extent, it seems as if we can plug in almost any sensor to almost any part of the brain and so, within the reason, the brain will learn to deal with it.
Here are a few more examples.
On the upper left is an example of learning to see with your tongue.
Here's a second example of human echo location or human sonar.
You can either snap your fingers, or click your tongue.
But there are blind people today that are actually being trained in schools to do this and learn to interpret the pattern of sounds bouncing off your environment - that's sonar.
So, if after you search on YouTube, there are actually videos of this amazing kid who tragically because of cancer had his eyeballs removed, so this is a kid with no eyeballs.
He can shoot a basketball into a hoop and this is a kid with no eyeballs.
Third example is the Haptic Belt where if you have a strap around your waist, ring up buzzers and always have the northmost one buzzing.
And, some of the bizarre example, but if you plug a third eye into a frog, the frog will learn to use that eye as well.
So, it's pretty amazing to what extent is as if you can plug in almost any sensor to the brain and the brain's learning algorithm will just figure out how to learn from that data and deal with that data.
And there's a sense that if we can figure out what the brain's learning algorithm is, and, you know, implement it or implement some approximation to that algorithm on a computer, maybe that would be our best shot at, you know, making real progress towards the AI, the artificial intelligence dream of someday building truly intelligent machines.
Now, of course, I'm not teaching Neural Networks, you know, just because they might give us a window into this far-off AI dream, even though I'm personally, that's one of the things that I personally work on in my research life.
But the main reason I'm teaching Neural Networks in this class is because it's actually a very effective state of the art technique for modern day machine learning applications.
So, in the next few videos, we'll start diving into the technical details of Neural Networks so that you can apply them to modern-day machine learning applications and get them to work well on problems.
But for me, you know, one of the reasons the excite me is that maybe they give us this window into what we might do if we're also thinking of what algorithms might someday be able to learn in a manner similar to humankind.
In this video, I want to start telling you about how we represent neural networks.
In other words, how we represent our hypothesis or how we represent our model when using neural networks.
Neural networks were developed as simulating neurons or networks of neurons in the brain.
So, to explain the hypothesis representation let's start by looking at what a single neuron in the brain looks like.
Your brain and mine is jam packed full of neurons like these and neurons are cells in the brain.
The neuron has a cell body, like so, and moreover, the neuron has a number of input wires, and these are called the dendrites.
You think of them as input wires, and these receive inputs from other locations.
So, at a simplistic level what a neuron is, is a computational unit that gets a number of inputs through it input wires and does some computation and then it says outputs via its axon to other nodes or to other neurons in the brain.
Here's a illustration of a group of neurons.
The way that neurons communicate with each other is with little pulses of electricity, they are also called spikes but that just means pulses of electricity.
So here is one neuron and what it does is if it wants a send a message what it does is sends a little pulse of electricity.
Varis axon to some different neuron and here, this axon that is this open wire, connects to the dendrites of this second neuron over here, which then accepts this incoming message that some computation.
And they, in turn, decide to send out this message on this axon to other neurons, and this is the process by which all human thought happens.
It's these Neurons doing computations and passing messages to other neurons as a result of what other inputs they've got.
And, by the way, this is how our senses and our muscles work as well.
If you want to move one of your muscles the way that where else in your neuron may send this electricity to your muscle and that causes your muscles to contract and your eyes, some senses like your eye must send a message to your brain while it does it senses hosts electricity entity to a neuron in your brain like so.
In a neuro network, or rather, in an artificial neuron network that we've implemented on the computer, we're going to use a very simple model of what a neuron does we're going to model a neuron as just a logistic unit.
And output some value on this output wire, or in the biological neuron, this is an axon.
And whenever I draw a diagram like this, what this means is that this represents a computation of h of x equals one over one plus e to the negative theta transpose x, where as usual, x and theta are our parameter vectors, like so.
So this is a very simple, maybe a vastly oversimplified model, of the computations that the neuron does, where it gets a number of inputs, x1, x2, x3 and it outputs some value computed like so.
When I draw a neural network, usually I draw only the input nodes x1, x2, x3.
Finally, one last bit of terminology when we talk about neural networks, sometimes we'll say that this is a neuron or an artificial neuron with a Sigmoid or logistic activation function.
This is just another term for that function for that non-linearity g(z) = 1 over 1+e to the -z.
Here, it's a copy to the parameters, but in neural networks, in the neural network literature sometimes you might hear people talk about weights of a model and weights just means exactly the same thing as parameters of a model.
But I'll mostly continue to use the terminology parameters in these videos, but sometimes, you might hear others use the weights terminology.
So, this little diagram represents a single neuron.
Completely, here we have input units x1, x2, x3 and once again, sometimes you can draw this extra note x0 and Sometimes not, just flow that in here.
And once again we can if we want add in just a0 and add the mixture bias unit there.
And then finally we have this third node and the final layer, and there's this third node that outputs the value that the hypothesis h(x) computes.
The final layer is also called the output layer because that layer has a neuron, this one over here, that outputs the final value computed by a hypothesis.
And then, layer 2 in between, this is called the hidden layer.
The term hidden layer isn't a great terminology, but this ideation is that, you know, you supervised early, where you get to see the inputs and get to see the correct outputs, where there's a hidden layer of values you don't get to observe in the training setup.
It's not x, and it's not y, and so we call those hidden.
But basically, anything that isn't an input layer and isn't an output layer is called a hidden layer.
So I want to be really clear about what this neural network is doing.
Let's step through the computational steps that are and body represented by this diagram.
To explain these specific computations represented by a neural network, here's a little bit more notation.
I'm going to use a superscript j subscript i to denote the activation of neuron i or of unit i in layer j.
So completely this gave superscript to sub group one, that's the activation of the first unit in layer two, in our hidden layer.
And by activation I just mean the value that's computed by and as output by a specific.
In addition, new network is parametrize by these matrixes, theta super script j Where theta j is going to be a matrix of weights controlling the function mapping form one layer, maybe the first layer to the second layer, or from the second layer to the third layer.
So here are the computations that are represented by this diagram.
This first hidden unit here has it's value computed as follows, there's a is a21 is equal to the sigma function of the sigma activation function, also called the logistics activation function, apply to this sort of linear combination of these inputs.
And then this second hidden unit has this activation value computer as sigmoid of this.
And similarly for this third hidden unit is computed by that formula.
So here we have 3 theta 1 which is matrix of parameters governing our mapping from our three different units, our hidden units.
And more generally, if a network has SJU units in there j and sj + 1 units and sj + 1 then the matrix theta j which governs the function mapping from there sj + 1.
Finally, there's a loss of this final and after that we have one more unit which computer h of x and that's equal can also be written as a(3)1 and that's equal to this.
And you notice that I've written this with a superscript two here, because theta of superscript two is the matrix of parameters, or the matrix of weights that controls the function that maps from the hidden units, that is the layer two units to the one layer three unit, that is the output unit.
To summarize, what we've done is shown how a picture like this over here defines an artificial neural network which defines a function h that maps with x's input values to hopefully to some space that provisions y.
And these hypothesis are parameterized by parameters denoting with a capital theta so that, as we vary theta, we get different hypothesis and we get different functions.
So this gives us a mathematical definition of how to represent the hypothesis in the neural network.
In the next few videos what I would like to do is give you more intuition about what these hypothesis representations do, as well as go through a few examples and talk about how to compute them efficiently.
In this and the next video I want to work through a detailed example showing how a neural network can compute a complex non linear function of the input.
So, either 0 or 1.
So, X1 and X2 can each take on only one of two possible values.
That you can think of this as a simplified version of a more complex learning problem where we may have a bunch of positive examples in the upper right and lower left and a bunch of negative examples denoted by the circles.
So, how can a neural network do this and rather than using the example and the variable to use this maybe easier to examine example on the left.
It turns out that these specific examples in the works out a little bit better if we use the XNOR example instead.
These two are the same of course.
In order to build up to a network that fits the XNOR example we're going to start with a slightly simpler one and show a network that fits the AND function.
This is a logical AND.
So, can we get a one-unit network to compute this logical AND function?
In order to do so, I'm going to actually draw in the bias unit as well the plus one unit.
Now let me just assign some values to the weights or parameters of this network.
And what this mean is just that I'm assigning a value of -30 to the value associated with X0 this +1 going into this unit and a parameter value of +20 that multiplies to X1 a value of +20 for the parameter that multiplies into x 2.
So, concretely it's the same that the hypothesis h(x)=g(-30+20 X1 plus 20 X2.
Draw these parameters up here in the diagram within and of course this- 30.
This is theta 1 of 1 1 and that's theta 1 of 1 2 but it's just easier to think about it as associating these parameters with the edges of the network.
Let's look at what this little single neuron network will compute.
It starts from 0 rises smoothly crosses 0.5 and then it asymptotic as 1 and to give you some landmarks, if the horizontal axis value z is equal to 4.6 then the sigmoid function is equal to 0.99.
This is very close to 1 and kind of symmetrically, if it's -4.6 then the sigmoid function there is 0.01 which is very close to 0.
Let's look at the four possible input values for x1 and x2 and look at what the hypotheses will output in that case.
If you look at this, if x1 x2 are both equal to 0 then the hypothesis of g of -30.
So, this is a very far to the left of this diagram so it will be very close to 0.
So, that's g of positive 10 which is there for very close to 1.
And if you look in this column this is exactly the logical and function.
In other words it outputs one If and only if x2, x1 and x2, are both equal to 1.
So, by writing out our little truth table like this we manage to figure what's the logical function that our neural network computes.
This network showed here computes the OR function.
If you are write out the hypothesis that this confusing g of -10 + 20 x 1 + 20 x 2 and so you fill in these values.
You find that's g of minus 10 which is approximately 0.
g of 10 which is approximately 1 and so on and these are approximately 1 and approximately 1 and these numbers are essentially the logical OR function.
So, hopefully with this you now understand how single neurons in a neural network can be used to compute logical functions like AND and OR and so on.
In the next video we'll continue building on these examples and work through a more complex example.
We'll get to show you how a neural network now with multiple layers of units can be used to compute more complex functions like the XOR function or the XNOR function.
In this video I'd like to keep working through our example to show how a Neural Network can compute complex non linear hypothesis.
In the last video we saw how a Neural Network can be used to compute the functions x1 AND x2, and the function x1 OR x2 when x1 and x2 are binary, that is when they take on values 0,1.
We can also have a network to compute negation, that is to compute the function not x1.
Let me just write down the ways associated with this network.
We have only one input feature x1 in this case and the bias unit +1.
And if I associate this with the weights plus 10 and -20, then my hypothesis is computing this h(x) equals sigmoid (10- 20 x1).
And so that's approximately 1, and when x is equal to 1, this will be g(-10) which is approximately equal to 0.
And if you look at what these values are, that's essentially the not x1 function.
Cells include negations, the general idea is to put that large negative weight in front of the variable you want to negate.
Minus 20 multiplied by x1 and that's the general idea of how you end up negating x1.
If you want to compute a function like this NOT x1 AND NOT x2, part of that will probably be putting large negative weights in front of x1 and x2, but it should be feasible.
All right, so this logical function, NOT x1 AND NOT x2, is going to be equal to 1 if and only if x1 equals x2 equals 0.
All right since this is a logical function, this says NOT x1 means x1 must be 0 and NOT x2, that means x2 must be equal to 0 as well.
Now, taking the three pieces that we have put together as the network for computing x1 AND x2, and the network computing for computing NOT x1 AND NOT x2.
And one last network computing for computing x1 OR x2, we should be able to put these three pieces together to compute this x1 XNOR x2 function.
And just to remind you if this is x1, x2, this function that we want to compute would have negative examples here and here, and we'd have positive examples there and there.
And so clearly this will need a non linear decision boundary in order to separate the positive and negative examples.
Let's draw the network.
And I'm gonna copy the weight over from the red network, the x1 and x2.
As well so then -30, 20, 20.
Next let me create a second hidden unit which I'm going to call a 2 2.
That is the second hidden unit of layer two.
And so, let's pull some of the truth table values.
For the red network, we know that was computing the x1 and x2, and so this will be approximately 0 0 0 1, depending on the values of x1 and x2, and for a 2 2, the cyan network.
The function NOT x1 AND NOT x2, that outputs 1 0 0 0, for the 4 values of x1 and x2.
This is one more output h(x) and I'm going to copy over the old network for that.
So that's -10, 20, 20 and we know earlier that this computes the OR function.
So let's fill in the truth table entries.
And thus h(x) is equal to 1 when either both x1 and x2 are zero or when x1 and x2 are both 1 and concretely h(x) outputs 1 exactly at these two locations and then outputs 0 otherwise.
And the more general intuition is that in the input layer, we just have our four inputs.
Then we have a hidden layer, which computed some slightly more complex functions of the inputs that its shown here this is slightly more complex functions.
And then by adding yet another layer we end up with an even more complex non linear function.
And this is a sort of intuition about why neural networks can compute pretty complicated functions.
That when you have multiple layers you have relatively simple function of the inputs of the second layer.
But the third layer I can build on that to complete even more complex functions, and then the layer after that can compute even more complex functions.
To wrap up this video, I want to show you a fun example of an application of a the Neural Network that captures this intuition of the deeper layers computing more complex features.
I want to show you a video of that customer a good friend of mine Yann LeCunj.
Yann is a professor at New York University, NYU and he was one of the early pioneers of Neural Network reasearch and is sort of a legend in the field now and his ideas are used in all sorts of products and applications throughout the world now.
So I wanna show you a video from some of his early work in which he was using a neural network to recognize handwriting, to do handwritten digit recognition.
You might remember early in this class, at the start of this class I said that one of the earliest successes of neural networks was trying to use it to read zip codes to help USPS Laws and read postal codes.
So this is one of the attempts, this is one of the algorithms used to try to address that problem.
In the video that I'll show you this area here is the input area that shows a canvasing character shown to the network.
So that the first hidden layer of the network and so the first hidden layer, this visualization shows different features.
Different edges and lines and so on detected.
This is a visualization of the next hidden layer.
You probably have a hard time seeing what's going on much beyond the first hidden layer, but then finally, all of these learned features get fed to the upper layer.
And shown over here is the final answer, it's the final predictive value for what handwritten digit the neural network thinks it is being shown.
So let's take a look at the video.
So I hope you enjoyed the video and that this hopefully gave you some intuition about the source of pretty complicated functions neural networks can learn.
The way we do multiclass classification in a neural network is essentially an extension of the one versus all method.
So, the output now is actually needing to be a vector of four numbers and what we're going to try to do is get the first output unit to classify: is the image a pedestrian, yes or no.
The second unit to classify: is the image a car, yes or no.
This unit to classify: is the image a motorcycle, yes or no, and this would classify: is the image a truck, yes or no.
And thus, when the image is of a pedestrian, we would ideally want the network to output 1, 0, 0, 0, when it is a car we want it to output 0, 1, 0, 0, when this is a motorcycle, we get it to or rather, we want it to output 0, 0, 1, 0 and so on.
So this is just like the "one versus all" method that we talked about when we were describing logistic regression, and here we have essentially four logistic regression classifiers, each of which is trying to recognize one of the four classes that we want to distinguish amongst.
So, rearranging the slide of it, here's our neural network with four output units and those are what we want h of x to be when we have the different images, and the way we're going to represent the training set in these settings is as follows.
Instead of representing y this way, we're going to instead represent y as follows: namely Yi will be either 1, 0, 0, 0 or 0, 1, 0, 0 or 0, 0, 1, 0 or 0, 0, 0, 1 depending on what the corresponding image Xi is.
And so one training example will be one pair Xi colon Yi where Xi is an image with, you know one of the four objects and Yi will be one of these vectors.
And hopefully, we can find a way to get our Neural Networks to output some value.
So, the h of x is approximately y and both h of x and Yi, both of these are going to be in our example, four dimensional vectors when we have four classes.
So, that's how you get neural network to do multiclass classification.
This wraps up our discussion on how to represent Neural Networks that is on our hypotheses representation.
In the next set of videos, let's start to talk about how take a training set and how to automatically learn the parameters of the neural network.
Neural networks are one of the most powerful learning algorithms that we have today.
In this and in the next few videos, I'd like to start talking about a learning algorithm for fitting the parameters of a neural network given a training set.
As with the discussion of most of our learning algorithms, we're going to begin by talking about the cost function for fitting the parameters of the network.
I'm going to focus on the application of neural networks to classification problems.
I'm going to use upper case L to denote the total number of layers in this network.
So for the network shown on the left we would have capital L equals 4.
I'm going to use S subscript L to denote the number of units, that is the number of neurons.
Not counting the bias unit in their L of the network.
And the output layer S four, which is also equal to S L because capital L is equal to four.
The output layer in my example under that has four units.
We're going to consider two types of classification problems.
The first is Binary classification, where the labels y are either 0 or 1.
And the output of the neural network would be h(x) is going to be a real number.
And in this case the number of output units, S L, where L is again the index of the final layer.
Cuz that's the number of layers we have in the network so the number of units we have in the output layer is going to be equal to 1.
So our early example had this representation for y if we have 4 classes, and in this case we will have capital K output units and our hypothesis or output vectors that are K dimensional.
And the number of output units will be equal to K.
And usually we would have K greater than or equal to 3 in this case, because if we had two causes, then we don't need to use the one verses all method.
We use the one verses all method only if we have K greater than or equals V classes, so having only two classes we will need to use only one upper unit.
Now let's define the cost function for our neural network.
The cost function we use for the neural network is going to be a generalization of the one that we use for logistic regression.
For a neural network, our cost function is going to be a generalization of this.
Where instead of having basically just one, which is the compression output unit, we may instead have K of them.
That is, h(x) is a k-dimensional vector and so this subscript i just selects out the ith element of the vector that is output by my neural network.
My cost function J(theta) is now going to be the following.
Is - 1 over M of a sum of a similar term to what we have for logistic regression, except that we have the sum from K equals 1 through K.
This summation is basically a sum over my K output.
So if I have four output units, that is if the final layer of my neural network has four output units, then this is a sum from k equals one through four of basically the logistic regression algorithm's cost function but summing that cost function over each of my four output units in turn.
This summation term looks really complicated, but all it's doing is it's summing over these terms theta j i l for all values of i j and l.
Except that we don't sum over the terms corresponding to these bias values like we have for logistic progression.
Completely, we don't sum over the terms responding to where i is equal to 0.
So that is because when we're computing the activation of a neuron, we have terms like these.
And so the values with a zero there, that corresponds to something that multiplies into an x0 or an a0.
But this is just one possible convention, and even if you were to sum over i equals 0 up to Sl, it would work about the same and doesn't make a big difference.
But maybe this convention of not regularizing the bias term is just slightly more common.
So that's the cost function we're going to use for our neural network.
In the next video we'll start to talk about an algorithm for trying to optimize the cost function.
In the previous video, we talked about a cost function for the neural network.
In this video, let's start to talk about an algorithm, for trying to minimize the cost function.
In particular, we'll talk about the back propagation algorithm.
Here's the cost function that we wrote down in the previous video.
What we'd like to do is try to find parameters theta to try to minimize j of theta.
Remember, that the parameters in the the neural network of these things, theta superscript l subscript ij, that's the real number and so, these are the partial derivative terms we need to compute.
In order to compute the cost function j of theta, we just use this formula up here and so, what I want to do for the most of this video is focus on talking about how we can compute these partial derivative terms.
Write a one training example as xy and let's tap through the sequence of calculations we would do with this one training example.
The first thing we do is we apply forward propagation in order to compute whether a hypotheses actually outputs given the input.
Concretely, the called the a(1) is the activation values of this first layer that was the input there.
So, I'm going to set that to x and then we're going to compute z(2) equals theta(1) a(1) and a(2) equals g, the sigmoid activation function applied to z(2) and this would give us our activations for the first middle layer.
That is for layer two of the network and we also add those bias terms.
Next we apply 2 more steps of this four and propagation to compute a(3) and a(4) which is also the upwards of a hypotheses h of x.
Next, in order to compute the derivatives, we're going to use an algorithm called back propagation.
The intuition of the back propagation algorithm is that for each note we're going to compute the term delta superscript l subscript j that's going to somehow represent the error of note j in the layer l.
So, how we might wish the activation of that note is slightly different.
Concretely, taking the example neural network that we have on the right which has four layers.
And so capital L is equal to 4.
For each output unit, we're going to compute this delta term.
So, delta for the j of unit in the fourth layer is equal to just the activation of that unit minus what was the actual value of 0 in our training example.
So, this term here can also be written h of x subscript j, right.
So this delta term is just the difference between when a hypotheses output and what was the value of y in our training set whereas y subscript j is the j of element of the vector value y in our labeled training set.
And by the way, if you think of delta a and y as vectors then you can also take those and come up with a vectorized implementation of it, which is just delta 4 gets set as a4 minus y.
Where here, each of these delta 4 a4 and y, each of these is a vector whose dimension is equal to the number of output units in our network.
So we've now computed the era term's delta 4 for our network.
What we do next is compute the delta terms for the earlier layers in our network.
And this dot times, this is the element y's multiplication operation that we know from MATLAB.
This term g prime of z3, that formally is actually the derivative of the activation function g evaluated at the input values given by z3.
If you know calculus, you can try to work it out yourself and see that you can simplify it to the same answer that I get.
What you do to compute this g prime, these derivative terms is just a3 dot times1 minus A3 where A3 is the vector of activations.
1 is the vector of ones and A3 is again the activation the vector of activation values for that layer.
Next you apply a similar formula to compute delta 2 where again that can be computed using a similar formula.
And finally, that's it and there is no delta1 term, because the first layer corresponds to the input layer and that's just the feature we observed in our training sets, so that doesn't have any error associated with that.
It's not like, you know, we don't really want to try to change those values.
The name back propagation comes from the fact that we start by computing the delta term for the output layer and then we go back a layer and compute the delta terms for the third hidden layer and then we go back another step to compute delta 2 and so, we're sort of back propagating the errors from the output layer to layer 3 to their to hence the name back complication.
Finally, the derivation is surprisingly complicated, surprisingly involved but if you just do this few steps steps of computation it is possible to prove viral frankly some what complicated mathematical proof.
It's possible to prove that if you ignore authorization then the partial derivative terms you want are exactly given by the activations and these delta terms.
We'll fix this detail later about the regularization term, but so by performing back propagation and computing these delta terms, you can, you know, pretty quickly compute these partial derivative terms for all of your parameters.
Let's take everything and put it all together to talk about how to implement back propagation to compute derivatives with respect to your parameters.
And for the case of when we have a large training set, not just a training set of one example, here's what we do.
The symbol we had on the previous slide was the lower case delta.
So the triangle is capital delta.
So as we'll see in a second, these deltas are going to be used as accumulators that will slowly add things in order to compute these partial derivatives.
So, we'll say for i equals 1 through m and so for the i iteration, we're going to working with the training example xi, yi.
Next, we're going to use the output label yi from this specific example we're looking at to compute the error term for delta L for the output there.
And by the way, if you look at this expression, it's possible to vectorize this too.
Concretely, if you think of delta ij as a matrix, indexed by subscript ij.
Then, if delta L is a matrix we can rewrite this as delta L, gets updated as delta L plus lower case delta L plus one times aL transpose.
So that's a vectorized implementation of this that automatically does an update for all values of i and j.
Finally, after executing the body of the four-loop we then go outside the four-loop and we compute the following.
We compute capital D as follows and we have two separate cases for j equals zero and j not equals zero.
The case of j equals zero corresponds to the bias term so when j equals zero that's why we're missing is an extra regularization term.
Finally, while the formal proof is pretty complicated what you can show is that once you've computed these D terms, that is exactly the partial derivative of the cost function with respect to each of your perimeters and so you can use those in either gradient descent or in one of the advanced authorization algorithms.
So that's the back propagation algorithm and how you compute derivatives of your cost function for a neural network.
I know this looks like this was a lot of details and this was a lot of steps strung together.
To a lot of people seeing it for the first time, their first impression is often that wow this is a really complicated algorithm, and there are all these different steps, and I'm not sure how they fit together.
In case that's how you're feeling about backpropagation, that's actually okay.
Backpropagation maybe unfortunately is a less mathematically clean, or less mathematically simple algorithm, compared to linear regression or logistic regression.
And even today I still don't sometimes feel like I have a very good sense of just what it's doing, or intuition about what back propagation is doing.
If, for those of you that are doing the programming exercises, that will at least mechanically step you through the different steps of how to implement back prop.
So you'll be able to get it to work for yourself.
In case even after this video in case back propagation still seems very black box and kind of like a, too many complicated steps and a little bit magical to you, that's actually okay.
And Even though I've used back prop for many years, sometimes this is a difficult algorithm to understand, but hopefully this video will help a little bit.
In order to better understand backpropagation, let's take another closer look at what forward propagation is doing.
Here's a neural network with two input units that is not counting the bias unit, and two hidden units in this layer, and two hidden units in the next layer.
And then, finally, one output unit.
Again, these counts two, two, two, are not counting these bias units on top.
In order to illustrate forward propagation, I'm going to draw this network a little bit differently.
And when we forward propagated to the first hidden layer here, what we do is compute z (2) 1 and z (2) 2.
And then we apply the sigmoid of the logistic function, and the sigmoid activation function applied to the z value.
So that gives us a (2) 1 and a (2) 2.
Apply the sigmoid of the logistic function, the activation function to that to get a (3) 1.
This gives us a (4)1, which is the final output value of the neural network.
Shown in magenta there is my weight theta (2) 1 0, the indexing is not important.
And this way here, which I'm highlighting in red, that is theta (2) 1 1 and this weight here, which I'm drawing in cyan, is theta (2) 1 2.
And then plus this red weight times this value, so that's theta(2) 11 times a(2)1.
And finally this cyan weight times this value, which is therefore plus theta(2)12 times a(2)1.
And it turns out that as we'll see later in this video, what backpropagation is doing is doing a process very similar to this.
Except that instead of the computations flowing from the left to the right of this network, the computations since their flow from the right to the left of the network.
And using a very similar computation as this.
To better understand what backpropagation is doing, let's look at the cost function.
It's just the cost function that we had for when we have only one output unit.
If we have more than one output unit, we just have a summation you know over the output units indexed by k there.
If you have only one output unit then this is a cost function.
And we do forward propagation and backpropagation on one example at a time.
So let's just focus on the single example, x (i) y (i) and focus on the case of having one output unit.
So y (i) here is just a real number.
Now if you look inside the summation, you find that the cost term associated with the training example, that is the cost associated with the training example x(i), y(i).
So, rather than looking at this complicated expression, if you want you can think of cost of i being approximately the square difference between what the neural network outputs, versus what is the actual value.
But for the purpose of intuition, feel free to think of the cost function as being the sort of the squared error cost function.
And so this cost(i) measures how well is the network doing on correctly predicting example i.
How close is the output to the actual observed label y(i)?
Now let's look at what backpropagation is doing.
And we can think of these as the quote error of the activation value that we got for unit j in the layer, in the lth layer.
More formally, for, and this is maybe only for those of you who are familiar with calculus.
So concretely, the cost function is a function of the label y and of the value, this h of x output value neural network.
And if we could go inside the neural network and just change those z l j values a little bit, then that will affect these values that the neural network is outputting.
And again really, this is only for those of you who are expert in Calculus.
If you're comfortable with partial derivatives, what these delta terms are is they turn out to be the partial derivative of the cost function, with respect to these intermediate terms that were confusing.
And so they're a measure of how much would we like to change the neural network's weights, in order to affect these intermediate values of the computation.
Don't worry about the rest of this, we can do without really talking about partial derivatives.
But let's look in more detail about what backpropagation is doing.
For the output layer, the first set's this delta term, delta (4) 1, as y (i) if we're doing forward propagation and back propagation on this training example i.
So this is really the error, right?
And then we're gonna propagate this further backward, and end up computing delta(2)1 and delta(2)2.
Now the backpropagation calculation is a lot like running the forward propagation algorithm, but doing it backwards.
So here's what I mean.
Let's look at how we end up with this value of delta(2)2.
And similar to forward propagation, let me label a couple of the weights.
Let's say that weight is theta(2)1 2, and this one down here when we highlight this in red.
So if we look at how delta(2)2, is computed, how it's computed with this note.
It turns out that what we're going to do, is gonna take this value and multiply it by this weight, and add it to this value multiplied by that weight.
So it's really a weighted sum of these delta values, weighted by the corresponding edge strength.
So completely, let me fill this in, this delta(2)2 is going to be equal to, Theta(2)1 2 is that magenta lay times delta(3)1.
Plus, and the thing I had in red, that's theta (2)2 times delta (3)2.
And that's how we wind up with that value of delta.
And just as another example, let's look at this value.
How do we get that value?
Then we have that delta (3) 2 is going to be equal to that green weight, theta (3) 12 times delta (4) 1.
And by the way, so far I've been writing the delta values only for the hidden units, but excluding the bias units.
Depending on how you define the backpropagation algorithm, or depending on how you implement it, you know, you may end up implementing something that computes delta values for these bias units as well.
The bias units always output the value of plus one, and they are just what they are, and there's no way for us to change the value.
I do end up computing these delta values, but we just discard them, we don't use them.
Because they don't end up being part of the calculation needed to compute a derivative.
So hopefully that gives you a little better intuition about what back propegation is doing.
In case of all of this still seems sort of magical, sort of black box, in a later video, in the putting it together video, I'll try to get a little bit more intuition about what backpropagation is doing.
But unfortunately this is a difficult algorithm to try to visualize and understand what it is really doing.
In the previous video, we talked about how to use back propagation to compute the derivatives of your cost function.
In this video, I want to quickly tell you about one implementational detail of unrolling your parameters from matrices into vectors, which we need in order to use the advanced optimization routines.
Concretely, let's say you've implemented a cost function that takes this input, you know, parameters theta and returns the cost function and returns derivatives.
Then you can pass this to an advanced authorization algorithm by fminunc and fminunc isn't the only one by the way.
But what all of them do is take those input pointedly the cost function, and some initial value of theta.
And both, and these routines assume that theta and the initial value of theta, that these are parameter vectors, maybe Rn or Rn plus 1.
But these are vectors and it also assumes that, you know, your cost function will return as a second return value this gradient which is also Rn and Rn plus 1.
So also a vector.
This worked fine when we were using logistic progression but now that we're using a neural network our parameters are no longer vectors, but instead they are these matrices where for a full neural network we would have parameter matrices theta 1, theta 2, theta 3 that we might represent in Octave as these matrices theta 1, theta 2, theta 3.
Well, in the previous video we showed how to compute these gradient matrices, which was capital D1, capital D2, capital D3, which we might represent an octave as matrices D1, D2, D3.
In this video I want to quickly tell you about the idea of how to take these matrices and unroll them into vectors.
So that they end up being in a format suitable for passing into as theta here off for getting out for a gradient there.
In this case, the dimension of your matrices theta and D are going to be given by these expressions.
For example, theta one is going to a 10 by 11 matrix and so on.
What you can do is take your theta 1, theta 2, theta 3, and write this piece of code and this will take all the elements of your three theta matrices and take all the elements of theta one, all the elements of theta 2, all the elements of theta 3, and unroll them and put all the elements into a big long vector.
Which is thetaVec and similarly the second command would take all of your D matrices and unroll them into a big long vector and call them DVec.
What you do to get back to theta one say is take thetaVec and pull out the first 110 elements.
And similarly, to get back theta 2 you pull out the next 110 elements and reshape it.
And for theta 3, you pull out the final eleven elements and run reshape to get back the theta 3.
So for this example let's set theta 1 equal to be ones of 10 by 11, so it's a matrix of all ones.
And just to make this easier seen, let's set that to be 2 times ones, 10 by 11 and let's set theta 3 equals 3 times 1's of 1 by 11.
So this is 3 separate matrices: theta 1, theta 2, theta 3.
We want to put all of these as a vector.
That's 231 elements.
If I display it, I find that this very long vector with all the elements of the first matrix, all the elements of the second matrix, then all the elements of the third matrix.
And if I want to get back my original matrices, I can do reshape thetaVec.
Let's pull out the first 110 elements and reshape them to a 10 by 11 matrix.
And if I then pull out the next 110 elements.
And if I go from 221 up to the last element, which is element 231, and reshape to 1 by 11, I get back theta 3.
To make this process really concrete, here's how we use the unrolling idea to implement our learning algorithm.
Let's say that you have some initial value of the parameters theta 1, theta 2, theta 3.
What we're going to do is take these and unroll them into a long vector we're gonna call initial theta to pass in to fminunc as this initial setting of the parameters theta.
The other thing we need to do is implement the cost function.
Here's my implementation of the cost function.
The cost function is going to give us input, thetaVec, which is going to be all of my parameters vectors that in the form that's been unrolled into a vector.
So I'll pull out elements from thetaVec and use reshape to get back my original parameter matrices, theta 1, theta 2, theta 3.
So that gives me a more convenient form in which to use these matrices so that I can run forward propagation and back propagation to compute my derivatives, and to compute my cost function j of theta.
But I'm gonna unroll D1, D2, D3, to get gradientVec which is now what my cost function can return.
It can return a vector of these derivatives.
So, hopefully, you now have a good sense of how to convert back and forth between the matrix representation of the parameters versus the vector representation of the parameters.
The advantage of the matrix representation is that when your parameters are stored as matrices it's more convenient when you're doing forward propagation and back propagation and it's easier when your parameters are stored as matrices to take advantage of the, sort of, vectorized implementations.
Whereas in contrast the advantage of the vector representation, when you have like thetaVec or DVec is that when you are using the advanced optimization algorithms.
Those algorithms tend to assume that you have all of your parameters unrolled into a big long vector.
And so with what we just went through, hopefully you can now quickly convert between the two as needed.
In the last few videos we talked about how to do forward propagation and back propagation in a neural network in order to compute derivatives.
But back prop as an algorithm has a lot of details and can be a little bit tricky to implement.
And one unfortunate property is that there are many ways to have subtle bugs in back prop.
So that if you run it with gradient descent or some other optimizational algorithm, it could actually look like it's working.
And your cost function, J of theta may end up decreasing on every iteration of gradient descent.
So that it looks J of theta is decreasing, but you might just wind up with a neural network that has a higher level of error than you would with a bug free implementation.
So, what can we do about this?
There's an idea called gradient checking that eliminates almost all of these problems.
So, today every time I implement back propagation or a similar gradient to a on a neural network or any other reasonably complex model, I always implement gradient checking.
And if you do this, it will help you make sure and sort of gain high confidence that your implementation of four prop and back prop or whatever is 100% correct.
And from what I've seen this pretty much eliminates all the problems associated with a sort of a buggy implementation as a back prop.
But once you implement numerical gradient checking, which is the topic of this video, you'll be able to absolute verify for yourself that the code you're writing does indeed, is indeed computing the derivative of the cross function J.
So here's the idea, consider the following example.
Suppose that I have the function J of theta and I have some value theta and for this example gonna assume that theta is just a real number.
And let's say that I want to estimate the derivative of this function at this point and so the derivative is equal to the slope of that tangent one.
Which is, the true derivative is the slope of that blue line over there.
So, you know it seems like it would be a pretty good approximation.
Mathematically, the slope of this red line is this vertical height divided by this horizontal width.
So this point on top is the J of (Theta plus Epsilon).
So my approximation is going to be that the derivative respect of theta of J of theta at this value of theta, that that's approximately J of theta plus epsilon minus J of theta minus epsilon over 2 epsilon.
Usually, I use a pretty small value for epsilon, expect epsilon to be maybe on the order of 10 to the minus 4.
There's usually a large range of different values for epsilon that work just fine.
And in fact, if you let epsilon become really small, then mathematically this term here, actually mathematically, it becomes the derivative.
It becomes exactly the slope of the function at this point.
It's just that we don't want to use epsilon that's too, too small, because then you might run into numerical problems.
So I usually use epsilon around ten to the minus four.
And by the way some of you may have seen an alternative formula for s meeting the derivative which is this formula.
This one on the right is called a one-sided difference, whereas the formula on the left, that's called a two-sided difference.
And this will give you a numerical estimate of the gradient at that point.
And in this example it seems like it's a pretty good estimate.
Now on the previous slide, we considered the case of when theta was a rolled number.
Now let's look at a more general case of when theta is a vector parameter, so let's say theta is an R n.
And it might be an unrolled version of the parameters of our neural network.
Concretely the partial derivative of a cost function with respect to the first parameter, theta one, that can be obtained by taking J and increasing theta one.
The partial derivative respect to the second parameter theta two, is again this thing except that you would take J of here you're increasing theta two by epsilon, and here you're decreasing theta two by epsilon and so on down to the derivative.
With respect of theta n would give you increase and decrease theta and by epsilon over there.
So, these equations give you a way to numerically approximate the partial derivative of J with respect to any one of your parameters theta i.
Completely, what you implement is therefore the following.
We implement the following in octave to numerically compute the derivatives.
We say, for i = 1:n, where n is the dimension of our parameter of vector theta.
And I usually do this with the unrolled version of the parameter.
So theta is just a long list of all of my parameters in my neural network, say.
And so this is basically thetaPlus is equal to theta except for thetaPlus(i) which is now incremented by epsilon.
Epsilon, so theta plus is equal to, write theta 1, theta 2 and so on.
Then theta I has epsilon added to it and then we go down to theta N.
And then finally you implement this gradApprox (i) and this would give you your approximation to the partial derivative respect of theta i of J of theta.
And the way we use this in our neural network implementation is, we would implement this four loop to compute the top partial derivative of the cost function for respect to every parameter in that network, and we can then take the gradient that we got from backprop.
All right, so backprop, backpropogation, was a relatively efficient way to compute a derivative or a partial derivative.
And what I usually do is then, take my numerically computed derivative that is this gradApprox that we just had from up here.
And if these two ways of computing the derivative give me the same answer, or give me any similar answers, up to a few decimal places, then I'm much more confident that my implementation of backprop is correct.
And when I plug these DVec vectors into gradient assent or some advanced optimization algorithm, I can then be much more confident that I'm computing the derivatives correctly, and therefore that hopefully my code will run correctly and do a good job optimizing J of theta.
Finally, I wanna put everything together and tell you how to implement this numerical gradient checking.
Here's what I usually do.
First thing I do is implement back propagation to compute DVec.
So there's a procedure we talked about in the earlier video to compute DVec which may be our unrolled version of these matrices.
So then what I do, is implement a numerical gradient checking to compute gradApprox.
So this is what I described earlier in this video and in the previous slide.
And finally and this is the important step, before you start to use your code for learning, for seriously training your network, it's important to turn off gradient checking and to no longer compute this gradApprox thing using the numerical derivative formulas that we talked about earlier in this video.
And the reason for that is the numeric code gradient checking code, the stuff we talked about in this video, that's a very computationally expensive, that's a very slow way to try to approximate the derivative.
Whereas In contrast, the back propagation algorithm that we talked about earlier, that is the thing we talked about earlier for computing.
So once you've verified that your implementation of back propagation is correct, you should turn off gradient checking and just stop using that.
So just to reiterate, you should be sure to disable your gradient checking code before running your algorithm for many iterations of gradient descent or for many iterations of the advanced optimization algorithms, in order to train your classifier.
Concretely, if you were to run the numerical gradient checking on every single iteration of gradient descent.
Because the numerical gradient checking code is much slower than the backpropagation algorithm, than the backpropagation method where, you remember, we were computing delta(4), delta(3), delta(2), and so on.
That is a much faster way to compute derivates than gradient checking.
So when you're ready, once you've verified the implementation of back propagation is correct, make sure you turn off or you disable your gradient checking code while you train your algorithm, or else you code could run very slowly.
So, that's how you take gradients numericaly, and that's how you can verify tha implementation of back propagation is correct.
Whenever I implement back propagation or similar gradient discerning algorithm for a complicated mode,l I always use gradient checking and this really helps me make sure that my code is correct.
In the previous video, we've put together almost all the pieces you need in order to implement and train in your network.
There's just one last idea I need to share with you, which is the idea of random initialization.
When you're running an algorithm of gradient descent, or also the advanced optimization algorithms, we need to pick some initial value for the parameters theta.
So for the advanced optimization algorithm, it assumes you will pass it some initial value for the parameters theta.
So what can we set the initial value of theta to?
Is it possible to set the initial value of theta to the vector of all zeros?
Consider trading the follow Neural network, and let's say we initialize all the parameters of the network to 0.
And if you do that, then what you, what that means is that at the initialization, this blue weight, colored in blue is gonna equal to that weight, so they're both 0.
And this weight that I'm coloring in in red, is equal to that weight, colored in red, and also this weight, which I'm coloring in green is going to equal to the value of that weight.
And what that means is that both of your hidden units, A1 and A2, are going to be computing the same function of your inputs.
And moreover because I'm not going to show this in too much detail, but because these outgoing weights are the same you can also show that the delta values are also gonna be the same.
You find that these two partial derivatives are going to be equal to each other.
And so what this means is that even after say one greater descent update, you're going to update, say, this first blue rate was learning rate times this, and you're gonna update the second blue rate with some learning rate times this.
And what this means is that even after one created the descent update, those two blue rates, those two blue color parameters will end up the same as each other.
So there'll be some nonzero value, but this value would equal to that value.
And similarly, even after one gradient descent update, this value would equal to that value.
There'll still be some non-zero values, just that the two red values are equal to each other.
Well, they'll both change values, but they'll both end up with the same value as each other.
So after each update, the parameters corresponding to the inputs going into each of the two hidden units are identical.
That's just saying that the two green weights are still the same, the two red weights are still the same, the two blue weights are still the same, and what that means is that even after one iteration of say, gradient descent and descent.
You find that your two headed units are still computing exactly the same functions of the inputs.
You still have the a1(2) = a2(2).
And as you keep running greater descent, the blue waves,, the two blue waves, will stay the same as each other.
And what this means is that your neural network really can compute very interesting functions, right?
Imagine that you had not only two hidden units, but imagine that you had many, many hidden units.
Then what this is saying is that all of your headed units are computing the exact same feature.
All of your hidden units are computing the exact same function of the input.
And this is a highly redundant representation because you find the logistic progression unit.
And this prevents you and your network from doing something interesting.
In order to get around this problem, the way we initialize the parameters of a neural network therefore is with random initialization.
Concretely, the problem was saw on the previous slide is something called the problem of symmetric ways, that's the ways are being the same.
So this random initialization is how we perform symmetry breaking.
So what we do is we initialize each value of theta to a random number between minus epsilon and epsilon.
So this is a notation to b numbers between minus epsilon and plus epsilon.
The way I write code to do this in octave is I've said Theta1 should be equal to this.
All the values are between 0 and 1, so these are going to be raw numbers that take on any continuous values between 0 and 1.
And so if you take a number between zero and one, multiply it by two times INIT_EPSILON then minus INIT_EPSILON, then you end up with a number that's between minus epsilon and plus epsilon.
And the so that leads us, this epsilon here has nothing to do with the epsilon that we were using when we were doing gradient checking.
So when numerical gradient checking, there we were adding some values of epsilon and theta.
We just wanted to notate init epsilon just to distinguish it from the value of epsilon we were using in gradient checking.
And similarly if you want to initialize theta2 to a random 1 by 11 matrix you can do so using this piece of code here.
So to summarize, to create a neural network what you should do is randomly initialize the waves to small values close to zero, between -epsilon and +epsilon say.
And then implement back propagation, do great in checking, and use either great in descent or 1b advanced optimization algorithms to try to minimize j(theta) as a function of the parameters theta starting from just randomly chosen initial value for the parameters.
And by doing symmetry breaking, which is this process, hopefully great gradient descent or the advanced optimization algorithms will be able to find a good value of theta.
So, it's taken us a lot of videos to get through the neural network learning algorithm.
In this video, what I'd like to do is try to put all the pieces together, to give a overall summary or a bigger picture view, of how all the pieces fit together and of the overall process of how to implement a neural network learning algorithm.
When training a neural network, the first thing you need to do is pick some network architecture and by architecture I just mean connectivity pattern between the neurons.
So, you know, we might choose between say, a neural network with three input units and five hidden units and four output units versus one of 3, 5 hidden, 5 hidden, 4 output and here are 3, 5, 5, 5 units in each of three hidden layers and four open units, and so these choices of how many hidden units in each layer and how many hidden layers, those are architecture choices.
So, how do you make these choices?
Well first, the number of input units well that's pretty well defined.
And once you decides on the fix set of features x the number of input units will just be, you know, the dimension of your features x(i) would be determined by that.
And if you are doing multiclass classifications the number of output of this will be determined by the number of classes in your classification problem.
And just a reminder if you have a multiclass classification where y takes on say values between 1 and 10, so that you have ten possible classes.
So instead of clause one, you recode it as a vector like that, or for the second class you recode it as a vector like that.
So if one of these apples takes on the fifth class, you know, y equals 5, then what you're showing to your neural network is not actually a value of y equals 5, instead here at the upper layer which would have ten output units, you will instead feed to the vector which you know with one in the fifth position and a bunch of zeros down here.
So the choice of number of input units and number of output units is maybe somewhat reasonably straightforward.
And as for the number of hidden units and the number of hidden layers, a reasonable default is to use a single hidden layer and so this type of neural network shown on the left with just one hidden layer is probably the most common.
Or if you use more than one hidden layer, again the reasonable default will be to have the same number of hidden units in every single layer.
So here we have two hidden layers and each of these hidden layers have the same number five of hidden units and here we have, you know, three hidden layers and each of them has the same number, that is five hidden units.
Rather than doing this sort of network architecture on the left would be a perfect ably reasonable default.
And as for the number of hidden units - usually, the more hidden units the better; it's just that if you have a lot of hidden units, it can become more computationally expensive, but very often, having more hidden units is a good thing.
And usually the number of hidden units in each layer will be maybe comparable to the dimension of x, comparable to the number of features, or it could be any where from same number of hidden units of input features to maybe so that three or four times of that.
Or actually have quite a lot I want to say later to make good choices for the number of hidden units, the number of hidden layers, and so on.
Next, here's what we need to implement in order to trade in neural network, there are actually six steps that I have; I have four on this slide and two more steps on the next slide.
First step is to set up the neural network and to randomly initialize the values of the weights.
And we usually initialize the weights to small values near zero.
Then we implement forward propagation so that we can input any excellent neural network and compute h of x which is this output vector of the y values.
We then also implement code to compute this cost function j of theta.
And next we implement back-prop, or the back-propagation algorithm, to compute these partial derivatives terms, partial derivatives of j of theta with respect to the parameters.
Usually we will do that with a fore loop over the training examples.
So there should be a four-loop in your implementation of back prop, at least the first time implementing it.
So concretely, we have a four-loop over my m-training examples and inside the four-loop we're going to perform fore prop and back prop using just this one example.
We're going to compute those delta terms, which are is the formula that we gave earlier.
And then finally, outside the having computed these delta terms, these accumulation terms, we would then have some other code and then that will allow us to compute these partial derivative terms.
Right and these partial derivative terms have to take into account the regularization term lambda as well.
And so, those formulas were given in the earlier video.
So, how do you done that you now hopefully have code to compute these partial derivative terms.
Next is step five, what I do is then use gradient checking to compare these partial derivative terms that were computed.
So, I've compared the versions computed using back propagation versus the partial derivatives computed using the numerical estimates as using numerical estimates of the derivatives.
So, I do gradient checking to make sure that both of these give you very similar values.
Having done gradient checking just now reassures us that our implementation of back propagation is correct, and is then very important that we disable gradient checking, because the gradient checking code is computationally very slow.
And finally, we then use an optimization algorithm such as gradient descent, or one of the advanced optimization methods such as LB of GS, contract gradient has embodied into fminunc or other optimization methods.
And so, we know how to compute the cost function, we know how to compute the partial derivatives using back propagation, so we can use one of these optimization methods to try to minimize j of theta as a function of the parameters theta.
Finally, gradient descents for a neural network might still seem a little bit magical.
So, let me just show one more figure to try to get that intuition about what gradient descent for a neural network is doing.
This was actually similar to the figure that I was using earlier to explain gradient descent.
So, we have some cost function, and we have a number of parameters in our neural network.
In reality, of course, in the neural network, we can have lots of parameters with these.
So we can have very high dimensional parameters but because of the limitations the source of parts we can draw.
Now, this cost function j of theta measures how well the neural network fits the training data.
So, if you take a point like this one, down here, that's a point where j of theta is pretty low, and so this corresponds to a setting of the parameters.
There's a setting of the parameters theta, where, you know, for most of the training examples, the output of my hypothesis, that may be pretty close to y(i) and if this is true than that's what causes my cost function to be pretty low.
Whereas in contrast, if you were to take a value like that, a point like that corresponds to, where for many training examples, the output of my neural network is far from the actual value y(i) that was observed in the training set.
So points like this on the line correspond to where the hypothesis, where the neural network is outputting values on the training set that are far from y(i).
So what gradient descent does is we'll start from some random initial point like that one over there, and it will repeatedly go downhill.
And so what back propagation is doing is computing the direction of the gradient, and what gradient descent is doing is it's taking little steps downhill until hopefully it gets to, in this case, a pretty good local optimum.
So, when you implement back propagation and use gradient descent or one of the advanced optimization methods, this picture sort of explains what the algorithm is doing.
It's trying to find a value of the parameters where the output values in the neural network closely matches the values of the y(i)'s observed in your training set.
So, hopefully this gives you a better sense of how the many different pieces of neural network learning fit together.
In case even after this video, in case you still feel like there are, like, a lot of different pieces and it's not entirely clear what some of them do or how all of these pieces come together, that's actually okay.
Neural network learning and back propagation is a complicated algorithm.
And even though I've seen the math behind back propagation for many years and I've used back propagation, I think very successfully, for many years, even today I still feel like I don't always have a great grasp of exactly what back propagation is doing sometimes.
And what the optimization process looks like of minimizing j if theta.
Much this is a much harder algorithm to feel like I have a much less good handle on exactly what this is doing compared to say, linear regression or logistic regression.
Which were mathematically and conceptually much simpler and much cleaner algorithms.
In this video, I'd like to show you a fun and historically important example of neural networks learning of using a neural network for autonomous driving.
That is getting a car to learn to drive itself.
And I want to tell what a visualization looks like before starting the video.
And so here you kinda see a road that's maybe going a bit to the left, and then going a little bit to the right.
And up here on top, this first horizontal bar shows the direction selected by the human driver.
And this location of this bright white band that shows the steering direction selected by the human driver where you know here far to the left corresponds to steering hard left, here corresponds to steering hard to the right.
And so this location which is a little bit to the left, a little bit left of center means that the human driver at this point was steering slightly to the left.
And this second bot here corresponds to the steering direction selected by the learning algorithm and again the location of this sort of white band means that the neural network was here selecting a steering direction that's slightly to the left.
And in fact before the neural network starts leaning initially, you see that the network outputs a grey band, like a grey, like a uniform grey band throughout this region and sort of a uniform gray fuzz corresponds to the neural network having been randomly initialized.
Or initially having no idea of what direction to steer in.
And is only after it has learned for a while, that will then start to output like a solid white band in just a small part of the region corresponding to choosing a particular steering direction.
And that corresponds to when the neural network becomes more confident in selecting a band in one particular location, rather than outputting a sort of light gray fuzz, but instead outputting a white band that's more constantly selecting one's steering direction.
>> ALVINN is a system of artificial neural networks that learns to steer by watching a person drive.
ALVINN is designed to control the NAVLAB 2, a modified Army Humvee who had put sensors, computers, and actuators for autonomous navigation experiments.
Once every two seconds, ALVINN digitizes a video image of the road ahead, and records the person's steering direction.
This training image is reduced in resolution to 30 by 32 pixels and provided as input to ALVINN's three layered network.
Using the back propagation learning algorithm,ALVINN is training to output the same steering direction as the human driver for that image.
Initially the network steering response is random.
After about two minutes of training the network learns to accurately imitate the steering reactions of the human driver.
This same training procedure is repeated for other road types.
After the networks have been trained the operator pushes the run switch and ALVINN begins driving.
Twelve times per second, ALVINN digitizes the image and feeds it to its neural networks.
Each network, running in parallel, produces a steering direction, and a measure of its' confidence in its' response.
The steering direction, from the most confident network, in this network training for the one lane road, is used to control the vehicle.
Suddenly an intersection appears ahead of the vehicle.
As the vehicle approaches the intersection the confidence of the lone lane network decreases.
As it crosses the intersection and the two lane road ahead comes into view, the confidence of the two lane network rises.
When its' confidence rises the two lane network is selected to steer.
Of course there are more recently more modern attempts to do autonomous driving.
There are few projects in the US and Europe and so on, that are giving more robust driving controllers than this, but I think it's still pretty remarkable and pretty amazing how instant neural network trained with backpropagation can actually learn to drive a car somewhat well.
By now you have seen a lot of different learning algorithms.
And if you've been following along these videos you should consider yourself an expert on many state-of-the-art machine learning techniques.
There's often a huge difference between someone that really knows how to powerfully and effectively apply that algorithm, versus someone that's less familiar with some of the material that I'm about to teach and who doesn't really understand how to apply these algorithms and can end up wasting a lot of their time trying things out that don't really make sense.
What I would like to do is make sure that if you are developing machine learning systems, that you know how to choose one of the most promising avenues to spend your time pursuing.
And on this and the next few videos I'm going to give a number of practical suggestions, advice, guidelines on how to do that.
And concretely what we'd focus on is the problem of, suppose you are developing a machine learning system or trying to improve the performance of a machine learning system, how do you go about deciding what are the proxy avenues to try next?
To explain this, let's continue using our example of learning to predict housing prices.
Thus minimizing that cost function j.
The question is what should you then try mixing in order to improve the learning algorithm?
There are many things that one can think of that could improve the performance of the learning algorithm.
One thing they could try, is to get more training examples.
And concretely, you can imagine, maybe, you know, setting up phone surveys, going door to door, to try to get more data on how much different houses sell for.
But sometimes getting more training data doesn't actually help and in the next few videos we will see why, and we will see how you can avoid spending a lot of time collecting more training data in settings where it is just not going to help.
So if you have some set of features such as x1, x2, x3 and so on, maybe a large number of features.
Maybe you want to spend time carefully selecting some small subset of them to prevent overfitting.
Maybe the current set of features aren't informative enough and you want to collect more data in the sense of getting more features.
And once again this is the sort of project that can scale up the huge projects can you imagine getting phone surveys to find out more houses, or extra land surveys to find out more about the pieces of land and so on, so a huge project.
And once again it would be nice to know in advance if this is going to help before we spend a lot of time doing something like this.
We can still spend quite a lot of time thinking about that and we can also try other things like decreasing lambda, the regularization parameter or increasing lambda.
Given a menu of options like these, some of which can easily scale up to six month or longer projects.
Unfortunately, the most common method that people use to pick one of these is to go by gut feeling.
Fortunately, there is a pretty simple technique that can let you very quickly rule out half of the things on this list as being potentially promising things to pursue.
And there is a very simple technique, that if you run, can easily rule out many of these options, and potentially save you a lot of time pursuing something that's just is not going to work.
In the next two videos after this, I'm going to first talk about how to evaluate learning algorithms.
And in the next few videos after that, I'm going to talk about these techniques, which are called the machine learning diagnostics.
But I should mention in advance that diagnostics can take time to implement and can sometimes, you know, take quite a lot of time to implement and understand but doing so can be a very good use of your time when you are developing learning algorithms because they can often save you from spending many months pursuing an avenue that you could have found out much earlier just was not going to be fruitful.
So in the next few videos, I'm going to first talk about how evaluate your learning algorithms and after that I'm going to talk about some of these diagnostics which will hopefully let you much more effectively select more of the useful things to try mixing if your goal to improve the machine learning system.
In this video, I would like to talk about how to evaluate a hypothesis that has been learned by your algorithm.
In later videos, we will build on this to talk about how to prevent in the problems of overfitting and underfitting as well.
When we fit the parameters of our learning algorithm we think about choosing the parameters to minimize the training error.
One might think that getting a really low value of training error might be a good thing, but we have already seen that just because a hypothesis has low training error, that doesn't mean it is necessarily a good hypothesis.
And we've already seen the example of how a hypothesis can overfit.
And therefore fail to generalize the new examples not in the training set.
So how do you tell if the hypothesis might be overfitting.
In this simple example we could plot the hypothesis h of x and just see what was going on.
But in general for problems with more features than just one feature, for problems with a large number of features like these it becomes hard or may be impossible to plot what the hypothesis looks like and so we need some other way to evaluate our hypothesis.
Here I have just shown 10 training examples, but of course usually we may have dozens or hundreds or maybe thousands of training examples.
In order to make sure we can evaluate our hypothesis, what we are going to do is split the data we have into two portions.
The first portion is going to be our usual training set and the second portion is going to be our test set, and a pretty typical split of this all the data we have into a training set and test set might be around say a 70%, 30% split.
And so now, if we have some data set, we run a sine of say 70% of the data to be our training set where here "m" is as usual our number of training examples and the remainder of our data might then be assigned to become our test set.
Finally, one last detail whereas here I've drawn this as though the first 70% goes to the training set and the last 30% to the test set.
That should be better to send a random 70% of your data to the training set and a random 30% of your data to the test set.
Before you know sending the first 70% in the training set and the last 30% of the test set.
Here then is a fairly typical procedure for how you would train and test the learning algorithm and the learning regression.
First, you learn the parameters theta from the training set so you minimize the usual training error objective j of theta, where j of theta here was defined using that 70% of all the data you have.
There is only the training data.
And then you would compute the test error.
And so what you do is take your parameter theta that you have learned from the training set, and plug it in here and compute your test set error.
So this is basically the average squared error as measured on your test set.
It's pretty much what you'd expect.
And of course, this is the definition of the test set error if we are using linear regression and using the squared error metric.
How about if we were doing a classification problem and say using logistic regression instead.
In that case, the procedure for training and testing say logistic regression is pretty similar first we will do the parameters from the training data, that first 70% of the data.
And it will compute the test error as follows.
While this definition of the test set error j subscript test is perfectly reasonable.
Sometimes there is an alternative test sets metric that might be easier to interpret, and that's the misclassification error.
Here's what I mean.
So either thought it was more likely to be 1, but it was actually 0, or your hypothesis stored was more likely to be 0, but the label was actually 1.
And otherwise, we define this error function to be zero.
If your hypothesis basically classified the example y correctly.
We could then define the test error, using the misclassification error metric to be one of the m tests of sum from i equals one to m subscript test of the error of h of x(i) test comma y(i).
And so that's just my way of writing out that this is exactly the fraction of the examples in my test set that my hypothesis has mislabeled.
And so that's the definition of the test set error using the misclassification error of the 0 1 misclassification metric.
So that's the standard technique for evaluating how good a learned hypothesis is.
In the next video, we will adapt these ideas to helping us do things like choose what features like the degree polynomial to use with the learning algorithm or choose the regularization parameter for learning algorithm.
Suppose you're left to decide what degree of polynomial to fit to a data set.
Or suppose you'd like to choose the regularization parameter longer for learning algorithm.
How do you do that?
Browsers, and in our discussion of how to do this, we'll talk about not just how to split your data into the train and test sets, but how to switch data into what we discover is called the train, validation, and test sets.
We'll see in this video just what these things are, and how to use them to do model selection.
More generally, this is why the training set's error is not a good predictor for how well the hypothesis will do on new example.
Well, this doesn't mean much in terms of predicting how well your hypothesis will generalize to new examples not seen in the training set.
And a more general principle is that once your parameter is what fit to some set of data.
Then the error of your hypothesis as measured on that same data set, such as the training error, that's unlikely to be a good estimate of your actual generalization error.
That is how well the hypothesis will generalize to new examples.
Now let's consider the model selection problem.
Let's say you're trying to choose what degree polynomial to fit to data.
So, should you choose a linear function, a quadratic function, a cubic function?
So it's as if there's one extra parameter in this algorithm, which I'm going to denote d, which is, what degree of polynomial.
So it's as if, in addition to the theta parameters, it's as if there's one more parameter, d, that you're trying to determine using your data set.
So, the first option is d equals one, if you fit a linear function.
So, we'd like to fit this extra sort of parameter which I'm denoting by d.
And concretely let's say that you want to choose a model, that is choose a degree of polynomial, choose one of these 10 models.
And fit that model and also get some estimate of how well your fitted hypothesis was generalize to new examples.
What you could, first take your first model and minimize the training error.
And you could then take your second model, the quadratic function, and fit that to your training set and this will give you some other.
In order to distinguish between these different parameter vectors, I'm going to use a superscript one superscript two there where theta superscript one just means the parameters I get by fitting this model to my training data.
And theta superscript two just means the parameters I get by fitting this quadratic function to my training data and so on.
By fitting a cubic model I get parenthesis three up to, well, say theta 10.
And one thing we ccould do is that take these parameters and look at test error.
So I can compute on my test set J test of one, J test of theta two, and so on.
J test of theta three, and so on.
So I'm going to take each of my hypotheses with the corresponding parameters and just measure the performance of on the test set.
Now, one thing I could do then is, in order to select one of these models, I could then see which model has the lowest test set error.
And let's just say for this example that I ended up choosing the fifth order polynomial.
But now let's say I want to take my fifth hypothesis, this, this, fifth order model, and let's say I want to ask, how well does this model generalize?
One thing I could do is look at how well my fifth order polynomial hypothesis had done on my test set.
But the problem is this will not be a fair estimate of how well my hypothesis generalizes.
And the reason is what we've done is we've fit this extra parameter d, that is this degree of polynomial.
And what fits that parameter d, using the test set, namely, we chose the value of d that gave us the best possible performance on the test set.
And so, the performance of my parameter vector theta5, on the test set, that's likely to be an overly optimistic estimate of generalization error.
And specifically, what we did was, we fit this parameter d to the test set.
To address this problem, in a model selection setting, if we want to evaluate a hypothesis, this is what we usually do instead.
And finally we also have a test set over here with our m subscript test being the number of test examples.
And finally, what this means is that that parameter d, remember d was the degree of polynomial, right?
What we've done is we'll fit that parameter d and we'll say d equals four.
And so this degree of polynomial, so the parameter, is no longer fit to the test set, and so we've not saved away the test set, and we can use the test set to measure, or to estimate the generalization error of the model that was selected.
So, that was model selection and how you can take your data, split it into a training, validation, and test set.
If you run a learning algorithm and it doesn't do as long as you are hoping, almost all the time, it will be because you have either a high bias problem or a high variance problem, in other words, either an underfitting problem or an overfitting problem.
In this case, it's very important to figure out which of these two problems is bias or variance or a bit of both that you actually have.
Because knowing which of these two things is happening would give a very strong indicator for whether the useful and promising ways to try to improve your algorithm.
In this video, I'd like to delve more deeply into this bias and variance issue and understand them better as was figure out how to look in a learning algorithm and evaluate or diagnose whether we might have a bias problem or a variance problem since this will be critical to figuring out how to improve the performance of a learning algorithm that you will implement.
Now that we're armed with the notion of chain training and validation in test sets, we can understand the concepts of bias and variance a little bit better.
Concretely, let's let our training error and cross validation error be defined as in the previous videos.
Just say the squared error, the average squared error, as measured on the training sets or as measured on the cross validation set.
Now, let's plot the following figure.
On the horizontal axis I'm going to plot the degree of polynomial.
So, as I go to the right I'm going to be fitting higher and higher order polynomials.
So where the left of this figure where maybe d equals one, we're going to be fitting very simple functions whereas we're here on the right of the horizontal axis, I have much larger values of ds, of a much higher degree polynomial.
So here, that's going to correspond to fitting much more complex functions to your training set.
Let's look at the training error and the cross validation error and plot them on this figure.
Let's start with the training error.
So, as we increase the degree of polynomial, we find typically that the training error decreases.
So I'm going to write J subscript train of theta there, because our training error tends to decrease with the degree of the polynomial that we fit to the data.
So, we know that if d equals one, we're fitting a very simple function and so we may be underfitting the training set and so it's going to be very high cross-validation error.
So if d took on say a value of four, then we're again overfitting, and so we end up with a high value for cross-validation error.
So, if you were to vary this smoothly and plot a curve, you might end up with a curve like that where that's JCV of theta.
Again, if you plot J test of theta you get something very similar.
So, this sort of plot also helps us to better understand the notions of bias and variance.
So, the setting of a cross-validation error being high corresponds to either this regime or this regime.
So, this regime on the left corresponds to a high bias problem.
That is, if you are fitting a overly low order polynomial such as a d equals one when we really needed a higher order polynomial to fit to data, whereas in contrast this regime corresponds to a high variance problem.
That is, if d the degree of polynomial was too large for the data set that we have, and this figure gives us a clue for how to distinguish between these two cases.
Concretely, for the high bias case, that is the case of underfitting, what we find is that both the cross validation error and the training error are going to be high.
So, if your algorithm is suffering from a bias problem, the training set error will be high and you might find that the cross validation error will also be high.
It might be close, maybe just slightly higher, than the training error.
So, if you see this combination, that's a sign that your algorithm may be suffering from high bias.
In contrast, if your algorithm is suffering from high variance, then if you look here, we'll notice that J train, that is the training error, is going to be low.
That is, you're fitting the training set very well, whereas your cross validation error assuming that this is, say, the squared error which we're trying to minimize say, whereas in contrast your error on a cross validation set or your cross function or cross validation set will be much bigger than your training set error.
So if you see this combination of values, then that's a clue that your learning algorithm may be suffering from high variance and might be overfitting.
The key that distinguishes these two cases is, if you have a high bias problem, your training set error will also be high is your hypothesis just not fitting the training set well.
If you have a high variance problem, your training set error will usually be low, that is much lower than your cross-validation error.
So hopefully that gives you a somewhat better understanding of the two problems of bias and variance.
But we'll see that by figuring out whether a learning algorithm may be suffering from high bias or high variance or combination of both, that that would give us much better guidance for what might be promising things to try in order to improve the performance of a learning algorithm.
You've seen how regularization can help prevent over-fitting.
But how does it affect the bias and variances of a learning algorithm?
In this video I'd like to go deeper into the issue of bias and variances and talk about how it interacts with and is affected by the regularization of your learning algorithm.
Suppose we're fitting a high auto polynomial, like that showed here, but to prevent over fitting we need to use regularization, like that shown here.
So we have this regularization term to try to keep the values of the prem to small.
And as usual, the regularizations comes from J = 1 to m, rather than j = 0 to m.
Let's consider three cases.
The first is the case of the very large value of the regularization parameter lambda, such as if lambda were equal to 10,000.
In this case, all of these parameters, theta 1, theta 2, theta 3, and so on would be heavily penalized and so we end up with most of these parameter values being closer to zero.
And the hypothesis will be roughly h of x, just equal or approximately equal to theta zero.
So we end up with a hypothesis that more or less looks like that, more or less a flat, constant straight line.
At the other extreme is if we have a very small value of lambda, such as if lambda were equal to zero.
In that case, given that we're fitting a high order polynomial, this is a usual over-fitting setting.
In that case, given that we're fitting a high-order polynomial, basically, without regularization or with very minimal regularization, we end up with our usual high-variance, over fitting setting.
This is basically if lambda is equal to zero, we're just fitting with our regularization, so that over fits the hypothesis.
And it's only if we have some intermediate value of longer that is neither too large nor too small that we end up with parameters data that give us a reasonable fit to this data.
So, how can we automatically choose a good value for the regularization parameter?
For the setting where we're using regularization, let me define J train(theta) to be something different, to be the optimization objective, but without the regularization term.
Previously, in an earlier video, when we were not using regularization I define J train of data to be the same as J of theta as the cause function but when we're using regularization when the six well under term we're going to define J train my training set to be just my sum of squared errors on the training set or my average squared error on the training set without taking into account that regularization.
And similarly I'm then also going to define the cross validation sets error and to test that error as before to be the average sum of squared errors on the cross validation in the test sets so just to summarize my definitions of J train J CU and J test are just the average square there one half of the other square record on the training validation of the test set without the extra regularization term.
So, this is how we can automatically choose the regularization parameter lambda.
So what I usually do is maybe have some range of values of lambda I want to try out.
And I usually set these up in multiples of two, until some maybe larger value if I were to do these in multiples of 2 I'd end up with a 10.24.
It's 10 exactly, but this is close enough.
And the three to four decimal places won't effect your result that much.
So, this gives me maybe 12 different models.
And I'm trying to select a month corresponding to 12 different values of the regularization of the parameter lambda.
And of course you can also go to values less than 0.01 or values larger than 10 but I've just truncated it here for convenience.
Given the issue of these 12 models, what we can do is then the following, we can take this first model with lambda equals zero and minimize my cost function J of data and this will give me some parameter of active data.
To get some different parameter vector theta.
And so on until for my final model with lambda set to 10 or 10.24, I end up with this theta(12).
And I would then pick whichever one of these 12 models gives me the lowest error on the trans validation set.
And let's say, for the sake of this example, that I end up picking theta 5, the 5th order polynomial, because that has the lowest cause validation error.
Having done that, finally what I would do if I wanted to report each test set error, is to take the parameter theta 5 that I've selected, and look at how well it does on my test set.
So once again, here is as if we've fit this parameter, theta, to my cross-validation set, which is why I'm setting aside a separate test set that I'm going to use to get a better estimate of how well my parameter vector, theta, will generalize to previously unseen examples.
So that's model selection applied to selecting the regularization parameter lambda.
The last thing I'd like to do in this video is get a better understanding of how cross validation and training error vary as we vary the regularization parameter lambda.
And so just a reminder right, that was our original cost on j of theta.
But for this purpose we're going to define training error without using a regularization parameter, and cross validation error without using the regularization parameter.
And what I'd like to do is plot this Jtrain and plot this Jcv, meaning just how well does my hypothesis do on the training set and how does my hypothesis do when it cross validation sets.
So, for small values of lambda, the regularization term basically goes away, and you're just minimizing pretty much just gray arrows.
So when lambda is small, you end up with a small value for Jtrain, whereas if lambda is large, then you have a high bias problem, and you might not feel your training that well, so you end up the value up there.
So Jtrain of theta will tend to increase when lambda increases, because a large value of lambda corresponds to high bias where you might not even fit your trainings that well, whereas a small value of lambda corresponds to, if you can really fit a very high degree polynomial to your data, let's say.
And so the cross validation error will be high.
Let me just leave all of that to this Jcv (theta) because so, with high bias, we won't be fitting, we won't be doing well in cross validation sets, whereas here on the left, this is the high variance regime, where we have two smaller value with longer, then we may be over fitting the data.
And so by over fitting the data, then the cross validation error will also be high.
And so, this is what the cross validation error and what the trading error may look like on a trading stance as we vary the regularization parameter lambda.
And so once again, it will often be some intermediate value of lambda that is just right or that works best In terms of having a small cross validation error or a small test theta.
And whereas the curves I've drawn here are somewhat cartoonish and somewhat idealized so on the real data set the curves you get may end up looking a little bit more messy and just a little bit more noisy then this.
For some data sets you will really see these for sorts of trends and by looking at a plot of the hold-out cross validation error you can either manual, automatically try to select a point that minimizes the cross validation error and select the value of lambda corresponding to low cross validation error.
When I'm trying to pick the regularization parameter lambda for learning algorithm, often I find that plotting a figure like this one shown here helps me understand better what's going on and helps me verify that I am indeed picking a good value for the regularization parameter monitor.
So hopefully that gives you more insight into regularization and it's effects on the bias and variance of a learning algorithm.
By now you've seen bias and variance from a lot of different perspectives.
And what we like to do in the next video is take all the insights we've gone through and build on them to put together a diagnostic that's called learning curves, which is a tool that I often use to diagnose if the learning algorithm may be suffering from a bias problem or a variance problem, or a little bit of both.
In this video, I'd like to tell you about learning curves.
If either you wanted to sanity check that your algorithm is working correctly, or if you want to improve the performance of the algorithm.
And learning curves is a tool that I actually use very often to try to diagnose if a physical learning algorithm may be suffering from bias, sort of variance problem or a bit of both.
Here's what a learning curve is.
To plot a learning curve, what I usually do is plot j train which is, say, average squared error on my training set or Jcv which is the average squared error on my cross validation set.
And I'm going to plot that as a function of m, that is as a function of the number of training examples I have.
And so m is usually a constant like maybe I just have, you know, a 100 training examples but what I'm going to do is artificially with use my training set exercise.
So let's see what these plots may look like.
Well, I have only one training example.
Well the quadratic function can also fit that very well.
Here if I set M equals 3, say, and I train on only three examples, then, for this figure I am going to measure my training error only on the three examples that actually fit my data too and so even I have to say a 100 training examples but if I want to plot what my training error is the m equals 3.
And not all the other examples that I have deliberately omitted from the training process.
So just to summarize what we've seen is that if the training set size is small then the training error is going to be small as well.
It becomes harder and harder to ensure that I can find the quadratic function that process through all my examples perfectly.
It's pretty easy to fit every single one of your training examples perfectly and so your error is going to be small whereas when m is larger then gets harder all the training examples perfectly and so your training set error becomes more larger now, how about the cross validation error.
Well, the cross validation is my error on this cross validation set that I haven't seen and so, you know, when I have a very small training set, I'm not going to generalize well, just not going to do well on that.
So, right, this hypothesis here doesn't look like a good one, and it's only when I get a larger training set that, you know, I'm starting to get hypotheses that maybe fit the data somewhat better.
So your cross validation error and your test set error will tend to decrease as your training set size increases because the more data you have, the better you do at generalizing to new examples.
So, just the more data you have, the better the hypothesis you fit.
So if you plot j train, and Jcv this is the sort of thing that you get.
Now let's look at what the learning curves may look like if we have either high bias or high variance problems.
Suppose your hypothesis has high bias and to explain this I'm going to use a, set an example, of fitting a straight line to data that, you know, can't really be fit well by a straight line.
So we end up with a hypotheses that maybe looks like that.
Now let's think what would happen if we were to increase the training set size.
So if instead of five examples like what I've drawn there, imagine that we have a lot more training examples.
Well what happens, if you fit a straight line to this.
I mean a straight line that just cannot fit this data and getting a ton more data, well the straight line isn't going to change that much.
This is the best possible straight-line fit to this data, but the straight line just can't fit this data set that well.
So, if you plot across validation error, this is what it will look like.
Option on the left, if you have already a miniscule training set size like you know, maybe just one training example and is not going to do well.
And what you find in the high bias case is that the training error will end up close to the cross validation error, because you have so few parameters and so much data, at least when m is large.
And so, this is what your learning curves will look like, if you have an algorithm that has high bias.
And finally, the problem with high bias is reflected in the fact that both the cross validation error and the training error are high, and so you end up with a relatively high value of both Jcv and the j train.
This also implies something very interesting, which is that, if a learning algorithm has high bias, as we get more and more training examples, that is, as we move to the right of this figure, we'll notice that the cross validation error isn't going down much, it's basically fattened up, and so if learning algorithms are really suffering from high bias.
Getting more training data by itself will actually not help that much,and as our figure example in the figure on the right, here we had only five training.
examples, and we fill certain straight line.
And when we had a ton more training data, we still end up with roughly the same straight line.
And so if the learning algorithm has high bias give me a lot more training data.
So knowing if your learning algorithm is suffering from high bias seems like a useful thing to know because this can prevent you from wasting a lot of time collecting more training data where it might just not end up being helpful.
Next let us look at the setting of a learning algorithm that may have high variance.
Let us just look at the training error in a around if you have very smart training set like five training examples shown on the figure on the right and if we're fitting say a very high order polynomial, and I've written a hundredth degree polynomial which really no one uses, but just an illustration.
And if we're using a fairly small value of lambda, maybe not zero, but a fairly small value of lambda, then we'll end up, you know, fitting this data very well that with a function that overfits this.
So, if the training set size is small, our training error, that is, j train of theta will be small.
Now, how about the cross validation error?
Well, in high variance setting, a hypothesis is overfitting and so the cross validation error will remain high, even as we get you know, a moderate number of training examples and, so maybe, the cross validation error may look like that.
And the indicative diagnostic that we have a high variance problem, is the fact that there's this large gap between the training error and the cross validation error.
If we think about adding more training data, that is, taking this figure and extrapolating to the right, we can kind of tell that, you know the two curves, the blue curve and the magenta curve, are converging to each other.
And so, if we were to extrapolate this figure to the right, then it seems it likely that the training error will keep on going up and the cross-validation error would keep on going down.
And the thing we really care about is the cross-validation error or the test set error, right?
So in this sort of figure, we can tell that if we keep on adding training examples and extrapolate to the right, well our cross validation error will keep on coming down.
And, so, in the high variance setting, getting more training data is, indeed, likely to help.
And so again, this seems like a useful thing to know if your learning algorithm is suffering from a high variance problem, because that tells you, for example that it may be be worth your while to see if you can go and get some more training data.
Now, on the previous slide and this slide, I've drawn fairly clean fairly idealized curves.
If you plot these curves for an actual learning algorithm, sometimes you will actually see, you know, pretty much curves, like what I've drawn here.
But plotting learning curves like these can often tell you, can often help you figure out if your learning algorithm is suffering from bias, or variance or even a little bit of both.
So when I'm trying to improve the performance of a learning algorithm, one thing that I'll almost always do is plot these learning curves, and usually this will give you a better sense of whether there is a bias or variance problem.
And in the next video we'll see how this can help suggest specific actions is to take, or to not take, in order to try to improve the performance of your learning algorithm.
We've talked about how to evaluate learning algorithms, talked about model selection, talked a lot about bias and variance.
So how does this help us figure out what are potentially fruitful, potentially not fruitful things to try to do to improve the performance of a learning algorithm.
Let's go back to our original motivating example and go for the result.
So here is our earlier example of maybe having fit regularized linear regression and finding that it doesn't work as well as we're hoping.
So is there some way to figure out which of these might be fruitful options?
The first thing all of this was getting more training examples.
What this is good for, is this helps to fix high variance.
And concretely, if you instead have a high bias problem and don't have any variance problem, then we saw in the previous video that getting more training examples, while maybe just isn't going to help much at all.
So the first option is useful only if you, say, plot the learning curves and figure out that you have at least a bit of a variance, meaning that the cross-validation error is, you know, quite a bit bigger than your training set error.
Well, trying a smaller set of features, that's again something that fixes high variance.
And in other words, if you figure out, by looking at learning curves or something else that you used, that have a high bias problem; then for goodness sakes, don't waste your time trying to carefully select out a smaller set of features to use.
Because if you have a high bias problem, using fewer features is not going to help.
Whereas in contrast, if you look at the learning curves or something else you figure out that you have a high variance problem, then, indeed trying to select out a smaller set of features, that might indeed be a very good use of your time.
How about trying to get additional features, adding features, usually, not always, but usually we think of this as a solution for fixing high bias problems.
So if you are adding extra features it's usually because your current hypothesis is too simple, and so we want to try to get additional features to make our hypothesis better able to fit the training set.
And similarly, adding polynomial features; this is another way of adding features and so there is another way to try to fix the high bias problem.
And, if concretely if your learning curves show you that you still have a high variance problem, then, you know, again this is maybe a less good use of your time.
And finally, decreasing and increasing lambda.
This are quick and easy to try, I guess these are less likely to be a waste of, you know, many months of your life.
But decreasing lambda, you already know fixes high bias.
In case this isn't clear to you, you know, I do encourage you to pause the video and think through this that convince yourself that decreasing lambda helps fix high bias, whereas increasing lambda fixes high variance.
And if you aren't sure why this is the case, do pause the video and make sure you can convince yourself that this is the case.
Or take a look at the curves that we were plotting at the end of the previous video and try to make sure you understand why these are the case.
Finally, let us take everything we have learned and relate it back to neural networks and so, here is some practical advice for how I usually choose the architecture or the connectivity pattern of the neural networks I use.
If you're fitting a neural network, one option would be to fit a relatively small neural network with, say, relatively few, maybe only one hidden layer and maybe only a relatively few number of hidden units.
So, a network like this might have relatively few parameters and be more prone to underfitting.
The main advantage of these small neural networks is that the computation will be cheaper.
An alternative would be to fit a, maybe relatively large neural network with either more hidden units--there's a lot of hidden in one there--or with more hidden layers.
And so these neural networks tend to have more parameters and therefore be more prone to overfitting.
One disadvantage, often not a major one but something to think about, is that if you have a large number of neurons in your network, then it can be more computationally expensive.
Although within reason, this is often hopefully not a huge problem.
And the main possible disadvantage is that it can be more computationally expensive.
And finally, one of the other decisions is, say, the number of hidden layers you want to have, right?
So, do you want one hidden layer or do you want three hidden layers, as we've shown here, or do you want two hidden layers?
And usually, as I think I said in the previous video, using a single hidden layer is a reasonable default, but if you want to choose the number of hidden layers, one other thing you can try is find yourself a training cross-validation, and test set split and try training neural networks with one hidden layer or two hidden layers or three hidden layers and see which of those neural networks performs best on the cross-validation sets.
You take your three neural networks with one, two and three hidden layers, and compute the cross validation error at Jcv and all of them and use that to select which of these is you think the best neural network.
So, that's it for bias and variance and ways like learning curves, who tried to diagnose these problems.
As far as what you think is implied, for one might be truthful or not truthful things to try to improve the performance of a learning algorithm.
If you understood the contents of the last few videos and if you apply them you actually be much more effective already and getting learning algorithms to work on problems and even a large fraction, maybe the majority of practitioners of machine learning here in Silicon Valley today doing these things as their full-time jobs.
So I hope that these pieces of advice on by experience in diagnostics will help you to much effectively and powerfully apply learning and get them to work very well.
In the next few videos I'd like to talk about machine learning system design.
These videos will touch on the main issues that you may face when designing a complex machine learning system, and will actually try to give advice on how to strategize putting together a complex machine learning system.
In case this next set of videos seems a little disjointed that's because these videos will touch on a range of the different issues that you may come across when designing complex learning systems.
And even though the next set of videos may seem somewhat less mathematical, I think that this material may turn out to be very useful, and potentially huge time savers when you're building big machine learning systems.
Concretely, I'd like to begin with the issue of prioritizing how to spend your time on what to work on, and I'll begin with an example on spam classification.
Let's say you want to build a spam classifier.
Here are a couple of examples of obvious spam and non-spam emails.
if the one on the left tried to sell things.
Let's say we have a labeled training set of some number of spam emails and some non-spam emails denoted with labels y equals 1 or 0, how do we build a classifier using supervised learning to distinguish between spam and non-spam?
In order to apply supervised learning, the first decision we must make is how do we want to represent x, that is the features of the email.
Given the features x and the labels y in our training set, we can then train a classifier, for example using logistic regression.
Here's one way to choose a set of features for our emails.
And maybe for some reason I think the word "now" may be indicative of non-spam because I get a lot of urgent emails, and so on, and maybe we choose a hundred words or so.
Given a piece of email, we can then take this piece of email and encode it into a feature vector as follows.
I'm going to take my list of a hundred words and sort them in alphabetical order say.
But, you know, here's a, here's my list of words, just count and so on, until eventually I'll get down to now, and so on and given a piece of e-mail like that shown on the right, I'm going to check and see whether or not each of these words appears in the e-mail and then I'm going to define a feature vector x where in this piece of an email on the right, my name doesn't appear so I'm gonna put a zero there.
The word "due" appears, I put a one there.
The word "now" does appear and so on.
So I put ones and zeroes in this feature vector depending on whether or not a particular word appears.
And in this example my feature vector would have to mention one hundred, if I have a hundred, if if I chose a hundred words to use for this representation and each of my features Xj will basically be 1 if you have a particular word that, we'll call this word j, appears in the email and Xj would be zero otherwise.
Okay.
So that gives me a feature representation of a piece of email.
By the way, even though I've described this process as manually picking a hundred words, in practice what's most commonly done is to look through a training set, and in the training set depict the most frequently occurring n words where n is usually between ten thousand and fifty thousand, and use those as your features.
So rather than manually picking a hundred words, here you look through the training examples and pick the most frequently occurring words like ten thousand to fifty thousand words, and those form the features that you are going to use to represent your email for spam classification.
Now, if you're building a spam classifier one question that you may face is, what's the best use of your time in order to make your spam classifier have higher accuracy, you have lower error.
Right?
And in fact there's this tendency to think that, well the more data we have the better the algorithm will do.
And in fact, in the email spam domain, there are actually pretty serious projects called Honey Pot Projects, which create fake email addresses and try to get these fake email addresses into the hands of spammers and use that to try to collect tons of spam email, and therefore you know, get a lot of spam data to train learning algorithms.
But we've already seen in the previous sets of videos that getting lots of data will often help, but not all the time.
But for most machine learning problems, there are a lot of other things you could usually imagine doing to improve performance.
For spam, one thing you might think of is to develop more sophisticated features on the email, maybe based on the email routing information.
And this would be information contained in the email header.
So, when spammers send email, very often they will try to obscure the origins of the email, and maybe use fake email headers.
Through very unusual routes, in order to get the spam to you.
And some of this information will be reflected in the email header.
And so one can imagine, looking at the email headers and trying to develop more sophisticated features to capture this sort of email routing information to identify if something is spam.
Something else you might consider doing is to look at the email message body, that is the email text, and try to develop more sophisticated features.
Maybe even though one is lower case and one in capitalized in this example.
Or do we want more complex features about punctuation because maybe spam is using exclamation marks a lot more.
I don't know.
And along the same lines, maybe we also want to develop more sophisticated algorithms to detect and maybe to correct to deliberate misspellings, like mortgage, medicine, watches.
And this is why spammers do it.
While working on a machine learning problem, very often you can brainstorm lists of different things to try, like these.
By the way, I've actually worked on the spam problem myself for a while.
And I actually spent quite some time on it.
And even though I kind of understand the spam problem, I actually know a bit about it, I would actually have a very hard time telling you of these four options which is the best use of your time so what happens, frankly what happens far too often is that a research group or product group will randomly fixate on one of these options.
And sometimes that turns out not to be the most fruitful way to spend your time depending, you know, on which of these options someone ends up randomly fixating on.
By the way, in fact, if you even get to the stage where you brainstorm a list of different options to try, you're probably already ahead of the curve.
Sadly, what most people do is instead of trying to list out the options of things you might try, what far too many people do is wake up one morning and, for some reason, just, you know, have a weird gut feeling that, "Oh let's have a huge honeypot project to go and collect tons more data" and for whatever strange reason just sort of wake up one morning and randomly fixate on one thing and just work on that for six months.
But I think we can do better.
And in particular what I'd like to do in the next video is tell you about the concept of error analysis and talk about the way where you can try to have a more systematic way to choose amongst the options of the many different things you might work, and therefore be more likely to select what is actually a good way to spend your time, you know for the next few weeks, or next few days or the next few months.
In the previous video, I talked about error analysis and the importance of having error metrics, that is of having a single real number evaluation metric for your learning algorithm to tell how well it's doing.
In the context of evaluation and of error metrics, there is one important case, where it's particularly tricky to come up with an appropriate error metric, or evaluation metric, for your learning algorithm.
That case is the case of what's called skewed classes.
Let me tell you what that means.
Consider the problem of cancer classification, where we have features of medical patients and we want to decide whether or not they have cancer.
So this is like the malignant versus benign tumor classification example that we had earlier.
We have trained the progression classifier and let's say we test our classifier on a test set and find that we get 1 percent error.
Seems like a really impressive result, right.
But now, let's say we find out that only 0.5 percent of patients in our training test sets actually have cancer.
So only half a percent of the patients that come through our screening process have cancer.
In this case, the 1% error no longer looks so impressive.
And in particular, here's a piece of code, here's actually a piece of non learning code that takes this input of features x and it ignores it.
It just sets y equals 0 and always predicts, you know, nobody has cancer and this algorithm would actually get 0.5 percent error.
So this is even better than the 1% error that we were getting just now and this is a non learning algorithm that you know, it is just predicting y equals 0 all the time.
So this setting of when the ratio of positive to negative examples is very close to one of two extremes, where, in this case, the number of positive examples is much, much smaller than the number of negative examples because y equals one so rarely, this is what we call the case of skewed classes.
We just have a lot more of examples from one class than from the other class.
And by just predicting y equals 0 all the time, or maybe our predicting y equals 1 all the time, an algorithm can do pretty well.
So the problem with using classification error or classification accuracy as our evaluation metric is the following.
Let's say you have one joining algorithm that's getting 99.2% accuracy.
So, that's a 0.8% error.
Let's say you make a change to your algorithm and you now are getting 99.5% accuracy.
That is 0.5% error.
One of the nice things about having a single real number evaluation metric is this helps us to quickly decide if we just need a good change to the algorithm or not.
You know, did we just do something useful or did we just replace our code with something that just predicts y equals zero more often?
So, if you have very skewed classes it becomes much harder to use just classification accuracy, because you can get very high classification accuracies or very low errors, and it's not always clear if doing so is really improving the quality of your classifier because predicting y equals 0 all the time doesn't seem like a particularly good classifier.
But just predicting y equals 0 more often can bring your error down to, you know, maybe as low as 0.5%.
When we're faced with such a skewed classes therefore we would want to come up with a different error metric or a different evaluation metric.
Let me explain what that is.
Let's say we are evaluating a classifier on the test set.
For the examples in the test set the actual class of that example in the test set is going to be either one or zero, right, if there is a binary classification problem.
And what our learning algorithm will do is it will, you know, predict some value for the class and our learning algorithm will predict the value for each example in my test set and the predicted value will also be either one or zero.
If our learning algorithm predicted that something is negative, class zero, and the actual class is also class zero then that's what's called a true negative.
We predicted zero and it actually is zero.
To find the other two boxes, if our learning algorithm predicts that the class is one but the actual class is zero, then that's called a false positive.
So that means our algorithm for the patient is cancelled out in reality if the patient does not.
And finally, the last box is a zero, one.
That's called a false negative because our algorithm predicted zero, but the actual class was one.
And so, we have this little sort of two by two table based on what was the actual class and what was the predicted class.
So here's a different way of evaluating the performance of our algorithm.
We're going to compute two numbers.
The first is called precision - and what that says is, of all the patients where we've predicted that they have cancer, what fraction of them actually have cancer?
So let me write this down, the precision of a classifier is the number of true positives divided by the number that we predicted as positive, right?
So of all the patients that we went to those patients and we told them, "We think you have cancer." Of all those patients, what fraction of them actually have cancer?
So that's called precision.
And another way to write this would be true positives and then in the denominator is the number of predicted positives, and so that would be the sum of the, you know, entries in this first row of the table.
I'm going to abbreviate positive as POS and then plus false positives, again abbreviating positive using POS.
We think you have cancer," high precision means that of that group of patients most of them we had actually made accurate predictions on them and they do have cancer.
The second number we're going to compute is called recall, and what recall say is, if all the patients in, let's say, in the test set or the cross-validation set, but if all the patients in the data set that actually have cancer, what fraction of them that we correctly detect as having cancer.
So if all the patients have cancer, how many of them did we actually go to them and you know, correctly told them that we think they need treatment.
So, writing this down, recall is defined as the number of positives, the number of true positives, meaning the number of people that have cancer and that we correctly predicted have cancer and we take that and divide that by, divide that by the number of actual positives, so this is the right number of actual positives of all the people that do have cancer.
What fraction do we directly flag and you know, send the treatment.
So, to rewrite this in a different form, the denominator would be the number of actual positives as you know, is the sum of the entries in this first column over here.
And so writing things out differently, this is therefore, the number of true positives, divided by the number of true positives plus the number of false negatives.
And so once again, having a high recall would be a good thing.
So by computing precision and recall this will usually give us a better sense of how well our classifier is doing.
And more generally, even for settings where we have very skewed classes, it's not possible for an algorithm to sort of "cheat" and somehow get a very high precision and a very high recall by doing some simple thing like predicting y equals 0 all the time or predicting y equals 1 all the time.
And so we're much more sure that a classifier of a high precision or high recall actually is a good classifier, and this gives us a more useful evaluation metric that is a more direct way to actually understand whether, you know, our algorithm may be doing well.
So one final note in the definition of precision and recall, that we would define precision and recall, usually we use the convention that y is equal to 1, in the presence of the more rare class.
rare conditions such as cancer, hopefully that's a rare condition, precision and recall are defined setting y equals 1, rather than y equals 0, to be sort of that the presence of that rare class that we're trying to detect.
And by using precision and recall, we find, what happens is that even if we have very skewed classes, it's not possible for an algorithm to you know, "cheat" and predict y equals 1 all the time, or predict y equals 0 all the time, and get high precision and recall.
And in particular, if a classifier is getting high precision and high recall, then we are actually confident that the algorithm has to be doing well, even if we have very skewed classes.
So for the problem of skewed classes precision recall gives us more direct insight into how the learning algorithm is doing and this is often a much better way to evaluate our learning algorithms, than looking at classification error or classification accuracy, when the classes are very skewed.
In the previous video, we talked about evaluation metrics.
In this video, I'd like to switch tracks a bit and touch on another important aspect of machine learning system design, which will often come up, which is the issue of how much data to train on.
Now, in some earlier videos, I had cautioned against blindly going out and just spending lots of time collecting lots of data, because it's only sometimes that that would actually help.
But it turns out that under certain conditions, and I will say in this video what those conditions are, getting a lot of data and training on a certain type of learning algorithm, can be a very effective way to get a learning algorithm to do very good performance.
And this arises often enough that if those conditions hold true for your problem and if you're able to get a lot of data, this could be a very good way to get a very high performance learning algorithm.
So in this video, let's talk more about that.
Let me start with a story.
Many, many years ago, two researchers that I know, Michelle Banko and Eric Broule ran the following fascinating study.
Well, for this example, for breakfast I ate two, 2 eggs.
So, this is one example of a set of confusable words and that's a different set.
So they took machine learning problems like these, sort of supervised learning problems to try to categorize what is the appropriate word to go into a certain position in an English sentence.
They took a few different learning algorithms which were, you know, sort of considered state of the art back in the day, when they ran the study in 2001, so they took a variance, roughly a variance on logistic regression called the Perceptron.
And they used a naive based algorithm, which is something they'll actually talk about in this course.
The exact algorithms of these details aren't important.
Think of this as, you know, just picking four different classification algorithms and really the exact algorithms aren't important.
But what they did was they varied the training set size and tried out these learning algorithms on the range of training set sizes and that's the result they got.
And the trends are very clear right first most of these outer rooms give remarkably similar performance.
And second, as the training set size increases, on the horizontal axis is the training set size in millions go from you know a hundred thousand up to a thousand million that is a billion training examples.
The performance of the algorithms all pretty much monotonically increase and the fact that if you pick any algorithm may be pick a "inferior algorithm" but if you give that "inferior algorithm" more data, then from these examples, it looks like it will most likely beat even a "superior algorithm".
So since this original study which is very influential, there's been a range of many different studies showing similar results that show that many different learning algorithms you know tend to, can sometimes, depending on details, can give pretty similar ranges of performance, but what can really drive performance is you can give the algorithm a ton of training data.
And this is, results like these has led to a saying in machine learning that often in machine learning it's not who has the best algorithm that wins, it's who has the most data So when is this true and when is this not true?
Because we have a learning algorithm for which this is true then getting a lot of data is often maybe the best way to ensure that we have an algorithm with very high performance rather than you know, debating worrying about exactly which of these items to use.
Let's try to lay out a set of assumptions under which having a massive training set we think will be able to help.
Let's assume that in our machine learning problem, the features x have sufficient information with which we can use to predict y accurately.
Let's say that it features x capture what are the surrounding words around the blank that we're trying to fill in.
Then yeah that is pretty much information to tell me that the word I want in the middle is TWO and that is not word TO and its not the word TOO.
So that's an example what the future ex has sufficient information for specific y.
Consider a problem of predicting the price of a house from only the size of the house and from no other features.
I don't tell you that the house is in an expensive part of the city.
Or if I don't tell you that the house, the number of rooms in the house, or how nicely furnished the house is, or whether the house is new or old.
If I don't tell you anything other than that this is a 500 square foot house, well there's so many other factors that would affect the price of a house other than just the size of a house that if all you know is the size, it's actually very difficult to predict the price accurately.
So that would be a counter example to this assumption that the features have sufficient information to predict the price to the desired level of accuracy.
You go to someone that speaks English well, right, then a human expert in English just read most people like you and me will probably we would probably be able to predict what word should go in here, to a good English speaker can predict this well, and so this gives me confidence that x allows us to predict y accurately, but in contrast if we go to an expert in human prices.
If I just tell them the size of a house and I tell them what the price is well even an expert in pricing or selling houses wouldn't be able to tell me and so this is fine that for the housing price example knowing only the size doesn't give me enough information to predict the price of the house.
Let's see then, when having a lot of data could help.
Suppose the features have enough information to predict the value of y.
And let's suppose we use a learning algorithm with a large number of parameters so maybe logistic regression or linear regression with a large number of features.
Or one thing that I sometimes do, one thing that I often do actually is using neural network with many hidden units.
That would be another learning algorithm with a lot of parameters.
So these are all powerful learning algorithms with a lot of parameters that can fit very complex functions.
So, I'm going to call these, I'm going to think of these as low-bias algorithms because you know we can fit very complex functions and because we have a very powerful learning algorithm, they can fit very complex functions.
Chances are, if we run these algorithms on the data sets, it will be able to fit the training set well, and so hopefully the training error will be slow.
Now let's say, we use a massive, massive training set, in that case, if we have a huge training set, then hopefully even though we have a lot of parameters but if the training set is sort of even much larger than the number of parameters then hopefully these albums will be unlikely to overfit.
Right because we have such a massive training set and by unlikely to overfit what that means is that the training error will hopefully be close to the test error.
Finally putting these two together that the train set error is small and the test set error is close to the training error what this two together imply is that hopefully the test set error will also be small.
Another way to think about this is that in order to have a high performance learning algorithm we want it not to have high bias and not to have high variance.
So the bias problem we're going to address by making sure we have a learning algorithm with many parameters and so that gives us a low bias alorithm and by using a very large training set, this ensures that we don't have a variance problem here.
So hopefully our algorithm will have no variance and so is by pulling these two together, that we end up with a low bias and a low variance learning algorithm and this allows us to do well on the test set.
Because that's sort of a certification that y can be predicted accurately from the features x and second, can we actually get a large training set, and train the learning algorithm with a lot of parameters in the training set and if you can't do both then that's more often give you a very kind performance learning algorithm.
By now, you've seen a range of difference learning algorithms.
With supervised learning, the performance of many supervised learning algorithms will be pretty similar, and what matters less often will be whether you use learning algorithm a or learning algorithm b, but what matters more will often be things like the amount of data you create these algorithms on, as well as your skill in applying these algorithms.
Things like your choice of the features you design to give to the learning algorithms, and how you choose the colorization parameter, and things like that.
But, there's one more algorithm that is very powerful and is very widely used both within industry and academia, and that's called the support vector machine.
And compared to both logistic regression and neural networks, the Support Vector Machine, or SVM sometimes gives a cleaner, and sometimes more powerful way of learning complex non-linear functions.
And so let's take the next videos to talk about that.
Later in this course, I will do a quick survey of a range of different supervisory algorithms just as a very briefly describe them.
But the support vector machine, given its popularity and how powerful it is, this will be the last of the supervisory algorithms that I'll spend a significant amount of time on in this course as with our development other learning algorithms, we're gonna start by talking about the optimization objective.
So, let's get started on this algorithm.
In order to describe the support vector machine, I'm actually going to start with logistic regression, and show how we can modify it a bit, and get what is essentially the support vector machine.
So in logistic regression, we have our familiar form of the hypothesis there and the sigmoid activation function shown on the right.
And in order to explain some of the math, I'm going to use z to denote theta transpose axiom.
Now let's think about what we would like logistic regression to do.
If we have an example with y equals one and by this I mean an example in either the training set or the test set or the cross-validation set, but when y is equal to one then we're sort of hoping that h of x will be close to one.
And that's because it is z, the theta of transpose x is when z is much bigger than 0 is far to the right of the sphere.
Conversely, if we have an example where y is equal to zero, then what we're hoping for is that the hypothesis will output a value close to zero.
And that corresponds to theta transpose x of z being much less than zero because that corresponds to a hypothesis of putting a value close to zero.
If you look at the cost function of logistic regression, what you'll find is that each example (x,y) contributes a term like this to the overall cost function, right?
So for the overall cost function, we will also have a sum over all the chain examples and the 1 over m term, that this expression here, that's the term that a single training example contributes to the overall objective function so we can just rush them.
In the first case, let's suppose that y is equal to 1.
In that case, only this first term in the objective matters, because this one minus y term would be equal to zero if y is equal to one.
So when y is equal to one, when in our example x comma y, when y is equal to 1 what we get is this term..
And if we plot this function as a function of z, what you find is that you get this curve shown on the lower left of the slide.
And thus, we also see that when z is equal to large, that is, when theta transpose x is large, that corresponds to a value of z that gives us a fairly small value, a very, very small contribution to the consumption.
And this kinda explains why, when logistic regression sees a positive example, with y=1, it tries to set theta transport x to be very large because that corresponds to this term, in the cross function, being small.
Now, to fill the support vec machine, here's what we're going to do.
We're gonna take this cross function, this minus log 1 over 1 plus e to negative z, and modify it a little bit.
The new pass functions can be flat from here on out, and then we draw something that grows as a straight line, similar to logistic regression.
So the curve that I just drew in magenta, and the curve I just drew purple and magenta, so if it's pretty close approximation to the cross function used by logistic regression.
Except it is now made up of two line segments, there's this flat portion on the right, and then there's this straight line portion on the left.
And don't worry too much about the slope of the straight line portion.
But that's the new cost function we're going to use for when y is equal to one, and you can imagine it should do something pretty similar to logistic regression.
But turns out, that this will give the support vector machine computational advantages and give us, later on, an easier optimization problem that would be easier for software to solve.
We just talked about the case of y equals one.
In that case, if you look at the cost, then only the second term will apply because the first term goes away, right?
And so the cost of an example, or the contribution of the cost function, is going to be given by this term over here.
And if you plot that as a function of z, to have pure z on the horizontal axis, you end up with this one.
And that then grows as a straight line, like so.
So let me give these two functions names.
This function on the left I'm going to call cost subscript 1 of z, and this function of the right I'm gonna call cost subscript 0 of z.
And the subscript just refers to the cost corresponding to when y is equal to 1, versus when y Is equal to zero.
Armed with these definitions, we're now ready to build a support vector machine.
Here's the cost function, j of theta, that we have for logistic regression.
For the support vector machine what we're going to do is essentially take this and replace this with cost1 of z, that is cost1 of theta transpose x.
And we're going to take this and replace it with cost0 of z, that is cost0 of theta transpose x.
And the cost zero function, again what we had on the previous slide, and it looks like this.
Now, by convention, for the support of vector machine, we're actually write things slightly different.
First, we're going to get rid of the 1 over m terms, and this just this happens to be a slightly different convention that people use for support vector machines compared to or just a progression.
But here's what I mean.
I should end up with the same optimal value for theta.
Well, the minimum of this happens to be U equals five.
So multiply something that you're minimizing over, by some constant, 10 in this case, it does not change the value of U that gives us, that minimizes this function.
So the same way, what I've done is by crossing out the M is all I'm doing is multiplying my objective function by some constant M and it doesn't change the value of theta.
The second bit of notational change, which is just, again, the more standard convention when using SVMs instead of logistic regression, is the following.
So for logistic regression, we add two terms to the objective function.
The first is this term, which is the cost that comes from the training set and the second is this row, which is the regularization term.
And what we had was we had a, we control the trade-off between these by saying, what we want is A plus, and then my regularization parameter lambda.
And instead of prioritizing this as A plus lambda B, and so what we did was by setting different values for this regularization parameter lambda, we could trade off the relative weight between how much we wanted the training set well, that is, minimizing A, versus how much we care about keeping the values of the parameter small, so that will be, the parameter is B for the support vector machine, just by convention, we're going to use a different parameter.
So instead of using lambda here to control the relative waiting between the first and second terms.
So for logistic regression, if we set a very large value of lambda, that means you will give B a very high weight.
Here is that if we set C to be a very small value, then that responds to giving B a much larger rate than C, than A.
So this is just a different way of controlling the trade off, it's just a different way of prioritizing how much we care about optimizing the first term, versus how much we care about optimizing the second term.
And if you want you can think of this as the parameter C playing a role similar to 1 over lambda.
It's rather that if C is equal to 1 over lambda, then these two optimization objectives should give you the same value the same optimal value for theta so we just filling that in I'm gonna cross out lambda here and write in the constant C there.
And if you minimize that function, then what you have is the parameters learned by the SVM.
Finally unlike logistic regression, the support vector machine doesn't output the probability is that what we have is we have this cost function, that we minimize to get the parameter's data, and what a support vector machine does is it just makes a prediction of y being equal to one or zero, directly.
So the hypothesis will predict one if theta transpose x is greater or equal to zero, and it will predict zero otherwise and so having learned the parameters theta, this is the form of the hypothesis for the support vector machine.
So that was a mathematical definition of what a support vector machine does.
In the next few videos, let's try to get back to intuition about what this optimization objective leads to and whether the source of the hypotheses SVM will learn and we'll also talk about how to modify this just a little bit to the complex nonlinear functions.
Sometimes people talk about support vector machines, as large margin classifiers, in this video I'd like to tell you what that means, and this will also give us a useful picture of what an SVM hypothesis may look like.
Now, let's think about what it takes to make these cost functions small.
If you have a positive example, so if y is equal to 1, then cost 1 of Z is zero only when Z is greater than or equal to 1.
And that would mean that we classify correctly because if theta transpose x is greater than zero our hypothesis will predict zero.
And similarly, if you have a negative example, then really all you want is that theta transpose x is less than zero and that will make sure we got the example right.
But the support vector machine wants a bit more than that.
What i really want is for this to be quite a lot bigger than zero say maybe bit greater or equal to one and I want this to be much less than zero.
Maybe I want it less than or equal to -1.
And so this builds in an extra safety factor or safety margin factor into the support vector machine.
Logistic regression does something similar too of course, but let's see what happens or let's see what the consequences of this are, in the context of the support vector machine.
Let's see what the support vector machine will do.
If C is very, very large, then when minimizing this optimization objective, we're going to be highly motivated to choose a value, so that this first term is equal to zero.
So let's try to understand the optimization problem in the context of, what would it take to make this first term in the objective equal to zero, because you know, maybe we'll set C to some huge constant, and this will hope, this should give us additional intuition about what sort of hypotheses a support vector machine learns.
So we saw already that whenever you have a training example with a label of y=1 if you want to make that first term zero, what you need is is to find a value of theta so that theta transpose x i is greater than or equal to 1.
And similarly, whenever we have an example, with label zero, in order to make sure that the cost, cost zero of Z, in order to make sure that cost is zero we need that theta transpose x i is less than or equal to -1.
So, if we think of our optimization problem as now, really choosing parameters and show that this first term is equal to zero, what we're left with is the following optimization problem.
For example, here is one decision boundary that separates the positive and negative examples, but somehow that doesn't look like a very natural one, right?
Or by drawing an even worse one, you know here's another decision boundary that separates the positive and negative examples but just barely.
The Support Vector Machines will instead choose this decision boundary, which I'm drawing in black.
And that seems like a much better decision boundary than either of the ones that I drew in magenta or in green.
The black line seems like a more robust separator, it does a better job of separating the positive and negative examples.
And mathematically, what that does is, this black decision boundary has a larger distance.
and then that seems to do a less a good job separating the positive and negative classes than my black line.
So the support vector machine is sometimes also called a large margin classifier and this is actually a consequence of the optimization problem we wrote down on the previous slide.
I know that you might be wondering how is it that the optimization problem I wrote down in the previous slide, how does that lead to this large margin classifier.
I know I haven't explained that yet.
And in the next video I'm going to sketch a little bit of the intuition about why that optimization problem gives us this large margin classifier.
But this is a useful feature to keep in mind if you are trying to understand what are the sorts of hypothesis that an SVM will choose.
That is, trying to separate the positive and negative examples with as big a margin as possible.
I want to say one last thing about large margin classifiers in this intuition, so we wrote out this large margin classification setting in the case of when C, that regularization concept, was very large, I think I set that to a hundred thousand or something.
So given a dataset like this, maybe we'll choose that decision boundary that separate the positive and negative examples on large margin.
Now, the SVM is actually sligthly more sophisticated than this large margin view might suggest.
And in particular, if all you're doing is use a large margin classifier then your learning algorithms can be sensitive to outliers, so lets just add an extra positive example like that shown on the screen.
If he had one example then it seems as if to separate data with a large margin, maybe I'll end up learning a decision boundary like that, right?
that is the magenta line and it's really not clear that based on the single outlier based on a single example and it's really not clear that it's actually a good idea to change my decision boundary from the black one over to the magenta one.
And of course if the data were not linearly separable so if you had some positive examples in here, or if you had some negative examples in here then the SVM will also do the right thing.
And so this picture of a large margin classifier that's really, that's really the picture that gives better intuition only for the case of when the regulations parameter C is very large, and just to remind you this corresponds C plays a role similar to one over Lambda, where Lambda is the regularization parameter we had previously.
And also do fine and do reasonable things even if your data is not linearly separable.
But when we talk about bias and variance in the context of support vector machines which will do a little bit later, hopefully all of of this trade-offs involving the regularization parameter will become clearer at that time.
So I hope that gives some intuition about how this support vector machine functions as a large margin classifier that tries to separate the data with a large margin, technically this picture of this view is true only when the parameter C is very large, which is a useful way to think about support vector machines.
In this video, I'd like to tell you a bit about the math behind large margin classification.
It may also give you better intuition about how the optimization problem of the support vex machine, how that leads to large margin classifiers.
In order to get started, let me first remind you of a couple of properties of what vector inner products look like.
Let's say I have two vectors U and V, that look like this.
And U transpose V is also called the inner products between the vectors U and V.
Use a two dimensional vector, so I can on plot it on this figure.
And what I mean by that is if on the horizontal axis that value takes whatever value U1 is and on the vertical axis the height of that is whatever U2 is the second component of the vector U.
Now, one quantity that will be nice to have is the norm of the vector U.
So, these are, you know, double bars on the left and right that denotes the norm or length of U.
So this just means; really the euclidean length of the vector U.
And this is the length of the vector U.
Just say you know, what is the length of this, what is the length of this vector down here.
Now let's go back and look at the vector V because we want to compute the inner product.
So V will be some other vector with, you know, some value V1, V2.
And so, the vector V will look like that, towards V like so.
Now let's go back and look at how to compute the inner product between U and V.
Let me take the vector V and project it down onto the vector U.
So I'm going to take a orthogonal projection or a 90 degree projection, and project it down onto U like so.
And what I'm going to do measure length of this red line that I just drew here.
So, I'm going to call the length of that red line P.
So, P is the length or is the magnitude of the projection of the vector V onto the vector U.
Let me just write that down.
So, P is the length of the projection of the vector V onto the vector U.
And it is possible to show that unit product U transpose V, that this is going to be equal to P times the norm or the length of the vector U.
So, this is one way to compute the inner product.
And if you actually do the geometry figure out what P is and figure out what the norm of U is.
This should give you the same way, the same answer as the other way of computing unit product.
Which is if you take U transpose V then U transposes this U1 U2, its a one by two matrix, 1 times V.
And so the theorem of linear algebra that these two formulas give you the same answer.
And by the way, U transpose V is also equal to V transpose U.
And just to clarify what's going on in this equation the norm of U is a real number and P is also a real number.
And so U transpose V is the regular multiplication as two real numbers of the length of P times the normal view.
Just one last detail, which is if you look at the norm of P, P is actually signed so to the right.
And it can either be positive or negative.
Then if I project V onto U, what I get is a projection it looks like this and so that length P.
And in this case, I will still have that U transpose V is equal to P times the norm of U.
So, you know, in inner products if the angle between U and V is less than ninety degrees, then P is the positive length for that red line whereas if the angle of this angle of here is greater than 90 degrees then P here will be negative of the length of the super line of that little line segment right over there.
So the inner product between two vectors can also be negative if the angle between them is greater than 90 degrees.
So that's how vector inner products work.
We're going to use these properties of vector inner product to try to understand the support vector machine optimization objective over there.
Here is the optimization objective for the support vector machine that we worked out earlier.
Just for the purpose of this slide I am going to make one simplification or once just to make the objective easy to analyze and what I'm going to do is ignore the indeceptrums.
To make things easier to plot, I'm also going to set N the number of features to be equal to 2.
So, we have only 2 features, X1 and X2.
Now, let's look at the objective function.
The optimization objective of the SVM.
This can be written, one half of theta one squared plus theta two squared.
Because we only have two parameters, theta one and thetaa two.
And the reason I can do that, is because for any number, you know, W, right, the square roots of W and then squared, that's just equal to W.
What you may notice is that this term inside is that's equal to the norm or the length of the vector theta and what I mean by that is that if we write out the vector theta like this, as you know theta one, theta two.
Then this term that I've just underlined in red, that's exactly the length, or the norm, of the vector theta.
We are calling the definition of the norm of the vector that we have on the previous line.
And in fact this is actually equal to the length of the vector theta, whether you write it as theta zero, theta 1, theta 2.
So it's not going to matter for the rest of our derivation.
And so finally this means that my optimization objective is equal to one half of the norm of theta squared.
So all the support vector machine is doing in the optimization objective is it's minimizing the squared norm of the square length of the parameter vector theta.
Now what I'd like to do is look at these terms, theta transpose X and understand better what they're doing.
So given the parameter vector theta and given and example x, what is this is equal to?
And on the previous slide, we figured out what U transpose V looks like, with different vectors U and V.
And so we're going to take those definitions, you know, with theta and X(i) playing the roles of U and V.
And let's see what that picture looks like.
Let's say I look at just a single training example.
Let's say I have a positive example the drawing was across there and let's say that is my example X(i), what that really means is plotted on the horizontal axis some value X(i) 1 and on the vertical axis X(i) 2.
And although we haven't been really thinking of this as a vector, what this really is, this is a vector from the origin from 0, 0 out to the location of this training example.
And now let's say we have a parameter vector and I'm going to plot that as vector, as well.
What I mean by that is if I plot theta 1 here and theta 2 there so what is the inner product theta transpose X(i).
While using our earlier method, the way we compute that is we take my example and project it onto my parameter vector theta.
And then I'm going to look at the length of this segment that I'm coloring in, in red.
And so what we have is that theta transpose X(i) is equal to following what we have on the previous slide, this is going to be equal to P times the length of the norm of the vector theta.
And this is of course also equal to theta 1 x1 plus theta 2 x2.
So each of these is, you know, an equally valid way of computing the inner product between theta and X(i).
Okay.
What this means is that, this constrains that theta transpose X(i) be greater than or equal to one or less than minus one.
Because theta transpose X(i) is equal to P(i) times the norm of theta.
This is what we get where I have, instead of theta transpose X(i), I now have this P(i) times the norm of theta.
And just to remind you we worked out earlier too that this optimization objective can be written as one half times the norm of theta squared.
So, now let's consider the training example that we have at the bottom and for now, continuing to use the simplification that theta 0 is equal to 0.
Let's see what decision boundary the support vector machine will choose.
Here's one option, let's say the support vector machine were to choose this decision boundary.
This is not a very good choice because it has very small margins.
This decision boundary comes very close to the training examples.
Let's see why the support vector machine will not do this.
For this choice of parameters it's possible to show that the parameter vector theta is actually at 90 degrees to the decision boundary.
And so, that green decision boundary corresponds to a parameter vector theta that points in that direction.
And by the way, the simplification that theta 0 equals 0 that just means that the decision boundary must pass through the origin, (0,0) over there.
So now, let's look at what this implies for the optimization objective.
Let's say that this example here.
If we look at the projection of this example onto my parameters theta.
And so that little red line segment.
And that is going to be pretty small, right.
And similarly, if this example here, if this happens to be X2, that's my second example.
Then, if I look at the projection of this this example onto theta.
That's the projection of the second example onto my, onto the direction of my parameter vector theta which goes like this.
And so, this little projection line segment is getting pretty small.
This vector has greater than 90 degree angle with my parameter vector theta, it's going to be less than 0.
And so what we're finding is that these terms P(i) are going to be pretty small numbers.
So if we look at the optimization objective and see, well, for positive examples we need P(i) times the norm of theta to be bigger than either one.
If P1 of theta is small and we want P1 you know times in all of theta to be bigger than either one, well the only way for that to be true for the profit that these two numbers to be large if P1 is small, as we said we want the norm of theta to be large.
And similarly for our negative example, we need P2 times the norm of theta to be less than or equal to minus one.
And we saw in this example already that P2 is going pretty small negative number, and so the only way for that to happen as well is for the norm of theta to be large, but what we are doing in the optimization objective is we are trying to find a setting of parameters where the norm of theta is small, and so you know, so this doesn't seem like such a good direction for the parameter vector and theta.
In contrast, just look at a different decision boundary.
Here, let's say, this SVM chooses that decision boundary.
Now the is going to be very different.
If that is the decision boundary, here is the corresponding direction for theta.
So, with the direction boundary you know, that vertical line that corresponds to it is possible to show using linear algebra that the way to get that green decision boundary is have the vector of theta be at 90 degrees to it, and now if you look at the projection of your data onto the vector x, lets say its before this example is my example of x1.
So when I project this on to x, or onto theta, what I find is that this is P1.
The other example, that example is and I do the same projection and what I find is that this length here is a P2 really that is going to be less than 0.
And you notice that now P1 and P2, these lengths of the projections are going to be much bigger, and so if we still need to enforce these constraints that P1 of the norm of theta is phase number one because P1 is so much bigger now.
And so, what this means is that by choosing the decision boundary shown on the right instead of on the left, the SVM can make the norm of the parameters theta much smaller.
So, if we can make the norm of theta smaller and therefore make the squared norm of theta smaller, which is why the SVM would choose this hypothesis on the right instead.
Mainly, if you look at this green line, if you look at this green hypothesis we want the projections of my positive and negative examples onto theta to be large, and the only way for that to hold true this is if surrounding the green line.
And so by making the margin large, by these tyros P1, P2, P3 and so on that's the SVM can end up with a smaller value for the norm of theta which is what it is trying to do in the objective.
And this is why this machine ends up with enlarge margin classifiers because itss trying to maximize the norm of these P1 which is the distance from the training examples to the decision boundary.
The effect of that as I mentioned briefly, is that if theta 0 is equal to 0 what that means is that we are entertaining decision boundaries that pass through the origins of decision boundaries pass through the origin like that, if you allow theta zero to be non 0 then what that means is that you entertain the decision boundaries that did not cross through the origin, like that one I just drew.
It turns out that this same large margin proof works in pretty much in exactly the same way.
And there's a generalization of this argument that we just went through them long ago through that shows that even when theta 0 is non 0, what the SVM is trying to do when you have this optimization objective.
But it is possible to show that, you know, when theta is not equal to 0 this support vector machine is still finding is really trying to find the large margin separator that between the positive and negative examples.
So that explains how this support vector machine is a large margin classifier.
In the next video we will start to talk about how to take some of these SVM ideas and start to apply them to build a complex nonlinear classifiers.
In this video, I'd like to start adapting support vector machines in order to develop complex nonlinear classifiers.
The main technique for doing that is something called kernels.
Let's see what this kernels are and how to use them.
If you have a training set that looks like this, and you want to find a nonlinear decision boundary to distinguish the positive and negative examples, maybe a decision boundary that looks like that.
One way to do so is to come up with a set of complex polynomial features, right?
So, set of features that looks like this, so that you end up with a hypothesis X that predicts 1 if you know that theta 0 and plus theta 1 X1 plus dot dot dot all those polynomial features is greater than 0, and predict 0, otherwise.
And another way of writing this, to introduce a level of new notation that I'll use later, is that we can think of a hypothesis as computing a decision boundary using this.
Where I'm going to use this new denotation f1, f2, f3 and so on to denote these new sort of features that I'm computing, so f1 is just X1, f2 is equal to X2, f3 is equal to this one here.
So, f4 is equal to X1 squared where f5 is to be x2 squared and so on and we seen previously that coming up with these high order polynomials is one way to come up with lots more features, the question is, is there a different choice of features or is there better sort of features than this high order polynomials because you know it's not clear that this high order polynomial is what we want, and what we talked about computer vision talk about when the input is an image with lots of pixels.
So, is there a different or a better choice of the features that we can use to plug into this sort of hypothesis form.
So, here is one idea for how to define new features f1, f2, f3.
On this line I am going to define only three new features, but for real problems we can get to define a much larger number.
But here's what I'm going to do in this phase of features X1, X2, and I'm going to leave X0 out of this, the interceptor X0, but in this phase X1 X2, I'm going to just, you know, manually pick a few points, and then call these points l1, we are going to pick a different point, let's call that l2 and let's pick the third one and call this one l3, and for now let's just say that I'm going to choose these three points manually.
What I'm going to do is define my new features as follows, given an example X, let me define my first feature f1 to be some measure of the similarity between my training example X and my first landmark and this specific formula that I'm going to use to measure similarity is going to be this is E to the minus the length of X minus l1, squared, divided by two sigma squared.
So, depending on whether or not you watched the previous optional video, this notation, you know, this is the length of the vector W.
And so, this thing here, this X minus l1, this is actually just the euclidean distance squared, is the euclidean distance between the point x and the landmark l1.
We will see more about this later.
But that's my first feature, and my second feature f2 is going to be, you know, similarity function that measures how similar X is to l2 and the game is going to be defined as the following function.
And what this similarity function is, the mathematical term for this, is that this is going to be a kernel function.
And the specific kernel I'm using here, this is actually called a Gaussian kernel.
And so this formula, this particular choice of similarity function is called a Gaussian kernel.
But the way the terminology goes is that, you know, in the abstract these different similarity functions are called kernels and we can have different similarity functions and the specific example I'm giving here is called the Gaussian kernel.
But for now just think of these as similarity functions.
And so, instead of writing similarity between X and l, sometimes we also write this a kernel denoted you know, lower case k between x and one of my landmarks all right.
So let's see what a criminals actually do and why these sorts of similarity functions, why these expressions might make sense.
Just to make sure, you know, we are on the same page about what the numerator term is, the numerator can also be written as a sum from J equals 1 through N on sort of the distance.
So this is the component wise distance between the vector X and the vector l.
So just ignoring the intercept term X0, which is always equal to 1.
So, you know, this is how you compute the kernel with similarity between X and a landmark.
So let's see what this function does.
Suppose X is close to one of the landmarks.
Then this euclidean distance formula and the numerator will be close to 0, right.
And I'll put the approximation symbol here because the distance may not be exactly 0, but if X is closer to landmark this term will be close to 0 and so f1 would be close 1.
Conversely, if X is far from 01 then this first feature f1 will be E to the minus of some large number squared, divided divided by two sigma squared and E to the minus of a large number is going to be close to 0.
So what these features do is they measure how similar X is from one of your landmarks and the feature f is going to be close to one when X is close to your landmark and is going to be 0 or close to zero when X is far from your landmark.
That is, given the the training example X, we can now compute three new features: f1, f2, and f3, given, you know, the three landmarks that I wrote just now.
For this example, let's say I have two features X1 and X2.
And let's say my first landmark, l1 is at a location, 3 5.
So and let's say I set sigma squared equals one for now.
Given a certain training example, the training example here which shows the value of x1 and x2 at a height above the surface, shows the corresponding value of f1 and down below this is the same figure I had showed, using a quantifiable plot, with x1 on horizontal axis, x2 on horizontal axis and so, this figure on the bottom is just a contour plot of the 3D surface.
You notice that when X is equal to 3 5 exactly, then we the f1 takes on the value 1, because that's at the maximum and X moves away as X goes further away then this feature takes on values that are close to 0.
And so, this is really a feature, f1 measures, you know, how close X is to the first landmark and if varies between 0 and one depending on how close X is to the first landmark l1.
Now the other was due on this slide is show the effects of varying this parameter sigma squared.
So, sigma squared is the parameter of the Gaussian kernel and as you vary it, you get slightly different effects.
We set sigma square to 0.5, what you find is that the kernel looks similar, except for the width of the bump becomes narrower.
So if sigma squared equals to 0.5 then as you start from X equals 3 5 and as you move away, then the feature f1 falls to zero much more rapidly and conversely, if you has increase since where three in that case and as I move away from, you know l.
So it's shown up here.
And if sigma squared is large, then as you move away from l1, the value of the feature falls away much more slowly.
So, given this definition of the features, let's see what source of hypothesis we can learn.
Given the training example X, we are going to compute these features f1, f2, f3 and a hypothesis is going to predict one when theta 0 plus theta 1 f1 plus theta 2 f2, and so on is greater than or equal to 0.
For this particular example, let's say that I've already found a learning algorithm and let's say that, you know, somehow I ended up with these values of the parameter.
So let's say I have a training example X, what would my hypothesis predict?
Well, If I look at this formula.
Because my training example X is close to l1, we have that f1 is going to be close to 1 the because my training example X is far from l2 and l3 I have that, you know, f2 would be close to 0 and f3 will be close to 0.
Which is equal to 0.5 which is greater than or equal to 0.
So, at this point, we're going to predict Y equals 1, because that's greater than or equal to zero.
Now let's take a different point.
And so, we have theta 0 plus theta 1, f1, plus so on and this will be about equal to minus 0.5, because theta 0 is minus 0.5 and f1, f2, f3 are all zero.
So this will be minus 0.5, this is less than zero.
And if you do this yourself for a range of different points, be sure to convince yourself that if you have a training example that's close to L2, say, then at this point we'll also predict Y equals one.
And in fact, what you end up doing is, you know, if you look around this boundary, this space, what we'll find is that for points near l1 and l2 we end up predicting positive.
And for points far away from l1 and l2, that's for points far away from these two landmarks, we end up predicting that the class is equal to 0.
As so, what we end up doing,is that the decision boundary of this hypothesis would end up looking something like this where inside this red decision boundary would predict Y equals 1 and outside we predict Y equals 0.
We can learn pretty complex non-linear decision boundary, like what I just drew where we predict positive when we're close to either one of the two landmarks.
And so this is part of the idea of kernels of and how we use them with the support vector machine, which is that we define these extra features using landmarks and similarity functions to learn more complex nonlinear classifiers.
So hopefully that gives you a sense of the idea of kernels and how we could use it to define new features for the Support Vector Machine.
But there are a couple of questions that we haven't answered yet.
One is, how do we get these landmarks?
How do we choose these landmarks?
And another is, what other similarity functions, if any, can we use other than the one we talked about, which is called the Gaussian kernel.
In the next video we give answers to these questions and put everything together to show how support vector machines with kernels can be a powerful way to learn complex nonlinear functions.
So far we've been talking about SVMs in a fairly abstract level.
In this video I'd like to talk about what you actually need to do in order to run or to use an SVM.
The support vector machine algorithm poses a particular optimization problem.
But as I briefly mentioned in an earlier video, I really do not recommend writing your own software to solve for the parameter's theta yourself.
So just as today, very few of us, or maybe almost essentially none of us would think of writing code ourselves to invert a matrix or take a square root of a number, and so on.
So you come up with good software libraries and good software packages to do this.
And then strongly recommend just using one of the highly optimized software libraries rather than trying to implement something yourself.
And there are lots of good software libraries out there.
The two that I happen to use the most often are the linear SVM but there are really lots of good software libraries for doing this that you know, you can link to many of the major programming languages that you may be using to code up learning algorithm.
Even though you shouldn't be writing your own SVM optimization software, there are a few things you need to do, though.
First is to come up with with some choice of the parameter's C.
We talked a little bit of the bias/variance properties of this in the earlier video.
Second, you also need to choose the kernel or the similarity function that you want to use.
And the idea of no kernel is also called a linear kernel.
This term linear kernel, you can think of this as you know this is the version of the SVM that just gives you a standard linear classifier.
So that would be one reasonable choice for some problems, and you know, there would be many software libraries, like linear, was one example, out of many, one example of a software library that can train an SVM without using a kernel, also called a linear kernel.
So, why would you want to do this?
If you have a large number of features, if N is large, and M the number of training examples is small, then you know you have a huge number of features that if X, this is an X is an Rn, Rn +1.
So if you have a huge number of features already, with a small training set, you know, maybe you want to just fit a linear decision boundary and not try to fit a very complicated nonlinear function, because might not have enough data.
And you might risk overfitting, if you're trying to fit a very complicated function in a very high dimensional feature space, but if your training set sample is small.
So this would be one reasonable setting where you might decide to just not use a kernel, or equivalents to use what's called a linear kernel.
A second choice for the kernel that you might make, is this Gaussian kernel, and this is what we had previously.
And if you do this, then the other choice you need to make is to choose this parameter sigma squared when we also talk a little bit about the bias variance tradeoffs of how, if sigma squared is large, then you tend to have a higher bias, lower variance classifier, but if sigma squared is small, then you have a higher variance, lower bias classifier.
So when would you choose a Gaussian kernel?
Well, if your omission of features X, I mean Rn, and if N is small, and, ideally, you know, if n is large, right, so that's if, you know, we have say, a two-dimensional training set, like the example I drew earlier.
So n is equal to 2, but we have a pretty large training set.
I'll say more towards the end of the video, a little bit more about when you might choose a linear kernel, a Gaussian kernel and so on.
But if concretely, if you decide to use a Gaussian kernel, then here's what you need to do.
Depending on what support vector machine software package you use, it may ask you to implement a kernel function, or to implement the similarity function.
So if you're using an octave or MATLAB implementation of an SVM, it may ask you to provide a function to compute a particular feature of the kernel.
But what you need to do is write software that takes this input, you know, X1, X2 and computes this sort of similarity function between them and return a real number.
And so what some support vector machine packages do is expect you to provide this kernel function that take this input you know, X1, X2 and returns a real number.
And then it will take it from there and it will automatically generate all the features, and so automatically take X and map it to f1, f2, down to f(m) using this function that you write, and generate all the features and train the support vector machine from there.
But sometimes you do need to provide this function yourself.
Other if you are using the Gaussian kernel, some SVM implementations will also include the Gaussian kernel and a few other kernels as well, since the Gaussian kernel is probably the most common kernel.
If you have features of very different scales, it is important to perform feature scaling before using the Gaussian kernel.
What this is doing, the norm between X and l, that's really saying, you know, let's compute the vector V, which is equal to X minus l.
And then let's compute the norm does vector V, which is the difference between X.
Because here X is in Rn, or Rn plus 1, but I'm going to ignore, you know, X0.
So, let's pretend X is an Rn, square on the left side is what makes this correct.
And if X is in the range of thousands of square feet, for the first feature, X1.
So if this is in the range of one to five bedrooms, then X1 minus l1 is going to be huge.
This could be like a thousand squared, whereas X2 minus l2 is going to be much smaller and if that's the case, then in this term, those distances will be almost essentially dominated by the sizes of the houses and the number of bathrooms would be largely ignored.
As so as, to avoid this in order to make a machine work well, do perform future scaling.
And that will sure that the SVM gives, you know, comparable amount of attention to all of your different features, and not just to in this example to size of houses were big movement here the features.
When you try a support vector machines chances are by far the two most common kernels you use will be the linear kernel, meaning no kernel, or the Gaussian kernel that we talked about.
And just one note of warning which is that not all similarity functions you might come up with are valid kernels.
And the Gaussian kernel and the linear kernel and other kernels that you sometimes others will use, all of them need to satisfy a technical condition.
It's called Mercer's Theorem and the reason you need to this is because support vector machine algorithms or implementations of the SVM have lots of clever numerical optimization tricks.
In order to solve for the parameter's theta efficiently and in the original design envisaged, those are decision made to restrict our attention only to kernels that satisfy this technical condition called Mercer's Theorem.
And what that does is, that makes sure that all of these SVM packages, all of these SVM software packages can use the large class of optimizations and get the parameter theta very quickly.
Just to mention some of the other kernels that you may run across.
And for that the similarity between X and l is defined as, there are a lot of options, you can take X transpose l squared.
So, here's one measure of how similar X and l are.
If X and l are very close with each other, then the inner product will tend to be large.
And so, you know, this is a slightly unusual kernel.
That is not used that often, but you may run across some people using it.
This is one version of a polynomial kernel.
These are all examples of the polynomial kernel.
X transpose l plus maybe a number different then one 5 and, you know, to the power of 4 and so the polynomial kernel actually has two parameters.
One is, what number do you add over here?
It could be 0.
This is really plus 0 over there, as well as what's the degree of the polynomial over there.
So the degree power and these numbers.
And the more general form of the polynomial kernel is X transpose l, plus some constant and then to some degree in the X1 and so both of these are parameters for the polynomial kernel.
Usually it is used only for data where X and l are all strictly non negative, and so that ensures that these inner products are never negative.
And this captures the intuition that X and l are very similar to each other, then maybe the inter product between them will be large.
They have some other properties as well but people tend not to use it much.
And then, depending on what you're doing, there are other, sort of more esoteric kernels as well, that you may come across.
You know, there's a string kernel, this is sometimes used if your input data is text strings or other types of strings.
There are sort of more esoteric kernels that you can use to measure similarity between different objects.
So for example, if you're trying to do some sort of text classification problem, where the input x is a string then maybe we want to find the similarity between two strings using the string kernel, but I personally you know end up very rarely, if at all, using these more esoteric kernels.
I think I might have use the chi-square kernel, may be once in my life and the histogram kernel, may be once or twice in my life.
I've actually never used the string kernel myself.
You know, if you do a quick web search we do a quick Google search or quick Bing search you should have found definitions that these are the kernels as well.
So just two last details I want to talk about in this video.
One in multiclass classification.
Most SVM, many SVM packages already have built-in multiclass classification functionality.
So if your using a pattern like that, you just use the both that functionality and that should work fine.
Otherwise, one way to do this is to use the one versus all method that we talked about when we are developing logistic regression.
So what you do is you trade kSVM's if you have k classes, one to distinguish each of the classes from the rest.
theta 1, which is trying to distinguish class y equals one from all of the other classes, then you get the second parameter, vector theta 2, which is what you get when you, you know, have y equals 2 as the positive class and all the others as negative class and so on up to a parameter vector theta k, which is the parameter vector for distinguishing the final class key from anything else, and then lastly, this is exactly the same as the one versus all method we have for logistic regression.
Where we you just predict the class i with the largest theta transpose X.
For the more common cases that there is a good chance that whatever software package you use, you know, there will be a reasonable chance that are already have built in multiclass classification functionality, and so you don't need to worry about this result.
Finally, we developed support vector machines starting off with logistic regression and then modifying the cost function a little bit.
The last thing we want to do in this video is, just say a little bit about.
when you will use one of these two algorithms, so let's say n is the number of features and m is the number of training examples.
So, when should we use one algorithm versus the other?
Well, if n is larger relative to your training set size, so for example, if you take a business with a number of features this is much larger than m and this might be, for example, if you have a text classification problem, where you know, the dimension of the feature vector is I don't know, maybe, 10 thousand.
So, imagine a spam classification problem, where email spam, where you have 10,000 features corresponding to 10,000 words but you have, you know, maybe 10 training examples or maybe up to 1,000 examples.
So if n is large relative to m, then what I would usually do is use logistic regression or use it as the m without a kernel or use it with a linear kernel.
Because, if you have so many features with smaller training sets, you know, a linear function will probably do fine, and you don't have really enough data to fit a very complicated nonlinear function.
Now if is n is small and m is intermediate what I mean by this is n is maybe anywhere from 1 - 1000, 1 would be very small.
If m is pretty big like maybe 10,000 but not a million.
So if m is an intermediate size then often an SVM with a linear kernel will work well.
So, if n is equal to 2 where you have, you know, drawing in a pretty large number of training examples.
One third setting that's of interest is if n is small but m is large.
If you have, you know, maybe 50 thousands okay, but if you have a million training examples, maybe or even a 100,000 with a massive value of m.
Today's SVM packages are very good, but they can still struggle a little bit when you have a massive, massive trainings that size when using a Gaussian Kernel.
So in that case, what I would usually do is try to just manually create have more features and then use logistic regression or an SVM without the Kernel.
And in case you look at this slide and you see logistic regression or SVM without a kernel.
There's a reason for that, is that logistic regression and SVM without the kernel, those are really pretty similar algorithms and, you know, either logistic regression or SVM without a kernel will usually do pretty similar things and give pretty similar performance, but depending on your implementational details, one may be more efficient than the other.
But, where one of these algorithms applies, logistic regression where SVM without a kernel, the other one is to likely to work pretty well as well.
But along with the power of the SVM is when you use different kernels to learn complex nonlinear functions.
And this regime, you know, when you have maybe up to 10,000 examples, maybe up to 50,000.
That's a very common regime and maybe that's a regime where a support vector machine with a kernel kernel will shine.
And finally, where do neural networks fit in?
Well for all of these problems, for all of these different regimes, a well designed neural network is likely to work well as well.
The one disadvantage, or the one reason that might not sometimes use the neural network is that, for some of these problems, the neural network might be slow to train.
But if you have a very good SVM implementation package, that could run faster, quite a bit faster than your neural network.
And, although we didn't show this earlier, it turns out that the optimization problem that the SVM has is a convex optimization problem and so the good SVM optimization software packages will always find the global minimum or something close to it.
And so for the SVM you don't need to worry about local optima.
In practice local optima aren't a huge problem for neural networks but they all solve, so this is one less thing to worry about if you're using an SVM.
And depending on your problem, the neural network may be slower, especially in this sort of regime than the SVM.
In case the guidelines they gave here, seem a little bit vague and if you're looking at some problems, you know, the guidelines are a bit vague, I'm still not entirely sure, should I use this algorithm or that algorithm, that's actually okay.
And how skilled are you, how good are you at doing error analysis and debugging learning algorithms, figuring out how to design new features and figuring out what other features to give you learning algorithms and so on.
And often those things will matter more than what you are using logistic regression or an SVM.
And so I actually, together with logistic regressions, neural networks, SVM's, using those to speed learning algorithms you're I think very well positioned to build state of the art you know, machine learning systems for a wide region for applications and this is another very powerful tool to have in your arsenal.
One that is used all over the place in Silicon Valley, or in industry and in the Academia, to build many high performance machine learning system.
In this video, I'd like to start to talk about clustering.
This will be exciting, because this is our first unsupervised learning algorithm, where we learn from unlabeled data instead from labelled data.
So, what is unsupervised learning?
I briefly talked about unsupervised learning at the beginning of the class but it's useful to contrast it with supervised learning.
So, here's a typical supervised learning problem where we're given a labeled training set and the goal is to find the decision boundary that separates the positive label examples and the negative label examples.
So, the supervised learning problem in this case is given a set of labels to fit a hypothesis to it.
In contrast, in the unsupervised learning problem we're given data that does not have any labels associated with it.
And that's why the points plotted up on the figure don't have any labels with them.
So, in unsupervised learning what we do is we give this sort of unlabeled training set to an algorithm and we just ask the algorithm find some structure in the data for us.
Given this data set one type of structure we might have an algorithm find is that it looks like this data set has points grouped into two separate clusters and so an algorithm that finds clusters like the ones I've just circled is called a clustering algorithm.
And this would be our first type of unsupervised learning, although there will be other types of unsupervised learning algorithms that we'll talk about later that finds other types of structure or other types of patterns in the data other than clusters.
So, what is clustering good for?
Early in this class I already mentioned a few applications.
One is market segmentation where you may have a database of customers and want to group them into different marker segments so you can sell to them separately or serve your different market segments better.
So, things like Facebook, Google+, or maybe information about who other people that you email the most frequently and who are the people that they email the most frequently and to find coherence in groups of people.
So, this would be another maybe clustering algorithm where you know want to find who are the coherent groups of friends in the social network?
Here's something that one of my friends actually worked on which is, use clustering to organize computer clusters or to organize data centers better.
Because if you know which computers in the data center in the cluster tend to work together, you can use that to reorganize your resources and how you layout the network and how you design your data center communications.
And lastly, something that actually another friend worked on using clustering algorithms to understand galaxy formation and using that to understand astronomical data.
So, that's clustering which is our first example of an unsupervised learning algorithm.
In the clustering problem we are given an unlabeled data set and we would like to have an algorithm automatically group the data into coherent subsets or into coherent clusters for us.
The K means clustering algorithm is best illustrated in pictures.
Let's say I want to take an unlabeled data set like the one shown here, and I want to group the data into two clusters.
If I run the K Means clustering algorithm, here is what I'm going to do.
The first step is to randomly initialize two points, called the cluster centroids.
So, these two crosses here, these are called the Cluster Centroids and I have two of them because I want to group my data into two clusters.
K Means is an iterative algorithm and it does two things.
First is a cluster assignment step, and second is a move centroid step.
The first of the two steps in the loop of K means, is this cluster assignment step.
What that means is that, it's going through each of the examples, each of these green dots shown here and depending on whether it's closer to the red cluster centroid or the blue cluster centroid, it is going to assign each of the data points to one of the two cluster centroids.
Specifically, what I mean by that, is to go through your data set and color each of the points either red or blue, depending on whether it is closer to the red cluster centroid or the blue cluster centroid, and I've done that in this diagram here.
The other part of K means, in the loop of K means, is the move centroid step, and what we are going to do is, we are going to take the two cluster centroids, that is, the red cross and the blue cross, and we are going to move them to the average of the points colored the same colour.
So what we are going to do is look at all the red points and compute the average, really the mean of the location of all the red points, and we are going to move the red cluster centroid there.
And the same things for the blue cluster centroid, look at all the blue dots and compute their mean, and then move the blue cluster centroid there.
So, let me do that now.
The red one moved like that and the blue one moved like that and the red one moved like that.
And then we go back to another cluster assignment step, so we're again going to look at all of my unlabeled examples and depending on whether it's closer the red or the blue cluster centroid, I'm going to color them either red or blue.
I'm going to assign each point to one of the two cluster centroids, so let me do that now.
And so the colors of some of the points just changed.
So I'm going to compute the average of all the blue points, compute the average of all the red points and move my cluster centroids like this, and so, let's do that again.
Let me do one more cluster assignment step.
So colour each point red or blue, based on what it's closer to and then do another move centroid step and we're done.
And in fact if you keep running additional iterations of K means from here the cluster centroids will not change any further and the colours of the points will not change any further.
The K means algorithm takes two inputs.
One is a parameter K, which is the number of clusters you want to find in the data.
I'll later say how we might go about trying to choose k, but for now let's just say that we've decided we want a certain number of clusters and we're going to tell the algorithm how many clusters we think there are in the data set.
And then K means also takes as input this sort of unlabeled training set of just the Xs and because this is unsupervised learning, we don't have the labels Y anymore.
And for unsupervised learning of the K means I'm going to use the convention that XI is an RN dimensional vector.
The first step is that it randomly initializes k cluster centroids which we will call mu 1, mu 2, up to mu k.
And so in the earlier diagram, the cluster centroids corresponded to the location of the red cross and the location of the blue cross.
So there we had two cluster centroids, so maybe the red cross was mu 1 and the blue cross was mu 2, and more generally we would have k cluster centroids rather than just 2.
Then the inner loop of k means does the following, we're going to repeatedly do the following.
First for each of my training examples, I'm going to set this variable CI to be the index 1 through K of the cluster centroid closest to XI.
So this was my cluster assignment step, where we took each of my examples and coloured it either red or blue, depending on which cluster centroid it was closest to.
If I write the norm between Xi minus Mu-k, then this is the distance between my ith training example Xi and the cluster centroid Mu subscript K, this is--this here, that's a lowercase K.
So uppercase K is going to be used to denote the total number of cluster centroids, and this lowercase K's a number between one and capital K.
So we think of Ci as picking the cluster centroid with the smallest squared distance to my training example Xi.
But of course minimizing squared distance, and minimizing distance that should give you the same value of Ci, but we usually put in the square there, just as the convention that people use for K means.
The other in the loop of K means does the move centroid step.
And what that does is for each of my cluster centroids, so for lower case k equals 1 through K, it sets Mu-k equals to the average of the points assigned to cluster.
So as a concrete example, let's say that one of my cluster centroids, let's say cluster centroid two, has training examples, you know, 1, 5, 6, and 10 assigned to it.
And what this means is, really this means that C1 equals to C5 equals to C6 equals to and similarly well c10 equals, too, right?
If we got that from the cluster assignment step, then that means examples 1,5,6 and 10 were assigned to the cluster centroid two.
Then in this move centroid step, what I'm going to do is just compute the average of these four things.
And now I'm going to average them so here I have four points assigned to this cluster centroid, just take one quarter of that.
And now Mu2 is going to be an n-dimensional vector.
This has the effect of moving mu-2 to the average of the four points listed here.
One thing that I've asked is, well here we said, let's let mu-k be the average of the points assigned to the cluster.
But what if there is a cluster centroid no points with zero points assigned to it.
In that case the more common thing to do is to just eliminate that cluster centroid.
Before wrapping up this video I just want to tell you about one other common application of K Means and that's to the problems with non well separated clusters.
Here's what I mean.
But it turns out that very often K Means is also applied to data sets that look like this where there may not be several very well separated clusters.
Let's say you are a t-shirt manufacturer you've done is you've gone to the population that you want to sell t-shirts to, and you've collected a number of examples of the height and weight of these people in your population and so, well I guess height and weight tend to be positively highlighted so maybe you end up with a data set like this, you know, with a sample or set of examples of different peoples heights and weight.
Let's say I want to design and sell t shirts of three sizes, small, medium and large.
So how big should I make my small one?
So, even though the data, you know, before hand it didn't seem like we had 3 well separated clusters, K Means will kind of separate out the data into multiple pluses for you.
And this is in fact kind of an example of market segmentation where you're using K Means to separate your market into 3 different segments.
So you can design a product separately that is a small, medium, and large t-shirts, that tries to suit the needs of each of your 3 separate sub-populations well.
So that's the K Means algorithm.
And by now you should know how to implement the K Means Algorithm and kind of get it to work for some problems.
But in the next few videos what I want to do is really get more deeply into the nuts and bolts of K means and to talk a bit about how to actually get this to work really well.
Most of the supervised learning algorithms we've seen, things like linear regression, logistic regression, and so on, all of those algorithms have an optimization objective or some cost function that the algorithm was trying to minimize.
It turns out that k-means also has an optimization objective or a cost function that it's trying to minimize.
And the reason I want to do so is because this will be useful to us for two purposes.
First, knowing what is the optimization objective of k-means will help us to debug the learning algorithm and just make sure that k-means is running correctly.
And second, and perhaps more importantly, in a later video we'll talk about how we can use this to help k-means find better costs for this and avoid the local ultima.
But we do that in a later video that follows this one.
Just as a quick reminder while k-means is running we're going to be keeping track of two sets of variables.
First is the ci's and that keeps track of the index or the number of the cluster, to which an example xi is currently assigned.
Again, for k-means we use capital K to denote the total number of clusters.
And here lower case k is going to be an index into the cluster centroids and so, lower case k is going to be a number between one and capital K.
Now here's one more bit of notation, which is gonna use mu subscript ci to denote the cluster centroid of the cluster to which example xi has been assigned, right?
Right?
And so this mu subscript ci is the cluster centroid of cluster number five, which is the cluster to which my example xi has been assigned.
Out with this notation, we're now ready to write out what is the optimization objective of the k-means clustering algorithm and here it is.
The cost function that k-means is minimizing is a function J of all of these parameters, c1 through cm and mu 1 through mu K.
And the optimization objective is shown to the right, is the average of 1 over m of sum from i equals 1 through m of this term here.
The square distance between each example xi and the location of the cluster centroid to which xi has been assigned.
So let's draw this and just let me explain this.
Right, so here's the location of training example xi and here's the location of the cluster centroid to which example xi has been assigned.
So to explain this in pictures, if here's x1, x2, and if a point here is my example xi, so if that is equal to my example xi, and if xi has been assigned to some cluster centroid, I'm gonna denote my cluster centroid with a cross, so if that's the location of mu 5, let's say.
If x i has been assigned cluster centroid five as in my example up there, then this square distance, that's the square of the distance between the point xi and this cluster centroid to which xi has been assigned.
And what k-means can be shown to be doing is that it is trying to define parameters ci and mu i.
Trying to find c and mu to try to minimize this cost function J.
This cost function is sometimes also called the distortion cost function, or the distortion of the k-means algorithm.
And just to provide a little bit more detail, here's the k-means algorithm.
Here's exactly the algorithm as we have written it out on the earlier slide.
And what this first step of this algorithm is, this was the cluster assignment step where we assigned each point to the closest centroid.
And it's possible to show mathematically that what the cluster assignment step is doing is exactly Minimizing J, with respect to the variables c1, c2 and so on, up to cm, while holding the cluster centroids mu 1 up to mu K, fixed.
So what the cluster assignment step does is it doesn't change the cluster centroids, but what it's doing is this is exactly picking the values of c1, c2, up to cm.
But it has a pretty intuitive meaning of just well, let's assign each point to a cluster centroid that is closest to it, because that's what minimizes the square of distance between the points in the cluster centroid.
And once again I won't prove it, but it can be shown mathematically that what the move centroid step does is it chooses the values of mu that minimizes J, so it minimizes the cost function J with respect to, wrt is my abbreviation for, with respect to, when it minimizes J with respect to the locations of the cluster centroids mu 1 through mu K.
And what it does is it first minimizes J with respect to the variable c and then it minimizes J with respect to the variables mu and then it keeps on.
And, so all that's all that k-means does.
So, we now understand the k-means algorithm as trying to optimize this cost function J, which is also called the distortion function.
We can use that to debug k-means and help make sure that k-means is converging and is running properly.
And in the next video we'll also see how we can use this to help k-means find better clusters and to help k-means to avoid
Hello and welcome to advanced competitive strategy.
My name is Tobias Kretschmer and I'm a professor of , strategy technology and organization at Ludwig- Maximilians-University or LMU in Munich.
We are about to start a new course and a new adventure.
Advanced competitive strategy consists of seven different modules in which you will learn how you can apply business strategy in competitive situations.
Each one of our seven modules consists of a variety of around 10 different videos all of which include one or two individual quizzes, that are going to let you test your newly acquired knowledge immediately.
And of course, they should also be fun.
There will also be a longer quiz at the end of each module.
So, once you've completed all seven modules, you can also eventually take the final exam.
And please, do check out our forum.
Because it's a brilliant opportunity to connect to fellow students, to build study groups, to openly discuss questions, and to communicate with our wonderful and knowledgeable taching assistants.
In this video, I'd like to talk about how to initialize K-means and more importantly, this will lead into a discussion of how to make K-means avoid local optima as well.
Here's the K-means clustering algorithm that we talked about earlier.
One step that we never really talked much about was this step of how you randomly initialize the cluster centroids.
But, it turns out that there is one method that is much more recommended than most of the other options one might think about.
So, let me tell you about that option since it's what often seems to work best.
When running K-means, you should have the number of cluster centroids, K, set to be less than the number of training examples M.
It would be really weird to run K-means with a number of cluster centroids that's, you know, equal or greater than the number of examples you have, right?
So the way I usually initialize K-means is, I would randomly pick k training examples.
Lets say that k is equal to 2 and so on this example on the right let's say I want to find two clusters.
So that's my first cluster centroid and that's my second cluster centroid, and that's one random initialization of K-means.
And sometimes I might get less lucky and maybe I'll end up picking that as my first random initial example, and that as my second one.
Some we have randomly picked two training examples and if I chose those two then I'll end up with, may be this as my first cluster centroid and that as my second initial location of the cluster centroid.
And so at initialization, your first cluster centroid Mu1 will be equal to x(i) for some randomly value of i and Mu2 will be equal to x(j) for some different randomly chosen value of j and so on, if you have more clusters and more cluster centroid.
I should say that in the earlier video where I first illustrated K-means with the animation.
Only for the purpose of illustration.
But the method described on this slide, this is really the recommended way.
And the way that you should probably use, when you implement K-means.
You might really guess that K-means can end up converging to different solutions depending on exactly how the clusters were initialized, and so, depending on the random initialization.
K-means can end up at different solutions.
And, in particular, K-means can actually end up at local optima.
If you're given the data sale like this.
Well, it looks like, you know, there are three clusters, and so, if you run K-means and if it ends up at a good local optima this might be really the global optima, you might end up with that cluster ring.
But if you had a particularly unlucky, random initialization, K-means can also get stuck at different local optima.
So, in this example on the left it looks like this blue cluster has captured a lot of points of the left and then the they were on the green clusters each is captioned on the relatively small number of points.
And the term local optima, by the way, refers to local optima of this distortion function J, and what these solutions on the lower left, what these local optima correspond to is really solutions where K-means has gotten stuck to the local optima and it's not doing a very good job minimizing this distortion function J.
So, if you're worried about K-means getting stuck in local optima, if you want to increase the odds of K-means finding the best possible clustering, like that shown on top here, what we can do, is try multiple, random initializations.
So, instead of just initializing K-means once and hopping that that works, what we can do is, initialize K-means lots of times and run K-means lots of times, and use that to try to make sure we get as good a solution, as good a local or global optima as possible.
Concretely, here's how you could go about doing that.
So, let's say you decide to say K-means one hundred times.
So what that means is that we would randomnly initialize K-means.
You will have a hundred different ways of clustering the data and then finally what you do is all of these hundred ways you have found of clustering the data, just pick one, that gives us the lowest cost.
And it turns out that if you are running K-means with a fairly small number of clusters , so you know if the number of clusters is anywhere from two up to maybe 10 - then doing multiple random initializations can often, can sometimes make sure that you find a better local optima.
But it's really in the regime of where you have a relatively small number of clusters, especially if you have, maybe 2 or 3 or 4 clusters that random initialization could make a huge difference in terms of making sure you do a good job minimizing the distortion function and giving you a good clustering.
So, that's K-means with random initialization.
If you're trying to learn a clustering with a relatively small number of clusters, 2, 3, 4, 5, maybe, 6, 7, using multiple random initializations can sometimes, help you find much better clustering of the data.
But, even if you are learning a large number of clusters, the initialization, the random initialization method that I describe here.
In this video I'd like to talk about one last detail of K-means clustering which is how to choose the number of clusters, or how to choose the value of the parameter capsule K.
To be honest, there actually isn't a great way of answering this or doing this automatically and by far the most common way of choosing the number of clusters, is still choosing it manually by looking at visualizations or by looking at the output of the clustering algorithm or something else.
But I do get asked this question quite a lot of how do you choose the number of clusters, and so I just want to tell you know what are peoples' current thinking on it although, the most common thing is actually to choose the number of clusters by hand.
A large part of why it might not always be easy to choose the number of clusters is that it is often generally ambiguous how many clusters there are in the data.
Or some of you may see two clusters and that will suggest K equals 2 and now this may see three clusters.
And so, looking at the data set like this, the true number of clusters, it actually seems genuinely ambiguous to me, and I don't think there is one right answer.
And this is part of our supervised learning.
We are aren't given labels, and so there isn't always a clear cut answer.
And this is one of the things that makes it more difficult to say, have an automatic algorithm for choosing how many clusters to have.
When people talk about ways of choosing the number of clusters, one method that people sometimes talk about is something called the Elbow Method.
So the Elbow Method, what we're going to do is vary K, which is the total number of clusters.
So, we're going to run K-means with one cluster, that means really, everything gets grouped into a single cluster and compute the cost function or compute the distortion J and plot that here.
And then we're going to run K means with two clusters, maybe with multiple random initial agents, maybe not.
But then, you know, with two clusters we should get, hopefully, a smaller distortion, and so plot that there.
And then run K-means with three clusters, hopefully, you get even smaller distortion and plot that there.
And so we end up with a curve showing how the distortion, you know, goes down as we increase the number of clusters.
And so we get a curve that maybe looks like this.
Right, this is, would be by analogy to the human arm where, you know, if you imagine that you reach out your arm, then, this is your shoulder joint, this is your elbow joint and I guess, your hand is at the end over here.
And so this is the Elbow Method.
That it goes down, distortion goes down rapidly until K equals 3, really goes down very slowly after that.
If you apply the Elbow Method, and if you get a plot that actually looks like this, then, that's pretty good, and this would be a reasonable way of choosing the number of clusters.
It turns out the Elbow Method isn't used that often, and one reason is that, if you actually use this on a clustering problem, it turns out that fairly often, you know, you end up with a curve that looks much more ambiguous, maybe something like this.
And so, if you actually do this in a practice, you know, if your plot looks like the one on the left and that's great.
It gives you a clear answer, but just as often, you end up with a plot that looks like the one on the right and is not clear where the ready location of the elbow is.
It makes it harder to choose a number of clusters using this method.
So maybe the quick summary of the Elbow Method is that is worth the shot but I wouldn't necessarily, you know, have a very high expectation of it working for any particular problem.
Maybe you want to use K-means in order to do market segmentation, like in the T-shirt sizing example that we talked about.
If that gives you an evaluation metric, then often, a better way to determine the number of clusters, is to see how well different numbers of clusters serve that later downstream purpose.
So, I choose K equals 3, then I might have small, medium and large T-shirts.
Or maybe, I want to choose K equals 5, and then I might have, you know, extra small, small, medium, large and extra large T-shirt sizes.
So, you can have like 3 T-shirt sizes or four or five T-shirt sizes.
We could also have four T-shirt sizes, but I'm just showing three and five here, just to simplify this slide for now.
So, if I run K-means with K equals 3, maybe I end up with, that's my small and that's my medium and that's my large.
Whereas, if I run K-means with 5 clusters, maybe I end up with, those are my extra small T-shirts, these are my small, these are my medium, these are my large and these are my extra large.
And the nice thing about this example is that, this then maybe gives us another way to choose whether we want 3 or 4 or 5 clusters, and in particular, what you can do is, you know, think about this from the perspective of the T-shirt business and ask: "Well if I have five segments, then how well will my T-shirts fit my customers and so, how many T-shirts can I sell?
How happy will my customers be?" What really makes sense, from the perspective of the T-shirt business, in terms of whether, I want to have Goer T-shirt sizes so that my T-shirts fit my customers better.
And so, the t-shirt selling business, that might give you a way to decide, between three clusters versus five clusters.
So, that gives you an example of how a later downstream purpose like the problem of deciding what T-shirts to manufacture, how that can give you an evaluation metric for choosing the number of clusters.
For those of you that are doing the program exercises, if you look at this week's program exercise associative K-means, that's an example there of using K-means for image compression.
And so if you were trying to choose how many clusters to use for that problem, you could also, again use the evaluation metric of image compression to choose the number of clusters, K?
So, how good do you want the image to look versus, how much do you want to compress the file size of the image, and, you know, if you do the programming exercise, what I've just said will make more sense at that time.
So, just summarize, for the most part, the number of customers K is still chosen by hand by human input or human insight.
And then to think, what is the number of clusters K that serves that, you know, whatever later purpose that you actually run the K-means for.
In this video, I'd like to start talking about a second type of unsupervised learning problem called dimensionality reduction.
There are a couple of different reasons why one might want to do dimensionality reduction.
One is data compression, and as we'll see later, a few videos later, data compression not only allows us to compress the data and have it therefore use up less computer memory or disk space, but it will also allow us to speed up our learning algorithms.
But first, let's start by talking about what is dimensionality reduction.
As a motivating example, let's say that we've collected a data set with many, many, many features, and I've plotted just two of them here.
And let's say that unknown to us two of the features were actually the length of something in centimeters, and a different feature, x2, is the length of the same thing in inches.
So, this gives us a highly redundant representation and maybe instead of having two separate features x1 then x2, both of which basically measure the length, maybe what we want to do is reduce the data to one-dimensional and just have one number measuring this length.
In case this example seems a bit contrived, this centimeter and inches example is actually not that unrealistic, and not that different from things that I see happening in industry.
If you have hundreds or thousands of features, it is often this easy to lose track of exactly what features you have.
Then, that's why these examples don't lie perfectly on a straight line, because of, you know, round-off error to the nearest centimeter or the nearest inch.
And if we can reduce the data to one dimension instead of two dimensions, that reduces the redundancy.
For may years I've been working with autonomous helicopter pilots.
If you were to measure--if you were to, you know, do a survey or do a test of these different pilots--you might have one feature, x1, which is maybe the skill of these helicopter pilots, and maybe "x2" could be the pilot enjoyment.
And what you really care about might be this sort of this sort of, this direction, a different feature that really measures pilot aptitude.
And I'm making up the name aptitude of course, but again, if you highly correlated features, maybe you really want to reduce the dimension.
So, let me say a little bit more about what it really means to reduce the dimension of the data from 2 dimensions down from 2D to 1 dimensional or to 1D.
Let me color in these examples by using different colors.
And in this case by reducing the dimension what I mean is that I would like to find maybe this line, this, you know, direction on which most of the data seems to lie and project all the data onto that line which is true, and by doing so, what I can do is just measure the position of each of the examples on that line.
And what I can do is come up with a new feature, z1, and to specify the position on the line I need only one number, so it says z1 is a new feature that specifies the location of each of those points on this green line.
And what this means, is that where as previously if i had an example x1, maybe this was my first example, x1.
So in order to represent x1 originally x1.
I could use just z1 to represent my first example, and that's going to be a real number.
And similarly x2 you know, if x2 is my second example there, then previously, whereas this required two numbers to represent if I instead compute the projection of that black cross onto the line.
And now I only need one real number which is z2 to represent the location of this point z2 on the line.
So this is an approximation to the original training self because I have projected all of my training examples onto a line.
But now, I need to keep around only one number for each of my examples.
And so this halves the memory requirement, or a space requirement, or what have you, for how to store my data.
And perhaps more interestingly, more importantly, what we'll see later, in the later video as well is that this will allow us to make our learning algorithms run more quickly as well.
And that is actually, perhaps, even the more interesting application of this data compression rather than reducing the memory or disk space requirement for storing the data.
On the previous slide we showed an example of reducing data from 2D to 1D.
On this slide, I'm going to show another example of reducing data from three dimensional 3D to two dimensional 2D.
I'm going to use examples of 3D to 2D, or 2D to 1D.
So, let's have a data set like that shown here.
And so, I would have a set of examples x(i) which are points in r3.
I know it might be a little bit hard to see this on the slide, but I'll show a 3D point cloud in a little bit.
And it might be hard to see here, but all of this data maybe lies roughly on the plane, like so.
And so what we can do with dimensionality reduction, is take all of this data and project the data down onto a two dimensional plane.
So, here what I've done is, I've taken all the data and I've projected all of the data, so that it all lies on the plane.
Now, finally, in order to specify the location of a point within a plane, we need two numbers, right?
We need to, maybe, specify the location of a point along this axis, and then also specify it's location along that axis.
And so, what that means, is that we can now represent each example, each training example, using two numbers that I've drawn here, z1, and z2.
So, our data can be represented using vector z which are in r2.
And these subscript, z subscript 1, z subscript 2, what I just mean by that is that my vectors here, z, you know, are two dimensional vectors, z1, z2.
And so if I have some particular examples, z(i), or that's the two dimensional vector, z(i)1, z(i)2.
And on the previous slide when I was reducing data to one dimensional data then I had only z1, right?
And that is what a z1 subscript 1 on the previous slide was, but here I have two dimensional data, so I have z1 and z2 as the two components of the data.
Let's look at them a little bit further.
So, what we can do is take this data and here's my middle figure.
So, I've projected this data so that all of it now lies on this 2D surface.
As you can see all the data lies on a plane, 'cause we've projected everything onto a plane, and so what this means is that now I need only two numbers, z1 and z2, to represent the location of point on the plane.
So that's dimensionality reduction and how we can use it to compress our data.
And as we'll see later this will allow us to make some of our learning algorithms run much later as well, but we'll get to that only in a later video.
In the last video, we talked about dimensionality reduction for the purpose of compressing the data.
In this video, I'd like to tell you about a second application of dimensionality reduction and that is to visualize the data.
For a lot of machine learning applications, it really helps us to develop effective learning algorithms, if we can understand our data better.
If there is some way of visualizing the data better, and so, dimensionality reduction offers us, often, another useful tool to do so.
Let's start with an example.
Let's say we've collected a large data set of many statistics and facts about different countries around the world.
So, maybe the first feature, X1 is the country's GDP, or the Gross Domestic Product, and X2 is a per capita, meaning the per person GDP, X3 human development index, life expectancy, X5, X6 and so on.
And we may have a huge data set like this, where, you know, maybe 50 features for every country, and we have a huge set of countries.
So is there something we can do to try to understand our data better?
How do you visualize this data?
If you have 50 features, it's very difficult to plot 50-dimensional data.
What is a good way to examine this data?
Using dimensionality reduction, what we can do is, instead of having each country represented by this featured vector, xi, which is 50-dimensional, so instead of, say, having a country like Canada, instead of having 50 numbers to represent the features of Canada, let's say we can come up with a different feature representation that is these z vectors, that is in R2.
If that's the case, if we can have just a pair of numbers, z1 and z2 that somehow, summarizes my 50 numbers, maybe what we can do to.
It's often up to us to figure out you know, roughly what these features means.
But, And if you plot those features, here is what you might find.
So, here, every country is represented by a point ZI, which is an R2 and so each of those.
So, you might find, for example, That the horizontial axis the Z1 axis corresponds roughly to the overall country size, or the overall economic activity of a country.
So the overall GDP, overall economic size of a country.
Whereas the vertical axis in our data might correspond to the per person GDP.
Whereas here you might have a country like Singapore, which actually has a very high per person GDP as well, but because Singapore is a much smaller country the overall economy size of Singapore is much smaller than the US.
And, over here, you would have countries where individuals are unfortunately some are less well off, maybe shorter life expectancy, less health care, less economic maturity that's why smaller countries, whereas a point like this will correspond to a country that has a fair, has a substantial amount of economic activity, but where individuals tend to be somewhat less well off.
So you might find that the axes Z1 and Z2 can help you to most succinctly capture really what are the two main dimensions of the variations amongst different countries.
Such as the overall economic activity of the country projected by the size of the country's overall economy as well as the per-person individual well-being, measured by per-person GDP, per-person healthcare, and things like that.
So that's how you can use dimensionality reduction, in order to reduce data from 50 dimensions or whatever, down to two dimensions, or maybe down to three dimensions, so that you can plot it and understand your data better.
For the problem of dimensionality reduction, by far the most popular, by far the most commonly used algorithm is something called principle components analysis, or PCA.
In this video, I'd like to start talking about the problem formulation for PCA.
In other words, let's try to formulate, precisely, exactly what we would like PCA to do.
Let's say we have a data set like this.
So, this is a data set of examples x and R2 and let's say I want to reduce the dimension of the data from two-dimensional to one-dimensional.
In other words, I would like to find a line onto which to project the data.
So what seems like a good line onto which to project the data, it's a line like this, might be a pretty good choice.
And the reason we think this might be a good choice is that if you look at where the projected versions of the point scales, so I take this point and project it down here.
What we find is that the distance between each point and the projected version is pretty small.
That is, these blue line segments are pretty short.
So what PCA does formally is it tries to find a lower dimensional surface, really a line in this case, onto which to project the data so that the sum of squares of these little blue line segments is minimized.
The length of those blue line segments, that's sometimes also called the projection error.
And so what PCA does is it tries to find a surface onto which to project the data so as to minimize that.
As an aside, before applying PCA, it's standard practice to first perform mean normalization at feature scaling so that the features x1 and x2 should have zero mean, and should have comparable ranges of values.
I've already done this for this example, but I'll come back to this later and talk more about feature scaling and the normalization in the context of PCA later.
But coming back to this example, in contrast to the red line that I just drew, here's a different line onto which I could project my data, which is this magenta line.
And, as we'll see, this magenta line is a much worse direction onto which to project my data, right?
So if I were to project my data onto the magenta line, we'd get a set of points like that.
And the projection errors, that is these blue line segments, will be huge.
So these points have to move a huge distance in order to get projected onto the magenta line.
And so that's why PCA, principal components analysis, will choose something like the red line rather than the magenta line down here.
Let's write out the PCA problem a little more formally.
The goal of PCA, if we want to reduce data from two-dimensional to one-dimensional is, we're going to try find a vector that is a vector u1, which is going to be an Rn, so that would be an R2 in this case.
So, in this example I'm hoping that PCA will find this vector, which l wanna call u(1), so that when I project the data onto the line that I define by extending out this vector, I end up with pretty small reconstruction errors.
And that reference of data that looks like this.
And by the way, I should mention that where the PCA gives me u(1) or -u(1), doesn't matter.
So if it gives me a positive vector in this direction, that's fine.
But it gives a positive u(1) or negative u(1), it doesn't matter because each of these vectors defines the same red line onto which I'm projecting my data.
So this is a case of reducing data from two-dimensional to one-dimensional.
In the more general case we have n-dimensional data and we'll want to reduce it to k-dimensions.
In that case we want to find not just a single vector onto which to project the data but we want to find k-dimensions onto which to project the data.
So as to minimize this projection error.
If I have a 3D point cloud like this, then maybe what I want to do is find vectors.
I'm going to find a pair of vectors, sustained from the origin.
And together, these two vectors define a plane, or they define a 2D surface, right?
Like this with a 2D surface onto which I am going to project my data.
And what we're going to do is project the data onto the linear subspace spanned by this set of k vectors.
But if you're not familiar with linear algebra, just think of it as finding k directions instead of just one direction onto which to project the data.
So finding a k-dimensional surface is really finding a 2D plane in this case, shown in this figure, where we can define the position of the points in a plane using k directions.
And that's why for PCA we want to find k vectors onto which to project the data.
And so more formally in PCA, what we want to do is find this way to project the data so as to minimize the sort of projection distance, which is the distance between the points and the projections.
Given a point we would take the point and project it onto this 2D surface.
And so the projection error would be, the distance between the point and where it gets projected down to my 2D surface.
And so what PCA does is I try to find the line, or a plane, or whatever, onto which to project the data, to try to minimize that square projection, that 90 degree or that orthogonal projection error.
Because when explaining PCA, I sometimes end up drawing diagrams like these and that looks a little bit like linear regression.
It turns out PCA is not linear regression, and despite some cosmetic similarity, these are actually totally different algorithms.
If we were doing linear regression, what we would do would be, on the left we would be trying to predict the value of some variable y given some info features x.
And so linear regression, what we're doing is we're fitting a straight line so as to minimize the square error between point and this straight line.
And notice that I'm drawing these blue lines vertically.
Whereas in contrast, in PCA, what it does is it tries to minimize the magnitude of these blue lines, which are drawn at an angle.
All that linear regression as well as taking all the values of x and try to use that to predict y.
Whereas in PCA, there is no distinguish, or there is no special variable y that we're trying to predict.
And instead, we have a list of features, x1, x2, and so on, up to xn, and all of these features are treated equally, so no one of them is special.
As one last example, if I have three-dimensional data and I want to reduce data from 3D to 2D, so maybe I wanna find two directions, u(1) and u(2), onto which to project my data.
Then what I have is I have three features, x1, x2, x3, and all of these are treated alike.
All of these are treated symmetrically and there's no special variable y that I'm trying to predict.
And so PCA is not a linear regression, and even though at some cosmetic level they might look related, these are actually very different algorithms.
So hopefully you now understand what PCA is doing.
It's trying to find a lower dimensional surface onto which to project the data, so as to minimize this squared projection error.
In the next video, we'll start to talk about how to actually find this lower dimensional surface onto which to project the data.
In this video I'd like to tell you about the principle components analysis algorithm.
And by the end of this video you know to implement PCA for yourself.
And use it reduce the dimension of your data.
Before applying PCA, there is a data pre-processing step which you should always do.
this is very similar to the mean normalization and feature scaling process that we have for supervised learning.
In fact it's exactly the same procedure except that we're doing it now to our unlabeled data, X1 through Xm.
So for example, if x1 is the size of a house, and x2 is the number of bedrooms, to use our earlier example, we then also scale each feature to have a comparable range of values.
And so, similar to what we had with supervised learning, we would take x, i substitute j, that's the j feature and so we would subtract of the mean, now that's what we have on top, and then divide by sj.
Here, sj is some measure of the beta values of feature j.
So, it could be the max minus min value, or more commonly, it is the standard deviation of feature j.
Having done this sort of data pre-processing, here's what the PCA algorithm does.
So, just as a quick reminder of what reducing the dimension of the data means, for this example on the left we were given the examples xI, which are in r2.
And what we like to do is find a set of numbers zI in r push to represent our data.
So that's what from reduction from 2D to 1D means.
We need only one number to specify the position of the points on the line.
So i'm going to call that number z or z1.
Z here real number, so that's like a one dimensional vector.
So z1 just refers to the first component of this, you know, one by one matrix, or this one dimensional vector.
And so we need only one number to specify the position of a point.
So if this example here was my example X1, then maybe that gets mapped here.
So What PCA has to do is we need to come up with a way to compute two things.
One is to compute these vectors, u1, and in this case u1 and u2.
And the other is how do we compute these numbers, Z.
So on the example on the left we're reducing the data from 2D to 1D.
In the example on the right, we would be reducing data from 3 dimensional as in r3, to zi, which is now two dimensional.
So it would be z1 z2 like so, and so we need to give away to compute these new representations, the z1 and z2 of the data as well.
So how do you compute all of these quantities?
It turns out that a mathematical derivation, also the mathematical proof, for what is the right value U1, U2, Z1, Z2, and so on.
But once you've done it turns out that the procedure to actually find the value of u1 that you want is not that hard, even though so that the mathematical proof that this value is the correct value is someone more involved and more than i want to get into.
But let me just describe the specific procedure that you have to implement in order to compute all of these things, the vectors, u1, u2, the vector z.
Here's the procedure.
It's a bit unfortunate that the Greek alphabet sigma looks exactly like the summation symbols.
So this is the Greek alphabet Sigma is used to denote a matrix and this here is a summation symbol.
So hopefully in these slides there won't be ambiguity about which is Sigma Matrix, the matrix, which is a summation symbol, and hopefully it will be clear from context when I'm using each one.
What we need to do is compute something called the eigenvectors of the matrix sigma.
And an octave, the way you do that is you use this command, u s v equals s v d of sigma.
SVD, by the way, stands for singular value decomposition.
and It turns out that the SVD function and the I function it will give you the same vectors, although SVD is a little more numerically stable.
So I tend to use SVD, although I have a few friends that use the I function to do this as wellbut when you apply this to a covariance matrix sigma it gives you the same thing.
This is because the covariance matrix always satisfies a mathematical Property called symmetric positive definite You really don't need to know what that means, but the SVD and I-functions are different functions but when they are applied to a covariance matrix which can be proved to always satisfy this mathematical property; they'll always give you the same thing.
Okay, that was probably much more linear algebra than you needed to know.
All you need to know is that this system command you should implement in Octave.
And if you're implementing this in a different language than Octave or MATLAB, what you should do is find the numerical linear algebra library that can compute the SVD or singular value decomposition, and there are many such libraries for probably all of the major programming languages.
People can use that to compute the matrices u, s, and d of the covariance matrix sigma.
And one way to see that is if you look at the definition this is an n by 1 vector and this here I transpose is 1 by N so the product of these two things is going to be an N by N matrix.
1xN transfers, 1xN, so there's an NxN matrix and when we add up all of these you still have an NxN matrix.
And what the SVD outputs three matrices, u, s, and v.
The thing you really need out of the SVD is the u matrix.
The u matrix will also be a NxN matrix.
And if we look at the columns of the U matrix it turns out that the columns of the U matrix will be exactly those vectors, u1, u2 and so on.
And if we want to reduce the data from n dimensions down to k dimensions, then what we need to do is take the first k vectors.
the rest of the procedure from this SVD numerical linear algebra routine we get this matrix u.
So, just to wrap up the description of the rest of the procedure, from the SVD numerical linear algebra routine we get these matrices u, s, and d.
Now the other thing we need to is take my original data set, X which is an RN And find a lower dimensional representation Z, which is a R K for this data.
So the way we're going to do that is take the first K Columns of the U matrix.
Stack up U1, U2 and so on up to U K in columns.
It's really basically taking, you know, this part of the matrix, the first K columns of this matrix.
And so this is going to be an N by K matrix.
I'm going to give this matrix a name.
I'm going to call this matrix U, subscript "reduce," sort of a reduced version of the U matrix maybe.
I'm going to use it to reduce the dimension of my data.
When I take this transpose of this U matrix, what I'm going to end up with is these vectors now in rows.
Then take that times X, and that's how I get my vector Z.
And so z is k dimensional, is a k dimensional vector, which is exactly what we wanted.
And of course these x's here right, can be Examples in our training set can be examples in our cross validation set, can be examples in our test set, and for example if you know, I wanted to take training example i, I can write this as xi XI and that's what will give me ZI over there.
So, to summarize, here's the PCA algorithm on one slide.
After mean normalization, to ensure that every feature is zero mean and optional feature scaling whichYou really should do feature scaling if your features take on very different ranges of values.
You can implement in octave, you can even run sigma equals 1 over m, times x, which is this matrix up here, transpose times x and this simple expression, that's the vectorize implementation of how to compute the matrix sigma.
This is the correct vectorization whether you want, you can either numerically test this on yourself by trying out an octave and making sure that both this and this implementations give the same answers or you Can try to prove it yourself mathematically.
Either way but this is the correct vectorizing implementation, without compusingnext we can apply the SVD routine to get u, s, and d.
And then we grab the first k columns of the u matrix you reduce and finally this defines how we go from a feature vector x to this reduce dimension representation z.
So, this is not done with X-0 1.
Fortunately the PCA algorithm can be implemented in not too many lines of code.
and if you implement this in octave or algorithm, you actually get a very effective dimensionality reduction algorithm.
One thing I didn't do was give a mathematical proof that the U1 and U2 and so on and the Z and so on you get out of this procedure is really the choices that would minimize these squared projection error.
Right, remember we said What PCA tries to do is try to find a surface or line onto which to project the data so as to minimize to square projection error.
So I didn't prove that this that, and the mathematical proof of that is beyond the scope of this course.
But fortunately the PCA algorithm can be implemented in not too many lines of octave code.
That does do the right thing of minimizing this square projection error.
In an earlier video, I had said that PCA can be sometimes used to speed up the running time of a learning algorithm.
Here's how you can use PCA to speed up a learning algorithm, and this supervised learning algorithm speed up is actually the most common use that I personally make of PCA.
So, lets say that your examples, xi are 10,000 dimensional feature vectors.
So with very high-dimensional feature vectors like this, running a learning algorithm can be slow, right?
Just, if you feed 10,000 dimensional feature vectors into logistic regression, or a new network, or support vector machine or what have you, just because that's a lot of data, that's 10,000 numbers, it can make your learning algorithm run more slowly.
Fortunately with PCA we'll be able to reduce the dimension of this data and so make our algorithms run more efficiently.
So just extract the input vectors x1 through xm.
Then we're going to apply PCA and this will give me a reduced dimension representation of the data, so instead of 10,000 dimensional feature vectors I now have maybe one thousand dimensional feature vectors.
So this gives me, if you will, a new training set.
Because my training examples are now represented with this much lower dimensional representation Z1, Z2, up to ZM.
Finally, I can take this reduced dimension training set and feed it to a learning algorithm maybe a neural network, maybe logistic regression, and I can learn the hypothesis H, that takes this input, these low-dimensional representations Z and tries to make predictions.
So if I were using logistic regression for example, I would train a hypothesis that outputs, you know, one over one plus E to the negative-theta transpose Z, that takes this input to one these z vectors, and tries to make a prediction.
What you do is you would take your test example x, map it through the same mapping that was found by PCA to get you your corresponding z.
And that z then gets fed to this hypothesis, and this hypothesis then makes a prediction on your input x.
One final note, what PCA does is it defines a mapping from x to z and this mapping from x to z should be defined by running PCA only on the training sets.
And in particular, this mapping that PCA is learning, right, this mapping, what that does is it computes the set of parameters.
That's the feature scaling and mean normalization.
And then having found U reduced, or having found the parameters for feature scaling where the mean normalization and scaling the scale that you divide the features by to get them on to comparable scales.
Having found all those parameters on the training set, you can then apply the same mapping to other examples that may be In your cross-validation sets or in your test sets, OK?
Just to summarize, when you're running PCA, run your PCA only on the training set portion of the data not the cross-validation set or the test set portion of your data.
And that defines the mapping from x to z and you can then apply that mapping to your cross-validation set and your test set and by the way in this example I talked about reducing the data from ten thousand dimensional to one thousand dimensional, this is actually not that unrealistic.
You know by 5x maybe by 10x and still retain most of the variance and we can do this barely effecting the performance, in terms of classification accuracy, let's say, barely affecting the classification accuracy of the learning algorithm.
And by working with lower dimensional data our learning algorithm can often run much much faster.
To summarize, we've so far talked about the following applications of PCA.
First is the compression application where we might do so to reduce the memory or the disk space needed to store data and we just talked about how to use this to speed up a learning algorithm.
That would be a very typical choice for how to choose k.
So that summarizes the main applications of PCA, as well as how to choose the value of k for these different applications.
I just want to mention this so that you know not to do it.
And there is one bad use of PCA, which iss to try to use it to prevent over-fitting.
This is not a great way to use PCA, but here's the reasoning behind this method, which is,you know if we have Xi, then maybe we'll have n features, but if we compress the data, and use Zi instead and that reduces the number of features to k, which could be much lower dimensional.
And so if we have a much smaller number of features, if k is 1,000 and n is 10,000, then if we have only 1,000 dimensional data, maybe we're less likely to over-fit than if we were using 10,000-dimensional data with like a thousand features.
So some people think of PCA as a way to prevent over-fitting.
But just to emphasize this is a bad application of PCA and I do not recommend doing this.
And it's not that this method works badly.
If you want to use this method to reduce the dimensional data, to try to prevent over-fitting, it might actually work OK.
But this just is not a good way to address over-fitting and instead, if you're worried about over-fitting, there is a much better way to address it, to use regularization instead of using PCA to reduce the dimension of the data.
And the reason is, if you think about how PCA works, it does not use the labels y.
You are just looking at your inputs xi, and you're using that to find a lower-dimensional approximation to your data.
It throws away or reduces the dimension of your data without knowing what the values of y is, so this is probably okay using PCA this way is probably okay if, say 99 percent of the variance is retained, if you're keeping most of the variance, but it might also throw away some valuable information.
So, to summarize, it is a good use of PCA, if your main motivation to speed up your learning algorithm, but using PCA to prevent over-fitting, that is not a good use of PCA, and using regularization instead is really what many people would recommend doing instead.
Finally, one last misuse of PCA.
And so I should say PCA is a very useful algorithm, I often use it for the compression on the visualization purposes.
But, what I sometimes see, is also people sometimes use PCA where it shouldn't be.
So, here's a pretty common thing that I see, which is if someone is designing a machine-learning system, they may write down the plan like this: let's design a learning system.
Get a training set and then, you know, what I'm going to do is run PCA, then train logistic regression and then test on my test data.
So often at the very start of a project, someone will just write out a project plan than says lets do these four steps with PCA inside.
Before writing down a project plan the incorporates PCA like this, one very good question to ask is, well, what if we were to just do the whole without using PCA.
And often people do not consider this step before coming up with a complicated project plan and implementing PCA and so on.
And sometime, and so specifically, what I often advise people is, before you implement PCA, I would first suggest that, you know, do whatever it is, take whatever it is you want to do and first consider doing it with your original raw data xi, and only if that doesn't do what you want, then implement PCA before using Zi.
So, before using PCA you know, instead of reducing the dimension of the data, I would consider well, let's ditch this PCA step, and I would consider, let's just train my learning algorithm on my original data.
Let's just use my original raw inputs xi, and I would recommend, instead of putting PCA into the algorithm, just try doing whatever it is you're doing with the xi first.
And only if you have a reason to believe that doesn't work, so that only if your learning algorithm ends up running too slowly, or only if the memory requirement or the disk space requirement is too large, so you want to compress your representation, but if only using the xi doesn't work, only if you have evidence or strong reason to believe that using the xi won't work, then implement PCA and consider using the compressed representation.
Because what I do see, is sometimes people start off with a project plan that incorporates PCA inside, and sometimes they, whatever they're doing will work just fine, even with out using PCA instead.
So, just consider that as an alternative as well, before you go to spend a lot of time to get PCA in, figure out what k is and so on.
So, that's it for PCA.
But I think, just as common an application of PCA, is to use it to compress data, to reduce the memory or disk space requirements, or to use it to visualize data.
And PCA is one of the most commonly used and one of the most powerful unsupervised learning algorithms.
And with what you've learned in these videos, I think hopefully you'll be able to implement PCA and use them through all of these purposes as well.
In this next set of videos, I'd like to tell you about a problem called Anomaly Detection.
And one of the interesting aspects is that it's mainly for unsupervised problem, that there's some aspects of it that are also very similar to sort of the supervised learning problem.
So, what is anomaly detection?
So, the anomaly detection problem is the following.
Let's say that on, you know, the next day, you have a new aircraft engine that rolls off the assembly line and your new aircraft engine has some set of features x-test.
So, if your new aircraft engine looks like a point over there, well, you know, that looks a lot like the aircraft engines we've seen before, and so maybe we'll say that it looks okay.
Whereas, if your new aircraft engine, if x-test, you know, were a point that were out here, so that if X1 and X2 are the features of this new example.
and maybe send that aircraft engine for further testing before we ship it to a customer, since it looks very different than the rest of the aircraft engines we've seen before.
More formally in the anomaly detection problem, we're give some data sets, x1 through Xm of examples, and we usually assume that these end examples are normal or non-anomalous examples, and we want an algorithm to tell us if some new example x-test is anomalous.
The approach that we're going to take is that given this training set, given the unlabeled training set, we're going to build a model for p of x.
In other words, we're going to build a model for the probability of x, where x are these features of, say, aircraft engines.
And so, having built a model of the probability of x we're then going to say that for the new aircraft engine, if p of x-test is less than some epsilon then we flag this as an anomaly.
So we see a new engine that, you know, has very low probability under a model p of x that we estimate from the data, then we flag this anomaly, whereas if p of x-test is, say, greater than or equal to some small threshold.
And so, given the training set, like that plotted here, if you build a model, hopefully you will find that aircraft engines, or hopefully the model p of x will say that points that lie, you know, somewhere in the middle, that's pretty high probability, whereas points a little bit further out have lower probability.
Points that are even further out have somewhat lower probability, and the point that's way out here, the point that's way out there, would be an anomaly.
Whereas the point that's way in there, right in the middle, this would be okay because p of x right in the middle of that would be very high cause we've seen a lot of points in that region.
Perhaps the most common application of anomaly detection is actually for detection if you have many users, and if each of your users take different activities, you know maybe on your website or in the physical plant or something, you can compute features of the different users activities.
What is the probability of a particular vector of features of a users behavior so you know examples of features of a users activity may be on the website it'd be things like, maybe x1 is how often does this user log in, x2, you know, maybe the number of what pages visited, or the number of transactions, maybe x3 is, you know, the number of posts of the users on the forum, feature x4 could be what is the typing speed of the user and some websites can actually track that was the typing speed of this user in characters per second.
And so you can model p of x based on this sort of data.
And finally having your model p of x, you can try to identify users that are behaving very strangely on your website by checking which ones have probably effects less than epsilon and maybe send the profiles of those users for further review.
Or demand additional identification from those users, or some such to guard against you know, strange behavior or fraudulent behavior on your website.
This sort of technique will tend of flag the users that are behaving unusually, not just users that maybe behaving fraudulently.
So not just constantly having stolen or users that are trying to do funny things, or just find unusual users.
But this is actually the technique that is used by many online websites that sell things to try identify users behaving strangely that might be indicative of either fraudulent behavior or of computer accounts that have been stolen.
Another example of anomaly detection is manufacturing.
So, already talked about the aircraft engine thing where you can find unusual, say, aircraft engines and send those for further review.
A third application would be monitoring computers in a data center.
So if you have a lot of machines in a computer cluster or in a data center, we can do things like compute features at each machine.
As well as more complex features like what is the CPU load on this machine divided by the amount of network traffic on this machine?
Then given the dataset of how your computers in your data center usually behave, you can model the probability of x, so you can model the probability of these machines having different amounts of memory use or probability of these machines having different numbers of disc accesses or different CPU loads and so on.
And if you ever have a machine whose probability of x, p of x, is very small then you know that machine is behaving unusually and maybe that machine is about to go down, and you can flag that for review by a system administrator.
And this is actually being used today by various data centers to watch out for unusual things happening on their machines.
In the next video, I'll talk a bit about the Gaussian distribution and review properties of the Gaussian probability distribution, and in videos after that, we will apply it to develop an anomaly detection algorithm.
In this video, I'd like to talk about the Gaussian distribution which is also called the normal distribution.
In case you're already intimately familiar with the Gaussian distribution, it's probably okay to skip this video, but if you're not sure or if it has been a while since you've worked with the Gaussian distribution or normal distribution then please do watch this video all the way to the end.
And in the video after this we'll start applying the Gaussian distribution to developing an anomaly detection algorithm.
So this script N stands for normal since Gaussian and normal they mean the thing are synonyms.
And the Gaussian distribution is parametarized by two parameters, by a mean parameter which we denote mu and a variance parameter which we denote via sigma squared.
If we plot the Gaussian distribution or Gaussian probability density.
And so this bell shaped curve is paramafied by those two parameters, mu and sequel.
And the location of the center of this bell shaped curve is the mean mu.
And the width of this bell shaped curve, roughly that, is this parameter, sigma, is also called one standard deviation, and so this specifies the probability of x taking on different values.
So, x taking on values here in the middle here it's pretty high, since the Gaussian density here is pretty high, whereas x taking on values further, and further away will be diminishing in probability.
Finally just for completeness let me write out the formula for the Gaussian distribution.
So the probability of x, and I'll sometimes write this as the p (x) when we write this as P ( x ; mu, sigma squared), and so this denotes that the probability of X is parameterized by the two parameters mu and sigma squared.
So there's no need to memorize this formula.
This is just the formula for the bell-shaped curve over here on the left.
There's no need to memorize it, and if you ever need to use this, you can always look this up.
And so that figure on the left, that is what you get if you take a fixed value of mu and take a fixed value of sigma, and you plot P(x) so this curve here.
This is really p(x) plotted as a function of X for a fixed value of Mu and of sigma squared.
And sometimes is easier to think in terms of sigma.
So sigma is called the standard deviation, and so it specifies the width of this Gaussian probability density, where as the square sigma, or sigma squared, is called the variance.
Let's look at some examples of what the Gaussian distribution looks like.
Then we have a Gaussian distribution that's centered around zero, because that's mu and the width of this Gaussian, so that's one standard deviation is sigma over there.
Let's look at some examples of Gaussians.
If mu is equal to zero and sigma equals one, then that corresponds to a Gaussian distribution that is centered at zero, since mu is zero, and the width of this Gaussian is is controlled by sigma by that variance parameter sigma.
Here's another example.
That same mu is equal to 0 and sigma is equal to .5 so the standard deviation is .5 and the variance sigma squared would therefore be the square of 0.5 would be 0.25 and in that case the Gaussian distribution, the Gaussian probability density goes like this.
But because this is a probability distribution, the area under the curve, that's the shaded area there.
That area must integrate to one this is a property of probability distributing.
So this is a much taller Gaussian density because this half is Y but half the standard deviation but it twice as tall.
Another example is sigma is equal to 2 then you get a much fatter a much wider Gaussian density and so here the sigma parameter controls that Gaussian distribution has a wider width.
And once again, the area under the curve, that is the shaded area, will always integrate to one, that's the property of probability distributions and because it's wider it's also half as tall in order to still integrate to the same thing.
Then instead of being centered at 0 we now have a Gaussian distribution that's centered at 3 because this shifts over the entire Gaussian distribution.
So what's the parameter estimation problem?
Here in the figure I've plotted an example of the dataset so the horizontal axis is the x axis and either will have a range of examples of x, and I've just plotted them on this figure here.
And the parameter estimation problem is, let's say I suspect that these examples came from a Gaussian distribution.
Let's not suspect that each of these examples were distributed according to a normal distribution, or Gaussian distribution, with some parameter mu and some parameter sigma square.
But I don't know what the values of these parameters are.
The problem of parameter estimation is, given my data set, I want to try to figure out, well I want to estimate what are the values of mu and sigma squared.
So if you're given a data set like this, it looks like maybe if I estimate what Gaussian distribution the data came from, maybe that might be roughly the Gaussian distribution it came from.
Seems like a reasonable fit to the data.
Because, you know, looks like the data has a very high probability of being in the central region, and a low probability of being further out, even though probability of being further out, and so on.
So maybe this is a reasonable estimate of mu and sigma squared.
That is, if it corresponds to a Gaussian distribution function that looks like this.
So what I'm going to do is just write out the formula the standard formulas for estimating the parameters Mu and sigma squared.
And that just means the center of this distribution.
How about sigma squared?
And what the variance is, or one interpretation of the variance is that if you look at this term, that's the square difference between the value I got in my example minus the mean.
Minus the center, minus the mean of the distribution.
And so in the variance I'm gonna estimate as just the average of the square differences between my examples, minus the mean.
And as a side comment, only for those of you that are experts in statistics.
Finally one last side comment again only for those of you that have maybe taken the statistics class before but if you've taken statistics This class before.
In machine learning people tend to learn 1/M formula but in practice whether it is 1/M or 1/M-1 it makes essentially no difference assuming M is reasonably large.
So just in case you've seen this other version before.
In either version it works just about equally well but in machine learning most people tend to use 1/M in this formula.And the two versions have slightly different theoretical properties like these are different math properties.
In the next video, we'll start to take this and apply it to develop an anomaly detection algorithm.
In the last video, we talked about the Gaussian distribution.
In this video lets apply that to develop an anomaly detection algorithm.
Let's say that we have an unlabeled training set of M examples, and each of these examples is going to be a feature in Rn so your training set could be, feature vectors from the last M aircraft engines being manufactured.
The way we are going to address anomaly detection, is we are going to model p of x from the data sets.
Now I'm leaving space here cause I'll fill in something in a minute.
So, how do we model each of these terms, p of X1, p of X2, and so on.
What we're going to do, is assume that the feature, X1, is distributed according to a Gaussian distribution, with some mean, which you want to write as mu1 and some variance, which I'm going to write as sigma squared 1, and so p of X1 is going to be a Gaussian probability distribution, with mean mu1 and variance sigma squared 1.
And similarly, you know, X3 is yet another Gaussian, so this can have a different mean and a different standard deviation than the other features, and so on, up to XN.
Just as a side comment for those of you that are experts in statistics, it turns out that this equation that I just wrote out actually corresponds to an independence assumption on the values of the features x1 through xn.
But in practice it turns out that the algorithm of this fragment, it works just fine, whether or not these features are anywhere close to independent and even if independence assumption doesn't hold true this algorithm works just fine.
But in case you don't know those terms I just used independence assumptions and so on, don't worry about it.
You'll be able to understand it and implement this algorithm just fine and that comment was really meant only for the experts in statistics.
Finally, in order to wrap this up, let me take this expression and write it a little bit more compactly.
So, we're going to write this is a product from J equals one through N, of P of XJ parameterized by mu j comma sigma squared j.
So this funny symbol here, there is capital Greek alphabet pi, that funny symbol there corresponds to taking the product of a set of values.
And so, you're familiar with the summation notation, so the sum from i equals one through n, of i.
Where as this funny symbol here, this product symbol, right product from i equals 1 through n of i.
Then this means that, it's just like summation except that we're now multiplying.
And so using this product notation, this product from j equals 1 through n of this expression.
Since we're are taking these p of x j given mu j comma sigma squared j terms and multiplying them together.
And, by the way the problem of estimating this distribution p of x, they're sometimes called the problem of density estimation.
Hence the title of the slide.
So putting everything together, here is our anomaly detection algorithm.
The first step is to choose features, or come up with features xi that we think might be indicative of anomalous examples.
So what I mean by that, is, try to come up with features, so that when there's an unusual user in your system that may be doing fraudulent things, or when the aircraft engine examples, you know there's something funny, something strange about one of the aircraft engines.
But more generally, just try to choose features that describe general properties of the things that you're collecting data on.
And so this says for the mu J just take the mean over my training set of the values of the j feature.
And, just to mention, that you do this, you compute these formulas for j equals one through n.
So, this formula that I just wrote out estimates this xi as the feature vectors that estimates mu for all the values of n simultaneously.
And it's also possible to come up with a vectorized formula for estimating sigma squared j.
Finally, when you're given a new example, so when you have a new aircraft engine and you want to know is this aircraft engine anomalous.
So, p of x is equal to this product, and what you implement, what you compute, is this formula and where over here, this thing here this is just the formula for the Gaussian probability, so you compute this thing, and finally if this probability is very small, then you flag this thing as an anomaly.
Here's an example of an application of this method.
Let's say we have this data set plotted on the upper left of this slide.
If you look at this data set, it looks like on average, the features x1 has a mean of about 5 and the standard deviation, if you only look at just the x1 values of this data set has the standard deviation of maybe 2.
So that sigma 1 and looks like x2 the values of the features as measured on the vertical axis, looks like it has an average value of about 3, and a standard deviation of about 1.
So if you take this data set and if you estimate mu1, mu2, sigma1, sigma2, this is what you get.
So, just be careful whether you are using sigma 1, sigma 2, or sigma squared 1 or sigma squared 2.
So, sigma squared 1 of course would be equal to 4, for example, as the square of 2.
And in pictures what p of x1 parametrized by mu1 and sigma squared 1 and p of x2, parametrized by mu 2 and sigma squared 2, that would look like these two distributions over here.
And, turns out that if were to plot of p of x, right, which is the product of these two things, you can actually get a surface plot that looks like this.
This is a plot of p of x, where the height above of this, where the height of this surface at a particular point, so given a particular x1 x2 values of x2 if x1 equals 2, x equal 2, that's this point.
And the height of this 3-D surface here, that's p of x.
So p of x, that is the height of this plot, is literally just p of x1 parametrized by mu 1 sigma squared 1, times p of x2 parametrized by mu 2 sigma squared 2.
Now, so this is how we fit the parameters to this data.
Let's see if we have a couple of new examples.
Is this an anomaly or not?
So, is that an anomaly or not?
In particular, this is greater than, or greater than or equal to epsilon.
Whereas, if you compute p of X2 test, well that is just a much smaller value.
So this is less than epsilon and so we'll say that that is indeed an anomaly, because it is much smaller than that epsilon that we then chose.
It's saying that all the values of x1 and x2 that have a high height above the surface, corresponds to an a non-anomalous example of an OK or normal example.
Whereas all the points far out here, all the points out here, all of those points have very low probability, so we are going to flag those points as anomalous, and so it's gonna define some region, that maybe looks like this, so that everything outside this, it flags as anomalous, whereas the things inside this ellipse I just drew, if it considers okay, or non-anomalous, not anomalous examples.
And so this example x2 test lies outside that region, and so it has very small probability, and so we consider it an anomalous example.
In this video we talked about how to estimate p of x, the probability of x, for the purpose of developing an anomaly detection algorithm.
And in this video, we also stepped through an entire process of giving data set, we have, fitting the parameters, doing parameter estimations.
We get mu and sigma parameters, and then taking new examples and deciding if the new examples are anomalous or not.
In the last video, we developed an anomaly detection algorithm.
In previous videos, we've already talked about the importance of real number evaluation and this captures the idea that when you're trying to develop a learning algorithm for a specific application, you need to often make a lot of choices like, you know, choosing what features to use and then so on.
And making decisions about all of these choices is often much easier, and if you have a way to evaluate your learning algorithm that just gives you back a number.
If you can run the algorithm with the feature, and run the algorithm without the feature, and just get back a number that tells you, you know, did it improve or worsen performance to add this feature?
Then it gives you a much better way, a much simpler way, with which to decide whether or not to include that feature.
So in order to be able to develop an anomaly detection system quickly, it would be a really helpful to have a way of evaluating an anomaly detection system.
In order to do this, in order to evaluate an anomaly detection system, we're actually going to assume have some labeled data.
So, so far, we'll be treating anomaly detection as an unsupervised learning problem, using unlabeled data.
But if you have some labeled data that specifies what are some anomalous examples, and what are some non-anomalous examples, then this is how we actually think of as the standard way of evaluating an anomaly detection algorithm.
So taking the aircraft engine example again.
Let's say that, you know, we have some label data of just a few anomalous examples of some aircraft engines that were manufactured in the past that turns out to be anomalous.
I'm going to use y equals 0 to denote the normal or the non-anomalous example and y equals 1 to denote the anomalous examples.
The process of developing and evaluating an anomaly detection algorithm is as follows.
We're going to think of it as a training set and talk about the cross validation in test sets later, but the training set we usually think of this as still the unlabeled training set.
And so this is our large collection of normal, non-anomalous or not anomalous examples.
And usually we think of this as being as non-anomalous, but it's actually okay even if a few anomalies slip into your unlabeled training set.
And next we are going to define a cross validation set and a test set, with which to evaluate a particular anomaly detection algorithm.
So here's a specific example.
Let's say that, altogether, this is the data that we have.
We have manufactured 10,000 examples of engines that, as far as we know we're perfectly normal, perfectly good aircraft engines.
And let's say that, you know, historically, however long we've been running on manufacturing plant, let's say that we end up getting features, getting 24 to 28 anomalous engines as well.
And for a pretty typical application of anomaly detection, you know, the number non-anomalous examples, that is with y equals 1, we may have anywhere from, you know, 20 to 50.
It would be a pretty typical range of examples, number of examples that we have with y equals 1.
So, given this data set, a fairly typical way to split it into the training set, cross validation set and test set would be as follows.
Let's take 10,000 good aircraft engines and put 6,000 of that into the unlabeled training set.
So, I'm calling this an unlabeled training set but all of these examples are really ones that correspond to y equals 0, as far as we know.
And so, we will use this to fit p of x, right.
So, we will use these 6000 engines to fit p of x, which is that p of x one parametrized by Mu 1, sigma squared 1, up to p of Xn parametrized by Mu N sigma squared n.
And so it would be these 6,000 examples that we would use to estimate the parameters Mu 1, sigma squared 1, up to Mu N, sigma squared N.
And so that's our training set of all, you know, good, or the vast majority of good examples.
Next we will take our good aircraft engines and put some number of them in a cross validation set plus some number of them in the test sets.
And then we also have 20 flawed aircraft engines, and we'll take that and maybe split it up, you know, put ten of them in the cross validation set and put ten of them in the test sets.
And in the next slide we will talk about how to actually use this to evaluate the anomaly detection algorithm.
So what I have just described here is a you know probably the recommend a good way of splitting the labeled and unlabeled example.
Where we use like a 60, 20, 20% split for the good engines and we take the flawed engines, and we put them just in the cross validation set, and just in the test set, then we'll see in the next slide why that's the case.
Just as an aside, if you look at how people apply anomaly detection algorithms, sometimes you see other peoples' split the data differently as well.
So, another alternative, this is really not a recommended alternative, but some people want to take off your 10,000 good engines, maybe put 6000 of them in your training set and then put the same 4000 in the cross validation set and the test set.
And so, you know, we like to think of the cross validation set and the test set as being completely different data sets to each other.
But you know, in anomaly detection, you know, for sometimes you see people, sort of, use the same set of good engines in the cross validation sets, and the test sets, and sometimes you see people use exactly the same sets of anomalous engines in the cross validation set and the test set.
And so, all of these are considered, you know, less good practices and definitely less recommended.
Certainly using the same data in the cross validation set and the test set, that is not considered a good machine learning practice.
But, sometimes you see people do this too.
So, given the training cross validation and test sets, here's how you evaluate or here is how you develop and evaluate an algorithm.
First, we take the training sets and we fit the model p of x.
So, we fit, you know, all these Gaussians to my m unlabeled examples of aircraft engines, and these, I am calling them unlabeled examples, but these are really examples that we're assuming our goods are the normal aircraft engines.
Then imagine that your anomaly detection algorithm is actually making prediction.
So, on the cross validation of the test set, given that, say, test example X, think of the algorithm as predicting that y is equal to 1, p of x is less than epsilon, we must be taking zero, if p of x is greater than or equal to epsilon.
So given the training, cross validation, and test sets.
And more specifically, how do you evaluate an anomaly detection algorithm?
Well, to this whole, the first step is to take the unlabeled training set, and to fit the model p of x lead training data.
So you take this, you know on I'm coming, unlabeled training set, but really, these are examples that we are assuming, vast majority of which are normal aircraft engines, not because they're not anomalies and it will fit the model p of x.
It will fit all those parameters for all the Gaussians on this data.
Next on the cross validation of the test set, we're going to think of the anomaly detention algorithm as trying to predict the value of y.
We have these X-I tests, Y-I test, where y is going to be equal to 1 or 0 depending on whether this was an anomalous example.
So given input x in my test set, my anomaly detection algorithm think of it as predicting the y as 1 if p of x is less than epsilon.
So predicting that it is an anomaly, it is probably is very low.
If p of x is greater then or equals epsilon.
So predicting those normal example if the p of x is reasonably large.
And so we can now think of the anomaly detection algorithm as making predictions for what are the values of these y labels in the test sets or on the cross validation set.
And this puts us somewhat more similar to the supervised learning setting, right?
Where we have label test set and our algorithm is making predictions on these labels and so we can evaluate it you know by seeing how often it gets these labels right.
Of course these labels are will be very skewed because y equals zero, that is normal examples, usually be much more common than y equals 1 than anomalous examples.
But, you know, this is much closer to the source of evaluation metrics we can use in supervised learning.
Well, because the data is very skewed, because y equals 0 is much more common, classification accuracy would not be a good the evaluation metrics.
So, if you have a very skewed data set, then predicting y equals 0 all the time, will have very high classification accuracy.
Instead, we should use evaluation metrics, like computing the fraction of true positives, false positives, false negatives, true negatives or compute the position of the v curve of this algorithm or do things like compute the f1 score, right, which is a single real number way of summarizing the position and the recall numbers.
And so these would be ways to evaluate an anomaly detection algorithm on your cross validation set or on your test set.
So, epsilon is this threshold that we would use to decide when to flag something as an anomaly.
And so, if you have a cross validation set, another way to and to choose this parameter epsilon, would be to try a different, try many different values of epsilon, and then pick the value of epsilon that, let's say, maximizes f1 score, or that otherwise does well on your cross validation set.
And more generally, the way to reduce the training, testing, and cross validation sets, is that when we are trying to make decisions, like what features to include, or trying to, you know, tune the parameter epsilon, we would then continually evaluate the algorithm on the cross validation sets and make all those decisions like what features did you use, you know, how to set epsilon, use that, evaluate the algorithm on the cross validation set, and then when we've picked the set of features, when we've found the value of epsilon that we're happy with, we can then take the final model and evaluate it, you know, do the final evaluation of the algorithm on the test sets.
In this video, we started to use a bit of labeled data in order to evaluate the anomaly detection algorithm and this takes us a little bit closer to a supervised learning setting.
In the next video, I'm going to say a bit more about that.
And in particular we'll talk about when should you be using an anomaly detection algorithm and when should we be thinking about using supervised learning instead, and what are the differences between these two formalisms.
In the last video we talked about the process of evaluating an anomaly detection algorithm.
And there we started to use some label data with examples that we knew were either anomalous or not anomalous with Y equals one, or Y equals 0.
And so, the question then arises of, and if we have the label data, that we have some examples and know the anomalies, and some of them will not be anomalies.
So why don't we just use logistic regression, or a neuro network to try to learn directly from our labeled data to predict whether Y equals one or Y equals 0.
In this video, I'll try to share with you some of the thinking and some guidelines for when you should probably use an anomaly detection algorithm, and whether it might be more fruitful instead of using a supervisor in the algorithm.
This slide shows what are the settings under which you should maybe use anomaly detection versus when supervised learning might be more fruitful.
If you have a problem with a very small number of positive examples, and remember the examples of y equals one are the anomaly examples.
And usually we have such a small positive, set of positive examples, we're going to save the positive examples just for the cross validation set in the test set.
And in contrast, in a typical normal anomaly detection setting, we will often have a relatively large number of negative examples of the normal examples of normal aircraft engines.
And we can then use this very large number of negative examples With which to fit the model p(x).
And so there's this idea that in many anomaly detection applications, you have very few positive examples and lots of negative examples.
And when we're doing the process of estimating p(x), affecting all those Gaussian parameters, we need only negative examples to do that.
So if you have a lot negative data, we can still fit p(x) pretty well.
In contrast, for supervised learning, more typically we would have a reasonably large number of both positive and negative examples.
And so this is one way to look at your problem and decide if you should use an anomaly detection algorithm or a supervised.
Here's another way that people often think about anomaly detection.
So for anomaly detection applications, often there are very different types of anomalies.
There are so many things that could go wrong that could the aircraft engine.
And so if that's the case, and if you have a pretty small set of positive examples, then it can be hard for an algorithm, difficult for an algorithm to learn from your small set of positive examples what the anomalies look like.
And in particular, you know future anomalies may look nothing like the ones you've seen so far.
So maybe in your set of positive examples, maybe you've seen 5 or 10 or 20 different ways that an aircraft engine could go wrong.
And if that's the case, it might be more promising to just model the negative examples with this sort of calcium model p of x instead of try to hard to model the positive examples.
Because tomorrow's anomaly may be nothing like the ones you've seen so far.
In particular, if you think that future positive examples are likely to be similar to ones in the training set; then in that setting, it might be more reasonable to have a supervisor in the algorithm that looks at all of the positive examples, looks at all of the negative examples, and uses that to try to distinguish between positives and negatives.
Hopefully, this gives you a sense of if you have a specific problem, should you think about using an anomaly detection algorithm, or a supervised learning algorithm.
And a key difference really is that in anomaly detection, often we have such a small number of positive examples that it is not possible for a learning algorithm to learn that much from the positive examples.
And so what we do instead is take a large set of negative examples and have it just learn a lot, learn p(x) from just the negative examples.
Of the normal and we've reserved the small number of positive examples for evaluating our algorithms to use in the either the transvalidation set or the test set.
And just as a side comment about this many different types of easier.
In those examples, there are actually many different types of spam email, right?
There's spam email that's trying to sell you things.
But for the spam problem we usually have enough examples of spam email to see most of these different types of spam email because we have a large set of examples of spam.
And that's why we usually think of spam as a supervised learning setting even though there are many different types of.
If you have many different types of ways for people to try to commit fraud and a relatively small number of fraudulent users on your website, then I use an anomaly detection algorithm.
I should say, if you have, if you're a very major online retailer and if you actually have had a lot of people commit fraud on your website, so you actually have a lot of examples of y=1, then sometimes fraud detection could actually shift over to the supervised learning column.
But, if you haven't seen that many examples of users doing strange things on your website, then more frequently fraud detection is actually treated as an anomaly detection algorithm rather than a supervised learning algorithm.
Hopefully, you see more and more examples are not that many anomalies but if again for some manufacturing processes, if you manufacture in very large volumes and you see a lot of bad examples, maybe manufacturing can shift to the supervised learning column as well.
But if you haven't seen that many bad examples of so to do the anomaly detection monitoring machines in a data center similar source of apply.
So hopefully, that gives you a sense of one of the properties of a learning problem that would cause you to treat it as an anomaly detection problem versus a supervisory problem.
And for many other problems that are faced by various technology companies and so on, we actually are in the settings where we have very few or sometimes zero positive training examples.
There's just so many different types of anomalies that we've never seen them before.
And for those sorts of problems, very often the algorithm that is used is an anomaly detection algorithm.
By now you've seen the anomaly detection algorithm and we've also talked about how to evaluate an anomaly detection algorithm.
It turns out, that when you're applying anomaly detection, one of the things that has a huge effect on how well it does, is what features you use, and what features you choose, to give the anomaly detection algorithm.
So in this video, what I'd like to do is say a few words, give some suggestions and guidelines for how to go about designing or selecting features give to an anomaly detection algorithm.
In our anomaly detection algorithm, one of the things we did was model the features using this sort of Gaussian distribution.
With xi to mu i, sigma squared i, lets say.
And so one thing that I often do would be to plot the data or the histogram of the data, to make sure that the data looks vaguely Gaussian before feeding it to my anomaly detection algorithm.
And by the way, in case your data looks non-Gaussian, the algorithms will often work just find.
But, concretely if I plot the data like this, and if it looks like a histogram like this, and the way to plot a histogram is to use the HIST, or the HIST command in Octave, but it looks like this, this looks vaguely Gaussian, so if my features look like this, I would be pretty happy feeding into my algorithm.
But if i were to plot a histogram of my data, and it were to look like this well, this doesn't look at all like a bell shaped curve, this is a very asymmetric distribution, it has a peak way off to one side.
If this is what my data looks like, what I'll often do is play with different transformations of the data in order to make it look more Gaussian.
And again the algorithm will usually work okay, even if you don't.
But if you use these transformations to make your data more gaussian, it might work a bit better.
So given the data set that looks like this, what I might do is take a log transformation of the data and if i do that and re-plot the histogram, what I end up with in this particular example, is a histogram that looks like this.
And this looks much more Gaussian, right?
This looks much more like the classic bell shaped curve, that we can fit with some mean and variance paramater sigma.
So what I mean by taking a log transform, is really that if I have some feature x1 and then the histogram of x1 looks like this then I might take my feature x1 and replace it with log of x1 and this is my new x1 that I'll plot to the histogram over on the right, and this looks much more Guassian.
Rather than just a log transform some other things you can do, might be, let's say I have a different feature x2, maybe I'll replace that will log x plus 1, or more generally with log x with x2 and some constant c and this constant could be something that I play with, to try to make it look as Gaussian as possible.
Or for a different feature x3, maybe I'll replace it with x3, I might take the square root.
The square root is just x3 to the power of one half, right?
And this one half is another example of a parameter I can play with.
So, I might have x4 and maybe I might instead replace that with x4 to the power of something else, maybe to the power of 1/3.
And these, all of these, this one, this exponent parameter, or the C parameter, all of these are examples of parameters that you can play with in order to make your data look a little bit more Gaussian.
So, let me show you a live demo of how I actually go about playing with my data to make it look more Gaussian.
So, I have already loaded in to octave here a set of features x I have a thousand examples loaded over there.
So let's pull up the histogram of my data.
By default, I think this uses 10 bins of histograms, but I want to see a more fine grid histogram.
So we do hist to the x, 50, so, this plots it in 50 different bins.
Lets try a hist of x to the 0.5.
So we take the square root of the data, and plot that histogram.
Set this to 0.2.
Looks a little bit more Gaussian.
Let's reduce a little bit more 0.1.
Well, let's reduce it to 0.05.
And of course, there is more than one way to do this.
And, you know, that also look pretty Gaussian.
So, I can also define x mu equals log of x.
and that would be another pretty good choice of a feature to use.
So to summarize, if you plot a histogram with the data, and find that it looks pretty non-Gaussian, it's worth playing around a little bit with different transformations like these, to see if you can make your data look a little bit more Gaussian, before you feed it to your learning algorithm, although even if you don't, it might work okay.
But I usually do take this step.
Now, the second thing I want to talk about is, how do you come up with features for an anomaly detection algorithm.
And the way I often do so, is via an error analysis procedure.
So what I mean by that, is that this is really similar to the error analysis procedure that we have for supervised learning, where we would train a complete algorithm, and run the algorithm on a cross validation set, and look at the examples it gets wrong, and see if we can come up with extra features to help the algorithm do better on the examples that it got wrong in the cross-validation set.
So lets try to reason through an example of this process.
In anomaly detection, we are hoping that p of x will be large for the normal examples and it will be small for the anomalous examples.
And so a pretty common problem would be if p of x is comparable, maybe both are large for both the normal and the anomalous examples.
Lets look at a specific example of that.
Let's say that this is my unlabeled data.
And now let's say I have an anomalous example, and let's say that my anomalous example takes on an x value of 2.5.
And you know, it's kind of buried in the middle of a bunch of normal examples, and so, just this anomalous example that I've drawn in green, it gets a pretty high probability, where it's the height of the blue curve, and the algorithm fails to flag this as an anomalous example.
And if I managed to do so, the hope would be then, that, if I can create a new feature, X2, so that when I re-plot my data, if I take all my normal examples of my training set, hopefully I find that all my training examples are these red crosses here.
But now, if I model my data, I'll find that my anomaly detection algorithm gives high probability to data in the central regions, slightly lower probability to that, sightly lower probability to that.
An example that's all the way out there, my algorithm will now give very low probability to.
Look at the anomaly that the algorithm is failing to flag, and see if that inspires you to create some new feature.
So find something unusual about that aircraft engine and use that to create a new feature, so that with this new feature it becomes easier to distinguish the anomalies from your good examples.
And so that's the process of error analysis and using that to create new features for anomaly detection.
Finally, let me share with you my thinking on how I usually go about choosing features for anomaly detection.
So, usually, the way I think about choosing features is I want to choose features that will take on either very, very large values, or very, very small values, for examples that I think might turn out to be anomalies.
So let's use our example again of monitoring the computers in a data center.
And so you have lots of machines, maybe thousands, or tens of thousands of machines in a data center.
And we want to know if one of the machines, one of our computers is acting up, so doing something strange.
So here are examples of features you may choose, maybe memory used, number of disc accesses, CPU load, network traffic.
But now, lets say that I suspect one of the failure cases, let's say that in my data set I think that CPU load the network traffic tend to grow linearly with each other.
Maybe I'm running a bunch of web servers, and so, here if one of my servers is serving a lot of users, I have a very high CPU load, and have a very high network traffic.
But let's say, I think, let's say I have a suspicion, that one of the failure cases is if one of my computers has a job that gets stuck in some infinite loop.
So if I think one of the failure cases, is one of my machines, one of my web servers--server code-- gets stuck in some infinite loop, and so the CPU load grows, but the network traffic doesn't because it's just spinning it's wheels and doing a lot of CPU work, you know, stuck in some infinite loop.
In that case, to detect that type of anomaly, I might create a new feature, X5, which might be CPU load divided by network traffic.
And so here X5 will take on a unusually large value if one of the machines has a very large CPU load but not that much network traffic and so this will be a feature that will help your anomaly detection capture, a certain type of anomaly.
And this would be another variant of a feature like x5 to try to capture anomalies where one of your machines has a very high CPU load, that maybe doesn't have a commensurately large network traffic.
And by creating features like these, you can start to capture anomalies that correspond to unusual combinations of values of the features.
So in this video we talked about how to and take a feature, and maybe transform it a little bit, so that it becomes a bit more Gaussian, before feeding into an anomaly detection algorithm.
And also the error analysis in this process of creating features to try to capture different types of anomalies.
And with these sorts of guidelines hopefully that will help you to choose good features, to give to your anomaly detection algorithm, to help it capture all sorts of anomalies.
In this and the next video, I'd like to tell you about one possible extension to the anomaly detection algorithm that we've developed so far.
This extension uses something called the multivariate Gaussian distribution, and it has some advantages, and some disadvantages, and it can sometimes catch some anomalies that the earlier algorithm didn't.
To motivate this, let's start with an example.
Let's say that so our unlabeled data looks like what I have plotted here.
And I'm going to use the example of monitoring machines in the data center, monitoring computers in the data center.
So my two features are x1 which is the CPU load and x2 which is maybe the memory use.
And so this is how the anomaly detection algorithm models X1 and X2.
The location of that green cross, so the value of X 1 is about 0.4, and the value of X 2 is about 1.5.
Now, if you look at the data, it looks like, yeah, most of the data data lies in this region, and so that green cross is pretty far away from any of the data I've seen.
It looks like that should be raised as an anomaly.
So, in my data, in my, in the data of my good examples, it looks like, you know, the CPU load, and the memory use, they sort of grow linearly with each other.
It looks like that should be an anomaly.
But let's see what the anomaly detection algorithm will do.
Well, for the CPU load, it puts it at around there 0.5 and this reasonably high probability is not that far from other examples we've seen, maybe, whereas, for the memory use, this appointment, 0.5, whereas for the memory use, it's about 1.5, which is there.
Again, you know, it's all to us, it's not terribly Gaussian, but the value here and the value here is not that different from many other examples we've seen, and so P of X 1, will be pretty high, reasonably high.
I mean, if you look at this plot right, this point here, it doesn't look that bad, and if you look at this plot, you know across here, doesn't look that bad.
I mean, I have had examples with even greater memory used, or with even less CPU use, and so this example doesn't look that anomalous.
And so, an anomaly detection algorithm will fail to flag this point as an anomaly.
So, in order to fix this, we can, we're going to develop a modified version of the anomaly detection algorithm, using something called the multivariate Gaussian distribution also called the multivariate normal distribution.
So here's what we're going to do.
So the parameters of the multivariate Gaussian distribution are mu, which is a vector, and sigma, which is an n by n matrix, called a covariance matrix, and this is similar to the covariance matrix that we saw when we were working with the PCA, with the principal components analysis algorithm.
For the second complete is, let me just write out the formula for the multivariate Gaussian distribution.
So we say that probability of X, and this is parameterized by my parameters mu and sigma that the probability of x is equal to once again there's absolutely no need to memorize this formula.
You know, you can look it up whenever you need to use it, but this is what the probability of X looks like.
In this expression, these sigmas here, these are just n by n matrix.
This is not a summation and you know, the sigma there is an n by n matrix.
So that's the formula for P of X, but it's more interestingly, or more importantly, what does P of X actually looks like?
Lets look at some examples of multivariate Gaussian distributions.
Lets say I set MU to be equal to 0 and sigma to be equal to this matrix here.
In that case, p of x will look like this, and what I'm showing in this figure is, you know, for a specific value of X1 and for a specific value of X2, the height of this surface the value of p of x.
And so with this setting the parameters p of x is highest when X1 and X2 equal zero 0, so that's the peak of this Gaussian distribution, and the probability falls off with this sort of two dimensional Gaussian or this bell shaped two dimensional bell-shaped surface.
And so, with this distribution, you see that it faces most of the probability near 0,0 and then as you go out from 0,0 the probability of X1 and X2 goes down.
Now lets try varying some of the parameters and see what happens.
So let's take sigma and change it so let's say sigma shrinks a little bit.
Sigma is a covariance matrix and so it measures the variance or the variability of the features X1 X2.
So if the shrink sigma then what you get is what you get is that the width of this bump diminishes and the height also increases a bit, because the area under the surface is equal to 1.
So the integral of the volume under the surface is equal to 1, because probability distribution must integrate to one.
But, if you shrink the variance, it's kinda like shrinking sigma squared, you end up with a narrower distribution, and one that's a little bit taller.
And so you see here also the concentric ellipsis has shrunk a little bit.
Whereas in contrast if you were to increase sigma to 2 2 on the diagonals, so it is now two times the identity then you end up with a much wider and much flatter Gaussian.
And so the width of this is much wider.
This is hard to see but this is still a bell shaped bump, it's just flattened down a lot, it has become much wider and so the variance or the variability of X1 and X2 just becomes wider.
Now lets try varying one of the elements of sigma at the time.
What this does, is this reduces the variance of the first feature, X 1, while keeping the variance of the second feature X 2, the same.
And so with this setting of parameters, you can model things like that.
Whereas if I do this, if I set this matrix to 2, 1 then you can also model examples where you know here we'll say X1 can have take on a large range of values whereas X2 takes on a relatively narrower range of values.
And that's reflected in this figure as well, you know where, the distribution falls off more slowly as X 1 moves away from 0, and falls off very rapidly as X 2 moves away from 0.
Now, one of the cool things about the multivariate Gaussian distribution is that you can also use it to model correlations between the data.
That is we can use it to model the fact that X1 and X2 tend to be highly correlated with each other for example.
So specifically if you start to change the off diagonal entries of this covariance matrix you can get a different type of Gaussian distribution.
And so as I increase the off-diagonal entries from .5 to .8, what I get is this distribution that is more and more thinly peaked along this sort of x equals y line.
And so here the contour says that x and y tend to grow together and the things that are with large probability are if either X1 is large and Y2 is large or X1 is small and Y2 is small.
And as this entry, 0.8 gets large, you get a Gaussian distribution, that's sort of where all the probability lies on this sort of narrow region, where x is approximately equal to y.
This is a very tall, thin distribution you know line mostly along this line central region where x is close to y.
In contrast if we set these to negative values, as I decreases it to -.5 down to -.8, then what we get is a model where we put most of the probability in this sort of negative X one in the next 2 correlation region, and so, most of the probability now lies in this region, where X 1 is about equal to -X 2, rather than X 1 equals X 2.
And so this captures a sort of negative correlation between x1 and x2.
And so this is a hopefully this gives you a sense of the different distributions that the multivariate Gaussian distribution can capture.
So, hopefully, looking at all these different pictures gives you a sense of the sort of probability distributions that the Multivariate Gaussian Distribution allows you to capture.
And the key advantage of it is it allows you to capture, when you'd expect two different features to be positively correlated, or maybe negatively correlated.
In the next video, we'll take this multivariate Gaussian distribution and apply it to anomaly detection.
In the last video we talked about the Multivariate Gaussian Distribution and saw some examples of the sorts of distributions you can model, as you vary the parameters, mu and sigma.
In this video, let's take those ideas, and apply them to develop a different anomaly detection algorithm.
To recap the multivariate Gaussian distribution and the multivariate normal distribution has two parameters, mu and sigma.
Where mu this an n dimensional vector and sigma, the covariance matrix, is an n by n matrix.
And here's the formula for the probability of X, as parameterized by mu and sigma, and as you vary mu and sigma, you can get a range of different distributions, like, you know, these are three examples of the ones that we saw in the previous video.
So let's talk about the parameter fitting or the parameter estimation problem.
The question, as usual, is if I have a set of examples X1 through XM and here each of these examples is an n dimensional vector and I think my examples come from a multivariate Gaussian distribution.
Well the standard formulas for estimating them is you set mu to be just the average of your training examples.
And this is actually just like the sigma that we had written out, when we were using the PCA or the Principal Components Analysis algorithm.
So given the data set here is how you estimate mu and sigma.
Let's take this method and just plug it into an anomaly detection algorithm.
So how do we put all of this together to develop an anomaly detection algorithm?
Here 's what we do.
First we take our training set, and we fit the model, we fit P of X, by, you know, setting mu and sigma as described on the previous slide.
So if you are given a test example, lets take an earlier example to have a new example out here.
And that is my test example.
Given the new example X, what we are going to do is compute P of X, using this formula for the multivariate Gaussian distribution.
And then, if P of X is very small, then we flagged it as an anomaly, whereas, if P of X is greater than that parameter epsilon, then we don't flag it as an anomaly.
So it turns out, if we were to fit a multivariate Gaussian distribution to this data set, so just the red crosses, not the green example, you end up with a Gaussian distribution that places lots of probability in the central region, slightly less probability here, slightly less probability here, slightly less probability here, and very low probability at the point that is way out here.
And so, if you apply the multivariate Gaussian distribution to this example, it will actually correctly flag that example.
Finally it's worth saying a few words about what is the relationship between the multivariate Gaussian distribution model, and the original model, where we were modeling P of X as a product of this P of X1, P of X2, up to P of Xn.
It turns out that you can prove mathematically, I'm not going to do the proof here, but you can prove mathematically that this relationship, between the multivariate Gaussian model and this original one.
And in particular, it turns out that the original model corresponds to multivariate Gaussians, where the contours of the Gaussian are always axis aligned.
So all three of these are examples of Gaussian distributions that you can fit using the original model.
It turns out that that corresponds to multivariate Gaussian, where, you know, the ellipsis here, the contours of this distribution--it turns out that this model actually corresponds to a special case of a multivariate Gaussian distribution.
And in particular, this special case is defined by constraining the distribution of p of x, the multivariate a Gaussian distribution of p of x, so that the contours of the probability density function, of the probability distribution function, are axis aligned.
And so you can get a p of x with a multivariate Gaussian that looks like this, or like this, or like this.
And you notice, that in all 3 of these examples, these ellipses, or these ovals that I'm drawing, have their axes aligned with the X1 X2 axes.
And what we do not have, is a set of contours that are at an angle, right?
And this corresponded to examples where sigma is equal to 1 1, 0.8, 0.8.
So, it turns out that it's possible to show mathematically that this model actually is the same as a multivariate Gaussian distribution but with a constraint.
And the constraint is that the covariance matrix sigma must have 0's on the off diagonal elements.
In particular, the covariance matrix sigma, this thing here, it would be sigma squared 1, sigma squared 2, down to sigma squared n, and then everything on the off diagonal entries, all of these elements above and below the diagonal of the matrix, all of those are going to be zero.
And in fact if you take these values of sigma, sigma squared 1, sigma squared 2, down to sigma squared n, and plug them into here, and you know, plug them into this covariance matrix, then the two models are actually identical.
That is, this new model, using a multivariate Gaussian distribution, corresponds exactly to the old model, if the covariance matrix sigma, has only 0 elements off the diagonals, and in pictures that corresponds to having Gaussian distributions, where the contours of this distribution function are axis aligned.
So you aren't allowed to model the correlations between the diffrent features.
So in that sense the original model is actually a special case of this multivariate Gaussian model.
So when would you use each of these two models?
So when would you the original model and when would you use the multivariate Gaussian model?
The original model is probably used somewhat more often, and whereas the multivariate Gaussian distribution is used somewhat less but it has the advantage of being able to capture correlations between features.
But if you're willing to spend the time to manually create an extra feature like this, then the original model will work fine.
Whereas in contrast, the multivariate Gaussian model can automatically capture correlations between different features.
But the original model has some other more significant advantages, too, and one huge advantage of the original model is that it is computationally cheaper, and another view on this is that is scales better to very large values of n and very large numbers of features, and so even if n were ten thousand, or even if n were equal to a hundred thousand, the original model will usually work just fine.
Whereas in contrast for the multivariate Gaussian model notice here, for example, that we need to compute the inverse of the matrix sigma where sigma is an n by n matrix and so computing sigma if sigma is a hundred thousand by a hundred thousand matrix that is going to be very computationally expensive.
And so the multivariate Gaussian model scales less well to large values of N.
And finally for the original model, it turns out to work out ok even if you have a relatively small training set this is the small unlabeled examples that we use to model p of x of course, and this works fine, even if M is, you know, maybe 50, 100, works fine.
Whereas for the multivariate Gaussian, it is sort of a mathematical property of the algorithm that you must have m greater than n, so that the number of examples is greater than the number of features you have.
And there's a mathematical property of the way we estimate the parameters that if this is not true, so if m is less than or equal to n, then this matrix isn't even invertible, that is this matrix is singular, and so you can't even use the multivariate Gaussian model unless you make some changes to it.
And m greater than or equal to 10 n would be a reasonable rule of thumb to make sure that you can estimate this covariance matrix sigma reasonably well.
So in practice the original model shown on the left that is used more often.
And if you suspect that you need to capture correlations between features what people will often do is just manually design extra features like these to capture specific unusual combinations of values.
But in problems where you have a very large training set or m is very large and n is not too large, then the multivariate Gaussian model is well worth considering and may work better as well, and can save you from having to spend your time to manually create extra features in case the anomalies turn out to be captured by unusual combinations of values of the features.
Finally I just want to briefly mention one somewhat technical property, but if you're fitting multivariate Gaussian model, and if you find that the covariance matrix sigma is singular, or you find it's non-invertible, they're usually 2 cases for this.
One is if it's failing to satisfy this m greater than n condition, and the second case is if you have redundant features.
So by redundant features, I mean, if you have 2 features that are the same.
Okay, so if you have highly redundant features like these, you know, where if X3 is equal to X4 plus X5, well X3 doesn't contain any extra information, right?
And if you have this sort of redundant features, duplicated features, or this sort of features, than sigma may be non-invertible.
And so there's a debugging set-- this should very rarely happen, so you probably won't run into this, it is very unlikely that you have to worry about this-- but in case you implement a multivariate Gaussian model you find that sigma is non-invertible.
What I would do is first make sure that M is quite a bit bigger than N, and if it is then, the second thing I do, is just check for redundant features.
As an aside for those of you who are experts in linear algebra, by redundant features, what I mean is the formal term is features that are linearly dependent.
But in practice what that really means is one of these problems tripping up the algorithm if you just make you features non-redundant., that should solve the problem of sigma being non-invertable.
But once again the odds of your running into this at all are pretty low so chances are, you can just apply the multivariate Gaussian model, without having to worry about sigma being non-invertible, so long as m is greater than or equal to n.
So that's it for anomaly detection, with the multivariate Gaussian distribution.
And if you apply this method you would be able to have an anomaly detection algorithm that automatically captures positive and negative correlations between your different features and flags an anomaly if it sees is unusual combination of the values of the features.
In the last video, we talked about the recommender systems problem where for example you might have a set of movies and you may have a set of users, each who have rated some subset of the movies.
They've rated the movies one to five stars or zero to five stars.
And what we would like to do is look at these users and predict how they would have rated other movies that they have not yet rated.
In this video I'd like to talk about our first approach to building a recommender system.
This approach is called content based recommendations.
Here's our data set from before and just to remind you of a bit of notation, I was using nu to denote the number of users and so that's equal to 4, and nm to denote the number of movies, I have 5 movies.
So, how do I predict what these missing values would be?
Let's suppose that for each of these movies I have a set of features for them.
In particular, let's say that for each of the movies have two features which I'm going to denote x1 and x2.
So, if you take a movie, Love at last, you know it's 0.9 rating on the romance scale.
Romance forever is a 1.0, lot of romance and 0.01 action.
I don't know, maybe there's a minor car crash in that movie or something.
So there's a little bit of action.
Skipping one, let's do Swords vs karate, maybe that has a 0 romance rating and no romance at all in that but plenty of action.
And Nonstop car chases, maybe again there's a tiny bit of romance in that movie but mainly action.
And Cute puppies of love mainly a romance movie with no action at all.
So if we have features like these, then each movie can be represented with a feature vector.
Let's take movie one.
So let's call these movies 1, 2, 3, 4, and 5.
But my first movie, Love at last, I have my two features, 0.9 and 0.
And let's add an extra feature as usual, which is my interceptor feature x0 = 1.
So for Love at last I would have a feature vector x1, for the movie Romance forever I may have a software feature of vector x2, and so on, and for Swords vs karate I would have a different feature vector x superscript 5.
Also, consistence with our earlier node notation that we were using, we're going to set n to be the number of features not counting this x0 interceptor.
So n is equal to 2 because it's we have two features x1 and x2 capturing the degree of romance and the degree of action in each movie.
Now in order to make predictions here's one thing that we do which is that we could treat predicting the ratings of each user as a separate linear regression problem.
So specifically, let's say that for each user j, we're going to learn the parameter vector theta j, which would be an R3 in this case.
More generally, theta (j) would be an R (n+1), where n is the number of features not counting the set term.
And we're going to predict user j as rating movie i with just the inner product between parameters vectors theta and the features xi.
So let's take a specific example.
And associated with Alice would be some parameter vector theta 1.
And our second user, Bob, will be associated a different parameter vector theta 2.
Carol will be associated with a different parameter vector theta 3 and Dave a different parameter vector theta 4.
So let's say you want to make a prediction for what Alice will think of the movie Cute puppies of love.
And let's say, for this example, let's say that we've somehow already gotten a parameter vector theta 1 for Alice.
But let's just say for now that some unspecified learning algorithm has learned the parameter vector theta 1 and is equal to this 0,5,0.
So our prediction for this entry is going to be equal to theta 1, that is Alice's parameter vector, transpose x3, that is the feature vector for the Cute puppies of love movie, number 3.
And so the inner product between these two vectors is gonna be 5 times 0.99, which is equal to 4.95.
And so my prediction for this value over here is going to be 4.95.
And maybe that seems like a reasonable value if indeed this is my parameter vector theta 1.
So, all we're doing here is we're applying a different copy of this linear regression for each user, and we're saying that what Alice does is Alice has some parameter vector theta 1 that she uses, that we use to predict her ratings as a function of how romantic and how action packed a movie is.
More formally, here's how we can write down the problem.
That is, if that user has actually rated that movie.
And for each user and each movie, we predict that rating as follows.
We're gonna use mj to denote the number of users rated by movie j.
Now in order to learn the parameter vector for theta j, well how do we do so.
This is basically a linear regression problem.
So what we can do is just choose a parameter vector theta j so that the predicted values here are as close as possible to the values that we observed in our training sets and the values we observed in our data.
So let's write that down.
In order to learn the parameter vector theta j, let's minimize over the parameter vector theta j of sum, and I want to sum over all movies that user j has rated.
So the way to read this summation syntax is this is summation over all the values of i, so the r(i.j) is equal to 1.
So you'll be summing over all the movies that user j has rated.
So that's the prediction of using j's rating on movie i,- y (i,j).
So that's the actual observed rating squared.
And then, let me just divide by the number of movies that user j has actually rated.
And so this is just like the least squares regressions.
It's just like linear regression, where we want to choose the parameter vector theta j to minimize this type of squared error term.
User j has rated that many movies, it's not like we have that many data points with which to fit the parameters of theta j.
As usual, this sum is from k equals 1 through n, so here, theta j is going to be an n plus 1 dimensional vector, where in our early example n was equal to 2.
The sum is from k equals 1 through n.
So if you minimize this as a function of theta j you get a good solution, you get a pretty good estimate of a parameter vector theta j with which to make predictions for user j's movie ratings.
So to simplify the subsequent math, I with to get rid of this term mj.
So I can delete it without changing the value of theta j that I get out of this optimization.
So if you imagine taking this whole equation, taking this whole expression and multiplying it by mj, get rid of that constant.
In order to learn theta j which is the parameter for user j, we're going to minimize over theta j of this optimization objectives.
So this is our usual squared error term and then this is our regularizations term.
Now of course in building a recommender system, we don't just want to learn parameters for a single user.
We want to learn parameters for all of our users.
I have n subscript u users, so I want to learn all of these parameters.
And so, what I'm going to do is take this optimization objective and just add the mixture summation there.
Except that now instead of just doing this for a specific user theta j, I'm going to sum my objective over all of my users and then minimize this overall optimization objective, minimize this overall cost on.
And when I minimize this as a function of theta 1, theta 2, up to theta nu, I will get a separate parameter vector for each user.
And to give this thing a name, I'll just call this J(theta1, ..., theta nu).
So j as usual is my optimization objective, which I'm trying to minimize.
Next, in order to actually do the minimization, if you were to derive the gradient descent update, these are the equations that you would get.
So you take theta j, k, and subtract from an alpha, which is the learning rate, times these terms over here on the right.
Because our regularization term here regularizes only the values of theta jk for k not equal to 0, so we don't regularize theta 0, so with slightly different updates when k equals 0 and k is not equal to 0.
And this term over here, for example, is just the partial derivative with respect to your parameter, that of your optimization objective.
Right and so this is just gradient descent and I've already computed the derivatives and plugged them into here.
And if this gradient descent update look a lot like what we have here for linear regression.
That's because these are essentially the same as linear regression.
But otherwise, it's really some of my training examples of the ever times xk plus that regularization term, plus that term of regularization contributes to the derivative.
And so if you're using gradient descent here's how you can minimize the cost function j to learn all the parameters.
And using these formulas for the derivative if you want, you can also plug them into a more advanced optimization algorithm, like conjugate gradient or LBFGS or what have you.
And use that to try to minimize the cost function j as well.
So hopefully you now know how you can apply essentially a deviation on linear regression in order to predict different movie ratings by different users.
And so where features that capture what is the content of these movies, of how romantic is this movie, how much action is in this movie.
And we're really using features of a content of the movies to make our predictions.
But for many movies, we don't actually have such features.
Or maybe very difficult to get such features for all of our movies, for all of whatever items we're trying to sell.
In this video we'll talk about an approach to building a recommender system that's called collaborative filtering.
The algorithm that we're talking about has a very interesting property that it does what is called feature learning and by that I mean that this will be an algorithm that can start to learn for itself what features to use.
Here was the data set that we had and we had assumed that for each movie, someone had come and told us how romantic that movie was and how much action there was in that movie.
But as you can imagine it can be very difficult and time consuming and expensive to actually try to get someone to, you know, watch each movie and tell you how romantic each movie and how action packed is each movie, and often you'll want even more features than just these two.
So where do you get these features from?
So let's change the problem a bit and suppose that we have a data set where we do not know the values of these features.
So we're given the data set of movies and of how the users rated them, but we have no idea how romantic each movie is and we have no idea how action packed each movie is so I've replaced all of these things with question marks.
But now let's make a slightly different assumption.
Let's say we've gone to each of our users, and each of our users has told has told us how much they like the romantic movies and how much they like action packed movies.
Bob theta 2.
Carol theta 3.
Dave theta 4.
And let's say we also use this and that Alice tells us that she really likes romantic movies and so there's a five there which is the multiplier associated with X1 and lets say that Alice tells us she really doesn't like action movies and so there's a 0 there.
And Bob tells us something similar so we have theta 2 over here.
So let's assume that somehow we can go to users and each user J just tells us what is the value of theta J for them.
And so basically specifies to us of how much they like different types of movies.
If we can get these parameters theta from our users then it turns out that it becomes possible to try to infer what are the values of x1 and x2 for each movie.
Let's look at an example.
Let's look at movie 1.
So that movie 1 has associated with it a feature vector x1.
And you know this movie is called Love at last but let's ignore that.
Let's pretend we don't know what this movie is about, so let's ignore the title of this movie.
All we know is that Alice loved this move.
Bob loved this movie.
Carol and Dave hated this movie.
So what can we infer?
Well, we know from the feature vectors that Alice and Bob love romantic movies because they told us that there's a 5 here.
Whereas Carol and Dave, we know that they hate romantic movies and that they love action movies.
And so based on the fact that movie 1 is loved by Alice and Bob and hated by Carol and Dave, we might reasonably conclude that this is probably a romantic movie, it is probably not much of an action movie.
And from this it looks like, you know, X1 equals one that's the intercept term, and then 1.0, 0.0, that makes sense given what we know of Alice, Bob, Carol, and Dave's preferences for movies and the way they rated this movie.
And so more generally, we can go down this list and try to figure out what might be reasonable features for these other movies as well.
Let's formalize this problem of learning the features XI.
Let's say that our users have given us their preferences.
So let's say that our users have come and, you know, told us these values for theta 1 through theta of NU and we want to learn the feature vector XI for movie number I.
What we can do is therefore pose the following optimization problem.
So and then what we want to do is minimize this squared error, so we want to choose features XI, so that, you know, the predictive value of how user J rates movie I will be similar, will be not too far in the squared error sense of the actual value YIJ that we actually observe in the rating of user j on movie I.
So, just to summarize what this term does is it tries to choose features XI so that for all the users J that have rated that movie, the algorithm also predicts a value for how that user would have rated that movie that is not too far, in the squared error sense, from the actual value that the user had rated that movie.
So that's the squared error term.
As usual, we can also add this sort of regularization term to prevent the features from becoming too big.
So this is how we would learn the features for one specific movie but what we want to do is learn all the features for all the movies and so what I'm going to do is add this extra summation here so I'm going to sum over all Nm movies, N subscript m movies, and minimize this objective on top that sums of all movies.
And if you do that, you end up with the following optimization problem.
And if you minimize this, you have hopefully a reasonable set of features for all of your movies.
In the previous video, what we showed was that you know, if you have a set of movie ratings, so if you have the data the rij's and then you have the yij's that will be the movie ratings.
So if you knew the features, you can learn the parameters theta for your different users.
And what we showed earlier in this video is that if your users are willing to give you parameters, then you can estimate features for the different movies.
So this is kind of a chicken and egg problem.
Which comes first?
And what you can do is, and then this actually works, what you can do is in fact randomly guess some value of the thetas.
Now based on your initial random guess for the thetas, you can then go ahead and use the procedure that we just talked about in order to learn features for your different movies.
Now given some initial set of features for your movies you can then use this first method that we talked about in the previous video to try to get an even better estimate for your parameters theta.
Now that you have a better setting of the parameters theta for your users, we can use that to maybe even get a better set of features and so on.
We can sort of keep iterating, going back and forth and optimizing theta, x theta, x theta, nd this actually works and if you do this, this will actually cause your album to converge to a reasonable set of features for you movies and a reasonable set of parameters for your different users.
So this is a basic collaborative filtering algorithm.
This isn't actually the final algorithm that we're going to use.
But, hopefully this gives you a sense of how you can formulate a problem where you can simultaneously learn the parameters and simultaneously learn the features from the different movies.
And for this problem, for the recommender system problem, this is possible only because each user rates multiple movies and hopefully each movie is rated by multiple users.
And so you can do this back and forth process to estimate theta and x.
So to summarize, in this video we've seen an initial collaborative filtering algorithm.
And so there is a sense of collaboration where every user is helping the system learn better features for the common good.
This is this collaborative filtering.
And, in the next video what we going to do is take the ideas that have worked out, and try to develop a better an even better algorithm, a slightly better technique for collaborative filtering.
In the last couple videos, we talked about the ideas of how, first, if you're given features for movies, you can use that to learn parameters data for users.
And second, if you're given parameters for the users, you can use that to learn features for the movies.
So one of the things we worked out earlier is that if you have features for the movies then you can solve this minimization problem to find the parameters theta for your users.
And then we also worked that out, if you are given the parameters theta, you can also use that to estimate the features x, and you can do that by solving this minimization problem.
So one thing you could do is actually go back and forth.
Maybe randomly initialize the parameters and then solve for theta, solve for x, solve for theta, solve for x.
But, it turns out that there is a more efficient algorithm that doesn't need to go back and forth between the x's and the thetas, but that can solve for theta and x simultaneously.
What we are going to do, is basically take both of these optimization objectives, and put them into the same objective.
So I'm going to define the new optimization objective j, which is a cost function, that is a function of my features x and a function of my parameters theta.
And, it's basically the two optimization objectives I had on top, but I put together.
So, in order to explain this, first, I want to point out that this term over here, this squared error term, is the same as this squared error term and the summations look a little bit different, but let's see what the summations are really doing.
The first summation is sum over all users J and then sum over all movies rated by that user.
So, this is really summing over all pairs IJ, that correspond to a movie that was rated by a user.
Sum over J says, for every user, the sum of all the movies rated by that user.
This summation down here, just does things in the opposite order.
This says for every movie I, sum over all the users J that have rated that movie and so, you know these summations, both of these are just summations over all pairs ij for which r of i J is equal to 1.
It's just something over all the user movie pairs for which you have a rating.
and so those two terms up there is just exactly this first term, and I've just written the summation here explicitly, where I'm just saying the sum of all pairs IJ, such that RIJ is equal to 1.
So what we're going to do is define a combined optimization objective that we want to minimize in order to solve simultaneously for x and theta.
And then the other terms in the optimization objective are this, which is a regularization in terms of theta.
So that came down here and the final piece is this term which is my optimization objective for the x's and that became this.
And this optimization objective j actually has an interesting property that if you were to hold the x's constant and just minimize with respect to the thetas then you'd be solving exactly this problem, whereas if you were to do the opposite, if you were to hold the thetas constant, and minimize j only with respect to the x's, then it becomes equivalent to this.
So here's an optimization objective that puts together my cost functions in terms of x and in terms of theta.
And in order to come up with just one optimization problem, what we're going to do, is treat this cost function, as a function of my features x and of my user pro user parameters data and just minimize this whole thing, as a function of both the Xs and a function of the thetas.
And really the only difference between this and the older algorithm is that, instead of going back and forth, previously we talked about minimizing with respect to theta then minimizing with respect to x, whereas minimizing with respect to theta, minimizing with respect to x and so on.
In this new version instead of sequentially going between the 2 sets of parameters x and theta, what we are going to do is just minimize with respect to both sets of parameters simultaneously.
When we are using this sort of formalism where we're are actually learning the features, we are actually going to do away with this convention.
And so the features we are going to learn x, will be in Rn.
And the reason we do away with this convention is because we're now learning all the features, right?
So there is no need to hard code the feature that is always equal to one.
Because if the algorithm really wants a feature that is always equal to 1, it can choose to learn one for itself.
So if the algorithm chooses, it can set the feature X1 equals 1.
So there's no need to hard code the feature of 001, the algorithm now has the flexibility to just learn it by itself.
So, putting everything together, here is our collaborative filtering algorithm.
first we are going to initialize x and theta to small random values.
And this is a little bit like neural network training, where there we were also initializing all the parameters of a neural network to small random values.
Next we're then going to minimize the cost function using great intercepts or one of the advance optimization algorithms.
So, if you take derivatives you find that the great intercept like these and so this term here is the partial derivative of the cost function, I'm not going to write that out, with respect to the feature value Xik and similarly this term here is also a partial derivative value of the cost function with respect to the parameter theta that we're minimizing.
And just as a reminder, in this formula that we no longer have this X0 equals 1 and so we have that x is in Rn and theta is a Rn.
So there is now no longer a theta 0, which is why in these updates, I did not break out a special case for k equals 0.
And finally, given a user, if a user has some parameters, theta, and if there's a movie with some sort of learned features x, we would then predict that that movie would be given a star rating by that user of theta transpose j.
Or just to fill those in, then we're saying that if user J has not yet rated movie I, then what we do is predict that user J is going to rate movie I according to theta J transpose Xi.
In the last few videos, we talked about a collaborative filtering algorithm.
In this video I'm going to say a little bit about the vectorization implementation of this algorithm.
And also talk a little bit about other things you can do with this algorithm.
For example, one of the things you can do is, given one product can you find other products that are related to this so that for example, a user has recently been looking at one product.
Are there other related products that you could recommend to this user?
So let's see what we could do about that.
What I'd like to do is work out an alternative way of writing out the predictions of the collaborative filtering algorithm.
So, here we have five movies and four users, and so this matrix y is going to be a 5 by 4 matrix.
It's just you know, taking all of the elements, all of this data.
And of course the elements of this matrix of the (i, j) element of this matrix is really what we were previously writing as y superscript i, j.
It's the rating given to movie i by user j.
Given this matrix y of all the ratings that we have, there's an alternative way of writing out all the predictive ratings of the algorithm.
And, in particular if you look at what a certain user predicts on a certain movie, what user j predicts on movie i is given by this formula.
And so, if you have a matrix of the predicted ratings, what you would have is the following matrix where the i, j entry.
Now, given this matrix of predictive ratings there is then a simpler or vectorized way of writing these out.
In particular if I define the matrix x, and this is going to be just like the matrix we had earlier for linear regression to be sort of x1 transpose x2 transpose down to x of nm transpose.
So if you think of each movie as one example and stack all of the features of the different movies and rows.
And if we also to find a matrix capital theta, and what I'm going to do is take each of the per user parameter vectors, and stack them in rows, like so.
So that's theta 1, which is the parameter vector for the first user.
And, you know, theta 2, and so, you must stack them in rows like this to define a matrix capital theta and so I have nu parameter vectors all stacked in rows like this.
Now given this definition for the matrix x and this definition for the matrix theta in order to have a vectorized way of computing the matrix of all the predictions you can just compute x times the matrix theta transpose, and that gives you a vectorized way of computing this matrix over here.
The algorithm that we're using is also called low rank matrix factorization.
And so if you hear people talk about low rank matrix factorization that's essentially exactly the algorithm that we have been talking about.
And this term comes from the property that this matrix x times theta transpose has a mathematical property in linear algebra called that this is a low rank matrix and so that's what gives rise to this name low rank matrix factorization for these algorithms, because of this low rank property of this matrix x theta transpose.
In case you don't know what low rank means or in case you don't know what a low rank matrix is, don't worry about it.
You really don't need to know that in order to use this algorithm.
But if you're an expert in linear algebra, that's what gives this algorithm, this other name of low rank matrix factorization.
Finally, having run the collaborative filtering algorithm here's something else that you can do which is use the learned features in order to find related movies.
Specifically for each product i really for each movie i, we've learned a feature vector xi.
What are the important aspects that cause some users to like certain movies and cause some users to like different sets of movies.
So maybe you end up learning a feature, you know, where x1 equals romance, x2 equals action similar to an earlier video and maybe you learned a different feature x3 which is a degree to which this is a comedy.
And you have N features all together and after you have learned features it's actually often pretty difficult to go in to the learned features and come up with a human understandable interpretation of what these features really are.
But in practice, you know, the features even though these features can be hard to visualize.
It can be hard to figure out just what these features are.
Usually, it will learn features that are very meaningful for capturing whatever are the most important or the most salient properties of a movie that causes you to like or dislike it.
And so now let's say we want to address the following problem.
Say you have some specific movie i and you want to find other movies j that are related to that movie.
And so well, why would you want to do this?
Right, maybe you have a user that's browsing movies, and they're currently watching movie j, than what's a reasonable movie to recommend to them to watch after they're done with movie j?
Or if someone's recently purchased movie j, well, what's a different movie that would be reasonable to recommend to them for them to consider purchasing.
So, now that you have learned these feature vectors, this gives us a very convenient way to measure how similar two movies are.
and so if you can find a different movie, j, so that the distance between xi and xj is small, then this is a pretty strong indication that, you know, movies j and i are somehow similar.
At least in the sense that some of them likes movie i, maybe more likely to like movie j as well.
And this could give you a few different movies to recommend to your user.
So with that, hopefully, you now know how to use a vectorized implementation to compute all the predicted ratings of all the users and all the movies, and also how to do things like use learned features to find what might be movies and what might be products that aren't related to each other.
By now you've seen all of the main pieces of the recommender system algorithm or the collaborative filtering algorithm.
In this video I want to just share one last implementational detail, namely mean normalization, which can sometimes just make the algorithm work a little bit better.
To motivate the idea of mean normalization, let's consider an example of where there's a user that has not rated any movies.
So, in addition to our four users, Alice, Bob, Carol, and Dave, I've added a fifth user, Eve, who hasn't rated any movies.
Let's see what our collaborative filtering algorithm will do on this user.
So if we look in the first term in this optimization objective, well the user Eve hasn't rated any movies, so there are no movies for which Rij is equal to one for the user Eve and so this first term plays no role at all in determining theta 5 because there are no movies that Eve has rated.
And so the only term that effects theta 5 is this term.
And so we're saying that we want to choose vector theta 5 so that the last regularization term is as small as possible.
Because a regularization term is encouraging us to set parameters close to 0 and if there is no data to try to pull the parameters away from 0, because this first term doesn't effect theta 5, we just end up with theta 5 equals the vector of all zeros.
And so when we go to predict how user 5 would rate any movie, we have that theta 5 transpose xi, for any i, that's just going to be equal to zero.
Because theta 5 is 0 for any value of x, this inner product is going to be equal to 0.
But this doesn't seem very useful does it?
I mean if you look at the different movies, Love at Last, this first movie, a couple people rated it 5 stars.
So some people do like some movies.
It seems not useful to just predict that Eve is going to rate everything 0 stars.
As before let me group all of my movie ratings into this matrix Y, so just take all of these ratings and group them into matrix Y.
And this column over here of all question marks corresponds to Eve's not having rated any movies.
So the first movie got two 5-star and two 0-star ratings, so the average of that is a 2.5-star rating.
The second movie had an average of 2.5-stars and so on.
And the final movie that has 0, 0, 5, 0.
So this first element 5 I'm going to subtract off 2.5 and that gives me 2.5.
And the second element 5 subtract off of 2.5, get a 2.5.
In other words, what I'm going to do is take my matrix of movie ratings, take this wide matrix, and subtract form each row the average rating for that movie.
So, what I'm doing is just normalizing each movie to have an average rating of zero.
And so just one last example.
So now and of course the question marks stay a question mark.
So each movie in this new matrix Y has an average rating of 0.
What I'm going to do then, is take this set of ratings and use it with my collaborative filtering algorithm.
So I'm going to pretend that this was the data that I had gotten from my users, or pretend that these are the actual ratings I had gotten from the users, and I'm going to use this as my data set with which to learn my parameters theta J and my features XI - from these mean normalized movie ratings.
When I want to make predictions of movie ratings, what I'm going to do is the following: for user J on movie I, I'm gonna predict theta J transpose XI, where X and theta are the parameters that I've learned from this mean normalized data set.
But, because on the data set, I had subtracted off the means in order to make a prediction on movie i, I'm going to need to add back in the mean, and so i'm going to add back in mu i.
And so that's going to be my prediction where in my training data subtracted off all the means and so when we make predictions and we need to add back in these means mu i for movie i.
And so specifically if you user 5 which is Eve, the same argument as the previous slide still applies in the sense that Eve had not rated any movies and so the learned parameter for user 5 is still going to be equal to 0, 0.
And so what we're going to get then is that on a particular movie i we're going to predict for Eve theta 5, transpose xi plus add back in mu i and so this first component is going to be equal to zero, if theta five is equal to zero.
And so on movie i, we are going to end a predicting mu i.
It means that on movie 1 we're going to predict Eve rates it 2.5.
This actually makes sense, because it says that if Eve hasn't rated any movies and we just don't know anything about this new user Eve, what we're going to do is just predict for each of the movies, what are the average rating that those movies got.
Finally, as an aside, in this video we talked about mean normalization, where we normalized each row of the matrix y, to have mean 0.
In case you have some movies with no ratings, so it is analogous to a user who hasn't rated anything, but in case you have some movies with no ratings, you can also play with versions of the algorithm, where you normalize the different columns to have means zero, instead of normalizing the rows to have mean zero, although that's maybe less important, because if you really have a movie with no rating, maybe you just shouldn't recommend that movie to anyone, anyway.
And so, taking care of the case of a user who hasn't rated anything might be more important than taking care of the case of a movie that hasn't gotten a single rating.
Depending on your data set, this might some times make your implementation work just a little bit better.
In the next few videos, we'll talk about large scale machine learning.
One of the reasons that learning algorithms work so much better now than even say, 5-years ago, is just the sheer amount of data that we have now and that we can train our algorithms on.
In these next few videos, we'll talk about algorithms for dealing when we have such massive data sets.
So why do we want to use such large data sets?
We've already seen that one of the best ways to get a high performance machine learning system, is if you take a low-bias learning algorithm, and train that on a lot of data.
And so, one early example we have already seen was this example of classifying between confusable words.
And so it's results like these that has led to the saying in machine learning that often it's not who has the best algorithm that wins.
So you want to learn from large data sets, at least when we can get such large data sets.
But learning with large data sets comes with its own unique problems, specifically, computational problems.
Let's say your training set size is M equals 100,000,000.
And this is actually pretty realistic for many modern data sets.
If you look at the US Census data set, if there are, you know, 300 million people in the US, you can usually get hundreds of millions of records.
If you look at the amount of traffic that popular websites get, you easily get training sets that are much larger than hundreds of millions of examples.
And let's say you want to train a linear regression model, or maybe a logistic regression model, in which case this is the gradient descent rule.
And if you look at what you need to do to compute the gradient, which is this term over here, then when M is a hundred million, you need to carry out a summation over a hundred million terms, in order to compute these derivatives terms and to perform a single step of decent.
Because of the computational expense of summing over a hundred million entries in order to compute just one step of gradient descent, in the next few videos we've spoken about techniques for either replacing this with something else or to find more efficient ways to compute this derivative.
By the end of this sequence of videos on large scale machine learning, you know how to fit models, linear regression, logistic regression, neural networks and so on even today's data sets with, say, a hundred million examples.
Of course, before we put in the effort into training a model with a hundred million examples, We should also ask ourselves, well, why not use just a thousand examples.
So before investing the effort into actually developing and the software needed to train these massive models is often a good sanity check, if training on just a thousand examples might do just as well.
The way to sanity check of using a much smaller training set might do just as well, that is if using a much smaller n equals 1000 size training set, that might do just as well, it is the usual method of plotting the learning curves, so if you were to plot the learning curves and if your training objective were to look like this, that's J train theta.
And if your cross-validation set objective, Jcv of theta would look like this, then this looks like a high-variance learning algorithm, and we will be more confident that adding extra training examples would improve performance.
Whereas in contrast if you were to plot the learning curves, if your training objective were to look like this, and if your cross-validation objective were to look like that, then this looks like the classical high-bias learning algorithm.
And in the latter case, you know, if you were to plot this up to, say, m equals 1000 and so that is m equals 500 up to m equals 1000, then it seems unlikely that increasing m to a hundred million will do much better and then you'd be just fine sticking to n equals 1000, rather than investing a lot of effort to figure out how the scale of the algorithm.
Of course, if you were in the situation shown by the figure on the right, then one natural thing to do would be to add extra features, or add extra hidden units to your neural network and so on, so that you end up with a situation closer to that on the left, where maybe this is up to n equals 1000, and this then gives you more confidence that trying to add infrastructure to change the algorithm to use much more than a thousand examples that might actually be a good use of your time.
So in large-scale machine learning, we like to come up with computationally reasonable ways, or computationally efficient ways, to deal with very big data sets.
In the next few videos, we'll see two main ideas.
The first is called stochastic gradient descent and the second is called Map Reduce, for viewing with very big data sets.
And after you've learned about these methods, hopefully that will allow you to scale up your learning algorithms to big data and allow you to get much better performance on many different applications.
For many learning algorithms, among them linear regression, logistic regression and neural networks, the way we derive the algorithm was by coming up with a cost function or coming up with an optimization objective.
In this video, we'll talk about a modification to the basic gradient descent algorithm called Stochastic gradient descent, which will allow us to scale these algorithms to much bigger training sets.
Suppose you are training a linear regression model using gradient descent.
So, plotted as function of the parameters theta 0 and theta 1, the cost function J is a sort of a bow-shaped function.
And gradient descent looks like this, where in the inner loop of gradient descent you repeatedly update the parameters theta using that expression.
Now in the rest of this video, I'm going to keep using linear regression as the running example.
But the ideas here, the ideas of Stochastic gradient descent is fully general and also applies to other learning algorithms like logistic regression, neural networks and other algorithms that are based on training gradient descent on a specific training set.
So take a trajectory that looks like that and heads pretty directly to the global minimum.
Now, the problem with gradient descent is that if m is large.
Then computing this derivative term can be very expensive, because the surprise, summing over all m examples.
So in the United States, there are about 300 million people.
And so the US or United States census data may have on the order of that many records.
So you want to fit the linear regression model to that then you need to sum over 300 million records.
And that's very expensive.
To give the algorithm a name, this particular version of gradient descent is also called Batch gradient descent.
And the term Batch refers to the fact that we're looking at all of the training examples at a time.
We call it sort of a batch of all of the training examples.
And it really isn't the, maybe the best name but this is what machine learning people call this particular version of gradient descent.
The way this algorithm works is you need to read into your computer memory all 300 million records in order to compute this derivative term.
You need to stream all of these records through computer because you can't store all your records in computer memory.
So you need to read through them and slowly, you know, accumulate the sum in order to compute the derivative.
And then having done all that work, that allows you to take one step of gradient descent.
You know, scan through all 300 million records, accumulate these sums.
And having done all that work, you can take another little step using gradient descent.
And then do that again.
And so it's gonna take a long time in order to get the algorithm to converge.
In contrast to Batch gradient descent, what we are going to do is come up with a different algorithm that doesn't need to look at all the training examples in every single iteration, but that needs to look at only a single training example in one iteration.
Before moving on to the new algorithm, here's just a Batch gradient descent algorithm written out again with that being the cost function and that being the update and of course this term here, that's used in the gradient descent rule, that is the partial derivative with respect to the parameters theta J of our optimization objective, J train of theta.
Now, let's look at the more efficient algorithm that scales better to large data sets.
In order to work off the algorithms called Stochastic gradient descent, this vectors the cost function in a slightly different way then they define the cost of the parameter theta with respect to a training example x(i), y(i) to be equal to one half times the squared error that my hypothesis incurs on that example, x(i), y(i).
So this cost function term really measures how well is my hypothesis doing on a single example x(i), y(i).
Now you notice that the overall cost function j train can now be written in this equivalent form.
So j train is just the average over my m training examples of the cost of my hypothesis on that example x(i), y(i).
Armed with this view of the cost function for linear regression, let me now write out what Stochastic gradient descent does.
The first step of Stochastic gradient descent is to randomly shuffle the data set.
So by that I just mean randomly shuffle, or randomly reorder your m training examples.
But the main work of Stochastic gradient descent is then done in the following.
Gonna update the parameter theta j as theta j minus alpha times h of x(i) minus y(i) times x(i)j.
And we're going to do this update as usual for all values of j.
Now, you notice that this term over here is exactly what we had inside the summation for Batch gradient descent.
In fact, for those of you that are calculus is possible to show that that term here, that's this term here, is equal to the partial derivative with respect to my parameter theta j of the cost of the parameters theta on x(i), y(i).
Where cost is of course this thing that was defined previously.
And just the wrap of the algorithm, let me close my curly braces over there.
And then looking at only this first example, it's gonna take like a basically a little gradient descent step with respect to the cost of just this first training example.
So in other words, we're going to look at the first example and modify the parameters a little bit to fit just the first training example a little bit better.
Having done this inside this inner for-loop is then going to go on to the second training example.
And what it's going to do there is take another little step in parameter space, so modify the parameters just a little bit to try to fit just a second training example a little bit better.
Having done that, is then going to go onto my third training example.
And modify the parameters to try to fit just the third training example a little bit better, and so on until you know, you get through the entire training set.
And then this ultra repeat loop may cause it to take multiple passes over the entire training set.
This view of Stochastic gradient descent also motivates why we wanted to start by randomly shuffling the data set.
This doesn't show us that when we scan through the training site here, that we end up visiting the training examples in some sort of randomly sorted order.
Depending on whether your data already came randomly sorted or whether it came originally sorted in some strange order, in practice this would just speed up the conversions to Stochastic gradient descent just a little bit.
So in the interest of safety, it's usually better to randomly shuffle the data set if you aren't sure if it came to you in randomly sorted order.
But more importantly another view of Stochastic gradient descent is that it's a lot like descent but rather than wait to sum up these gradient terms over all m training examples, what we're doing is we're taking this gradient term using just one single training example and we're starting to make progress in improving the parameters already.
So rather than, you know, waiting 'till taking a path through all 300,000 United States Census records, say, rather than needing to scan through all of the training examples before we can modify the parameters a little bit and make progress towards a global minimum.
So, here's the algorithm written out again where the first step is to randomly shuffle the data and the second step is where the real work is done, where that's the update with respect to a single training example x(i), y(i).
So, let's see what this algorithm does to the parameters.
Previously, we saw that when we are using Batch gradient descent, that is the algorithm that looks at all the training examples in time, Batch gradient descent will tend to, you know, take a reasonably straight line trajectory to get to the global minimum like that.
The first iteration, you know, may take the parameters in that direction and maybe the second iteration looking at just the second example maybe just by chance, we get more unlucky and actually head in a bad direction with the parameters like that.
In the third iteration where we tried to modify the parameters to fit just the third training examples better, maybe we'll end up heading in that direction.
And then we'll look at the fourth training example and we will do that.
The fifth example, sixth example, 7th and so on.
And as you run Stochastic gradient descent, what you find is that it will generally move the parameters in the direction of the global minimum, but not always.
And so take some more random-looking, circuitous path to watch the global minimum.
But in practice this isn't a problem because, you know, so long as the parameters end up in some region there maybe it is pretty close to the global minimum.
So, as parameters end up pretty close to the global minimum, that will be a pretty good hypothesis and so usually running Stochastic gradient descent we get a parameter near the global minimum and that's good enough for, you know, essentially any, most practical purposes.
In Stochastic gradient descent, we had this outer loop repeat which says to do this inner loop multiple times.
So, how many times do we repeat this outer loop?
Depending on the size of the training set, doing this loop just a single time may be enough.
And up to, you know, maybe 10 times may be typical so we may end up repeating this inner loop anywhere from once to ten times.
So if we have a you know, truly massive data set like the this US census gave us that example that I've been talking about with 300 million examples, it is possible that by the time you've taken just a single pass through your training set.
In which case, you know, this inner loop you might need to do only once if m is very, very large.
But really it depends on the size of your training set.
With Batch gradient descent, after taking a pass through your entire training set, you would have taken just one single gradient descent steps.
And if you implement it, hopefully that will allow you to scale up many of your learning algorithms to much bigger data sets and get much more performance that way.
In the previous video, we talked about Stochastic gradient descent, and how that can be much faster than Batch gradient descent.
In this video, let's talk about another variation on these ideas is called Mini-batch gradient descent they can work sometimes even a bit faster than stochastic gradient descent.
In Batch gradient descent we will use all m examples in each generation.
Whereas in Stochastic gradient descent we will use a single example in each generation.
Specifically, with this algorithm we're going to use b examples in each iteration where b is a parameter called the "mini batch size" so the idea is that this is somewhat in-between Batch gradient descent and Stochastic gradient descent.
This is just like batch gradient descent, except that I'm going to use a much smaller batch size.
A typical choice for the value of b might be b equals 10, lets say, and a typical range really might be anywhere from b equals 2 up to b equals 100.
And the idea is that rather than using one example at a time or m examples at a time we will use b examples at a time.
So we're going to get, the next 10 examples from my training set so that may be some set of examples xi, yi.
So, that's any rate times one tenth times sum over k equals i through i+9 of h subscript theta of x(k) minus y(k) times x(k)j.
And so in this expression, where summing the gradient terms over my ten examples.
In order to simplify the indexing for this one at the right top, I'm going to assume we have a mini-batch size of ten and a training set size of a thousand, what we're going to do is have this sort of form, for i equals 1 and that in 21's the stepping, in steps of 10 because we look at 10 examples at a time.
And then we perform this sort of gradient descent update using ten examples at a time so this 10 and this i+9 those are consequence of having chosen my mini-batch to be ten.
And you know, this ultimate four-loop, this ends at 991 here because if I have 1000 training samples then I need 100 steps of size 10 in order to get through my training set.
Compared to batch gradient descent, this also allows us to make progress much faster.
Census data with 300 million training examples, then what we're saying is after looking at just the first 10 examples we can start to make progress in improving the parameters theta so we don't need to scan through the entire training set.
We just need to look at the first 10 examples and this will start letting us make progress and then we can look at the second ten examples and modify the parameters a little bit again and so on.
So, that is why Mini-batch gradient descent can be faster than batch gradient descent.
Namely, you can start making progress in modifying the parameters after looking at just ten examples rather than needing to wait 'till you've scan through every single training example of 300 million of them.
So, why do we want to look at b examples at a time rather than look at just a single example at a time as the Stochastic gradient descent?
The answer is in vectorization.
In particular, Mini-batch gradient descent is likely to outperform Stochastic gradient descent only if you have a good vectorized implementation.
In that case, the sum over 10 examples can be performed in a more vectorized way which will allow you to partially parallelize your computation over the ten examples.
So, in other words, by using appropriate vectorization to compute the rest of the terms, you can sometimes partially use the good numerical algebra libraries and parallelize your gradient computations over the b examples, whereas if you were looking at just a single example of time with Stochastic gradient descent then, you know, just looking at one example at a time their isn't much to parallelize over.
At least there is less to parallelize over.
One disadvantage of Mini-batch gradient descent is that there is now this extra parameter b, the Mini-batch size which you may have to fiddle with, and which may therefore take time.
But if you have a good vectorized implementation this can sometimes run even faster that Stochastic gradient descent.
So that was Mini-batch gradient descent which is an algorithm that in some sense does something that's somewhat in between what Stochastic gradient descent does and what Batch gradient descent does.
I usually use b equals 10, but, you know, other values, anywhere from say 2 to 100, would be reasonably common.
So we choose value of b and if you use a good vectorized implementation, sometimes it can be faster than both Stochastic gradient descent and faster than Batch gradient descent.
You now know about the stochastic gradient descent algorithm.
But when you're running the algorithm, how do you make sure that it's completely debugged and is converging okay?
Equally important, how do you tune the learning rate alpha with Stochastic Gradient Descent.
In this video we'll talk about some techniques for doing these things, for making sure it's converging and for picking the learning rate alpha.
Back when we were using batch gradient descent, our standard way for making sure that gradient descent was converging was we would plot the optimization cost function as a function of the number of iterations.
So that was the cost function and we would make sure that this cost function is decreasing on every iteration.
You don't want to have to pause stochastic gradient descent periodically in order to compute this cost function since it requires a sum of your entire training set size.
And the whole point of stochastic gradient was that you wanted to start to make progress after looking at just a single example without needing to occasionally scan through your entire training set right in the middle of the algorithm, just to compute things like the cost function of the entire training set.
So for stochastic gradient descent, in order to check the algorithm is converging, here's what we can do instead.
So the cost of the parameters theta with respect to a single training example is just one half of the square error on that training example.
So, in stochastic gradient descent we're going to look at the examples xi, yi, in order, and then sort of take a little update with respect to this example.
So, while the algorithm is looking at the example xi, yi, but before it has updated the parameters theta using that an example, let's compute the cost of that example.
Just to say the same thing again, but using slightly different words.
A stochastic gradient descent is scanning through our training set right before we have updated theta using a specific training example x(i) comma y(i) let's compute how well our hypothesis is doing on that training example.
And we want to do this before updating theta because if we've just updated theta using example, you know, that it might be doing better on that example than what would be representative.
Finally, in order to check for the convergence of stochastic gradient descent, what we can do is every, say, every thousand iterations, we can plot these costs that we've been computing in the previous step.
We can plot those costs average over, say, the last thousand examples processed by the algorithm.
And if you do this, it kind of gives you a running estimate of how well the algorithm is doing.
So, in contrast to computing J With this other procedure, well, as part of stochastic gradient descent, it doesn't cost much to compute these costs as well right before updating to parameter theta.
And all we're doing is every thousand integrations or so, we just average the last 1,000 costs that we computed and plot that.
And by looking at those plots, this will allow us to check if stochastic gradient descent is converging.
Suppose you have plotted the cost average over the last thousand examples, because these are averaged over just a thousand examples, they are going to be a little bit noisy and so, it may not decrease on every single iteration.
Then if you get a figure that looks like this, So the plot is noisy because it's average over, you know, just a small subset, say a thousand training examples.
If you get a figure that looks like this, you know that would be a pretty decent run with the algorithm, maybe, where it looks like the cost has gone down and then this plateau that looks kind of flattened out, you know, starting from around that point.
If you want to try using a smaller learning rate, something you might see is that the algorithm may initially learn more slowly so the cost goes down more slowly.
But then eventually you have a smaller learning rate is actually possible for the algorithm to end up at a, maybe very slightly better solution.
So the red line may represent the behavior of stochastic gradient descent using a slower, using a smaller leaning rate.
And the reason this is the case is because, you remember, stochastic gradient descent doesn't just converge to the global minimum, is that what it does is the parameters will oscillate a bit around the global minimum.
And so by using a smaller learning rate, you'll end up with smaller oscillations.
And sometimes this little difference will be negligible and sometimes with a smaller than you can get a slightly better value for the parameters.
Let's say you run stochastic gradient descent and you average over a thousand examples when plotting these costs.
So, you know, here might be the result of another one of these plots.
If you were to take this number, a thousand, and increase to averaging over 5 thousand examples.
And by averaging over, say 5,000 examples instead of 1,000, you might be able to get a smoother curve like this.
And so that's the effect of increasing the number of examples you average over.
The disadvantage of making this too big of course is that now you get one date point only every 5,000 examples.
Along a similar vein some times you may run a gradient descent and end up with a plot that looks like this.
And with a plot that looks like this, you know, it looks like the cost just is not decreasing at all.
It looks like the algorithm is just not learning.
It's just, looks like this here a flat curve and the cost is just not decreasing.
But again if you were to increase this to averaging over a larger number of examples it is possible that you see something like this red line it looks like the cost actually is decreasing, it's just that the blue line averaging over 2, 3 examples, the blue line was too noisy so you couldn't see the actual trend in the cost actually decreasing and possibly averaging over 5,000 examples instead of 1,000 may help.
That it's still flat even when you average over a larger number of examples.
And as you get that, then that's maybe just a more firm verification that unfortunately the algorithm just isn't learning much for whatever reason.
And you need to either change the learning rate or change the features or change something else about the algorithm.
Finally, one last thing that you might see would be if you were to plot these curves and you see a curve that looks like this, where it actually looks like it's increasing.
And what you really should do is use a smaller value of the learning rate alpha.
So hopefully this gives you a sense of the range of phenomena you might see when you plot these cost average over some range of examples as well as suggests the sorts of things you might try to do in response to seeing different plots.
So if the plots looks too noisy, or if it wiggles up and down too much, then try increasing the number of examples you're averaging over so you can see the overall trend in the plot better.
And if you see that the errors are actually increasing, the costs are actually increasing, try using a smaller value of alpha.
Finally, it's worth examining the issue of the learning rate just a little bit more.
We saw that when we run stochastic gradient descent, the algorithm will start here and sort of meander towards the minimum And then it won't really converge, and instead it'll wander around the minimum forever.
And so you end up with a parameter value that is hopefully close to the global minimum that won't be exact at the global minimum.
In most typical implementations of stochastic gradient descent, the learning rate alpha is typically held constant.
And so what you we end up is exactly a picture like this.
If you want stochastic gradient descent to actually converge to the global minimum, there's one thing which you can do which is you can slowly decrease the learning rate alpha over time.
So, a pretty typical way of doing that would be to set alpha equals some constant 1 divided by iteration number plus constant 2.
One of the reasons people tend not to do this is because you end up needing to spend time playing with these 2 extra parameters, constant 1 and constant 2, and so this makes the algorithm more finicky.
You know, it's just more parameters able to fiddle with in order to make the algorithm work well.
But if you manage to tune the parameters well, then the picture you can get is that the algorithm will actually around towards the minimum, but as it gets closer because you're decreasing the learning rate the meanderings will get smaller and smaller until it pretty much just to the global minimum.
And the reason this formula makes sense is because as the algorithm runs, the iteration number becomes large So alpha will slowly become small, and so you take smaller and smaller steps until it hopefully converges to the global minimum.
So If you do slowly decrease alpha to zero you can end up with a slightly better hypothesis.
But because of the extra work needed to fiddle with the constants and because frankly usually we're pretty happy with any parameter value that is, you know, pretty close to the global minimum.
Typically this process of decreasing alpha slowly is usually not done and keeping the learning rate alpha constant is the more common application of stochastic gradient descent although you will see people use either version.
To summarize in this video we talk about a way for approximately monitoring how the stochastic gradient descent is doing in terms for optimizing the cost function.
And this is a method that does not require scanning over the entire training set periodically to compute the cost function on the entire training set.
And you can use this method both to make sure the stochastic gradient descent is okay and is converging or to use it to tune the learning rate alpha.
In the last few videos, we talked about stochastic gradient descent, and, you know, other variations of the stochastic gradient descent algorithm, including those adaptations to online learning, but all of those algorithms could be run on one machine, or could be run on one computer.
And some machine learning problems are just too big to run on one machine, sometimes maybe you just so much data you just don't ever want to run all that data through a single computer, no matter what algorithm you would use on that computer.
So in this video I'd like to talk about different approach to large scale machine learning, called the map reduce approach.
And even though we have quite a few videos on stochastic gradient descent and we're going to spend relative less time on map reduce--don't judge the relative importance of map reduce versus the gradient descent based on the amount amount of time I spend on these ideas in particular.
Here's the idea.
And to keep the writing on this slide tractable, I'm going to assume throughout that we have m equals 400 examples.
So in that case, the batch gradient descent learning rule has this 400 and the sum from i equals 1 through 400 through my 400 examples here, and if m is large, then this is a computationally expensive step.
So, what the MapReduce idea does is the following, and I should say the map reduce idea is due to two researchers, Jeff Dean and Sanjay Gimawat.
Jeff Dean, by the way, is one of the most legendary engineers in all of Silicon Valley and he kind of built a large fraction of the architectural infrastructure that all of Google runs on today.
But here's the map reduce idea.
So, let's say I have some training set, if we want to denote by this box here of X Y pairs, where it's X1, Y1, down to my 400 examples, Xm, Ym.
In the MapReduce idea, one way to do, is split this training set in to different subsets.
assume for this example that I have 4 computers, or 4 machines to run in parallel on my training set, which is why I'm splitting this into 4 machines.
And what the first of my 4 machines is to do, say, is use just the first one quarter of my training set--so use just the first 100 training examples.
And in particular, what it's going to do is look at this summation, and compute that summation for just the first 100 training examples.
So that's just that gradient descent term up there.
And similarly machines 3 and 4 will use the third quarter and the fourth quarter of my training set.
So now each machine has to sum over 100 instead of over 400 examples and so has to do only a quarter of the work and thus presumably it could do it about four times as fast.
Finally, after all these machines have done this work, I am going to take these temp variables and put them back together.
You know, up to and within this number of features.
Right, that's just the sum of this, plus the sum of this, plus the sum of this, plus the sum of that, and those four things just add up to be equal to this sum that we're originally computing a batch stream descent.
So, here's what the general picture of the MapReduce technique looks like.
We have some training sets, and if we want to paralyze across four machines, we are going to take the training set and split it, you know, equally.
Then we are going to take the 4 subsets of the training data and send them to 4 different computers.
So, on the previous line in that example, the bulk of the work in gradient descent, was computing the sum from i equals 1 to 400 of something.
So more generally, sum from i equals 1 to m of that formula for gradient descent.
And now, because each of the four computers can do just a quarter of the work, potentially you can get up to a 4x speed up.
In particular, if there were no network latencies and no costs of the network communications to send the data back and forth, you can potentially get up to a 4x speed up.
Of course, in practice, because of network latencies, the overhead of combining the results afterwards and other factors, in practice you get slightly less than a 4x speedup.
But, none the less, this sort of macro juice approach does offer us a way to process much larger data sets than is possible using a single computer.
By paralleling the computation over different computers, the key question to ask yourself is, can your learning algorithm be expressed as a summation over the training set?
And it turns out that many learning algorithms can actually be expressed as computing sums of functions over the training set and the computational expense of running them on large data sets is because they need to sum over a very large training set.
So, whenever your learning algorithm can be expressed as a sum of the training set and whenever the bulk of the work of the learning algorithm can be expressed as the sum of the training set, then map reviews might a good candidate for scaling your learning algorithms through very, very good data sets.
Lets just look at one more example.
Let's say that we want to use one of the advanced optimization algorithm.
For that, we need to compute two main quantities.
One is for the advanced optimization algorithms like, you know, LPF and constant gradient.
We need to provide it a routine to compute the cost function of the optimization objective.
And so for logistic regression, you remember that a cost function has this sort of sum over the training set, and so if youre paralizing over ten machines, you would split up the training set onto ten machines and have each of the ten machines compute the sum of this quantity over just one tenth of the training data.
Then, the other thing that the advanced optimization algorithms need, is a routine to compute these partial derivative terms.
Once again, these derivative terms, for which it's a logistic regression, can be expressed as a sum over the training set, and so once again, similar to our earlier example, you would have each machine compute that summation over just some small fraction of your training data.
And finally, having computed all of these things, they could then send their results to a centralized server, which can then add up the partial sums.
This corresponds to adding up those tenth i or tenth ij variables, which were computed locally on machine number i, and so the centralized server can sum these things up and get the overall cost function and get the overall partial derivative, which you can then pass through the advanced optimization algorithm.
So, more broadly, by taking other learning algorithms and expressing them in sort of summation form or by expressing them in terms of computing sums of functions over the training set, you can use the MapReduce technique to parallelize other learning algorithms as well, and scale them to very large training sets.
Finally, as one last comment, so far we have been discussing MapReduce algorithms as allowing you to parallelize over multiple computers, maybe multiple computers in a computer cluster or over multiple computers in the data center.
It turns out that sometimes even if you have just a single computer, MapReduce can also be applicable.
In particular, on many single computers now, you can have multiple processing cores.
You can have multiple CPUs, and within each CPU you can have multiple proc cores.
If you have a large training set, what you can do if, say, you have a computer with 4 computing cores, what you can do is, even on a single computer you can split the training sets into pieces and send the training set to different cores within a single box, like within a single desktop computer or a single server and use MapReduce this way to divvy up work load.
The advantage of thinking about MapReduce this way, as paralyzing over cause within a single machine, rather than parallelizing over multiple machines is that, this way you don't have to worry about network latency, because all the communication, all the sending of the back and forth, all that happens within a single machine.
And so network latency becomes much less of an issue compared to if you were using this to over different computers within the data sensor.
Finally, one last caveat on parallelizing within a multi-core machine.
It turns out that the sum numerical linear algebra libraries that can automatically parallelize their linear algebra operations across multiple cores within the machine.
for other any problems, taking advantage of this sort of map reducing commentation, finding and using this MapReduce formulation and to paralelize a cross coarse except yourself might be a good idea as well and could let you speed up your learning algorithm.
In this video, we talked about the MapReduce approach to parallelizing machine learning by taking a data and spreading them across many computers in the data center.
Although these ideas are critical to paralysing across multiple cores within a single computer as well.
Today there are some good open source implementations of MapReduce, so there are many users in open source system called Hadoop and using either your own implementation or using someone else's open source implementation, you can use these ideas to parallelize learning algorithms and get them to run on much larger data sets than is possible using just a single machine.
In this and the next few videos, I want to tell you about a machine learning application example, or a machine learning application history centered around an application called Photo OCR .
Second, once told the concepts of a machine learning a type line and how to allocate resources when you're trying to decide what to do next.
And this can either be in the context of you working by yourself on the big application Or it can be the context of a team of developers trying to build a complex application together.
And then finally, the Photo OCR problem also gives me an excuse to tell you about just a couple more interesting ideas for machine learning.
One is some ideas of how to apply machine learning to computer vision problems, and second is the idea of artificial data synthesis, which we'll see in a couple of videos.
So, let's start by talking about what is the Photo OCR problem.
Photo OCR stands for Photo Optical Character Recognition.
With the growth of digital photography and more recently the growth of camera in our cell phones we now have tons of visual pictures that we take all over the place.
And one of the things that has interested many developers is how to get our computers to understand the content of these pictures a little bit better.
The photo OCR problem focuses on how to get computers to read the text to the purest in images that we take.
The Photo OCR problem does exactly this, and it does so in several steps.
First, given the picture it has to look through the image and detect where there is text in the picture.
And after it has done that or if it successfully does that it then has to look at these text regions and actually read the text in those regions, and hopefully if it reads it correctly, it'll come up with these transcriptions of what is the text that appears in the image.
Whereas OCR, or optical character recognition of scanned documents is relatively easier problem, doing OCR from photographs today is still a very difficult machine learning problem, and you can do this.
Not only can this help our computers to understand the content of our though images better, there are also applications like helping blind people, for example, if you could provide to a blind person a camera that can look at what's in front of them, and just tell them the words that my be on the street sign in front of them.
For example, imagine if your car could read the street signs and help you navigate to your destination.
In order to perform photo OCR, here's what we can do.
First we can go through the image and find the regions where there's text and image.
So, shown here is one example of text and image that the photo OCR system may find.
Second, given the rectangle around that text region, we can then do character segmentation, where we might take this text box that says "Antique Mall" and try to segment it out into the locations of the individual characters.
And finally, having segmented out into individual characters, we can then run a crossfire, which looks at the images of the visual characters, and tries to figure out the first character's an A, the second character's an N, the third character is a T, and so on, so that up by doing all this how that hopefully you can then figure out that this phrase is Rulegee's antique mall and similarly for some of the other words that appear in that image.
I should say that there are some photo OCR systems that do even more complex things, like a bit of spelling correction at the end.
Then, you know, a sort of spelling correction system might tell you that this is probably the word 'cleaning', and your character classification algorithm had just mistaken the l for a 1.
But for the purpose of what we want to do in this video, let's ignore this last step and just focus on the system that does these three steps of text detection, character segmentation, and character classification.
A system like this is what we call a machine learning pipeline.
In particular, here's a picture showing the photo OCR pipeline.
We have an image, which then fed to the text detection system text regions, we then segment out the characters--the individual characters in the text--and then finally we recognize the individual characters.
If you're designing a machine learning system one of the most important decisions will often be what exactly is the pipeline that you want to put together.
In other words, given the photo OCR problem, how do you break this problem down into a sequence of different modules.
And you design the pipeline and each the performance of each of the modules in your pipeline.
If you have a team of engineers working on a problem like this is also very common to have different individuals work on different modules.
So I could easily imagine tech easily being the of anywhere from 1 to 5 engineers, character segmentation maybe another 1-5 engineers, and character recognition being another 1-5 engineers, and so having a pipeline like often offers a natural way to divide up the workload amongst different members of an engineering team, as well.
Although, or course, all of this work could also be done by just one person if that's how you want to do it.
In complex machine learning systems the idea of a pipeline, of a machine of a pipeline, is pretty pervasive.
And what you just saw is a specific example of how a Photo OCR pipeline might work.
In the next few videos I'll tell you a little bit more about this pipeline, and we'll continue to use this as an example to illustrate--I think--a few more key concepts of machine learning.
In the previous video, we talked about the photo OCR pipeline and how that worked.
In which we would take an image and pass the Through a sequence of machine learning components in order to try to read the text that appears in an image.
A little bit more about how the individual components of the pipeline works.
In particular most of this video will center around the discussion.
The first stage of the filter was the Text detection where we look at an image like this and try to find the regions of text that appear in this image.
Text detection is an unusual problem in computer vision.
Because depending on the length of the text you're trying to find, these rectangles that you're trying to find can have different aspect.
So in order to talk about detecting things in images let's start with a simpler example of pedestrian detection and we'll then later go back to.
Ideas that were developed in pedestrian detection and apply them to text detection.
So in pedestrian detection you want to take an image that looks like this and the whole idea is the individual pedestrians that appear in the image.
So there's one pedestrian that we found, there's a second one, a third one a fourth one, a fifth one.
This problem is maybe slightly simpler than text detection just for the reason that the aspect ratio of most pedestrians are pretty similar.
So by aspect ratio I mean the ratio between the height and the width of these rectangles.
They're all the same.
for different pedestrians but for text detection the height and width ratio is different for different lines of text Although for pedestrian detection, the pedestrians can be different distances away from the camera and so the height of these rectangles can be different depending on how far away they are.
but the aspect ratio is the same.
Let's say that we decide to standardize on this aspect ratio of 82 by 36 and we could have chosen some rounded number like 80 by 40 or something, but 82 by 36 seems alright.
What we would do is then go out and collect large training sets of positive and negative examples.
On this slide I show 12 positive examples of y1 and 12 examples of y0.
In a more typical pedestrian detection application, we may have anywhere from a 1,000 training examples up to maybe 10,000 training examples, or even more if you can get even larger training sets.
And what you can do, is then train in your network or some other learning algorithm to take this input, an MS patch of dimension 82 by 36, and to classify 'y' and to classify that image patch as either containing a pedestrian or not.
So this gives you a way of applying supervised learning in order to take an image patch can determine whether or not a pedestrian appears in that image capture.
Now, lets say we get a new image, a test set image like this and we want to try to find a pedestrian's picture image.
What we would do is start by taking a rectangular patch of this image.
Like that shown up here, so that's maybe a 82 X 36 patch of this image, and run that image patch through our classifier to determine whether or not there is a pedestrian in that image patch, and hopefully our classifier will return y equals 0 for that patch, since there is no pedestrian.
Next, we then take that green rectangle and we slide it over a bit and then run that new image patch through our classifier to decide if there's a pedestrian there.
And having done that, we then slide the window further to the right and run that patch through the classifier again.
So you can use the step size or stride of 1, that usually performs best, that is more cost effective, and so using a step size of maybe 4 pixels at a time, or eight pixels at a time or some large number of pixels might be more common, since you're then moving the rectangle a little bit more each time.
So, using this process, you continue stepping the rectangle over to the right a bit at a time and running each of these patches through a classifier, until eventually, as you slide this window over the different locations in the image, first starting with the first row and then we go further rows in the image, you would then run all of these different image patches at some step size or some stride through your classifier.
Now, that was a pretty small rectangle, that would only detect pedestrians of one specific size.
So now let's take larger images patches, like those shown here and run those through the crossfire as well.
And by the way when I say take a larger image patch, what I really mean is when you take an image patch like this, what you're really doing is taking that image patch, and resizing it down to 82 X 36, say.
So you take this larger patch and re-size it to be smaller image and then it would be the smaller size image that is what you would pass through your classifier to try and decide if there is a pedestrian in that patch.
Let's have a turn to the text detection example and talk about that stage in our photo OCR pipeline, where our goal is to find the text regions in unit.
similar to pedestrian detection you can come up with a label training set with positive examples and negative examples with examples corresponding to regions where text appears.
So instead of trying to detect pedestrians, we're now trying to detect texts.
And so positive examples are going to be patches of images where there is text.
And negative examples is going to be patches of images where there isn't text.
Having trained this we can now apply it to a new image, into a test set image.
So here's the image that we've been using as example.
Now, last time we run, for this example we are going to run a sliding windows at just one fixed scale just for purpose of illustration, meaning that I'm going to use just one rectangle size.
What i have done on this image on the lower left is actually use white to show where the classifier thinks it has found text.
So what that does is, it take the image here, and it takes each of the white blobs, it takes each of the white regions and it expands that white region.
Mathematically, the way you implement that is, if you look at the image on the right, what we're doing to create the image on the right is, for every pixel we are going to ask, is it withing some distance of a white pixel in the left image.
And so, if a specific pixel is within, say, five pixels or ten pixels of a white pixel in the leftmost image, then we'll also color that pixel white in the rightmost image.
And so, the effect of this is, we'll take each of the white blobs in the leftmost image and expand them a bit, grow them a little bit, by seeing whether the nearby pixels, the white pixels, and then coloring those nearby pixels in white as well.
We can now look at this right most image and just look at the connecting components and look at the as white regions and draw bounding boxes around them.
And in particular, if we look at all the white regions, like this one, this one, this one, and so on, and if we use a simple heuristic to rule out rectangles whose aspect ratios look funny because we know that boxes around text should be much wider than they are tall.
This example by the actually misses one piece of text.
This is very hard to read, but there is actually one piece of text there.
That says are corresponding to this but the aspect ratio looks wrong so we discarded that one.
So you know it's ok on this image, but in this particular example the classifier actually missed one piece of text.
It's very hard to read because there's a piece of text written against a transparent window.
So that's text detection using sliding windows.
And having found these rectangles with the text in it, we can now just cut out these image regions and then use later stages of pipeline to try to meet the texts.
Now, you recall that the second stage of pipeline was character segmentation, so given an image like that shown on top, how do we segment out the individual characters in this image?
So what we can do is again use a supervised learning algorithm with some set of positive and some set of negative examples, what were going to do is look in the image patch and try to decide if there is split between two characters right in the middle of that image match.
This first cross example, this image patch looks like the middle of it is indeed the middle has splits between two characters and the second example again this looks like a positive example, because if I split two characters by putting a line right down the middle, that's the right thing to do.
So, these are positive examples, where the middle of the image represents a gap or a split between two distinct characters, whereas the negative examples, well, you know, you don't want to split two characters right in the middle, and so these are negative examples because they don't represent the midpoint between two characters.
So what we will do is, we will train a classifier, maybe using new network, maybe using a different learning algorithm, to try to classify between the positive and negative examples.
Having trained such a classifier, we can then run this on this sort of text that our text detection system has pulled out.
As we start by looking at that rectangle, and we ask, "Gee, does it look like the middle of that green rectangle, does it look like the midpoint between two characters?".
There's only one row here.
But now, with the classifier in this position, we ask, well, should we split those two characters or should we put a split right down the middle of this rectangle.
And hopefully, the classifier will output y equals one, in which case we will decide to draw a line down there, to try to split two characters.
Then we slide the window over again, optic process, don't close the gap, slide over again, optic says yes, do split there and so on, and we slowly slide the classifier over to the right and hopefully it will classify this as another positive example and so on.
And we will slide this window over to the right, running the classifier at every step, and hopefully it will tell us, you know, what are the right locations to split these characters up into, just split this image up into individual characters.
And so thats 1D sliding windows for character segmentation.
So, here's the overall photo OCR pipe line again.
The final step through the pipeline is the character qualification step and that step you might already be much more familiar with the early videos on supervised learning where you can apply a standard supervised learning within maybe on your network or maybe something else in order to take it's input, an image like that and classify which alphabet or which 26 characters A to Z, or maybe we should have 36 characters if you have the numerical digits as well, the multi class classification problem where you take it's input and image contained a character and decide what is the character that appears in that image?
So that was the photo OCR pipeline and how you can use ideas like sliding windows classifiers in order to put these different components to develop a photo OCR system.
In the next few videos we keep on using the problem of photo OCR to explore somewhat interesting issues surrounding building an application like this.
I've seen over and over that one of the most reliable ways to get a high performance machine learning system is to take a low bias learning algorithm and to train it on a massive training set.
But where did you get so much training data from?
Turns out that the machine earnings there's a fascinating idea called artificial data synthesis, this doesn't apply to every single problem, and to apply to a specific problem, often takes some thought and innovation and insight.
But if this idea applies to your machine, only problem, it can sometimes be a an easy way to get a huge training set to give to your learning algorithm.
The idea of artificial data synthesis comprises of two variations, main the first is if we are essentially creating data from , creating new data from scratch.
And the second is if we already have it's small label training set and we somehow have amplify that training set or use a small training set to turn that into a larger training set and in this video we'll go over both those ideas.
To talk about the artificial data synthesis idea, let's use the character portion of the photo OCR pipeline, we want to take it's input image and recognize what character it is.
If we go out and collect a large label data set, here's what it is and what it look like.
For this particular example, I've chosen a square aspect ratio.
And the goal is to take an image patch and recognize the character in the middle of that image patch.
And for the sake of simplicity, I'm going to treat these images as grey scale images, rather than color images.
It turns out that using color doesn't seem to help that much for this particular problem.
So given this image patch, we'd like to recognize that that's a T.
Given this image patch, we'd like to recognize that it's an 'S'.
Given that image patch we would like to recognize that as an 'I' and so on.
So all of these, our examples of row images, how can we come up with a much larger training set?
Modern computers often have a huge font library and if you use a word processing software, depending on what word processor you use, you might have all of these fonts and many, many more Already stored inside.
So if you want more training examples, one thing you can do is just take characters from different fonts and paste these characters against different random backgrounds.
If you do that you now have a training example of an image of the character C.
So after some amount of work, you know this, and it is a little bit of work to synthisize realistic looking data.
Every image shown on the right was actually a synthesized image.
Where you take a font, maybe a random font downloaded off the web and you paste an image of one character or a few characters from that font against this other random background image.
And then apply maybe a little blurring operators -----of app finder, distortions that app finder, meaning just the sharing and scaling and little rotation operations and if you do that you get a synthetic training set, on what the one shown here.
But if you look at the synthetic data looks remarkably similar to the real data.
And so by using synthetic data you have essentially an unlimited supply of training examples for artificial training synthesis And so, if you use this source synthetic data, you have essentially unlimited supply of label data to create a improvised learning algorithm for the character recognition problem.
So this is an example of artificial data synthesis where youre basically creating new data from scratch, you just generating brand new images from scratch.
The other main approach to artificial data synthesis is where you take a examples that you currently have, that we take a real example, maybe from real image, and you create additional data, so as to amplify your training set.
So here is an image of a compared to a from a real image, not a synthesized image, and I have overlayed this with the grid lines just for the purpose of illustration.
So what you can do is then take this alphabet here, take this image and introduce artificial warpings or artificial distortions into the image so they can take the image a and turn that into 16 new examples.
So in this way you can take a small label training set and amplify your training set to suddenly get a lot more examples, all of it.
Again, in order to do this for application, it does take thought and it does take insight to figure out what our reasonable sets of distortions, or whether these are ways that amplify and multiply your training set, and for the specific example of character recognition, introducing these warping seems like a natural choice, but for a different learning machine application, there may be different the distortions that might make more sense.
Let me just show one example from the totally different domain of speech recognition.
So the speech recognition, let's say you have audio clips and you want to learn from the audio clip to recognize what were the words spoken in that clip.
So let's see how one labeled training example.
So let's say you have one labeled training example, of someone saying a few specific words.
Alright, so someone counting from 0 to 5, and so you want to try to apply a learning algorithm to try to recognize the words said in that.
So, how can we amplify the data set?
Well, one thing we do is introduce additional audio distortions into the data set.
When you hear beeping sounds, that's actually part of the audio track, that's nothing wrong with the speakers, I'm going to play this now.
0-1-2-3-4-5.
Right, so you can listen to that sort of audio clip and recognize the sounds, that seems like another useful training example to have, here's another example, noisy background.
Zero, one, two, three four five you know of cars driving past, people walking in the background, here's another one, so taking the original clean audio clip so taking the clean audio of someone saying 0 1 2 3 4 5 we can then automatically synthesize these additional training examples and thus amplify one training example into maybe four different training examples.
So let me play this final example, as well.
0-1 3-4-5 So by taking just one labelled example, we have to go through the effort to collect just one labelled example fall of the 01205, and by synthesizing additional distortions, by introducing different background sounds, we've now multiplied this one example into many more examples.
And for audio, well, we do wanna recognize speech, even against a bad self internal connection, against different types of background noise, and so for the audio, we're again synthesizing examples are actually representative of the sorts of examples that we want to classify, that we want to recognize correctly.
In contrast, usually it does not help perhaps you actually a meaning as noise to your data.
I'm not sure you can see this, but what we've done here is taken the image, and for each pixel, in each of these 4 images, has just added some random Gaussian noise to each pixel.
To each pixel, is the pixel brightness, it would just add some, you know, maybe Gaussian random noise to each pixel.
So it's just a totally meaningless noise, right?
And so, unless you're expecting to see these sorts of pixel wise noise in your test set, this sort of purely random meaningless noise is less likely to be useful.
But the process of artificial data synthesis it is you know a little bit of an art as well and sometimes you just have to try it and see if it works.
But if you're trying to decide what sorts of distortions to add, you know, do think about what other meaningful distortions you might add that will cause you to generate additional training examples that are at least somewhat representative of the sorts of images you expect to see in your test sets.
Finally, to wrap up this video, I just wanna say a couple of words, more about this idea of getting loss of data via artificial data synthesis.
As always, before expending a lot of effort, you know, figuring out how to create artificial training examples, it's often a good practice is to make sure that you really have a low biased crossfire, and having a lot more training data will be of help.
And standard way to do this is to plot the learning curves, and make sure that you only have a low as well, high variance falsifier.
Only to realize afterward, that, you know, your learning algorithm, performance doesn't improve that much, even when you're given a huge training set.
So that's about my usual advice about of a testing that you really can make use of a large training set before spending a lot of effort going out to get that large training set.
Second is, when i'm working on machine learning problems, one question I often ask the team I'm working with, often ask my students, which is, how much work would it be to get 10 times as much date as we currently had.
When I face a new machine learning application very often I will sit down with a team and ask exactly this question, I've asked this question over and over and over and I've been very surprised how often this answer has been that.
You know, it's really not that hard, maybe a few days of work at most, to get ten times as much data as we currently have for a machine running application and very often if you can get ten times as much data there will be a way to make your algorithm do much better.
So, you know, if you ever join the product team working on some machine learning application product this is a very good questions ask yourself ask the team don't be too surprised if after a few minutes of brainstorming if your team comes up with a way to get literally ten times this much data, in which case, I think you would be a hero to that team, because with 10 times as much data, I think you'll really get much better performance, just from learning from so much data.
So there are several waysand that comprised both the ideas of generating data from scratch using random fonts and so on.
As well as the second idea of taking an existing example and and introducing distortions that amplify to enlarge the training set A couple of other examples of ways to get a lot more data are to collect the data or to label them yourself.
A second way to get a lot of data is to just collect the data and you label it yourself.
So, for example, that, for our machine learning application, currently we have 1,000 examples, so M 1,000.
That what we do is sit down and ask, how long does it take me really to collect and label one example.
And sometimes maybe it will take you, you know ten seconds to label one new example, and so if I want 10 X as many examples, I'd do a calculation.
If it takes me 10 seconds to get one training example.
If I wanted to get 10 times as much data, then I need 10,000 examples.
So I do the calculation, how long is it gonna take to label, to manually label 10,000 examples, if it takes me 10 seconds to label 1 example.
Third and finally, one sometimes good way to get a lot of data is to use what's now called crowd sourcing.
So today, there are a few websites or a few services that allow you to hire people on the web to, you know, fairly inexpensively label large training sets for you.
So this idea of crowd sourcing, or crowd sourced data labeling, is something that has, is obviously, like an entire academic literature, has some of it's own complications and so on, pertaining to labeler reliability.
Maybe, you know, hundreds of thousands of labelers, around the world, working fairly inexpensively to help label data for you, and that I've just had mentioned, there's this one alternative as well.
And probably Amazon Mechanical Turk systems is probably the most popular crowd sourcing option right now.
If you want to try to hire many people, fairly inexpensively on the web, our labels launch miles of data for you.
So this video, we talked about the idea of artificial data synthesis of either creating new data from scratch, looking, using the ramming funds as an example, or by amplifying an existing training set, by taking existing label examples and introducing distortions to it, to sort of create extra label examples.
And finally, one thing that I hope you remember from this video this idea of if you are facing a machine learning problem, it is often worth doing two things.
One just a sanity check, with learning curves, that having more data would help.
And second, assuming that that's the case, I will often seat down and ask yourself seriously: what would it take to get ten times as much creative data as you currently have, and not always, but sometimes, you may be surprised by how easy that turns out to be, maybe a few days, a few weeks at work, and that can be a great way to give your learning algorithm a huge boost in performance
In earlier videos, I've said over and over that, when you're developing a machine learning system, one of the most valuable resources is your time as the developer, in terms of picking what to work on next.
Again, one of the most valuable resources is the time of the engineers or the developers working on the system.
Only to realize after weeks or months of time spent, that all that worked just doesn't make a huge difference on the performance of the final system.
In this video what I'd like to do is something called ceiling analysis.
When you're the team working on the pipeline machine on your system, this can sometimes give you a very strong signal, a very strong guidance on what parts of the pipeline might be the best use of your time to work on.
And see right here each of these boxes, text detection, character segmentation, character recognition, each of these boxes can have even a small engineering team working on it.
But the question is where should you allocate resources?
Which of these boxes is most worth your effort of trying to improve the performance of.
In order to explain the idea of ceiling analysis, I'm going to keep using the example of our photo OCR pipeline.
As I mentioned earlier, each of these boxes here, each of these machines and components could be the work of a small team of engineers, or the whole system could be built by just one person.
But the question is, where should you allocate scarce resources?
That is, which of these components, which one or two or maybe all three of these components is most worth your time, to try to improve the performance of.
As in the development process for other machine learning systems as well, in order to make decisions on what to do for developing the system is going to be very helpful to have a single rolled number evaluation metric for this learning system.
So if you're given a test set image, what is the fraction of alphabets or characters in a test image that we recognize correctly?
And we find that on our test set the overall accuracy of the entire system was 72% on whatever metric you chose.
Now here's the idea behind ceiling analysis, which is that we're going to go through, let's say the first module of our machinery pipeline, say text detection.
For every test example, which is going to provide it the correct text detection outputs, so in other words, we're going to go to the test set and just manually tell the algorithm where the text is in each of the test examples.
So in other words gonna simulate what happens if you have a text detection system with a hundred percent accuracy, for the purpose of detecting text in an image.
And really the way you do that's pretty simple, right?
Instead of letting your learning algorhtim detect the text in the images.
You wouldn't say go to the images and just manually label what is the location of the text in my test set image.
And you would then let these correct or let these ground truth labels of where is the text be part of your test set.
And just use these ground truth labels as what you feed in to the next stage of the pipeline, so the character segmentation pipeline.
So just to say that again.
By putting a checkmark over here, what I mean is I'm going to go to my test set and just give it the correct answers.
Give it the correct labels for the text detection part of the pipeline.
So that as if I have a perfect test detection system on my test set.
What we need to do then is run this data through the rest of the pipeline.
And then use the same evaluation metric as before, to measure what was the overall accuracy of the entire system.
And with perfect text detection, hopefully the performance will go up.
And in this example, it goes up by by 89%.
So again, I'm gonna go to my test set, and now I'm going to give it the correct text detection output and give it the correct character segmentation output.
So go to the test set and manually label the correct segmentations of the text into individual characters, and see how much that helps.
And let's say it goes up to 90% accuracy for the overall system.
So as always the accuracy of the overall system.
So is whatever the final output of the character recognition system is.
Whatever the final output of the overall pipeline, is going to measure the accuracy of that.
Now the nice thing about having done this analysis is, we can now understand what is the upside potential of improving each of these components?
So we see that if we get perfect text detection, our performance went up from 72 to 89%.
So that's a 17% performance gain.
So this means that if we take our current system we spend a lot of time improving text detection, that means that we could potentially improve our system's performance by 17%.
It seems like it's well worth our while.
Whereas in contrast, when going from text detection when we gave it perfect character segmentation, performance went up only by 1%, so that's a more sobering message.
It means that no matter how much time you spend on character segmentation.
Maybe the upside potential is going to be pretty small, and maybe you do not want to have a large team of engineers working on character segmentation.
This sort of analysis shows that even when you give it the perfect character segmentation, you performance goes up by only one percent.
And finally, going from character, when we get better character recognition with the forms went up by ten percent.
So again you can decide is ten percent improvement, how much is worth your while?
This tells you that maybe with more effort spent on the last stage of the pipeline, you can improve the performance of the systems as well.
Another way of thinking about this, is that by going through these sort of analysis you're trying to think about what is the upside potential of improving each of these components.
Or how much could you possibly gain if one of these components became absolutely perfect?
And this really places an upper bound on the performance of that system.
Let's say that you want to do face recognition from images.
You want to look at the picture and recognize whether or not the person in this picture is a particular friend of yours, and try to recognize the person Shown in this image.
This is a slightly artificial example, this isn't actually how face recognition is done in practice.
But we're going to set for an example, what a pipeline might look like to give you another example of how a ceiling analysis process might look.
So we have a camera image, and let's say that we design a pipeline as follows, the first thing you wanna do is pre-processing of the image.
So let's take this image like we have shown on the upper right, and let's say we want to remove the background.
Having detected the face, it turns out that if you want to recognize people, it turns out that the eyes is a highly useful cue.
We actually are, in terms of recognizing your friends the appearance of their eyes is actually one of the most important cues that you use.
So lets run another crossfire to detect the eyes of the person.
So the segment of the eyes and then since this will give us useful features to recognize the person.
Maybe segment of the nose, segment of the mouth.
And then having found the eyes, the nose, and the mouth, all of these give us useful features to maybe feed into a logistic regression classifier.
And there's a job with a cost priority, they'd give us the overall label, to find the label for who we think is the identity of this person.
So how do you go through ceiling analysis for this pipeline.
Well se step through these pieces one at a time.
Let's say your overall system has 85% accuracy.
The first thing I do is go to my test set and manually give it the full background segmentation.
And use Photoshop or something to just tell it where's the background and just manually remove the graph background, so this is a ground true background, and see how much the accuracy changes.
In this example the accuracy goes up by 0.1%.
So this is a strong sign that even if you have perfect background segmentation, the form is, even with perfect background removal the performance or your system isn't going to go up that much.
Then quickly goes to test set give it the correct face detection images then again step though the eyes nose and mouth segmentation in some order just pick one order.
And so as I go through the system and just give more and more components, the correct labels in the test set, the performance of the overall system goes up and you can look at how much the performance went up on different steps.
So from giving it the perfect face detection, it looks like the overall performance of the system went up by 5.9%.
It means that maybe it's worth quite a bit effort on better face detection.
So it looks like the components that most work are while are, when I gave it perfect face detection system went up by 5.9 performance when given perfect eyes segmentation went to four percent.
And so this tells maybe whether the components are most worthwhile working on.
But after all that work they found that it just did not make huge difference to the overall performance of the actual application they were working on and if only someone were to do ceiling analysis before hand maybe they could have realized.
And one of them said to me afterward.
If only you've did this sort of analysis like this maybe they could have realized before their 18 months of work.
So to summarize, pipelines are pretty pervasive in complex machine learning applications.
And when you're working on a big machine learning application, your time as developer is so valuable, so just don't waste your time working on something that ultimately isn't going to matter.
Will actually have a huge effect on the overall performance of your final system.
So over the years working machine learning, I've actually learned to not trust my own gut feeling about what components to work on.
So very often, I've work on machine learning for a long time, but often I look at a machine learning problem, and I may have some gut feeling about oh, let's jump on that component and just spend all the time on that.
But over the years, I've come to even trust my own gut feelings and learn not to trust gut feelings that much.
And be kind of reassured that, when you do that, it won't actually have a huge effect on the final performance of the overall system.
Watch the following videos, if you want to find out more about these strategic advantages and benefits, that you can achieve by implementing a suitable price discrimination strategy.
The goal of the course is to help you develop a valuable mental ability, a powerful way of thinking that people have developed over 3,000 years.
What I want to do today is get you ready for the course and tell you a little bit about the way the course will work.
Apart from the final two lectures, there's very little mathematical content in the course and you won't learn any new mathematical procedures.
But mathematical thinking is essential if you want to make the transition from high school math to university level mathematics.
The quickest way to learn what mathematical thinking is, is to take a course like this.
So by the time we're finished, you should know what it is.
If we compare mathematics with the automotive world, school math corresponds to learning to drive.
In the automotive equivalent to college mathematics, in contrast, you will learn how a car works, how to maintain and repair it, and if you pursue the subject far enough, how to design and build your own car.
The only prerequisite for the course is completion or pending completion of high school mathematics.
In contrast, the key to success in high school math was to learn to think inside the box.
It's because thinking outside the box is such a valuable ability in today's world that this course could be valuable to many people.
But my primary student is someone in their final year of high school or their first year at college or university, who's thinking of majoring in mathematics or a math dependent subject.
If that's you, then you will probably find the transition from high school mathematics to college level, pure abstract mathematics, difficult.
Not because the mathematics gets harder, once you've successfully made the transition, I think you will agree that college math is in many ways easier.
At high school, the focus is primarily on mastering procedures to solve various kinds of problems.
That gives the subject very much the flavor of a cookbook, full of mathematical recipes, thinking inside boxes.
At university, the focus is on learning to think a different way, to think like a mathematician, thinking outside the box.
Those designed for science and engineering students are often very much in the same vein as the courses you had in high school.
It's the courses that form the bulk of the mathematics major that are different.
But some of those courses are usually required for more advanced work in science and engineering.
So if you're a student in those disciplines, you may also find yourself faced with this different kind of mathematics.
If you did well at math in school, you probably got good at recognizing different kinds of problems so you could apply different techniques you learned.
At university you have to learn how to approach a new problem, one that doesn't quite fit any template you're familiar with.
It comes down to learning how to think about a problem in a certain way.
The first key step is learn to stop looking for a formula to apply or a procedure to follow.
Approaching a new problem by looking for a template, a worked example in a textbook or presented on YouTube and then just changing the numbers, often won't work.
Sometimes it will.
So all that work you did at high school won't go to waste, but it isn't enough for many of your college math courses.
If you can't solve a problem by looking for a template to follow or a formula to plug some numbers into or a procedure to apply, what do you do?
The answer is you think about the problem a certain way.
Not the form of the problem, that's probably what you were taught to do at school and it served you well there.
Rather, you have to look at what the problem actually says.
That sounds as though it ought to be easy, but most of us initially find it extremely hard and very frustrating.
You have to work at it.
You're going to have to accept going a lot slower than you're used to.
Most of the time you won't feel as though you're making any progress.
Your goal has to be understanding, not doing.
They're there to aid your understanding.
That part's crucial.
A lot of what we'll be doing is not so much focused on right and wrong but on learning how to think about a problem.
But usually there are many different right answers, or different ways to the right answer, and many wrong ones.
When you're learning how to think mathematically, it's how and why you got something right or wrong that's important.
The only way to find that out, to find out how well you're doing, is for somebody else to look at your attempt, and critique your work.
Maybe one day, artificial intelligence will have advanced far enough for a course like this to be automated, though frankly I doubt it.
But right now you need feedback from other people.
For a regular class here at Stanford, the professor and the graduate student TAs grade students' work and provide feedback.
I've designed the course so that the benefit comes primarily from doing the work and discussing it with other students.
Getting it right is important in mathematics, but in a massively open online course, a MOOC like this, there's no way to guarantee that.
Incidentally, not being sure if we are right until others have seen our work is very familiar to we mathematicians.
Even very famous mathematicians have had the experience of thinking they've solved the problem, then writing it up, writing up their solution and sending it off for publication, only for an anonymous referee to find an error.
In mathematics, there is such as thing as right and wrong, but deciding between them can be very difficult.
So even the professionals have to live with never being sure whether they're right or not.
Part of this introductory section is a reading assignment.
It gives you a bit of the history that should explain why today's mathematics students need a course such as this.
In Lecture One, there'll be a short quiz on the reading.
Let me say a few words about the quizzes.
If you were in one of my regular physical classes, I'd talk with you to find out if you had understood the material sufficiently to progress.
You have to monitor yourself.
The quizzes are one way to help you do that.
I'll say a little bit more about the quizzes later.
But before you start Lecture One, please read a file called Background Reading.
It's just over six pages long.
It's a PDF file so you can download it and read it offline.
Hello and welcome back to advanced competitive strategy.
So imagine a football game in which both opponents work together to achieve a settled score, rather than compete against each other and there will be more on this in the following video.
So in this module, we will learn an overview of the aims and instruments of competition policy that will help you to keep your business clean.
And if mindfulness were not being commodified, that would be enormously surprising.
It has not got, it is not immune to the same forces that govern pretty much everything else that the mass media turns its attention to.
So I am not surprised whatsoever that people are trying to cash in on mindfulness, whether that be corporations thinking that their work force will be more docile if their mindful, or whether it's Buddhist groups trying to raise some money to fix the roof on the temple, and putting on a mindfulness course, about which they may not know a great deal.
This is just the way the world works.
So I am not particularly bothered by all of that.
But what I am concerned about is that we're faced here with, I think, a window of opportunity that may not be open that long, it's all over the place, mindfulness is everywhere now, but it is also a fad, very likely, a fashion.
Something else will come along, which the media will latch on to, mindfulness and will become probably a bit passe.
And I think that this window of opportunity is and extraordinary important moment in our culture whereby those of us who, I think, are concerned with this either as mindfulness teachers or as secular Buddhists or whatever, I think we need to maximize, or let's say, I think we need to optimize this opportunity.
To really think through as carefully as we can what the implications of the mindfulness movement are, of how we might create a framework or a structure in which we can move this forward in ways that are not in the service of commodification but, in the service of human well being, and human sanity.
That at least is very much how I see my own work at the moment, is trying to craft a language, a discourse, an idiom in which we can talk about these things without either borrowing buddhist jargon or simply repeating psychotherapeutic phraseology.
We need to find an idiom, a language, that speaks to people in their ordinary lives and speaks beyond their own personal well being to make them more open and aware of the suffering in the wider world, both of humans and other forms of life.
What would you like research to tell you?
Let's pause for a moment to take a survey and see what you think.
Whatever you wanted that research to tell you, whether it was to listen to music or not to listen to music, you can find research that will back you up.
Here's what we do know.
If the music is fast and loud, it disrupts reading comprehension, in part because you use some of the same areas of the brain to process music as you do to process language.
On the other hand, researchers have found that if you're listening to a favorite style of music it could enhance your studies.
In the final analysis, all this means that when it comes to music you should use commonsense and discover what works best for you.
Welcome to the machine learning specialization and this first course on the fundamentals of machine learning.
We're really excited to embark on this journey with you.
Happy?
Are you going to say who you are?
>> And together, we're going to learn about applications of machine learning, how to build machine learning systems, and how the algorithms behind them work, and how to build those algorithms.
>> We're clearly just so excited about this course and this specialization.
We can bearly put the words together to describe it.
Build really intelligent applications, as you go through this process, not just at the end, but throughout the whole specialization.
You'll be building cool, cool stuff, and you'll be learning about a wide range of concepts and building the algorithm.
So the first course is really about using those pre-built machine learning algorithms to build a range of intelligent applications.
Now, the follow up courses, the second through the fifth, takes the different areas and really goes in depth, talk about the algorithms, the methods, the techniques behind it.
Now let's go back and talk about the capstone.
You're gonna build a really cool, impressive application that uses machine learning.
In fact, we can actually look at the coefficients with that line for our model.
And we can get the coefficients.
So these are what in the chorus we call the weights.
And so, there are two weights, two coefficients.
The first one is the intercept to where this line crosses the y axis.
And the second one is the coefficient of the square feet, so this angle, which corresponds to, if you interpret it in this case, the price per square feet.
How much does a square foot of a house cost?
And its $280 per square foot.
This is the kind of average for Seattle.
But on the average, if you think about it, it's about $208 per square foot, or at least according to this regression model.
Which is perhaps one of the most common areas of machine learning, one of the most used, and useful areas of machine learning.
And perhaps, one of those most intuitive ones as well.
So things like figuring out whether your email's spam or not, or whether a document comes from a sports topic, or it's about politics, or it's about entertainment, and so on.
But as usual, we're going to start with a use case, which is an exciting one, around restaurant reviews.
Okay, so in this module, we're gonna talk about clustering and similarity.
And the point here is the fact that often we have lots of observations, and we want to infer some kind of structure underlying these observations.
And in this case, the structure we're gonna talk about is groups of related observations or clusters.
And as with all of our modules, we're gonna motivate everything with a real world application, a case study.
In this case we're gonna talk about a task of retrieving documents of interest.
So let's start with describing this task in a little bit more detail.
Okay, so let's say we're sitting here, reading an article.
Here we are, reading our article.
Or as he would call it football if he was wearing his Argentina jersey or footsie ball if he was wearing his Brazil jersey and clearly, I'm not pronouncing either of those words correctly.
Carlos can correct me later.
But the point is that he likes this article and what we'd like to do is retrieve another article that he might be interested in reading.
But a question is how do we do this?
So we like to think of a way to automatically retrieve a document that might be of interest to him.
By questions here are first, how to we measure similarity between articles?
We need to have that in order to say that this article is similar to the one he's reading now and might also be of interest to him.
Or that, here's a large set of articles that are very different and probably are not of interest to him.
And one prototypical example of where recommender systems are really useful is in recommending products.
And what we're going to talk about is how to use machine learning techniques in order to use the past history of your own purchases, as well as the purchases of other people, to determine which products to recommend to you.
And recommender systems just have a really, really wide range of applications and they've exploded in popularity over the last decade.
But Amazon was an early pioneer in this area, focused on an application we're gonna be talking about, which is product recommendation.
And we'll talk a little bit about that application in this module.
But it really spurred a lot of activity in this area, developing new recommender systems and a lot of research following that.
And we measure how many of my liked items were actually retrieved or actually recommended to me.
Well, as the title answers, there's a very easy way to maximize recall.
Just recommend everything.
If you recommend everything, you're guaranteed to recommend the products that I like.
So in this case what would recall be?
It would just be 1, because all 5 of the products I liked were recommended.
Well, it can actually be arbitrarily small.
Because if you have tons and tons and tons of products out there, and if I like only a very, very small number of them, then if you recommend everything, I'm gonna have very small precision.
So let's just say this is small and maybe very small.
So that's not really a great strategy.
What's the best recommender you can imagine?
Well, the best recommender is one that recommends all the products I like but only the products I like.
No wasted effort, capture everything I like, gonna make lots of money with this recommender system.
Both are 1 in this case.
And you can go through and verify that using the equations from the previous slides.
Today, we're gonna talk about one of the most exciting things to be happening with machine learning over the last few years.
It's a new area called deep learning.
In particular, we're gonna talk about a particular use case of this area related to shopping for products just based on the image similarity.
So I showed you some examples of neural networks in computer vision and doing classification.
Is there a labrador retriever in this image?
But they can do quite a bit more.
So, for example, we can do image parsing.
So in this example, for every picture in the image, you're trying to classify it and discover regions.
And this kind of image description, or is called scene understanding, is pretty cool, and you know networks again, provided significant gains.
But if we go back to the beginning of the module when we discussed a new way to shop for shoes or dresses, the thing that we're really trying to do there is retrieve similar images.
So, for example, if I give you the input of this boring black shoe, what neural network with output.
A bunch of boring black shoes.
Now, if I do this a little bit more stylish boot, you'll see that it gives you a variety of interesting boots like that.
Similarly, for heels, for brown shoes, for sneakers and so on.
So this is the core of the concept that we're using in the demo that we showed at the beginning of the module.
So, this is going to be pretty simple.
It'll be similar to the document retrieval notebook that we did to find documents that were similar to Barack Obama, to Clinton, to Beckham, and others.
So, let's go ahead and what we're going to do is train a nearest-neighbors model for retrieving images using deep features.
And we're gonna call it the, knn_model, just like we did with document retrieval.
I'm going to tell it what features to use.
So the features that I'm going to use are going to be exactly those deep features.
And then just as a reminder, you can give it a label ID.
Emily and I really hope you've enjoyed the course so far.
We've really explored the foundations of machine learning on a wide range of domains with a range of different applications.
And really touched many of the practical issues around deploying and building machine learning systems.
And now in this closing module we're going to really summarize some of the concepts that we've learned.
Talk about how to deploy these ideas, especially machine learning systems in production and then what's ahead in the specialization and in machine learning as a whole.
Some really exciting stuff as we close off this first course.
Hi.
I'm a professor of history at the University of Virginia.
You're joining me for a course on the modern world, global history since 1760.
That's the last 250 years of world history.
But really just a series of conversations, in which we're going to talk about this course.
True, it's a lot of conversations to have with a professor, and you don't get to talk back directly.
But on the plus side, you get to stop, pause, fast forward, rewind, or if you get tired of the professor, just turn him off.
So, welcome to the modern world.
As a subject for our first conversation today, I just want to talk a little bit about the study of history.
Okay, history.
We would think about the study of history as, well what happened in the past?
What happened?
Well, finding out what happened just, kind of what happened in the past, is often extremely hard.
I've served in the government in a number of different jobs over the last 30 years.
One of those jobs in 2003 and 2004 was to manage a small government agency called the 9/11 Commission.
Our job was to look into the facts of what happened on the morning of 9/11, and why it happened.
It turned out to be extremely difficult just to untangle the story of what happened on the morning of 9/11.
So, literally it took our commission years after the fact of this enormously important event, just to get down to the truth of what happened on the morning of 9/11.
So for a lot of historians and a lot of history readers, just reading about what happened is enough.
But a lot of this course is not going to just be about what happened.
A lot of this course is going to be about why.
So take a step back, and the big point I'm just trying to make here is, these why questions are actually really, really important, and this course is going to spend a lot of time on why questions.
Well, when you ask those why questions, what your answers will be are sometimes they'll just be circumstances.
But a lot of it, especially cause we're dealing with history, is going to be about choices.
Here's a picture of a volcano.
A volcano is caused by geological circumstances.
No human being made a decision that was going to produce the eruption of a volcano.
The American Civil War, not like a volcano.
This is not just well the lava just happened to erupt in 1861 because that was its time.
That's actually what makes the story so interesting.
Is to understand those choices.
How did they make them, why did they make them?
If you set up the why problems as choices, you can see how interesting this gets.
Because then all of a sudden you see, history could have taken a different path.
Because you unpack choices people like you made, long ago, that could've steered history in a totally different place.
When you examine those sorts of choices, what you'll find is a cycle that looks something like this.
Here are people, they look at a situation.
They see a problem, or, maybe they see an opportunity.
Maybe, you would have come up with a different solution, but you're interested in figuring out what they thought their options were.
But this cycle I've just described here, that's a story, that's a narrative.
Stories about choices that determine history going down one pathway, instead of down another.
Enough about the general study of history.
The next thing we'll talk about is to just get some sense of what a huge divide there was between the traditional world and the modern world we're going to study in this course.
I look forward to seeing you then.
Welcome.
In this presentation, I want to introduce you to the great divide between the traditional world and the modern world, because there are a lot of ways to define the traditional world and the modern world.
Here is what I'm going to do.
I think of the traditional world as a world in which the basic circumstances of life don't change much from one generation to the next.
One way of measuring that great divide is by looking at population, people's lives getting longer, women having more children.
You can see some really pretty striking numbers.
So if you look at this chart, you'll see that between the year zero in the common era, and the year 1,000, 1000 years, ten million people.
In the next 250 years, between the year 1000 and the year 1250, up 90 million.
In the next 250 years, between 1250 and 1500, up 100 million.
Then this picks up a little bit between 1500 and 1750.
It looks like in that 250 year period, 290 million people in 250 years.
There have been some developments in irrigation capabilities and so on that have caused population growth in China, in India, in northwest Europe.
So remember that we said that between 1500 and 1750, 290 million in 250 years.
Now look at this.
50 years.
Think that's a fluke?
1800 to 1850, that's 284 million: 50 years.
In other words, the rate of population growth has more than tripled in the second half of the 1700s.
So something has happened.
At which the whole rate of human population on planet earth has dramatically changed in the late 1700s, a change then that doesn't quit.
That's a great divide.
Now here, with the aid of a wonderful interactive map prepared by the Public Broadcasting System for their Nova series.
You can also see the distribution of population, as well as seeing how much it changes.
Year zero, 1000 years later, very little change, you see where the distribution is.
800 years later, more change, up to a billion people.
There's a lot more people now in this place called North America.
Even 33 years later now, yet another billion.
And only 14 years later, the next billion.
And by the year 2050, nine billion people.
And you can see some of the distribution.
So you can see then, as a historian, what an enormous swing is occurring beginning in the late 1700s.
Now, let's look at another metric.
Let's look at real income.
It's really hard to calculate real income over different historical periods in different places.
But a lot of economic historians, especially the late Angus Maddison, worked very hard at this and have come up with some roughly comparable numbers that allow us to get a sense of how real income has changed over time.
Here's a wonderful chart from the economic historian, Gregory Clark, in his book published by Princeton University Press.
Now the point of this chart is: even if population is increasing, if there's still only a finite amount of stuff that people are producing, more people have less stuff to go around, therefore the amount of food available to them drops if the population goes up.
This is called the Malthusian trap.
Real income stays pretty constant.
Because there's just a finite amount of stuff to go around.
And then you can see what happens after that.
You can see the great divide, too, in the changing nature of political ideas.
The political revolutions, what we might think of in America as the American Revolution, the Declaration of Independence and all that.
In Europe, they might think of the French Revolution.
These are all developments that convulse the European world in the late 1700s, but then they become part of a global political vocabulary.
Either people accepting it or rejecting it, but they're reacting to it.
Yet another break is cultural.
In the traditional world, there seemed to be finite limits on everything: on how much food could be grown, on the availability of energy, limits on how much you can even understand the world around you.
With all kinds of breakthroughs in science and the development of technology in the late 1700s and 1800s, the sense of human mastery over the environment, human ability to create new sources of energy, has enormous cultural effects.
Just the whole beliefs people have, about their relation to the world, change.
Their sense of not just limits, but also possibilities, the way in which they get to know or perceive other kinds of humans.
The way they identify themselves.
Who are we?
To what community do we belong?
How do we define our status?
In what ways do we try to get income and assure our prosperity?
How do we protect ourselves?
All of these things are undergoing enormous change.
We'll talk some more about those different belief systems next time, delving more into what we mean by the traditional and the modern.
In this presentation, I want to say a little more about what I mean by these terms, traditional and modern, and make this a lot more concrete for you.
Let's think about this as a series of contrasts.
First, in the traditional world, things move based on natural energy.
In other words, for most all of the history of the human species, the only energy available to people was the energy of animal power, wind, water, maybe assisted by crude pulleys.
In the modern age, we've tapped sources of energy embedded in fossil fuels.
So the contrast between a world of natural energy, which seemed to be the eternal limits for all of human history up to about 250 years ago, and a world in which we have manmade energy of entirely new kinds.
The traditional world is overwhelmingly rural and agricultural.
Just to give you some sense of this: for most all of human history at no point do more than 10 to 15 percent of the population even live in towns.
That is, no more than 10 to 15 percent of the population live in a community of more than 2,000 people.
In the modern era, larger and larger fractions of the human population are not only living in towns, they're living in cities to a degree that had no precedent in human history.
They're moving into an urban and industrial age.
This being a picture of the dawn of that era.
The warrens of an industrial city in England in the mid-1800s.
Through most of human history, we saw that real income remained relatively constant.
It's remaining pretty constant because there are pretty finite resources available.
Most people are growing just enough food to get by, they hope.
People have more and more surplus resources.
Surpluses that they can even turn into cash money that they can save or invest.
This fourth point is a little more subtle.
People's lives in the traditional world were highly unstable.
But their communities had a stable rhythm about them.
Your life was much like your father's life, much like your grandfather's life, much like the lives your children would live.
A world in which people are living longer lives, maybe even more secure lives.
More sheltered from random everyday violence.
But the communities they live in are now becoming more unstable.
So look at the paradox.
A traditional world of unstable lives and stable communities to a modern world of more secure individual lives but less stable communities.
The modern world represents more of a fusion in which religious faith continues, but is increasingly mixed up and challenged by emerging understandings about science and scientific explanations for many kinds of phenomena, the sense of human mastery over the environment instead of human submission to the environment.
A sixth contrast is one about the way people identified themselves and lived their lives.
In the traditional world, almost all people were born, lived, died in a radius of maybe 30 to 50 miles - their entire life.
It was difficult, if not impossible, to travel significant distances.
It was not even very easy to get news of what happened in far away places.
People like kings or emperors were images seen on coins, or maybe depicted in a sculpture.
Therefore, peoples' identities, the sense of the community they belong to, their culture, were intensely local.
Many, many more languages, for example, in the world than the number of languages routinely spoken today.
In the modern world not only can people travel more, but also through modern information and communications they feel like they're participants in vastly larger communities.
Their identity then becomes more of a mass identity.
They're learning from participating in larger beliefs, larger cultures.
In the traditional world, it looks like there is some really powerful states.
You look on the map, you see the Persian empire or the Spanish empire, but in a way these are relatively simple states.
Theyï¿1⁄2re agrarian empires in which you have a king, priest, warrior elite, and they basically extract tribute from peoples they conquer.
But, the administrative capabilities of these states were very crude.
Their ability to give an order and have it carried out, 100, 200, 300 miles away, even, modest.
You compare that to the powers at the disposal of modern nation-states, and you can see the contrast.
And we'll be talking much more about those contrasts in presentations to come.
In the next presentation, we'll explore some of the why questions around the great divide.
Make yourself comfortable, because we're going to take a tour around the world of 1760.
Just to give you a general overview of that world, I mentioned earlier it's dominated by these Eurasian land empires.
For a 1000 years before the 1700s, Eurasia had been dominated by warrior horsemen.
Organizing in large groups out of the pasture lands.
That basic dynamic really began to change in the 1500s, 1600s, and 1700s.
A big reason for that, which I'll get into in another presentation in a little more detail, is gun powder.
And settled communities that could leverage the power of settled communities (i.e.taxes, building primitive industries) were better positioned to harness that technology and recruit and build gun powder armies.
The empires that could pull together these gunpowder armies gained a decided advantage over the traditional nomadic horse warriors.
So one huge factor: the consolidation of large land empires in Eurasia.
Now, another huge factor: the discovery and opening up of the New World.
Here's a map that gives you a sense of European world trade just after Columbus' discovery of the New World in 1492.
Now contrast that with this map of world trading empires in 1770.
Let's just zoom in on this a little bit more.
You don't have to follow this in detail.
All I want you to do is be able to contrast this with the previous map and just get a sense of the scale.
Now, let's dive into some particular regions.
Probably the most powerful region in the whole world in 1760 was East Asia.
The Ming Dynasty that had governed this part of East Asia and the agrarian settlements along the Yangtze River Valley and the Yellow River Valley historically very strong.
The Ming Empire actually built a powerful navy that made these historic voyages, in the early 1400s, all around the Indian Ocean.
But then, on their return, the empire essentially decided to scrap this navy and wasn't much interested in expanding Chinese commerce beyond Southeast Asia.
Why?
Because their main focus was not on the ocean.
Their main focus was on enemies and opportunities in the Eurasian hinterland.
In the 1600s, the Ming Dynasty itself falls to invasions from the north, from the Manchurians, from the Manchus, who create a new Qing Dynasty that will rule China from the 1640s to the early 1900s.
That's the main focus of their attention.
Interestingly, this portrait was done by a Western painter, an Italian who is visiting the Qing court.
Its people spoke a variety of different languages.
But there was a particular court culture, an ideal of civilization that the empire tried to spread to all its domains.
This is at Canton in the south of what we now call ï¿1⁄2China.ï¿1⁄2 Moving across the water a little bit to Japan.
Japan also had a ruling dynasty, but here too there was a Western trading outpost, really one trading outpost, in Nagasaki, at the far southern end of the Japanese domains.
In Nagasaki, in this Japanese print, you see the city and these Dutch ships.
And indeed, all Western culture was known in Japan in this period as ï¿1⁄2Dutch cultureï¿1⁄2 or ï¿1⁄2Dutch ideas.ï¿1⁄2 If, in East Asia, the most powerful empire was the Qing; in South Asia, the powerful empire in the 1600s and much of the 1700s had been the Mogul Empire.
The Moguls were Muslim invaders who had come in from the north, ruling over again a multilingual society.
During the 1600s, the Moguls had penetrated far to the south, all the way to here.
But during the 1700s, their domain begins to contract.
There's a rise of a confederacy of Hindu princes, the Marathas, who enjoy a couple hundred years of expanding power.
This map shows the way the Marathas were carving up pieces of the Mogul domain as it began to recede.
Here you see the fragmentation of the former Mogul, or Mughal, domains.
So let's pause and just reflect a little bit on the significance of what's going on in the Mogul or Mughal Empire in the middle of the 1700s.
Because of the attacks that have come in from the north by conquerors like Nader Shah, they quickly recede, but what's left is a greatly weakened empire.
All of this area in purple: these are under a variety of autonomous local rulers.
The Hindu princes, the Marathas, have expanded their own area of control, but much of this is now broken up under a variety of local rulers and princelings.
That fact is going to acquire world historical importance in the late 1700s.
This map is just designed to give you a brief glimpse of India's economic structure in the mid-1700s.
The only key point to take away from this map is a number of points for trade in some goods with the outside world along the coast.
Most of the countryside, being oriented around local subsistence.
In Southeast Asia, these European trading outposts were especially important.
Spices are important because they're very light.
These sailing ships of the 1600s, 1700s, couldn't carry very much.
In Southwest Asia, very much the dominant empire is an empire created by a group of Turkic warrior chiefs, who establish a dynasty called the Ottoman Dynasty, ruling over their sprawling, multi-ethnic domain.
In the 1500s and 1600s, the Ottomans had hugely expanded their domains in Europe, in Central Asia, in Southwest Asia, as this map shows here.
Fighting significant border wars with enemies in what used to be considered Ancient Persia and enemies in Europe.
By the early 1700s, the balance of power is tipping.
In 1683, the Ottomans besieged the city of Vienna, almost captured it.
But by the early 1700s, European armies are doing a little better.
They're driving back some of the Ottoman domains, as you see here in this map.
And the Ottoman Empire is coming to terms in establishing a border with another ruling dynasty, established by warrior chieftains, the Safavid dynasty, in present day Iran.
Europe in the 1500s was a pretty complicated place.
In fact, this map actually simplifies the picture of just how fragmented Europe was.
The most coherent kingdom is that here in France, that here in England being another.
And there's the rising power of the Russian Empire, over here.
In fact, the 1600s and the 1700s will be an enormous period of growth and consolidation for the Russian Empire.
An exceptionally important example of how one of these organized states is able to use the gunpowder revolution to subdue and take away the territories of the Central Asian nomadic tribes.
Another important state development in Europe in the 1700s is the rise of a German-speaking state called Prussia.
You see here in deep orange, the borders of the Prussian state at the beginning of the 1700s.
But still, it's just one German state, an important one, among a great many of them.
Above all, the Europeans have now placed themselves at the center of an entire Atlantic world.
Think about the Europeans as facing the Atlantic, populating thin stretches of territory along the coast, or in a few particularly lucrative areas inland, for example where there are mines; plus areas of settlement along the coast here in the Pacific, for those people who can make the voyage around the horn or get their supplies up to the Isthmus of Panama, where they can get back into the Atlantic world by that trade route.
In this area of English settlement, think about almost everyone being within 50 miles of the sea coast, except for a few river valleys penetrating a little bit inland.
Think about the French settlement then, clustered along the St.
Lawrence River, and a little bit along these lakes, down here at New Orleans.
Even here within the Spanish domains, these areas of purple almost exaggerate a little bit the scale of the settlement into these thinly populated areas, where Native American tribes still hold sway.
In fact, now that some of these tribes have access to horses, they're establishing the kind of horse warrior raiding tribes, or even raiding empires, that were commonplace in Central Asia for so many centuries.
It's relatively light.
And of course, once Europe develops a sweet tooth, the demand for sugar is pretty substantial.
This gives you a sense of the trade routes, the sugar, rum, coffee going out, coming back in, servants, manufactures, and slaves from Mexico, in particular, and other areas in South America.
The colonies of the Atlantic world are basically two kinds.
Places where you can build mines and extract silver, gold, other valuable minerals.
The plantations are usually worked by actual slaves, mainly Africans brought over in the millions, in the 1600s and in the 1700s, who can survive the hard labor in the fields.
You can see where the dominant concentrations are of the slaves.
You can see that that number is eclipsed by the numbers of slaves working in the Caribbean in the West Indies.
In fact, the slave trade to the West Indies is much, much larger than these numbers imply because the death rate of the slaves working in the Caribbean and also in Brazil was much higher than the death rate of slaves working in the Southern United States.
Traditional societies, with some of the population clustered along the coast, organized into tribes but in some cases more elaborate kingdoms: here in Ethiopia, here in West Africa, and in other places.
Yes there had been some overland trade with the Muslim world in Northern Africa or in Southwest Asia, but not much.
The slave trade is enormously lucrative for the slave traders of course, but also for those African kingdoms that can capture the slaves that the slave traders want to buy.
So, what happens here is the Europeans set up these trading outposts, and then African kings or chiefs would launch raids, capture enemy peoples, bring these captives to the trading posts, and then sell them there for goods they desired.
So, social upheaval, economic upheaval, and political changes as a result of this interaction with the Atlantic World, even though the Europeans themselves are still on the fringes of the African continent.
So here's the heart of one of those sugar plantations that I have mentioned in the Caribbean: this is the sugar mill.
You see over in the bottom left hand corner: the overseer of the plantation, his foremen.
But a lot of it now are centers of economic activity here in Northwest Europe, some degree in Spain, but especially in England, invigorated by their interaction with this world of Atlantic commerce.
Hello, and welcome back to advanced competitive strategy.
We will find that considering these two concepts and formulating our business strategy can help us improve our strategy's effectiveness and eventually increase our returns.
But obviously, things have changed in the meantime.
What is a musician's response to the condition of the world?
Do musicians have an obligation and an opportunity to serve the needs of the world with their musicianship?
At a time of crisis, for the classical music profession, with a changing commercial landscape, a shrinking audience base and a contraction in the number of professional orchestras, how does a young musician construct a career today?
Are we looking at a dying art form or a moment of reinvigoration?
In this course, we will explore one answer to this question; the notion, that the classical musician, the artist is an important public figure with a critical role to play in society.
That a thriving free society depends on artists to serve an important role.
I think I was reading something about the Nazi time.
A discussion about freedom, civil society, and ways that art can play a role in readying people for democracy.
Philosophy of Education as it relates to the question of positive social change and an exploration of musical and artistic initiatives that have been particularly focused on a positive social impact.
Guiding questions for this course inquiry will include: How can classical music affect social change?
How has music made positive change in communities around the globe?
What can classical musicians learn from other movements for social change?
And how have educators and philosophers thought about the arts and their connection to daily contemporary life?
Each class will include, a set of critical questions to which the course participants will respond.
In over the entirety of the course, we aim to stimulate a discussion in many communities about new ways we can see the connection of art and artists forming healthy and just societies.
We opened this course with two American philosophers, John Dewey, whose work and writing comes from the first half of the 20th century, and Maxine Greene, who was actively writing and teaching until her death in 2014 at the age of 96.
Both Dewey and Greene deal with the topic of aesthetic experience and the possibilities contained within experiences of art.
Dewey was part of a group of philosophers in the early 20th century that considered their practice to be different from the previous philosophical traditions.
Instead of deriving their theories from abstract principles, doing this group focused on the common experiences that people have, and use these examples to build theories that could be directly relevant to the world around them.
Because he felt there was this ongoing relationship between ideas and experience, Dewey felt that certain dichotomies were unhelpful and unnecessary, like that between knowledge and action or theory and practice.
For Maxine Greene and Dewey, a discussion about art and its meaning therefore goes beyond this idea of art for art's sake, and instead, considers how art is a component of human experience, essentially knowable and accessible.
As people, both Maxine and Dewey immersed themselves in art and artistic activity.
Their theories come very significantly from their own lived experience.
In Dewey's case, he was profoundly influenced by his relationship with Albert Barnes, this deep friendship where Barnes was an art collector and also a physician and entrepreneur.
And they shared these artistic experiences, both of sort of the European masters and Barnes' collection included the first major African American art collection, and the museum's programming included this regular series of concerts by African American singing groups.
So his theories of art emerged from this premise that we need to understand art not simply as an intellectual pursuit, but for the possibility that art can be as Dewey and Barnes would say in their letters, soul thrilling.
As I'll discuss in this class, Maxine picks up on a lot of Dewey's threads, including this clear conviction that we can't attend to a work of art passively.
But then in order to fully experience the soul thrilling quality, the person perceiving it needs to bring an energy, an awake energy and an open receptiveness to the possibilities that might be contained within the work.
In her book, Releasing the Imagination, Maxine says, Aesthetic experiences require conscious participation in a work, a going out of energy, an ability to notice what there is to be noticed in the play, the poem, the quartet.
Knowing about, even in the most formal academic manner, is entirely different from constituting a fictive world imaginatively and entering it perceptually, affectively, and cognitively.
She was always voracious in her appetite for all kinds of artistic experiences in different genres, in different forms, from different time periods.
And her descriptions and her writing and in speaking with her really reflected both this sort of learned, but also very personal response to every work of art.
So we start the course with these philosophers in part because Dewey and Greene eloquently bring art into the realm of being accessible to everyone.
They both define aesthetic experience in ways that suggest it can be transformative.
And therefore set us up for an inquiry into how we may eventually take social action through the arts.
Welcome to the Capstone course.
If you're looking at this video, you have already taken Developing Your Musicianship one, two, and three.
I look forward to seeing you in class.
My name is George Siedel.
I'm a professor at the Ross School of Business at the University of Michigan.
Welcome to our course on successful negotiation.
This session and way to provide a course overview.
So let's start with the goal of the course.
We negotiate with our friends, our spouses, our parents, our children.
We negotiate when we rent an apartment, when we buy a car, when we buy a house, or when we apply for a job.
Negotiation is also the key to business success.
No business can survive without profitable contracts.
And negotiation skills are important to your career advancement.
My goal in this course is simple.
I wanna help you become a successful negotiator in your personal life.
I live and work in a state called Michigan.
For those of you are from outside of the United States, and perhaps unfamiliar with the geography, you might know where Chicago is located.
Right in the center of America.
And Michigan is due east from Chicago.
I was born south of the border in a state called Ohio.
I spent the first 18 years of my life on a farm in Ohio.
I finally escaped from the farm and went to a small college down the road called the College of Wooster.
I didn't even have to turn to get from the farm to the college.
I'd drove out the driveway, turned right on FDR 6, drove for 30 miles, and there was the College of Wooster.
After graduating from college, I attended law school at the University of Michigan.
And then I received a scholarship to do research at Cambridge University.
After completing my research I returned to the states, I practiced law for a couple of years, and then began my teaching career.
And I spent most of my career in Ann Arbor, Michigan at the University of Michigan although I have been a visiting professor at Harvard University, Stanford University, and I've gone back to Cambridge three times as a visiting fellow.
During my career I've been fortunate to have two unusual opportunities.
First, I've had the opportunity to teach and lecture on negotiation in Europe, Asia, North America, South America, Australia, and Africa.
For example, I currently teach annual courses in Italy and Eastern Europe.
And for many years I taught an annual seminar in Hong Kong.
I've also had the opportunity to teach negotiation to undergraduates, MBA students, business leaders, lawyers, athletic directors, physicians, judges and entrepreneurs.
And I mentioned this because this course draws on my experience in two ways.
Now I should mention one other aspect of my background, it's a little bit embarrassing and I have never disclosed this publicly.
So you are the first to know.
My daughter recently purchased a DNA kit for me that enabled me to trace my ancestry.
And what I discovered is that part of my ancestry is based in the British Isles.
That's my mother's side.
The name Siedel comes from Alsace, which is a part of France and it's been kicked back and forth between France and Germany over the years.
I knew that.
But what I didn't discover, and I didn't know until this DNA test, is that I am also 3.1% Neanderthal.
Now my friends and relatives probably realized that all along from my behaviors, but this was the first time that I learned about this type of my background.
And so as former Neanderthals, we have to address our Neanderthal heritage, which is based on the flight or fight response.
We either fight the tiger or we flee.
Today, when we are confronted with a difficult negotiation, when we're confronted with a car salesman, we have the same tendency.
We're fearful, we wanna flee, or we fight, and one of the goals in this course is to give you the skills and strategies that us fellow Neanderthals need to overcome our common heritage.
Let's now take a look at the course game plan.
And this is the big picture, what we'll be covering in the course.
And then I'm going to give you an introduction to the University of Michigan.
If you're from outside the United States, this segment might be of interest because it will also give you an insider's view of what a major university looks like.
But if you're not interested in that segment, you can jump right to the course material.
And the heart of the course focuses on the four stage negotiation process.
In other words we deal sequentially with the issues that you face in a real negotiation.
How do you conduct a negotiation analysis?
How do you incorporate into your analysis your BATNA?
Then we move onto the second unit on negotiating and the tactics that you can use for success.
In this unit we'll look at the source of power in a negotiation and how you can increase your power.
We'll also look at psychological tools that are very effective in negotiation.
These tools also represent traps when used by the other side.
So you have to be prepared to avoid the traps.
Then we'll look at closing the deal and creating a contract.
Basically we'll look at the legal framework for negotiation.
For example you should be able to address this question; if a company makes a job offer to you what are the legal dangers in making a counter offer?
And then finally we'll look at performance, and we'll look at especially some processes that you can use when you face difficulties with performance.
So after covering that process, you'll then have a chance to practice your negotiation skills with a negation called The House on Elm Street.
And with this negotiation you will find a partner and you'll negotiate The House on Elm Street one-on-one with this person.
And then at the conclusion of the negotiation, you'll receive feedback from the other side.
What do you do well as a negotiator?
How can you improve as a negotiator?
This feedback from the other side is one of the unique features of this course that you never obtain in real life.
In real life, when you finish a negotiation, the other side never sits down with you and says to you, well, you know you did a pretty good job in this negotiation, but if you had done this, this, and this you could have done a lot better.
My former students frequently send me emails telling me about the value of this feedback.
Let me give you a couple of examples.
Here's one.
The email says, negotiation is a fundamental skill we need to learn how to use.
I was a bit hesitant to join the class as I thought I had excellent negotiation skills.
However, I soon realized there was a lot to learn.
The key difference is that in class I got feedback and know what I did right and wrong.
Further, the class gave me a scientific/conceptual framework, which provided a significant level of discipline into what is stereotyped as an artistic skill.
The course gave me the chance to test and evaluate myself outside the work environment.
Yet the ability to get feedback and actually debrief a negotiation is really powerful.
I considered myself rather self actualized, but some interesting things came to light.
I've received of course a lot of other feedback.
One piece that comes to mind was a student in a class who was actually in one of my executive classes.
Who headed labor relations for one of the largest companies in the world.
And he liked this approach so much that when he prepared for his labor negotiations, he created what he called a huddle.
They did simulations such as the one you're going to do, and then they use the same feedback mechanism.
Let's take a look at the course format.
So, here's the basic format.
You're going to be watching a series of videos that last 5 to 20 minutes.
I know you're very busy people, and you can't sit down and watch, let's say a two and a half video in one chunk.
So you can watch these short segments.
You can do exercises while you watch the segments.
They are also very interactive.
I will frequently ask you questions as I do in class, and what you might want to do when I ask you a question, hit pause, write down your answer, think about it of course, write down your answer, and then we'll discuss the solution.
You can watch these segments weekly, which I recommend, but if necessary you can also binge watch.
In the way you watch Breaking Bad or House of Cards or Game of Thrones.
There are suggested readings for the course.
However, the primary learning mechanism in the course will be the videos.
And actually what I suggest is doing the readings after the videos.
So you don't have to take a lot of notes in the course, but recommend that you save the readings and that you also use the readings for future negotiations.
These readings will be structured as a game plan that should be very useful to you in your future negotiations.
Because this is a short course, because you have a chance to participate in this final negotiation I hope that each and every one of you complete the course.
And at the end of the course if you're interested you can take an exam that we'll test your negotiation literacy.
And I, again, look forward to working with you in this course.
My name is George Siedel.
I'm a professor at the Ross School of Business at the University of Michigan.
Welcome to our course on successful negotiation.
This session and way to provide a course overview.
So let's start with the goal of the course.
We negotiate with our friends, our spouses, our parents, our children.
We negotiate when we rent an apartment, when we buy a car, when we buy a house, or when we apply for a job.
Negotiation is also the key to business success.
No business can survive without profitable contracts.
And negotiation skills are important to your career advancement.
My goal in this course is simple.
I wanna help you become a successful negotiator in your personal life.
I live and work in a state called Michigan.
For those of you are from outside of the United States, and perhaps unfamiliar with the geography, you might know where Chicago is located.
Right in the center of America.
And Michigan is due east from Chicago.
I was born south of the border in a state called Ohio.
I spent the first 18 years of my life on a farm in Ohio.
I finally escaped from the farm and went to a small college down the road called the College of Wooster.
I didn't even have to turn to get from the farm to the college.
I'd drove out the driveway, turned right on FDR 6, drove for 30 miles, and there was the College of Wooster.
After graduating from college, I attended law school at the University of Michigan.
And then I received a scholarship to do research at Cambridge University.
After completing my research I returned to the states, I practiced law for a couple of years, and then began my teaching career.
And I spent most of my career in Ann Arbor, Michigan at the University of Michigan although I have been a visiting professor at Harvard University, Stanford University, and I've gone back to Cambridge three times as a visiting fellow.
During my career I've been fortunate to have two unusual opportunities.
First, I've had the opportunity to teach and lecture on negotiation in Europe, Asia, North America, South America, Australia, and Africa.
For example, I currently teach annual courses in Italy and Eastern Europe.
And for many years I taught an annual seminar in Hong Kong.
I've also had the opportunity to teach negotiation to undergraduates, MBA students, business leaders, lawyers, athletic directors, physicians, judges and entrepreneurs.
And I mentioned this because this course draws on my experience in two ways.
Now I should mention one other aspect of my background, it's a little bit embarrassing and I have never disclosed this publicly.
So you are the first to know.
My daughter recently purchased a DNA kit for me that enabled me to trace my ancestry.
And what I discovered is that part of my ancestry is based in the British Isles.
That's my mother's side.
The name Siedel comes from Alsace, which is a part of France and it's been kicked back and forth between France and Germany over the years.
I knew that.
But what I didn't discover, and I didn't know until this DNA test, is that I am also 3.1% Neanderthal.
Now my friends and relatives probably realized that all along from my behaviors, but this was the first time that I learned about this type of my background.
And so as former Neanderthals, we have to address our Neanderthal heritage, which is based on the flight or fight response.
We either fight the tiger or we flee.
Today, when we are confronted with a difficult negotiation, when we're confronted with a car salesman, we have the same tendency.
We're fearful, we wanna flee, or we fight, and one of the goals in this course is to give you the skills and strategies that us fellow Neanderthals need to overcome our common heritage.
Let's now take a look at the course game plan.
And this is the big picture, what we'll be covering in the course.
And then I'm going to give you an introduction to the University of Michigan.
If you're from outside the United States, this segment might be of interest because it will also give you an insider's view of what a major university looks like.
But if you're not interested in that segment, you can jump right to the course material.
And the heart of the course focuses on the four stage negotiation process.
In other words we deal sequentially with the issues that you face in a real negotiation.
How do you conduct a negotiation analysis?
How do you incorporate into your analysis your BATNA?
Then we move onto the second unit on negotiating and the tactics that you can use for success.
In this unit we'll look at the source of power in a negotiation and how you can increase your power.
We'll also look at psychological tools that are very effective in negotiation.
These tools also represent traps when used by the other side.
So you have to be prepared to avoid the traps.
Then we'll look at closing the deal and creating a contract.
Basically we'll look at the legal framework for negotiation.
For example you should be able to address this question; if a company makes a job offer to you what are the legal dangers in making a counter offer?
And then finally we'll look at performance, and we'll look at especially some processes that you can use when you face difficulties with performance.
So after covering that process, you'll then have a chance to practice your negotiation skills with a negation called The House on Elm Street.
And with this negotiation you will find a partner and you'll negotiate The House on Elm Street one-on-one with this person.
And then at the conclusion of the negotiation, you'll receive feedback from the other side.
What do you do well as a negotiator?
How can you improve as a negotiator?
This feedback from the other side is one of the unique features of this course that you never obtain in real life.
In real life, when you finish a negotiation, the other side never sits down with you and says to you, well, you know you did a pretty good job in this negotiation, but if you had done this, this, and this you could have done a lot better.
My former students frequently send me emails telling me about the value of this feedback.
Let me give you a couple of examples.
Here's one.
The email says, negotiation is a fundamental skill we need to learn how to use.
I was a bit hesitant to join the class as I thought I had excellent negotiation skills.
However, I soon realized there was a lot to learn.
The key difference is that in class I got feedback and know what I did right and wrong.
Further, the class gave me a scientific/conceptual framework, which provided a significant level of discipline into what is stereotyped as an artistic skill.
The course gave me the chance to test and evaluate myself outside the work environment.
Yet the ability to get feedback and actually debrief a negotiation is really powerful.
I considered myself rather self actualized, but some interesting things came to light.
I've received of course a lot of other feedback.
One piece that comes to mind was a student in a class who was actually in one of my executive classes.
Who headed labor relations for one of the largest companies in the world.
And he liked this approach so much that when he prepared for his labor negotiations, he created what he called a huddle.
They did simulations such as the one you're going to do, and then they use the same feedback mechanism.
Let's take a look at the course format.
So, here's the basic format.
You're going to be watching a series of videos that last 5 to 20 minutes.
I know you're very busy people, and you can't sit down and watch, let's say a two and a half video in one chunk.
So you can watch these short segments.
You can do exercises while you watch the segments.
They are also very interactive.
I will frequently ask you questions as I do in class, and what you might want to do when I ask you a question, hit pause, write down your answer, think about it of course, write down your answer, and then we'll discuss the solution.
You can watch these segments weekly, which I recommend, but if necessary you can also binge watch.
In the way you watch Breaking Bad or House of Cards or Game of Thrones.
There are suggested readings for the course.
However, the primary learning mechanism in the course will be the videos.
And actually what I suggest is doing the readings after the videos.
So you don't have to take a lot of notes in the course, but recommend that you save the readings and that you also use the readings for future negotiations.
These readings will be structured as a game plan that should be very useful to you in your future negotiations.
Because this is a short course, because you have a chance to participate in this final negotiation I hope that each and every one of you complete the course.
And at the end of the course if you're interested you can take an exam that we'll test your negotiation literacy.
And I, again, look forward to working with you in this course.
This course is based on courses that I teach at the University of Michigan, but before we dive into the course material, I'd like to give you a snapshot of the town where I live, which is Ann Arbor, Michigan.
The university and then the business school where I teach which is within the university.
This might be a greater interest to those of you from outside the United States whether you're from inside the US or outside the US, please feel free to skip this segment and move on to the, first unit on preparing for negotiation.
The town where I live Ann Arbor, Michigan, was founded in 1824.
Has a nickname of Tree Town.
It's a rather small town or you could even call it a small city with 116,000 residents.
We're a relatively fat town, 27% of us are obese, which probably is pretty similar to the rest of the United States.
We're an educated town, 70% of the people in Ann Arbor have a bachelor's degree or higher, and we're people on the search for a mate.
Almost 6 out of 10 people have never married in Ann Arbor, and generally we're pretty chilly.
We're in Michigan, which is in the northern part of the United States.
For those of you who are outside the United States, if you can picture Chicago, which is right in the center of the country, north central part of the country, Ann Arbor, Michigan is about a four hour drive east of Chicago.
We have a mixed population, you can see the demographics here and over 20% of the people in Ann Arbor speak a language other than English in the home.
This is important to consider later in the course when we talk about cross cultural negotiation.
Often we think cross cultural means cross country, but in fact in a country like the United States and many other countries of the world, there's a diversity of cultures even within a country and that raises cross cultural considerations.
You can see here that about one third of the population of Ann Arbor is affiliated with the religious congregation and you can see the mix, the top six religions represented by this one third of the population.
Here's a number of rankings related to Ann Arbor Michigan.
You can see it's one of the most highly rated college towns.
Number one best city for singles, but it's number two also among the great cities for raising families.
It's a healthy, smart, digital, educated community, according to these various rankings.
On the left is a night scene of the city.
That's a picture of the farmers market in the center.
And a major art fair in the summer, which is the picture on the right.
I mentioned earlier that Ann Arbor is called Tree Town and you can see why from this picture.
A lot of trees in the city which are spectacular in the fall with various colors, red, oranges and greens.
A big splash of color on the horizon in the fall.
Now the University of Michigan is a major employer within the city of Ann Arbor.
You can see here that the university was founded in 1817, and currently has three campuses.
But there are also campuses in Dearborn and Flint.
60,000 students that come from all 50 states and 122 countries.
Most of the students 43,000 are on the Ann Arbor Campus, and 28,000 of the 43,000 are undergrads.
There is one faculty member for every 16 students, and the campus has grown from its original 1,920 acres to 21,157 acres.
This is a major operation.
If the University of Michigan were a corporation we would rank among the largest in the world.
Within operating budget of over $6 billion we receive $300 million in state support.
Now, for, for those of you from outside the U.S., you might not be familiar with the distinction that we make in the U.S.
Michigan is considered a state university because we receive support from the state.
But as you can see here, the amount of support is relatively small compared to the overall budget.
$300 million out of a $6 billion budget, which would be around 5% of that overall budget.
So we're, we're grateful for the state's support but it's a small percentage.
We spend a lot of money on research at the University of Michigan, over $1 billion.
And we're usually ranked number one or two in the United States in terms of research expenditures.
We have singers, such as Madonna.
We have, people talented in the arts, such as the playwright Arthur Miller, and people who are very successful in business, among those is Larry Page, the co-founder of Google.
Of course, there are many rankings, this is one of the rankings we like better than some of the others.
Here is some pictures of the University of Michigan.
And they succeeded spectacularly with the law quad.
Hear is the football stadium.
At Michigan, we don't have a school of theology.
Instead some say the religion might be football.
It's the largest football stadium in America.
So the city if very quiet on a football afternoon when the stadium is packed with a 114,000 fans.
Let's move on then to the business school within the university, which is where I teach.
Founded in 1923 with a very good faculty student ratio, 15 faculty and 26 students.
Today that has expanded to over 3000 students, 126 full time faculty who teach in eight areas.
When we look at these areas, they represent the key functions in any successful business.
Seven of the eight are business functions.
The eighth one, which is Business Economics & Public Policy, is a key discipline, a key foundation that our students need in order to perform well in business.
We have several Master's programs ranging from the full-time MBA to global to part-time.
We have Masters in Accounting, Supply Chain Management, Entrepreneurship and a general one year Master of Management program.
This will give you a flavor for the kinds of students who walk around the Ross Business School.
We admit 450 MBAs to our full-time program every year.
Average age 28.
We want people who had business experience.
I think the educational experience is more valuable when they do have this experience.
Just to give you a sample of what my class looks like, my negotiation course at Ross, the last time I taught the course 50% of the students were from outside the US.
And 50% from within the U.S.
This is what the MBAs do after graduation.
Over a third of them go into consulting.
Marketing is very popular.
And then followed by general management strategy and operations.
In 2013, the median starting salary was a 112,000 but that does not include starting bonuses.
On the undergraduate side, the US News and World Report does a ranking of BBA programs, and Michigan is tied for second with MIT and Berkeley, after Wharton.
On the MBA side, a magazine called Business Week began ranking schools 25 years ago.
They were really the founders of the ranking business.
And four schools have appeared in the top 10 in their rankings every ranking over the last 25 years.
You can see the listed here Harvard, Northwestern, Michigan and Wharton.
So here's a picture of where I teach, the Ross School of Business.
We named the Ross School after Steven Ross, a very successful graduate of the Ross School who was successful in real estate development.
A few years ago he wrote a check to the school for $100 million, which allowed us to build this building.
And more recently he wrote another check for another $100 million to help us renovate some of the other buildings on campus.
So that's our snapshot look at the city of Ann Arbor, the University of Michigan within the city, and then the Ross Business School within the University of Michigan.
We're now ready to begin our look at the four stage negotiation process, and we begin with preparing for a negotiation, planning your negotiation strategy.
Most people when they think of negotiation and when they take negotiation courses, focus on the second stage which is actually negotiating being in the room with another person, arguing, trying to persuade that other person.
Often the analogy is two gunfighters in the room, seeing who can draw the fastest, who has the best tools and techniques for persuading somebody else to do what you want.
And of course that's an important part of negotiation, but equally important and perhaps more important is first of all, how you prepare for a negotiation.
And then, after you've reached an agreement, how you bring that agreement to closure through forming a contract and then finally, how you perform the contract.
And they'll respond yes, I, I got the price I wanted or I got the quantity, and the quality of grids that I wanted from the supplier.
The question should be, were you successful with performance of the contract?
So we're going to take a very holistic view, of the negotiation process.
Specifically we're going to ask these seven questions.
And we start with a preliminary question, the people don't often think about.
Here's a depiction a simple depiction of your question, yes or no.
Now In my courses at the University of Michigan, I ask my students to do a real life negotiation.
Where they do into the, into the city of Ann Arbor, they walk into retail stores, they walk into restaurants, they might walk into for instance a McDonalds.
And their assignment is to try to negotiate a lower price, on what they are purchasing.
Now I want you to estimate how many students, what percentage of my students do you think are successful, in this attempt to negotiate a lower price?
Do you think you would be succesful, if you went into a retail establishment.
Please write down on a piece of paper what percentage of my students do you think are successful in negotiating a lower price.
Well you can see here 69% of the class, was successful.
The 100% included students who, for example, negotiated for a free cup of coffee or a free breakfast.
The average discount was 40% and you can see here the total savings in the class was over $1,500.
Now, in performing these negotiations students used a variety of strategies.
They used a BATNA strategy, stretch goals, relationship building.
These are all strategies that we're going to cover in this course, and you're going to be very well versed in how to use these strategies.
Let, let me give you an example of the unconventional strategies, used by one of the students.
So he went in to a sushi restaurant and he arrived late at night, five minutes before the restaurant was going to close, realizing that the restaurant had already prepared what are called bento boxes, which are little boxes of sushi and other Japanese food.
And realizing that the restaurant might want to get rid of them at that time of the night.
Before he walked into the negotiation, he put a $20 bill in one of his pockets and a $10 bill in the other pocket, so that he could argue depending on the, on the amount that was being negotiated he could pull out the twenty or the ten and say this is all the money I have.
So he pled poverty, he stretched the truth a little bit.
He used timing, and then finally he used sympathy.uh, he told the person running the sushi restaurant that he had three hungry children at home and they loved sushi.
End result he negotiated a 50% discount, off of the normal price of the, bento boxes that he bought he saved around $50 from this negotiation.
And, we're going to get to stretching the truth later, in the course when we talk about ethics and some ethical standards that you, should use in negotiation.
How did my students feel about this experience?
Well as you can guess there was a mixed bag of feelings.
Many students felt about this experience, the way that many people feel about negotiation in general.
Some people are simply uncomfortable with negotiating in any situation, or they're embarrassed.
And others enjoyed the experience and in fact.
Some students enjoy this experience so much, that they continue to engage in this type of experience following the course and they will send me emails about their negotiating experiences.
Here's an example received an email from a student who had settled in San Francisco and this is what he said in the email.
Professor Sidell, just wanted to alert you that the negotiation skills I picked up in your class, saved me $130 per month on an apartment in San Francisco.
Every penny counts but, they failed to win me a free desert at a restaurant last night I'll keep trying.
Here's another example, a student who sent me a message about a good news and bad news he had with his negotiating experience.
The good news was he said I tremendously enjoyed the tactics, especially for hotels.
I always get a big discount and I frequently found I don't have a big enough stretch core, so that was a good news the bad news is my wife wont go with me anymore to the front desk.
And here's an inter, international example a student I taught in Europe.
Her father refused to deal with the negot, with the mafia, and she wanted to test out here negotiation skills, she negotiated with the mafia and successfully got her father's car back.
Now if you decide to negotiate there are some factors to consider.
What do you think about this situation?
Here we have a negotiation professor, in fact one of the top negotiation professors in the country.
Buying a big screen TV, he does lots of research on different models and on dealer costs.
He visits several dealers, and he packages, he bundles the price of the TV with installation, satellite dish and other features.
Now, what do you think about this?
Would you call this a successful negotiation or not?
Here's somebody who went down the path of negotiation, he decided to negotiate but should he have negotiated?
Whether you call this successful or not, depends a little bit on your personality.
But what happened, the aftermath of this case was, he went home, he proudly announced to his wife that he had saved $120.
How much time did you spend on this negotiation, he thought for a second, he said well, 20 hours.
And she said, is your time really worth $6 an hour?
So, I think we all have to make this kind of decision, in deciding whether to negotiate.
Some people love to negotiate, some people have no problem with this.
Other people might ask, is this the way we want to spend our brief time on Earth?
Do we want to, spend time engaged in negotiations like this, or we'd rather spend time with our family and friends.
If you enjoy this, if this, is what turns you on, then, I would call this a success because you enjoy it.
But, but I think it's also important to think of the cost and the benefits.
Especially the costs in pulling you away from other opportunities.
Here's one final example of somebody who, decided to negotiate.
This, this happened very recently, and created quite a buzz in the United States.
We have a, college offering a job to a professor, and she replies by e-mail, granting some of the following provisions would make my decision whether to accept your job offer easier.
Let me know what you think for example, she wondered if they would consider a higher salary, and she wondered if they would consider no more than three new class preparations per year for the first three years.
Now, later on in the course, we're going to talk about contract negotiations and whether the search committee in this case, for example, could legally withdraw the job offer after it was made.
But, here's another factor in considering whether or not to negotiate you have to consider the risks, and balance those against the benefits.
So bottom line, in answering this first preliminary question, should I negotiate?
You have to consider not only your feelings about negotiating in general, but also the risks as illustrate by the professor case, and do a cost benefit analysis of the rewards as illustrated by the TV negotiation.
So that concludes our look at the first question of whether you should negotiate at all, before you dive into additional preparation.
Probably takes up more time than any other aspect of the whole negotiation process.
And there's seven key questions to ask.
And we're now at question number 2, which is to try to step back from the negotiation and decide whether the negotiation is a position-based negotiation or an interest-based negotiation.
So, in other words, once you get on this path of, yes, you're gonna negotiate, your next question is, is it position-based or interest-based.
Traditionally, negotiations were very much positional.
I take one position.
You take the other position, low price.
And then we fight over whether the price is a high price or low price or maybe something in the middle.
Sometimes people confuse positional negotiation with being happy or not.
And I want the pizza and you want the pizza, so we each have a position.
Well, as any parent knows, one possibility is to ask you to cut the pizza in half and then I get to pick which half I want, and we might leave that negotiation feeling very pleased or happy.
I've talked with people from very large corporations, from consulting firms, who work with these companies on negotiation.
And basically they think of win-win negotiation as each side leaving happy.
And in Getting to Yes, the authors emphasized moving beyond positions and trying to ask what are the underlying interests that the people negotiating are interested in.
In other words, don't ask somebody else what do you want, what's your position.
Instead ask, why do you want it, what is your underlying interest.
And so in the pizza negotiation, let's say that, for instance, we're negotiating over anchovy pizza.
And, again, a positional result might be to cut the pizza in half and the person, one person cuts, the other person chooses.
With an interest-based negotiation, we would ask both sides, why do you want the pizza.
So if I asked you why you want the pizza, maybe it's because you love the anchovies that are on the pizza.
But as it turns out, you just want the center of the pizza, you don't want the crust.
You ask me, why do I want the pizza.
I've seen some great recipes, by the way, for this pizza crust addition to pasta.
Doesn't sound especially good to me, but I know it's very popular.
But by asking why, by identifying the interests, we've created a real win-win situation, because I get what I want without taking away what you want.
Now, this gets a little complicated when you start with this basic strategy, one side dividing the pizza, that's positional bargaining, the other side trying to build a larger pie.
On the surface, that looks simple.
There are two types of negotiation.
But it gets complicated because of the terminology used by negotiators, by teachers, and in negotiation books.
For example, dividing the pie is often referred to by academics as distributive negotiation.
You're taking the fixed pie and distributing the pieces of the pie versus enlarging the pie, which is called integrative negotiation, where you try to find the interest of the parties, integrate those interests and build a larger pie.
Dividing is sometimes referred to as competitive as opposed to cooperative.
Win-lose versus win-win.
And so somehow you have to cut through all this verbiage and keep in mind the central issue, which is what type of negotiation am I involved with, is it dividing the pie or enlarging the pie, and that will help shape your strategy.
If it's a negotiation that creates opportunities for building a larger pizza, then you'll want to spend a lot more time searching for mutual interests that enable you to do this.
Another group of people, often very experienced businesspeople, say, well, you know, that's interesting.
There's no harm in searching for underlying interests.
But in most negotiations, it's simply a waste of time.
How can I build a larger pie when I'm selling you my car and we're fighting over price?
How can I build a larger pie when I'm a manufacturer and I'm selling goods and I want a high price and you want to pay a low price?
They argue that most negotiations are positional negotiations.
So, again, two groups, one group very enthusiastic about interest-based negotiation, the other group very skeptical.
I would argue that both are right, because with any negotiation you're probably going to start from a position.
You should always ask, why do you want what you're requesting, what's the reason for your position.
So bottom line, I think both sides are correct, and I think that the key takeaway here is, regardless or whether a negotiation appears to be position-based or interest-based, always try to search for the underlying interests in an attempt to build a larger pie.
But always be ready for positional bargaining, even when you are able to build a larger pie.
So that concludes our look at this very important question of determining at the outset whether the negotiation is position-based or interest-based.
So in other words, once you've decided to go down the path of yes, you're gonna to negotiate.
It's important to step back and ask, am I negotiating the resolution of a dispute or am I making a deal?
Frank Sander by the way, is one of the fathers of alternative dispute resolution, ADR which we're gonna be talking about in a few minutes.
He's a friend of mine who teaches at the Harvard Law School.
In fact, he invited me to teach for a week in his course once and that he's a true pioneer in the field of dispute resolution.
And Frank and Jeff in their article, clearly noted that when you're making a deal, you tend to be forward looking.
It's the face of the Roman God Janus that's looking to the future.
Where as if you're the face of the God Janus looking toward the past and trying to resolve a dispute, you're looking backward, you're more positional and the negotiations tend to be more adversarial.
So it's very important from the outset to think about this distinction.
However, even when you're dealing with the dispute resolution negotiation, you should be thinking, how can I focus on the interests of the parties to make a larger pie to develop a solution that benefits both sides?
So basically, it was an intellectual property dispute and a very contentious dispute.
Well, what many students discovered in wrestling with this dispute, is that, actually there was an opportunity for the licensee and the software company to form a joint venture, which was beneficial to both sides.
And so, even though you're in the dispute resolution side, try to think of opportunities for an interest-based negotiation.
Now, if you are on the dispute side, you're trying to resolve a dispute.
Here's an example of a recent dispute at my university.
Students at my university love basketball and when there's an important game, they will wait in line for many hours to try to obtain tickets.
And so, recently on a February morning, a line of students developed, they began forming the line at 4:00 AM in the morning, on a very cold morning.
Around 7:00 AM, another line of students developed and there was an argument as to which line was in the right place.
They had to call in University Police.
Here's the basic scenario, 4:00 AM, the students began forming the line, 7:00 AM other students formed a second line.
And my question to you is, when we have this type of dispute, what processes do we as human beings use to resolve this type of dispute?
Think about this for a second and write down a list of processes that might be possible for resolving this dispute or any dispute, any personal dispute or any business dispute.
Here's a spectrum showing the six main processes.
You can start on the right hand side, Avoidance.
One line of students might simply say to the other line of students, okay, you win.
That's avoidance.
The second of course, is Negotiation.
Which is used for both deal making and dispute resolution.
A mediation is a negotiation, but it is a negotiation assisted by a third party.
A fourth possibility is Arbitration.
Bringing in a third party, but in this case the third party has the right to decide the dispute.
So arbitration and litigation are very similar.
And later in this course, we're gonna look at them in more details, especially arbitration.
I'll show you a video clip of an arbitration.
But for now, think of arbitration as simply a private form of litigation.
The students could begin fighting with each other, pushing back and forth to determine who would be at the head of the line.
In this particular case, what happened is that they used a combination of mediation and arbitration.
First of all, the police came in.
And as arbitrators, ordered the students from one line, the students waiting since 4 o'clock, to the back of the other line.
Then, a representative of the athletic department came out, and acted as a mediator trying to mediate a resolution and actually came up with some additional tickets to satisfy both sides.
And in the following day the students met in a negotiation to prevent this from happening again.
So, they actually used three processes in resolving this dispute.
Now, you can look at these dispute resolution processes through a variety of lenses.
And let's take a look at three of those lenses.
The first of which is called alternative dispute resolution, or shorthand is ADR.
Several years ago, people in business began to become concerned about the high cost of litigation.
And they started to ask this question.
Why is it that when we are involved in a business dispute, we outsource the dispute to lawyers and to the legal system?
We have the business skills to resolve disputes.
Why aren't we using those skills?
And so they started to develop alternatives to litigation.
I remember when this happened in the mid 80s, because the CEO of a large corporation called Citicorp called in a group of us from 10 leading business schools for lunch.
We had a long lunch and a long meeting.
He said why aren't you teaching ADR in business schools?
In terms of time and money to businesses, you should be teaching future business leaders how to use ADR.
And the ten of us went back to our campuses and we began developing courses on negotiating and dispute resolution.
So my question for you is, look at this spectrum.
Which of these processes would you call alternatives to litigation?
Litigation is the enemy.
And the alternatives you should have written down are arbitration, mediation and negotiation.
And we're going to explore these later in the course.
And I'm going to give you some tools that you can use for avoiding litigation later on.
A second lens that you can use in looking at the spectrum of processes is the so called third party lens.
When you read the newspaper, often you'll read that a business was involved in a dispute, or in litigation, and they used a third party process to resolve the dispute.
Which of these processes would you call third party processes?
The third party is a judge, arbitration, which involves bringing in an arbitrator.
And mediation, which is assisted negotiation where a mediator helps the parties resolve the dispute.
Now, in thinking about these third party processes, you can think about your external disputes.
But, there are also internal third party processes where you as a manager or as a leader in a company will play the role of an arbitrator or a mediator in resolving a dispute.
And so later when we look at a film clip of the mediation you will see some techniques and tools that you can use as a business leader for resolving disputes within your company.
The third lens I'd like to look at is an academic lens called power, rights, and interests.
Of course, power is obvious, but which of these processes relate to rights?
That is to determine who's right and wrong.
And which of these processes relate to finding the underlying interests of the parties and trying to build something that benefits both sides?
Think about that for a second, write down your answer.
Where the judge or arbitrator decides who's right or wrong usually based on a legal rule.
Again, mediation is simply a form of negotiation assisted by a third party.
Now, even though this is an academic construct, power, rights of interest, I personally think it's a very practical tool for giving you options when you are faced with a dispute.
And in fact, some companies use this as a tool.
Here's an example, I won't identify the company but its from an internal company document and I paraphrase, but what they say in the document, if you were involved in a dispute involving our company, here are your choices.
You can force the other side to do what we want.
We're powerful and regardless of whether we're right or wrong we can force them to do what we want.
Second, we can try a rights option.
We can go to a judge or an arbitrator who will decide who is right or wrong.
Third, we can use avoidance.
Let's say we're in a dispute with a key customer and we don't want to lose the customer.
Even though we're sure we're right, we'll let them have what they want.
And then finally there's the interest option, try to negotiate an agreement based on our needs.
So, those are the three lenses.
All of these processes can be used for resolving disputes.
But what if you're doing a deal?
Whereas the other processes relate to dispute resolution.
However, there has been a major change over the last decade, where some of these processes such as arbitration and mediation are used for deal making as well as for dispute resolution.
And I'll give you some detail examples later in the course.
A few years ago, I was teaching a negotiation course in Hong Kong and one of the participants came up to me during a coffee break.
The power company wanted to purchase gas, basically.
And they have been negotiating for months and they were stalled, they were not making any progress.
And so he wanted my advice on how to move things forward.
Now i'm thinking to myself, now let me get this straight, you're a negotiation consultant, you're a professional consultant, you've been working on this for months, and you want me to solve this problem during a 15 minute coffee break.
That was my first thought, which I didn't say to the other person.
But then I started to ask this person a couple of questions.
That I'm sure you would ask, especially after you finish this course.
Second, have you explored all of your bad options.
Now that's not gonna mean anything to you right now, but it will shortly.
BATNA is a critical concept.
And his basic answer was yes, we've thoroughly looked at all BATNA possibilities.
And at that point, the light went on.
He had not thought about using arbitration or mediation for deal making, as opposed to dispute resolution.
And he left with that takeaway idea.
So we're gonna get into this in more detail later, but think of these two processes, arbitration and mediation, as useful not only for deal making, but also for dispute resolution.
So, in conclusion, we think about the distinctions between dispute resolution and deal making.
It's important to understand the six types of dispute resolution.
And the three lenses that you can use for looking at these types.
The ADR lens, the third party processes lens and the power/rights/interests lens.
And finally, consider using dispute resolution processes for deal making, such as mediation and arbitration.
We now continue our look at preparing for negotiation and planning your negotiation strategy by looking at an especially important question that will apply to.
How should I analyze a negotiation?
This question is so important that I'm breaking the discussion into three segments.
First of all, what questions should I ask to complete an analysis?
Second, what is my BATNA in a dispute resolution negotiation?
And finally, how can I use an especially valuable tool called a decision tree to complete a BATNA analysis, regardless of whether it's a dispute resolution negotiation or a deal-making negotiation.
So let's start with this first question.
What questions should I ask to complete a negotiation analysis?
In order to give a framework for our discussion, let's take this simple negotiation.
Pooja is the only person who responded to an ad that you posted a week ago.
You need at least 4,000 from the sale to finance the purchase of a truck that you have ordered.
You want to keep your car for three more weeks, which is when the truck will arrive.
You've done a lot of research on this.
If you can't find a buyer willing to pay at least 4,500, you'll sell the car to a friend, Tommaso for 4,000.
Now, what I'd like you to do is to hit pause, and think about this situation.
If this was you, what would be your strategy going into this negotiation with Pooja?
Just jot down a few points that you would use as your negotiation strategy.
When I ask my students this question, when I give them a negotiation similar to this and ask what is your strategy going into the negotiation?
Now there's nothing wrong with that.
In fact asking questions is very positive.
The problem is that, if that's your strategy, you have no way to measure the information that you are getting from Puja.
You need some kind of a framework for considering the answers that she gives you.
If you don't know where you're going, you might end up somewhere else.
A few years ago, I looked at the richest people in the world and tried to find out what their negotiation strategies are.
And what I discovered, a common theme among these rich people, Is they entered every negotiation knowing exactly where they wanted to be.
And if they didn't get it, they walked away.
So very important to have a framework for considering the information that you uncovered during a negotiation.
And what I would suggest is to focus on these key questions.
First of all, what's your overall goal in reaching the negotiated agreement with Pooja?
Second, what issues are most important to you in reaching that goal?
Try to get to the interest behind your position.
Third, and this one is especially important.
This is what gives you leverage.
This is how you can measure the agreement that you're developing with Pooja.
If that agreement the Pooja is willing to enter into with you is not as good as your best alternative, then walk away.
This is negotiation language for saying in this negotiation what's the lowest price?
What's a reasonable price that you would be happy with?
And then finally what is your stretch goal?
Now this last question is especially important because the negotiation research shows that the people who select the largest stretch goal.
Now because of a large stretch goal, they might lose out in individual negotiations but when you look at their overall results, they are most successful.
If that's true, then in this particular negotiation with Pooja.
You think that you might end up with $5,000 for the car.
What answer would you come up with to that question?
If stretch goals are so important, why not use a very large stretch goal such as 25,000.
And I think you'll immediately respond, well, if I do that, I don't have any factual basis for 25,000 and I'm going to lose credibility, Pooja is simply going to walk away.
And I think that's the risk.
You want to pick a large stretch goal.
I don't know if you've ever heard of an American athlete by the name of Michael Tyson.
I happened to be in Rome a few years ago, with my son and we walked by Evander and he's a very, very nice person.
And I asked if I could take a picture with my son and he graciously said yes.
I was tempted to say, Evander Holyfield can you turn your head a little bit so we can see the ear., but I didn't.
In any event Mike Tyson is known for that fight and Mike awhile ago bought a little place in Farmington Connecticut.
56,000 square feet, 18 bedrooms, 28 bathrooms.
He bought the house in 1997 for 2.7 million.
And the very next year, he put it on the market for 22 million.
And so, he tried to back track a little bit the following year.
Obviously, he had lost credibility with that huge stretch goal.
This is from an article in The Wall Street Journal Entitled no Bites on Tyson House.
Here's another example, a very sad story that was written up in a book called A Civil Action, which was later turned into a movie starring John Travolta.
And he sued two large companies.
At one point in the film, and in real life, they held a settlement meeting to try to negotiate a settlement to the lawsuits.
And at this meeting it was clear, as depicted in the movie, it was clear that the companies we'd probably settle the case for 25 million, however the attorney ratcheted up the demand to 320 million, huge stretch goal.
So basically the other attorneys ended up walking out of the settlement conference, they thought that was a ridiculous stretch goal.
And the end result was the case against one of the companies was dismissed.
The other company settled for $8 million, far less than probably what they would've paid initially and the attorney ended up filing for bankruptcy.
And of course, the parents were deprived of a larger settlement for their loss.
So those are examples of the impact of becoming too greedy with a large stretch goal.
So let's go back to the case involved Pooja and what I'd like you to do is to look at the facts in this case and try to answer the key questions that I posed earlier.
So please take a pencil and paper and let's go down the list of questions.
And the first one is what is your overall goal in the negotiation.
Second, what issues are most important to you?
And why are these issues important?
Third, what's your BATNA?
Very important question, often probably the very first question you always wanna ask in preparing for any negotiation.
What's your BATNA?
And finally what is your stretch goal?
Now you have data for all questions except for the last one, stretch goal and you're gonna have to be creative in coming up with the answer to that question.
So, again, these are the questions, and let's look at the answers to those questions, what's your overall goal?
What issues are important to you?
Price is an important issue and the reason is that you need the money to buy a truck.
The transfer date is important, because you need the car in the next 3 weeks.
What's your best alternative, what's your BATNA?
And stretch goal, probably a lot of variation here, but let's assume that the stretch goal is 6,000.
Now in answering those questions, it's often useful to try to diagram your answers.
So this is what your analysis might look like.
Now this is a critical part of the analysis, and you can complete this part fairly easily.
What becomes more difficult is trying to look at how this negotiation looks from the perspective of the other side.
This is the way a very famous negotiator put it.
I find it helpful to try to figure out in advance where the other person would like to end up.
At what point he will do the deal and still feel like he's coming away with something.
As we'll talk about later when we get to the psychology of negotiation, this is one of the landmarks of successful negotiators.
They always look at the deal from the perspective of the other side.
Now, of course, it's often difficult to obtain details of what the deal looks like from the other side.
You might have to guess before you go into the room and then.
Once you go into the negotiating room and start negotiating, you probably will want to revise your figures.
But let's say that the other side's figures look something like this.
Puja is willing to pay that much for the car.
Pooja thinks it probably should be able to get the car for 4500 and let's say her stretch goal is 3500.
She would like to get you to agree to a low price of 3500.
Z-O-P-A.
And that is when you look at these numbers, try to determine where the deal can take place between what number and what number.
Think about that for a second and write down the zone of potential agreement.
And the answer that you should've come up with is that the deal can take place between the two reservation prices.
In other words the price might be as low as $4500, which is the lowest price that you're willing to take as the seller, or it might be as high as $5500 which is the most that Pooja is willing to pay as the buyer.
This is Zone of Potential Agreement, the ZOPA.
Now a couple of years ago, I was teaching in Bulgaria to a group of students from pretty much around the world.
And there were three Russian students in the front row.
And we were talking about this concept of ZOPA and I explained to the class that it's really great if you can go into a negotiation where there is a very large zone of potential agreement.
And whenever I said this, the rest of the students began to laugh, so finally I had to stop and say, what's so funny about ZOPA?
That's one of the challenges in cross cultural teaching.
We've covered these in great detail.
These questions of course focus on the numbers.
And there are other issues that are likely to arise, and let's just conclude by a question about one of these other issues.
We determined earlier that an issue that was very important to you was the date of transfer.
You wanted to keep the car for three weeks.
So let's say you're negotiating with Pooja and you tell Pooja that this is one of your demands, no transfer until three weeks.
Now, think of how Pooja can respond to that demand.
Two basic responses.
First of all, maybe that delivery date is not important to Pooja at all.
She's going to use that as a bargaining chip.
She might pretend as though the issue is important, but it's just a bargaining tactic.
The other issue is, the other response from Pooja is that maybe this issue is very important to Pooja.
How can you respond?
Think about that for a second?
The way to analyze the standoff is you each have a position.
Your position is three weeks from now.
Her position is immediately.
Remember what to do when you're faced with positional bargaining.
Ask why?
Pooja, why do you need the car Immediately?
Her answer might be for example, well, I just started a new job and I need the car to get to work.
Well, once you focus on her interests, maybe you can think of ways to meet those interests.
Maybe you could even give her a ride to work.
Where does she live?
Is it close to where you live.
You might be able to meet her interests in a way that also match your interests.
So that concludes our look at this first phase of a negotiation analysis and we're now going to look at two other aspects of negotiation analysis.
We're now gonna continue with our analysis of a negotiation.
The analysis that you conduct in preparing for a negotiation.
And as I mentioned earlier there are three key questions.
We already talked about the cluster of questions you should ask to complete the analysis.
The second big question is, what is my BATNA when I'm involved in a dispute resolution negotiation?
So how is a dispute resolution negotiation different?
Please try to think about that for a second.
If you're involved in a dispute with somebody, what is the alternative if your negotiation fails?
In a dispute resolution negotiation, the ultimate BATNA might be litigation or an arbitration, which is basically private litigation.
And as a result, to analyze your litigation BATNA, especially in a global economy, you should understand some basic differences between the litigation process in the US and the litigation process in other countries.
Here are the key differences between litigation in the US and elsewhere.
In the United States, unlike many other countries, lawyers can be hired on a contingency fee basis.
And what that means is that the lawyer's fee is contingent on the results in the litigation.
Let's assume for example that you hire a lawyer on a 30% contingency.
If the lawyer wins $10 million in a lawsuit, the lawyer's fee is 30% of the 10 million, or $3 million.
If the lawyer loses the lawsuit, then the lawyer's fee is 30% of zero.
The lawyer does not get paid.
In the US, class actions have long been used in certain types of cases.
It's not worth it.
But let's assume that the company has overcharged 30 million customers.
Now 30 million customers can join together in a class, and sue the company for the 30 million.
Guess who's the big winner in a class action?
The lawyers might take, let's say one-third of the 30 million, $10 million.
The other two-thirds might go to the customers.
So I would end up with two-thirds of a dollar or $0.66, or perhaps a coupon to buy products from the company that cheated me in the first place.
Third feature of the US legal system, it's quite different from elsewhere, is discovery.
There are a number of tools that lawyers can use to discover what kind of a case the other side has, and two of these are especially important.
One is document discovery, where lawyers can sweep into your business, or if it's personal litigation, they can uncover personal documents and examine those documents and use them in court.
Every time you create a document, every time you use email, every time you text, use voice mail, all of those are subject to discovery.
You always have to be thinking about the potential for litigation as a result of the information you create.
That's one form of discovery.
The other very popular form of discovery is the deposition, where the opposing attorneys will force you to testify under oath before a court reporter, and that's a very effective way for them to gain information about the litigation.
If you're interested in seeing what a deposition looks like, I have a link here to a YouTube deposition of the president of a healthcare system, and he is being questioned about the pricing used in one of his hospitals.
I highly recommend that you look at this deposition for a flavor of what goes on, and try to put yourself into the CEO's position.
How would you deal with the questions raised by the opposing attorney?
It only takes about five or six minutes, but highly worthwhile.
A number of other countries use jury trials in criminal cases.
The US is one of a very few countries that use jury trials in civil cases, for example, business litigation.
In every country in the world, if you injure me, and I sue you, I can recover what are called compensatory damages, damages to compensate me for my loss.
However, in the US, if your injury was caused by conduct that was malicious or intentional, then the court might tack on punitive damages to punish you for your outrageous conduct.
This is sort of like a criminal fine in other countries.
The difference is that the criminal fine goes to me, unless there's a local law that provides it should go elsewhere.
And finally, in the United States, there is the so called American Rule regarding attorney's fees.
And that rule provides that even if I win my case, you do not have to pay my attorney's fees.
Which provides that if you lose your case, then you have to pay the winner's attorney's fees.
So those are the six key features, the six key distinctions between the US and other countries.
When you look at combinations of these features you can see why litigation might be more popular in the US than in other countries.
B immediately goes to court and has the case dismissed.
So what does A have to pay, A the loser, have to pay his own attorney under the contingency fee?
What does plaintiff A have to pay to cover attorney B's fees under the American rule?
So in other words, there's a very low barrier to entry into the US legal system, when you look at the contingency fee system in combination with the so-called American rule.
So that lays out the basic distinctions between the US and elsewhere that you need to think about in looking at your BATNA in a dispute resolution.
So here's the situation.
We've got a grandfather driving a Dodge Caravan with a friend sitting in the passenger's side.
His daughter's in the backseat with his eight month old grandson Jason, who's sitting in a car seat.
A pickup truck speeding 70 miles an hour in a 35 mile an hour zone crashes into the rear-end of the Dodge Caravan.
The passenger side seat in the front collapses back on top of baby Joshua, killing the baby.
So those are the facts, and now we have litigation started by Joshua's parents.
That isn't required, but that's typical for a case like this.
And in their case they asked for punitive damages, a second feature of the US system.
Daimler Chrysler failed to warn consumers the seats were dangerous and therefore, the company should be liable for compensatory damages to compensate for the loss.
So after starting the lawsuit, then the company has a chance to respond, and they basically said look, our seats were designed to protect occupants of the front seat.
We couldn't avoid the design we used.
Now other countries, as well as the US, use discovery, but the United States is more liberal in allowing the parties into the records of other companies in searching for evidence.
So in this case, the parents' attorneys searched the company's records, and developed this evidence.
First of all, they found an expert who testified that the current seat design was not necessary to protect occupants of the front seat, as the company claimed.
And they found evidence that the company knew of their seat design problems for 20 years.
And the team concluded that the seat design was unacceptable and inadequate to protect consumers.
So what did the company do?
They ordered the chair of the leadership team to destroy the minutes, and they disbanded the leadership team and fired the chair.
So this is the evidence that then went to the jury, another feature of the US legal system.
Did they do something wrong?
Number two, should they also be held liable for punitive damages to punish the company for conduct that was intentional, malicious, or reckless, especially if they knew of the design problem and didn't correct it?
And then, how much would you reward in punitive damages?
So let's assume you're sitting on the jury.
You know the facts, the same facts that the jury had.
Please write down your answers to these three questions.
Yes or no?
Do you think the company should also be held liable for punitive damages?
Yes or no?
And then if you were on the jury, how much would you award in punitive damages?
The jury decided that the company and the pickup driver who rear-ended the Dodge Caravan should be liable for $5 million In compensatory damages, 50% each for the wrongful death.
And in addition, the company should write a check for $98 million to the parents as punitive damages.
After the jury verdict, the trial court reduced the punitive damages from $98 million to $13 million because of the very large discrepancy between the actual damages and the punitive damages.
And then the case was appealed to the Tennessee Supreme Court.
So this illustrates various features of the US legal system that you need to consider, at least in the United States, when analyzing your BATNA.
So in conclusion, if you can't negotiate the settlement of a dispute, either directly or with the help of a mediator, your BATNA might be litigation or arbitration.
And in analyzing your litigation BATNA, especially in a global economy, you should understand the basic elements of the litigation process and how they differ, especially the difference between the United States and other countries.
We looked at a list of questions that you should ask in completing any analysis.
We then looked at a specific problem that arises with dispute resolution negotiation.
And that is, that your BATNA often is litigation or perhaps arbitration.
And therefore it's important to understand what goes on in a litigation and some fundamental differences in a global economy between US style litigation and elsewhere.
Now we're dealing with a final question relating to analysis of a negotiation.
And that is, how can I use decision trees to complete my BATNA analysis?
A decision tree is a very useful tool in doing the BATNA analysis and beyond.
It's, it's a very useful tool for making all sorts of business decisions.
So I hope that this segment will be useful to you.
Not only in negotiation, but also in other aspects of your personal life or your business life.
So let's start with this example.
This happens to be a dispute resolution example, but I'll look at a deal making example in a few minutes.
Let's say your company has sued a supplier for $4.6 million.
There's a 50-50 chance your company will win.
Future legal and other expenses to litigate the case total $400,000.
During negotiations, the defendant has offered to settle the case for two million.
Should your company accept the offer?
Now think about that for a second.
If you use pure logic in answering that question, you didn't use emotion.
Would it make sense for you to accept the $2 million offer or to continue on with your litigation where you might win $4.6 million?
Okay, write down your answer.
Now, let's look at how you can analyse this question by using a decision tree.
And the decision in a decision tree is represented by a square or rectangle.
So we have here, the decision is do you continue with the litigation or do you settle?
And the uncertainty is if you continue, will you win or lose?
So you start your decision tree analysis with step one by drawing a picture of the decision.
And this is a very useful tool even if you never add numbers.
I use this tool constantly.
But in this case, we're going further than this.
If you win, you will net $4.2 million after deducting attorney's fees.
If you lose, you lose $400,000.
So in this case, 50% of 4.2 is 2.1 minus 50% of 400,000.
And you can see here that's less than accepting the settlement offer.
So this gives you a nice tool for analyzing your BATNA in a dispute resolution type negotiation such as this.
Decision tree analysis is also a very useful tool for doing a BATNA analysis when you're involved in negotiating a deal.
Let's assume that you're making a decision.
Should you acquire Company A, which has a $21 million value, or Company B which has a $15 million value.
The price is the same for both companies.
Now if you stopped there, the decision would be easy.
Of course you would acquire Company A if the price is the same as for Company B, because of the different valuation.
However, the problem is that if you acquire Company A, there's a 90% chance the government will challenge the acquisition, and a 60% chance the government will win.
If the government wins, a value of A drops to 14 million because of legal fees plus sell-off costs.
Even if the government loses, the value drops to 19 million because of legal fees.
Where as if you acquire company B, there's not going to be a government challenge, we know that.
So before you do a decision tree analysis, what would be your gut reaction?
What, what does your intuition tell you about this decision?
Please write down A or B.
When I ask this question in class, a large majority of the class usually picks company B.
Now let's try a decision tree analysis of the same decision.
So you know now how to do a decision tree analysis.
Remember the decision is the square and the uncertainties are represented by circles.
Plug in the numbers and calculate the weighted average.
Please hit Pause while you do this, and then we'll compare results.
This is what my decision tree looks like for this decision.
The decision is, do you acquire company A, or company B?
And if you acquire Company A, then you have two uncertainties.
And if the government does challenge, will the government win or lose?
And then you plug in your numbers, 90% chance the government will challenge.
If the government wins, the value drops to $14 million.
Even if the government loses, the value does drop a little to $19 million.
So you plug in the numbers and then you do your weighted average calculation.
60% of 14 plus 40% of 19 is 16.
90% of 16 plus 10% of 21 is 16.5.
So the weighted average, or the so called expected value of acquiring company A is $16.5 million, which is still quite a bit higher than the value of company B.
So if you use just a decision tree analysis, you know, forgetting about emotions, forgetting about attitude toward risk, the logical decision would be to acquire company A.
So, in conclusion, decision trees are valuable tools for analyzing your BATNA in both dispute resolution and deal-making negotiations.
And, this is a tool that you should also use for making other complex business decisions.
And that's the question of whether you're involved in a cross cultural negotiation.
In any negotiation, you start by analyzing your own interests, as we did earlier.
And then you try to analyze the other side's interests.
Asking why they want what they're interested in.
With a cross cultural negotiation, it's especially challenging analyzing the other side's interests, because there are two hurdles that you must leap to find out their interests.
First of all, there's the question of their negotiation style.
And second, their underlying values and beliefs.
Negotiation style is often referred to as the surface culture.
Whereas the underlying values and beliefs are referred to as the deep culture.
So obviously in a negotiation, we all know culture can influence the results of a negotiation and the success of a negotiation.
For example, when I talk with people from northern Italy, they explain that the culture in southern Italy is quite different from northern Ital, Italy.
Let me give you an example.
For several years, I was an Associate Dean at the Michigan business school.
And one of my responsibilities was a program that involved sending our MBAs to the Navajo reservation.
And occasionally I would visit the reservation.
Before my first visit, I studied the Navajo culture.
I talked with Navajo friends.
I read books about the Navajo culture.
Because I wanted to be respectful of that culture during my visit to the tribe.
And also a firm handshake is often not used within the Navajo culture.
So made my first to the reservation and met my very first Navajo on the reservation.
A person named Art, who was a tribal official.
He looked a lot like John Wayne.
And Art walked up to me and he looked me straight in the eye.
He slapped me on the back and gave me the firmest handshake I've ever had in my life.
And said, welcome to the reservation George.
And here I am, thinking that, I, expecting a weak handshake and, an indirect look in the eyes.
So I'm holding out my hand weakly and looking off to the side.
So that was a lesson to me that there are many variations within a culture.
Now I discovered in dealing with other members of the Navajo tribe, that the indirect look and weak handshake were very common.
But the important message here is that there are many variations within a culture.
And therefore the message is try to be sensitive to culture, but realize that there are variations.
Now in becoming sensitive to culture, there's a wonderful tool available, developed by Jesua Sollicuz of Tuft's University.
This tool allows you to be sensitive to cultures while not stereotyping the other culture.
And this tool is a 10 part questionnaire that asks you a number of questions that you can use in not only assessing the cultural style of the other side, but also assessing your own style.
And then you can do what's called a Gap Analysis.
You can look at situations where there's a huge gap in your values as opposed to the values of the other culture.
Maybe to you time is money.
You want to get things done quickly.
Where as the other culture is much more relaxed when it comes to time.
That's an important cultural trait to be sensitive to as you enter a cross cultural negotiation.
If you want details regarding this assessment, which I strongly recommend that you use in any cross cultural negotiation.
I strongly recommend that you use the assessment, and also for details regarding the, the assessment, this is a very useful article in the Ivey Business Journal.
And you have identified through a gap analysis the major differences between your culture and the other side.
Now when I teach negotiation around the world, I've discovered that this phrase is fairly universal in almost every country except in Italy.
I teach in Italy every spring.
And when I ask the Italians, hey have you heard about this phrase, when in Rome do as the Romans do?
But it is common around the world.
And so the basic question is when you're negotiating in another country should you adopt the other sides style?
Yes or no?
Basically many people would say no, or a qualified no.
Because there are problems when you try to modify your behavior and act as the other side does.
For example, what happens if you adopt the negotiation style of the other side, and then they adopt your style?
You're both going to feel a little foolish acting out the surface culture of the other side.
Somebody told me once that they saw a picture of an American businessman meeting a businessman from Japan for the first time.
And as they walk up to each other, the Japanese businessman reaches out to hug the American just as the American bows to the Japanese businessperson.
Another problem is where you don't fully understand the local culture.
You have to be very careful that if you're going to adopt this style, you're doing it in a respectful knowledgeable manner.
And most of us aren't familiar enough with other cultures to do this comfortably, and we don't want to do it in a way that would be disrespectful of the other culture.
Now of course there are exceptions.
A few years ago I was teaching a negotiation course, and one of the people in the course was the president of the country's subsidiary of one of the large auto makers.
Instead of living in an enclave with other auto executives, he intentionally took his family to a local village.
They were immersed in the local culture, the local language, the local customs, and so he felt very comfortable, comfortable acting in the local style.
But for most of us that is a, that is a difficult challenge.
So the bottom line is probably moderate adaptation is often better than major ad, adaptation.
In otherwords, try to identify some key features of the other culture, some clear taboos that you want to avoid, rather than completely immersing yourself, self into the other side's style.
Let me give you a quick cultural, a cross cultural test to see how aware you are of some major taboos in other cultures.
Let's assume that you and I have just completed a negotiation, we're sitting side by side.
And as we finish the negotiation I pat you on the back and I say good job.
You can probably think of a number of problems with the touching.
Maybe the touching alone is a problem.
But notice the way that I touched you, and specifically the hand that I used.
in, in some cultures, you do not touch somebody with your left hand, that is your toilet hand.
That is taboo.
So that's problem number one.
Problem number two is when I say great job.
In some cultures, this is equivalent to a middle finger in other cultures.
So that's, that's what you want to be aware of.
One of my most successful students was from Japan, and after he returned to his country, he rose to the top of the largest life insurance company in the world.
And occasionally we'll talk about negotiation.
And once I sent him an email and I asked him the question about adaptation.
I said, Mokoto, should Americans adopt other country's styles when negotiating in those countries.
Because I realize that he negotiated around the world as a representative of this life insurance company.
And I think his advice is about the best I've ever seen.
This was his email response.
I definitely believe that Americans should stay within their own style.
Of course it is important to respect the culture of each country.
I believe if we respect each other, the negotiation will be comfortable and constructive.
When I negotiated with people from the USA including Jim Robinson, former CEO of American Express, Richard Fuld CEO of Lehman Brothers, or the people of Europe including Dr.
Although they were more straight forward, more open, more aggressive, and their attitude was more relaxed especially the Americans.
I think that the success of negotiation between cross-national companies depends on respect of each other rather than style.
And I think that's about the best advice that you'll ever receive.
So, in conclusion, when you're involved in cross cultural negotiations, start with a gap analysis to identify how your negotiation style differs from the other side.
Try to keep in mind that there are variances within each culture, and conduct research so that you can avoid actions that are offensive in the other culture.
Just let me add a final tip that might be useful as you prepare for a cross-cultural negotiation, and that is to try a role reversal.
This is called a role reversal.
And it's a very useful exercise, because it gives you insight into the actions of the other side, and it might even provide you with some additional negotiations strategy, and tactics to use in your own future negotiations.
I use a role reversal in my courses, and in one role reversal, one of the sides is supposed to remain very quiet.
And I've discovered over the years that the people playing that role during a culture where people tend to listen rather than talk constantly.
After the course, people sen, send me emails and comments, and here are a couple of comments from people who participated in this role reversal.
In my daily life, I tend to be one of those people who loves to hear the sound of his or her own voice.
This made me realize how much I can learn from the other party by just letting them talk.
Additionally, I found that when presented with periods of silence, the other side will just keep talking.
And here's another quick example.
It was amazing to see the other side destroy their position by talking over themselves.
Their interests were plainly clear to me, and my quietness unnerved them to the point that I think they were desperate to sign a deal.
By being quieter and never interrupting, both of which are a challenge for me, I will much more quickly and thoroughly understand the others' interests in Batna and position myself better for the final negations.
This exercise illustrated that if you speak little your words carry much more weight.
Number one, deeper understanding of the other side.
In this week we're going to go over the basics of neural network programming.
For example, if you have a training set of m training examples, you might be used to processing the training set by having a four loop step through your m training examples.
But it turns out that when you're implementing a neural network, you usually want to process your entire training set without using an explicit four loop to loop over your entire training set.
So, you'll see how to do that in this week's materials.
Another idea, when you organize the computation of, in your network, usually you have what's called a forward pause or forward propagation step, followed by a backward pause or what's called a backward propagation step.
And so in this week's materials, you also get an introduction about why the computations, in learning an neural network can be organized in this for propagation and a separate backward propagation.
For this week's materials I want to convey these ideas using logistic regression in order to make the ideas easier to understand.
But even if you've seen logistic regression before, I think that there'll be some new and interesting ideas for you to pick up in this week's materials.
So with that, let's get started.
Logistic regression is an algorithm for binary classification.
So let's start by setting up the problem.
Here's an example of a binary classification problem.
You might have an input of an image, like that, and want to output a label to recognize this image as either being a cat, in which case you output 1, or not-cat in which case you output 0, and we're going to use y to denote the output label.
Let's look at how an image is represented in a computer.
To store an image your computer stores three separate matrices corresponding to the red, green, and blue color channels of this image.
So if your input image is 64 pixels by 64 pixels, then you would have 3 64 by 64 matrices corresponding to the red, green and blue pixel intensity values for your images.
Although to make this little slide I drew these as much smaller matrices, so these are actually 5 by 4 matrices rather than 64 by 64.
So to turn these pixel intensity values- Into a feature vector, what we're going to do is unroll all of these pixel values into an input feature vector x.
So to unroll all these pixel intensity values into Feature vector, what we're going to do is define a feature vector x corresponding to this image as follows.
We're just going to take all the pixel values 255, 231, and so on.
And then eventually 255 134 255, 134 and so on until we get a long feature vector listing out all the red, green and blue pixel intensity values of this image.
If this image is a 64 by 64 image, the total dimension of this vector x will be 64 by 64 by 3 because that's the total numbers we have in all of these matrixes.
And so we're going to use nx=12288 to represent the dimension of the input features x.
And sometimes for brevity, I will also just use lowercase n to represent the dimension of this input feature vector.
So in binary classification, our goal is to learn a classifier that can input an image represented by this feature vector x.
And predict whether the corresponding label y is 1 or 0, that is, whether this is a cat image or a non-cat image.
Let's now lay out some of the notation that we'll use throughout the rest of this course.
A single training example is represented by a pair, (x,y) where x is an x-dimensional feature vector and y, the label, is either 0 or 1.
And so your training sets will be written (x1, y1) which is the input and output for your first training example (x(2), y(2)) for the second training example up to <xm, ym) which is your last training example.
So I'm going to use lowercase m to denote the number of training samples.
And sometimes to emphasize that this is the number of train examples, I might write this as M = M train.
And when we talk about a test set, we might sometimes use m subscript test to denote the number of test examples.
So that's the number of test examples.
Finally, to output all of the training examples into a more compact notation, we're going to define a matrix, capital X.
So we take X1 and put that as a first column of this matrix, X2, put that as a second column and so on down to Xm, then this is the matrix capital X.
So this matrix X will have M columns, where M is the number of train examples and the number of railroads, or the height of this matrix is NX.
Notice that in other causes, you might see the matrix capital X defined by stacking up the train examples in rows like so, X1 transpose down to Xm transpose.
It turns out that when you're implementing neural networks using this convention I have on the left, will make the implementation much easier.
So just to recap, x is a nx by m dimensional matrix, and when you implement this in Python, you see that x.shape, that's the python command for finding the shape of the matrix, that this an nx, m.
That just means it is an nx by m dimensional matrix.
So that's how you group the training examples, input x into matrix.
How about the output labels Y?
It turns out that to make your implementation of a neural network easier, it would be convenient to also stack Y In columns.
So we're going to define capital Y to be equal to Y 1, Y 2, up to Y m like so.
And again, to use the notation without the shape of Y will be 1, m.
And as you influence your new network, mtrain discourse, you find that a useful convention would be to take the data associated with different training examples, and by data I mean either x or y, or other quantities you see later.
But to take the stuff or the data associated with different training examples and to stack them in different columns, like we've done here for both x and y.
So, that's a notation we we'll use e for a regression and for neural networks networks later in this course.
If you ever forget what a piece of notation means, like what is M or what is N or what is something else, we've also posted on the course website a notation guide that you can use to quickly look up what any particular piece of notation means.
So with that, let's go on to the next video where we'll start to fetch out logistic regression using this notation.
In this video, we'll go over logistic regression.
This is a learning algorithm that you use when the output labels Y in a supervised learning problem are all either zero or one, so for binary classification problems.
More formally, you want Y hat to be the probability of the chance that, Y is equal to one given the input features X.
So in other words, if X is a picture, as we saw in the last video, you want Y hat to tell you, what is the chance that this is a cat picture?
So X, as we said in the previous video, is an X dimensional vector, given that the parameters of logistic regression will be W which is also an X dimensional vector, together with b which is just a real number.
So given an input X and the parameters W and b, how do we generate the output Y hat?
Well, one thing you could try, that doesn't work, would be to have Y hat be w transpose X plus B, kind of a linear function of the input X.
And in fact, this is what you use if you were doing linear regression.
But this isn't a very good algorithm for binary classification because you want Y hat to be the chance that Y is equal to one.
So in logistic regression our output is instead going to be Y hat equals the sigmoid function applied to this quantity.
This is what the sigmoid function looks like.
If on the horizontal axis I plot Z then the function sigmoid of Z looks like this.
So it goes smoothly from zero up to one.
Let me label my axes here, this is zero and it crosses the vertical axis as 0.5.
Here's the formula for the sigmoid function.
Sigmoid of Z, where Z is a real number, is one over one plus E to the negative Z.
So notice a couple of things.
If Z is very large then E to the negative Z will be close to zero.
So this is close to 1.
And indeed, if you look in the plot on the left, if Z is very large the sigmoid of Z is very close to one.
Conversely, if Z is very small, or it is a very large negative number, then sigmoid of Z becomes one over one plus E to the negative Z, and this becomes, it's a huge number.
So this becomes, think of it as one over one plus a number that is very, very big, and so, that's close to zero.
And indeed, you see that as Z becomes a very large negative number, sigmoid of Z goes very close to zero.
So when you implement logistic regression, your job is to try to learn parameters W and B so that Y hat becomes a good estimate of the chance of Y being equal to one.
When we programmed neural networks, we'll usually keep the parameter W and parameter B separate, where here, B corresponds to an inter-spectrum.
In some other courses, you might have seen a notation that handles this differently.
In some conventions you define an extra feature called X0 and that equals a one.
So that now X is in R of NX plus one.
It turns out, when you implement you implement your neural network, it will be easier to just keep B and W as separate parameters.
And so, in this class, we will not use any of this notational convention that I just wrote in red.
If you've not seen this notation before in other courses, don't worry about it.
It's just that for those of you that have seen this notation I wanted to mention explicitly that we're not using that notation in this course.
But if you've not seen this before, it's not important and you don't need to worry about it.
So you have now seen what the logistic regression model looks like.
Next to change the parameters W and B you need to define a cost function.
Let's do that in the next video
In a previous video, you saw the logistic regression model.
To train the parameters W and B of the logistic regression model, you need to define a cost function.
Let's take a look at the cost function you can use to train logistic regression.
To recap, this is what we had to find from the previous slide.
So your output y-hat is sigmoid of w transpose x plus b where a sigmoid of Z is as defined here.
The predictions you have on the training set, which we only write as y-hat (i) that that will be close to the ground truth labels y_i that you got in the training set.
So to throw in a little bit more detail for the equation on top, we had said that y-hat is as defined at the top for a training example x and of course for each training example, we're using these superscripts with round brackets with parentheses to index and to differentiate examples.
Your prediction on training sample (i) which is y-hat (i) is going to be obtained by taking the sigmoid function and applying it to W transpose X, (i) the input that the training example plus V and you can also define Z (i) as follows.
So throughout this course, we're going to use this notational convention, that the superscript parentheses i refers to data.
X or Y or Z or something else associated with the i-th training example, associated with the i-th example.
Now, let's see what loss function or error function we can use to measure how well our algorithm is doing.
One thing you could do is define the loss when your algorithm outputs y-hat and the true label as Y to be maybe the square error or one half a square error.
It turns out that you could do this, but in logistic regression people don't usually do this because when you come to learn the parameters, you find that the optimization problem which we talk about later becomes non-convex.
If you didn't understand the last couple of comments.
Don't worry about it, we'll get to it in later video.
But the intuition to take away is that this function L called the loss function is a function you'll need to define to measure how good our output y-hat is when the true label is y.
As square error seems like it might be a reasonable choice except that it makes gradient descent not work well.
So in logistic regression, we will actually define a different loss function that plays a similar role as squared error, that will give us an optimization problem that is convex and so we'll see in that later video becomes much easier to optimize.
Here's some intuition for why this loss function makes sense.
Keep in mind that if we're using squared error then you want the squared error to be as small as possible.
And with this logistic regression loss function, we'll also want this to be as small as possible.
To understand why this makes sense, let's look at the two cases.
In the first case, let's say Y is equal to one then the loss function y-hat comma y is justice for us to write this negative sign.
Because if y equals one then the second term one minus Y is equal to zero.
So this says if y equals one you want negative log y-hat to be as big as possible.
So that means you want log y-hat to be large, to be as big as possible and that means you want y-hat to be large.
But because y-hat is you know, the sigmoid function, it can never be bigger than one.
So this is saying that if y is equal to one you, want y-hat to be as big as possible.
The other case is if y equals zero.
If y equals zero then this first term in the loss function is equal to zero because y zero and then the second term defines the loss function.
And so if in your learning procedure you try to make the loss function small, what this means is that you want log one minus y-hat to be large.
And because it's a negative sign there and then through a similar piece of reason you can conclude that this loss function is trying to make y-hat as small as possible.
This is saying that if y is equal to zero then your loss function will push the parameters to make y-hat as close to zero as possible.
Now, there are a lot of functions with Rafidah's effect that if y is equal to one we try to make y-hat large and if Y is equal to zero we try to make y-hat small.
We just gave here in green a somewhat informal justification for this loss function will provide an optional video later to give a more formal justification for why in logistic regression we like to use the loss function with this particular form.
Finally, the loss function was defined with respect to a single training example.
It measures how well you're doing on a single training example.
I'm now going to define something called the cost function, which measures how well you're doing an entire training set.
So the cost function J which is applied to your parameters W and B is going to be the average with one of the m of the sum of the loss function applied to each of the training examples and turn.
While here y-hat is of course the prediction output by your logistic regression algorithm using you know, a particular set of parameters W and B.
And so just to expand this out, this is equal to negative one over m sum from i equals one through m of the definition of the loss function.
So this is y (i) Log y-hat (i) plus one line is y (i) log one line is y-hat (i).
So the terminology I'm going to use is that the loss function is applied to just a single training example like so.
And the cost function is the cost of your parameters.
So in training your logistic regression model, we're going to try to find parameters W and B that minimize the overall costs of machine J written at the bottom.
So, you've just seen the set up for the logistic regression algorithm, the loss function for training example and the overall cost function for the parameters of your algorithm.
It turns out that logistic regression can be viewed as a very very small neural network.
In the next video we'll go over that so you can start gaining intuition about what neural networks do.
So that let's go onto the next video about how to view logistic regression as a very small neural network.
You've seen the logistic regression model.
You've seen the loss function that measures how well you're doing on the single training example.
You've also seen the cost function that measures how well your parameters w and b are doing on your entire training set.
Now let's talk about how you can use the gradient descent algorithm to train, or to learn, the parameters w and b on your training set.
To recap, here is the familiar logistic regression algorithm.
And we have on the second line the cost function, J, which is a function of your parameters w and b.
So it's 1 over m times the sum of this loss function.
And so the loss function measures how well your algorithms outputs y-hat(i) on each of the training examples stacks up or compares to the ground true label y(i) on each of the training examples.
So the cost function measures how well your parameters w and b are doing on the training set.
So in order to learn the set of parameters w and b it seems natural that we want to find w and b that make the cost function J(w, b) as small as possible.
In this diagram the horizontal axes represent your spatial parameters, w and b.
In practice, w can be much higher dimensional, but for the purposes of plotting, let's illustrate w as a single real number and b as a single real number.
The cost function J(w,b,) is, then, some surface above these horizontal axes w and b.
So the height of the surface represents the value of J(w,b) at a certain point.
And what we want to do is really to find the value of w and b that corresponds to the minimum of the cost function J.
It turns out that this cost function J is a convex function.
So it's just a single big bowl, so this is a convex function and this is opposed to functions that look like this, which are non-convex and has lots of different local.
So the fact that our cost function J(w,b) as defined here is convex is one of the huge reasons why we use this particular cost function, J, for logistic regression.
So to find a good value for the parameters, what we'll do is initialize w and b to some initial value, maybe denoted by that little red dot.
And for logistic regression almost any initialization method works, usually you initialize the value to zero.
Random initialization also works, but people don't usually do that for logistic regression.
But because this function is convex, no matter where you initialize, you should get to the same point or roughly the same point.
And what gradient descent does is it starts at that initial point and then takes a step in the steepest downhill direction.
So after one step of gradient descent you might end up there, because it's trying to take a step downhill in the direction of steepest descent or as quickly downhill as possible.
So that's one iteration of gradient descent.
I guess this is now hidden by the back of the plot until eventually, hopefully you converge to this global optimum or get to something close to the global optimum.
For the purpose of illustration, let's say that there's some function, J(w), that you want to minimize, and maybe that function looks like this.
To make this easier to draw, I'm going to ignore b for now, just to make this a one-dimensional plot instead of a high-dimensional plot.
So gradient descent does this, we're going to repeatedly carry out the following update.
So set w to w minus alpha, times, and this is a derivative dJ(w)/dw.
I will repeatedly do that until the algorithm converges.
So couple of points in the notation, alpha here, is the learning rate, and controls how big a step we take on each iteration or gradient descent.
We'll talk later about some ways by choosing the learning rate alpha.
And second, this quantity here, this is a derivative.
This is basically the update or the change you want to make to the parameters w.
When we start to write code to implement gradient descent, we're going to use the convention that the variable name in our code dw will be used to represent this derivative term.
Now let's just make sure that this gradient descent update makes sense.
So you're at this point on the cost function J(w).
Remember that the definition of a derivative is the slope of a function at the point.
So the slope of the function is really the height divided by the width, right, of a low triangle here at this tangent to J(w) at that point.
And so, here the derivative is positive.
W gets updated as w minus a learning rate times the derivative.
The derivative is positive and so you end up subtracting from w, so you end up taking a step to the left.
And so gradient descent will make your algorithm slowly decrease the parameter if you have started off with this large value of w.
As another example, if w was over here, then at this point the slope here of dJ/dw will be negative and so the gradient descent update would subtract alpha times a negative number.
And so end up slowly increasing w, so you end up making w bigger and bigger with successive iterations and gradient descent.
If you're not familiar with derivates or with calculus and what this term dJ(w)/dw means, don't worry too much about it.
We'll talk some more about derivatives in the next video.
If you have a deep knowledge of calculus, you might be able to have a deeper intuitions about how neural networks work.
But even if you're not that familiar with calculus, in the next few videos we'll give you enough intuitions about derivatives and about calculus that you'll be able to effectively use neural networks.
But the overall intuition for now is that this term represents the slope of the function, and we want to know the slope of the function at the current setting of the parameters so that we can take these steps of steepest descent, so that we know what direction to step in in order to go downhill on the cost function J.
So we wrote our gradient descent for J(s) if only w was your parameter.
In logistic regression, your cost function is a function of both w and b.
So in that case, the inner loop of gradient descent, that is this thing here, this thing you have to repeat becomes as follows.
You end up updating w as w minus the learning rate times the derivative of J(w,b) respect to w.
And you update b as b minus the learning rate times the derivative of the cost function in respect to b.
So these two equations at the bottom are the actual update you implement.
As an aside I just want to mention one notational convention in calculus that is a bit confusing to some people.
I don't think it's super important that you understand calculus, but in case you see this I want to make sure that you don't think too much of this.
Which is that in calculus, this term here, we actually write as fallows, of that funny squiggle symbol.
So this symbol, this is actually just a lower case d in a fancy font, in a stylized font for when you see this expression all this means is this isn't J(w,b) or really the slope of the function J(w,b), how much that function slopes in the w direction.
And the rule of the notation in calculus, which I think isn't totally logical, but the rule in the notation for calculus, which I think just makes things much more complicated than you need to be is that if J is a function of two or more variables, then instead of using lowercase d you use this funny symbol.
This is called a partial derivative symbol.
But don't worry about this, and if J is a function of only one variable, then you use lowercase d.
So the only difference between whether you use this funny partial derivative symbol or lowercase d as we did on top, is whether J is a function of two or more variables.
In which case, you use this symbol, the partial derivative symbol, or if J is only a function of one variable then you use lower case d.
This is one of those funny rules of notation in calculus that I think just make things more complicated than they need to be.
But if you see this partial derivative symbol all it means is you're measure the slope of the function, with respect to one of the variables.
And similarly to adhere to the formerly correct mathematical notation in calculus, because here J has two inputs not just one.
But it really means the same thing as, almost the same thing as lower case d.
Finally, when you implement this in code, we're going to use the convention that this quantity, really the amount by which you update w, will denote as the variable dw in your code.
The amount by which you want to update b will denote by the variable db in your code.
All right, so, that's how you can implement gradient descent.
Now if you haven't seen calculus for a few years, I know that that might seem like a lot more derivatives in calculus than you might be comfortable with so far.
But if you're feeling that way, don't worry about it.
In the next video, we'll give you better intuition about derivatives.
And even without the deep mathematical understanding of calculus, with just an intuitive understanding of calculus you will be able to make neural networks work effectively.
So that, let's go onto the next video where we'll talk a little bit more about derivatives.
When you implement back propagation for your neural network, you need to either compute the slope or the derivative of the activation functions.
So, let's take a look at our choices of activation functions and how you can compute the slope of these functions.
Here's the familiar Sigmoid activation function.
So, for any given value of z, maybe this value of z.
If you are familiar with calculus and know how to take derivatives, if you take the derivative of the Sigmoid function, it is possible to show that it is equal to this formula.
So, let's just sanity check that this expression make sense.
This isn't the correct because when z is very large, the slope is close to 0.
Conversely, if z is equal to minus 10, so it says well there, then g of z is close to 0.
So, the formula on the left tells us d dz g of z would be close to g of z, which is 0 times 1 minus 0.
So it is also very close to 0, which is correct.
Finally, just to introduce one more piece of notation, sometimes instead of writing this thing, the shorthand for the derivative is g prime of z.
So, g prime of z in calculus, the little dash on top is called prime, but so g prime of z is a shorthand for the calculus for the derivative of the function of g with respect to the input variable z.
Then in a neural network, we have a equals g of z, equals this, then this formula also simplifies to a times 1 minus a.
The advantage of this formula is that if you've already computed the value for a, then by using this expression, you can very quickly compute the value for the slope for g prime as well.
So, that was the sigmoid activation function.
Let's now look at the Tanh activation function.
So, if you want you can sanity check that this formula makes sense.
So, for example, if z is equal to 10, Tanh of z will be very close to 1.
Then g prime of z, according to this formula, would be about 1 minus 1 squared, so there's very close to 0.
So, that was if z is very large, the slope is close to 0.
Conversely, if z is very small, say z is equal to minus 10, then Tanh of z will be close to minus 1, and so g prime of z will be close to 1 minus negative 1 squared.
So, just to summarize, if a is equal to g of z, so if a is equal to this Tanh of z, then the derivative, g prime of z, is equal to 1 minus a squared.
So, once again, if you've already computed the value of a, you can use this formula to very quickly compute the derivative as well.
Finally, here's how you compute the derivatives for the ReLU and Leaky ReLU activation functions.
It's actually undefined, technically undefined if z is equal to exactly 0.
But if you're implementing this in software, it might not be a 100 percent mathematically correct, but it'll work just fine if z is exactly a 0, if you set the derivative to be equal to 1.
If you're an expert in optimization, technically, g prime then becomes what's called a sub-gradient of the activation function g of z, which is why gradient descent still works.
But you can think of it as that, the chance of z being exactly 0.000000.
It's so small that it almost doesn't matter where you set the derivative to be equal to when z is equal to 0.
So, in practice, this is what people implement for the derivative of z.
So, under these formulas, you should either compute the slopes or the derivatives of your activation functions.
Now, we have this building block, you're ready to see how to implement gradient descent for your neural network.
Let's go on to the next video to see that.
In the last video, we described what is a deep L-layer neural network and also talked about the notation we use to describe such networks.
In this video, you see how you can perform forward propagation, in a deep network.
As usual, let's first go over what forward propagation will look like for a single training example x, and then later on we'll talk about the vectorized version, where you want to carry out forward propagation on the entire training set at the same time.
But given a single training example x, here's how you compute the activations of the first layer.
So w1 and b1 are the parameters that affect the activations in layer one.
The activation function g depends on what layer you're at and maybe what index set as the activation function from layer one.
So if you do that, you've now computed the activations for layer one.
How about layer two?
Then, so the activation of layer two is the y matrix times the outputs of layer one.
Until you get to the upper layer, that's layer four.
So, that's how you compute your estimated output, y hat.
So, just one thing to notice, x here is also equal to a0, because the input feature vector x is also the activations of layer zero.
And then, the activations for that layer is the activation function applied to the values of z.
So, that's the general forward propagation equation.
How about for doing it in a vectorized way for the whole training set at the same time?
The equations look quite similar as before.
You could take this, let me scratch out X, they can put A0 there.
We're just taking these vectors z or a and so on, and stacking them up.
Similarly, for capital A, just as capital X.
In this process, you end up with y hat which is equal to g of Z4, this is also equal to A4.
That's the predictions on all of your training examples stacked horizontally.
So just to summarize on notation, I'm going to modify this up here.
A notation allows us to replace lowercase z and a with the uppercase counterparts, is that already looks like a capital Z.
That gives you the vectorized version of forward propagation that you carry out on the entire training set at a time, where A0 is X.
Now, if you look at this implementation of vectorization, it looks like that there is going to be a For loop here.
So, seems that there is a For loop here.
I know that when implementing neural networks, we usually want to get rid of explicit For loops.
But this is one place where I don't think there's any way to implement this without an explicit For loop.
No one knows, and I don't think there is any way to do this without a For loop that goes from one to capital L, from one through the total number of layers in the neural network.
So, that's it for the notation for deep neural networks, as well as how to do forward propagation in these networks.
If the pieces we've seen so far looks a little bit familiar to you, that's because what we're seeing is taking a piece very similar to what you've seen in the neural network with a single hidden layer and just repeating that more times.
Now, it turns out that we implement a deep neural network, one of the ways to increase your odds of having a bug-free implementation is to think very systematic and carefully about the matrix dimensions you're working with.
So, when I'm trying to debug my own code, I'll often pull a piece of paper, and just think carefully through, so the dimensions of the matrix I'm working with.
Let's see how you could do that in the next video.
So, what does deep learning have to do with the brain?
But let's take a quick look at why people keep making the analogy between deep learning and the human brain.
There is a very loose analogy between, let's say a logistic regression unit with a sigmoid activation function, and here's a cartoon of a single neuron in the brain.
So, there is a very simplistic analogy between a single neuron in a neural network and a biological neuron-like that shown on the right, but I think that today even neuroscientists have almost no idea what even a single neuron is doing.
A single neuron appears to be much more complex than we are able to characterize with neuroscience, and while some of what is doing is a little bit like logistic regression, there's still a lot about what even a single neuron does that no human today understands.
For example, exactly how neurons in the human brain learns, is still a very mysterious process.
So, when I think of deep learning, I think of it as being very good at learning very flexible functions, very complex functions to learn X to Y mappings, to learn input-output mappings in supervised learning.
I think the field has moved to the point where that analogy is breaking down and I tend not to use that analogy much anymore.
So, that's it for neural networks and the brain.
So, that's it for this video.
You now know how to implement forward prop and back prop and gradient descent even for deep neural networks.
Best of luck with the problem exercise, and I look forward to sharing more of these ideas with you in the second course.
Hello from the past ladies and gentlemen.
And in particular, time travel.
And the aim of this talk is to give you a short overview of the philosophy of time travel and some of the philosophical problems that this topic throws up.
The key text for this talk, is a 1976 paper by David Lewis, 1941-2001, called The Paradoxes of Time Travel.
And in that paper, Lewis tries to defend the logical possibility of backwards time travel.
So a really good way into the debate, is to begin by looking at Lewis' definition of what time travel might actually involve.
External time is time as it's registered by the world at large.
Which might be, times as it's registered by the movement of the tides, by the rotation of the sun, by the movement of the air through space, by the sun rising and setting.
So external time is simply time as it's registered by the majority of the non time traveling universe, time for everybody.
Time registered by the accumulation of the traveler's memories, time registered by the accumulation of the traveler's digestive products, time registered by the traveler's hair graying or cells dying.
Now for most us, and I'm going to assume for the purposes of this talk that most of us aren't time travelers, external time and personal time march in-step.
If five minutes elapses for you, as recorded by your watch, by your digestion, by your blood circulating, you should typically find that five minutes has passed in the external world.
But in cases of time travel, personal time and external time diverge.
And there are two ways in which this could be imagined as happening.
In case there's a forward time travel, personal time and external time share the same direction, but they have different measures of duration.
Suppose for example, I depart from January 2013, in my time machine.
And I arrive in January of 2063.
But in my frame of reference, aboard the machine measure by my watch, my digestion, the accumulation of my memories, all the process that travel with me, only five minutes has elapsed.
So I get out the machine five minutes older, in personal time, only to find that fifty years has elapsed in the extent of the world.
So in case there's a forward time travel, personal time and external time share the same direction, but different duration.
Cases of backward time travel, personal time and external time again diverge.
Remember that Lewis thinks that divergences between personal time and external time aren't actually constitutive of time travel.
So in backward time travel, personal time and external time diverge, but they diverge in direction.
Suppose now, that my 5 minute personal time journey from January, 2013, doesn't take me into the future, it takes me into the past.
So, I activate the machine, five minutes passes for me.
Five minutes seems to elapse in my frame of reference.
But when I arrive, I've arrived in January, 1863.
So in backward time travel, personal time and external time diverge in direction.
So, in this case, five minutes positive personal time, measures the same journey as a 150, year negative interval of external time.
Now a backward time journey has the peculiarity that in external time the journey begins, after it ends.
The journey ends in 1863, but it begins in 2013.
So, says Lewis, given a distinction between personal time and external time, it is at least possible to imagine both forward time travel and backward time travel.
Now the details of this are slightly technical, but forward time travel seems to be a very deeply embedded phenomenon, and one of our best supported physical theories.
Einstein's special theory of relativity predicts that the rate at which time passes is not an absolute, not an invariant, but varies according to relative speed.
In other words, the greater the relative velocity between two systems, the closer that, that relative velocity comes to the speed of light.
Now, if I'm lucky, I maybe have forty or even fifty years of personal time ahead of me.
And the Special Theory of Relativity says, that if I travel fast enough relative to the solar system, I can make that forty or fifty year interval of personal time, comprise tens, or hundreds, or millions, or even billions of years of external time.
Provided that I travel fast enough, I can make my 40 years of personal time extend through the entire future history of the Sun.
So forward time travel is very deeply embedded in Einstein's special theory of relativity.
And we have decade and decade of very well supported physical results that suggests that these divergences between frames of reference really, really occur.
Backward time travel is a bit more speculative, and whether physics permits backward time travel, is still something that's naturally hotly contested.
But the General Theory of Relativity seems to predict that under certain circumstances, given an enormous amount of mass, or an enormous density of mass, or enormously rapid movement of mass, it's possible to create circumstances where personal time and external time diverge.
There's a famous model universe, by the Austrian Mathematical physicist Kurt Godel, which describes a relativistic possible universe where it's possible to t-, jump these into the local future that can visit any point in the external past.
So the General Theory of Relativity seems to underwrite the kind of personal time, external time discrepancies, there's a constitutive of backward time travel as well.
How does science work?
How do scientists like myself and the people we're going to be learning about come to conclusions.
Now I want to differentiate between, here, between facts and the process.
Scientific facts can change.
Unfortunately, you're going to be tested upon facts, but you need to know that some of these facts, may not really be facts.
We saw that, for example, with Barbara McClintock, who discovered, against what people had thought, against popular idea, that the DNA can change.
But now we know that that really is a scientific fact, that DNA can change.
Well, there's two general processes.
This is what Darwin did when he went out on the Beagle.
He started collecting data and based on this data, through induction, he developed new theories and new hypotheses which then could lead to experiments.
This is the same type of approach that used in the modern genome project, where they're developing huge or gathering huge amounts of data.
But the approach used by most scientists is what I would call the deductive approach.
And I want to just give a very simple example.
And as you're watching me speak, you're yawning.
You're getting very tired.
Now, I want your thesis, your master's thesis, to be about why are you tired at 9 o'clock at night while you're watching Daniel Shamovitz teach what a plant knows?
Now to develop your thesis, you're going to need to develop first hypotheses, and we could think of several hypotheses.
Maybe the first hypothesis is that Shamovitz is a rather boring teacher.
The second hypothesis could be that you woke up too early in the morning and that's why you're tired.
So now what experiments can you design to test these hypotheses?
Let's go to the first one that I'm a boring lecturer.
So you'll go back to the Coursera homepage, choose another course, and start watching it.
Now does that finding prove that I'm not boring?
because he could also be boring in the next lecture.
So you do a third lecture.
But if you do this enough times, and each time, you're still tired.
You've realized that you don't have enough proof to actually support that hypothesis.
So now, let's go to the second hypothesis.
That you woke up too early in the morning.
Again, it's pretty obvious.
Let's say you don't wake up until noon the next time you watch my lecture.
And now you come to the lecture of Shamowitz g/ and what a plant knows and lo and behold, you're full of energy.
The result is that you were tired because you're not getting enough sleep.
So that's on a very simple level.
And what we want to see now through plant biology, are what are the hypotheses that lead to the findings that we're going to be talking about.
Hello and welcome back to Advanced Competitive Strategy.
Hey, I'm Karen Reivich and I want to welcome you to the Resilience course of the Foundations of Positive Psychology specialization.
I'm the Director of Training at the University of Pennsylvania Positive Psychology Center.
And I also teach here in the Master of Applied Positive Psychology Program.
Much of my work focuses on resilience.
I've been really lucky to work with a range of people including students and educators, soldiers in the US Army, business leaders, and the Oklahoma City Thunder.
So thank you for joining me.
The first module is an exploration of resilience.
What is it, and what is the role of optimism in resilience?
The second module, we're going to look at the cognitive skills that increase resilience.
We'll explore when our thinking gets in the way of resilience.
And how to challenge that thinking so that we're more resilient.
In our third module, we're going to explore emotion.
First we'll look at anxiety, and we'll talk about thinking styles that drive unhelpful amounts of anxiety.
And we'll talk about some skills you can use to challenge that unhelpful thinking.
We'll also talk about mindfulness, and how through practices of mindfulness you can manage your anxiety.
Why is positive emotion important in resilience?
I'm going to ask you the question, who are you at your best?
What are your top character strengths?
Whether that be curiosity, or love, or playfulness, or humor.
And then we're going to talk about how you can use your top character strengths to overcome challenges, to bounce back from setback.
We'll also, in that last module, talk about the importance of relationships in resilience.
I'm going to teach you a skill around communicating with other people around joy, and why that matters so much in resilience.
Now, I don't want this just to be the science of resilience.
A big part of the work I do, is teaching other people how to enhance their resilience.
So as you go through this MOOC with me, learn the science, listen to the fantastic guest speakers we have lined up for you, but most importantly, try out the skills that I teach.
Because that's how you're going to leave this course, not just knowing about resilience, but enhancing your resilience.
Okay, so week one, let's get started.
I want to talk about definitions of resilience, of course.
And also, what are the variables that science tells us are critical in building resilience?
And then, after we explore all of those variables, we're going to focus on optimism.
And I hope to convince you that optimism is among the most important variables for resilience, for well-being, strong relationships.
All right, let's get started.
So what we're going to do is explore the concept of resilience.
What is it?
And I want to identify for you the variables that the science tells us are critical in contributing to a person's resilience.
After we do that I'm going to spend a little a bit of time on one variable and in particular and that's optimism.
And I'm going to convince you of why optimism matters so much in terms of our resilience, and our well being in our relationships.
Okay, now before I give you the field's definition of resilience.
Here's what I'd like you to do.
Take a minute and write down your definition, and write down some keywords that popped to your mind when you hear the word resilience.
Okay, I'm guessing if you're like the thousands of people we've worked with, some of you have written down the word flexible.
That you know that part of resilience is about being flexible, and being able to try new things when something you're doing isn't working.
I'm guessing some of you wrote down the word overcome or overcoming.
Because you know that part of resilience is overcoming whatever life puts in your path.
That's a common word we hear.
Some of you probably put down the word strength or mental toughness.
Because you know that part of resilience is in your mind.
It's how you think about your life.
It's how you think about adversity and stress.
So those are some very common words we hear when people think about the word resilience.
Less common words, so see if you wrote down the word love.
We don't hear that often, but I hope to convince you that love and strong relationships, knowing who you can rely on no matter what's going on in your life, that that's critical in resilience.
Did you write that word down?
We know that gratitude is one of those emotions that helps us connect to others.
How about faith?
That's a word that we don't often hear, but attachment to something larger than yourself.
Feeling part of something bigger than you, is critical in resilience.
We're going to be exploring all of these things in one way or another in our course together.
All right, so, let's talk about definitions of resilience.
If you scoured the empirical literature, you would see that there's lots of different definitions of resilience.
Here's one that I particularly like.
We're actually going to talk about some of their research around positive emotion a little later.
They define resilience as characterized by the ability to bounce back from negative emotional experiences and by flexible adaptation to the changing demands of stressful experiences.
What I like about this definition in particular is it talks about that flexibility, being able to try different strategies so that you're able to meet the demands of whatever that stressor or challenge is.
I think that's really important in resilience.
So our shop at Penn has a slightly different definition of resilience.
Resilience is the ability to bounce back from adversity.
But notice this other part, resilience is also the ability to grow from challenges.
And in this course we're going to explore both.
Skills to help you to get back on course when adversity strikes.
But also skills to help you to learn and grow from the stressors and challenges you confront.
We've talked about optimism a lot and now we're going to play a little game called Spot the Optimism.
Here's what I want you to do.
I want to really tune your thinking to noticing the very, very specific behaviors that an optimist engages in that leads to greater resilience.
It came out in about 2006 and Will Smith plays the character of Chris Gardner.
Chris Gardner was homeless and he's really working hard in this movie to get a job at a financial services firm, Dean Witter.
And so, in the clip we're going to ask you to watch, I want you to notice all of the behaviors that demonstrate his optimism.
So as you watch this clip, jot down all of the different behaviors you see that demonstrate Chris Gardner's optimism and then we'll talk about it.
Yeah, you got to stay until this thing clears.
No, I can't spend the night here.
I have to pick up my son.
9:30 tomorrow morning.
What am I supposed to do with my son?
What am I supposed to do with my son?
Is there anyone else who can take care of him?
Good morning.
Chris Gardner.
Chris Gardner.
Good to see you again.
Chris Gardner.
I've been sitting out there for the last half hour trying to come up with a story that would explain my being here dressed like this.
And I wanted to come up with a story that would demonstrate qualities that I'm sure you all admire here like earnestness or diligence and team play, something, and I couldn't think of anything.
So the truth is I was arrested for failure to pay parking tickets.
And I ran all the way here from the Polk station, the police station.
What were you doing before you were arrested?
I was painting my apartment.
He's been waiting outside the front of the building with some 40-pound gizmo for over a month.
He said you're smart.
And you want to learn this business.
I want to learn this business.
How many times have you seen Chris?
No, no.
High school?
How many in the class?
It was a small town.
But I was also first in my radar class in the Navy and that was a class of 20.
Can I say something?
Chris, what would you say if a guy walked in for an interview without a shirt on and I hired him?
What would you say?
He must've had on some really nice pants.
I don't know how many you found.
I think every time I watch that video I see more.
There are some obvious ones that I'm guessing you notice, like the fact that he even went to the city interview after spending the night in jail.
That's obviously the behavior of an optimist.
But there are more subtle ones as well.
He couldn't control what he was wearing, right?
He didn't have time to go home and change and put on a business suit.
But he could control that even though he was in that paint-stained T-shirt, that he was going to look as good as he possibly could in that paint-stained T-shirt.
Also, we talked about how optimists seek out information, right?
An optimist is somebody who's looking for information so they could use that information to their advantage, from a resilience perspective, to help them cope with the situation.
And that to me is the behavior of an optimist.
So, as we continue to go through this move together, I want to challenge you to spot optimism.
When you see an optimistic behavior in yourself, name it for yourself.
When you see an optimistic behavior in your child, call him or her out on it.
Point out that behavior so that your child knows that that behavior is one that's going to serve him or her in resilience.
Many of you are employers, right?
So, when you see optimism in people that work for you, when you see behaviors of optimism, don't let them go unnoticed.
Praise those behaviors because by praising those behaviors, you're going to get more of those behaviors out of people and you're going to get happier, healthier, more productive of colleagues.
All right, so now what I would love for you to do is to put optimism into practice in a situation that matters to you.
Or maybe it's that you're on the job market and you have received a lot of no's and you're starting to feel really frustrated and worn down by that.
So, I want you start off by identifying a situation that's hard for you and now, you're going to apply the skill of optimism.
I want you to take some time and to list out all of the aspects of that situation that you can control.
Now, think of control broadly.
Sometimes we can full-on control something but we can leverage it.
We can influence it.
There's a little wiggle room there that you can effect change.
So, I want you to challenge yourself not just to identify the first thing that occurs to you that you can control, but push yourself.
Are there other aspects of this situation that you can control or influence or leverage?
So, you're going to come up with, I hope, a long list, two, three, four, five, depending on the situation, things that you can control.
That's what an optimist does.
But an optimist also identifies and lets go of the things that he or she can't control.
So, I want you to do that as well.
Maybe there's aspects of that situation.
Your fight with your your significant other, or your kids, or not getting a job currently that you have to just accept.
What are all the aspects of this situation that you just need to accept and by putting those two lists together, what you can control, influence, leverage what you have to accept.
Now you can start to make some decisions about how to use your energy and resources.
You're maybe going to be less likely to lament and ruminate on the things you can't do anything about, because right there in front of you have this long list of things that you can influence or change.
So you're going to make those two lists: control, except.
An optimist doesn't just identify the problem.
So, once you've identified what you can control versus what you need to accept, I want you to challenge yourself to come up with some actions that you can take to affect the variables that you just identified that you can control.
So, what will you start to do differently?
Okay.
I was lucky enough to get to work here at Penn with the Division of Public Safety.
So, we spent about a year working with all the police officers and the dispatchers and the detectives and other first responders at Penn's Division of Public safety.
And this was under the leadership of the Vice President for Public Safety, Maureen Rush.
She's also the Superintendent of Penn Police Department.
Maureen Rush is somebody everyone's got to know.
She was one of the first female police officers in Philadelphia.
She's an incredible leader and just an amazing human being, and so you're going to get now to listen to Maureen Rush talk about some of her experiences in terms of the importance of optimism in policing.
Unfortunately, police are generally up here all the time, right?
So, learning how to understand what you can control and work on those measures will make you feel a lot happier at the end of the day.
Hone is a resilience researcher.
She also was one of my students in our Master of Applied Positive Psychology Program here at Penn.
She's from New Zealand, and she's going to talk to you about resilient grieving.
Few years ago, her daughter, Abi, was tragically killed in a car accident.
She dove into all that was known about grieving, and discovered that for her, what was known was missing some important things in her own grief process.
And so, Lucy has written a book called, What Abi Taught Us, that's the title if you buy the book in New Zealand.
If you buy the book here in the US, it's called resilient grieving, How to Live with Loss that Changes Everything.
And in this book, Lucy talks about her own experience, grieving the loss of Abi.
Her family's experience grieving the loss of Abi.
And she gives us a practical guide to help us think about what resilient grieving looks like.
And so you're going to hear in this segment Dr.
Lucy Hone, and I work at the Human Potential Center out of AUT in Auckland.
I actually live in Christchurch.
And I'm talking to you today because two and a half years ago I got that dreadful phone call from the police saying they were coming to see us.
And to tell us that our daughter, 12-year-old little girl, beautiful Abi, had been killed in a tragic road accident.
Where a driver had just driven straight through a stop sign and killed Abi along with her best friend, and Ella's mom Sully, who was a really dear friend of mine as well.
So, as anyone will tell you who has experienced that phone call, your life stops and spins and you get all those physical sensations.
So really, since that day, have become really fascinated and sort of I'm developing this notion of resilient grieving.
We decided, my husband Trevor and I, right from the outset, we decided that we weren't going to blame the driver.
I've always felt sorry for him actually.
It was a mistake, we all make mistakes.
It's a terribly costly mistake, but blaming him was only going to drag me down.
And I wanted to really focus my energy and my attention on the things that we can change, not the things that we can't.
We work really hard at not being victims, so we decided not to go to his trial.
He went to court, and we intentionally, instead, decided to drive straight past the courtroom.
And I can picture it now, seeing all the media outside the courtroom.
It was a really big, and he was a foreign driver, sadly, and so there was a lot of media attention on that.
And because we have a few incidents and deaths in New Zealand with foreign drivers, not knowing our silly roads.
Choosing to focus our attention on the things that we could do.
So I think I've always had this little voice in my head that says choose life, not death.
I felt we could have just got sucked down into a vortex of blame and pain and misery.
And that wasn't going to help us as a family, and it wasn't going to help our boys.
There is a way, we have a choice over this.
Right, actually, now that I think about it from those very first moments, I remember thinking, wow, jeepers.
And really what I was thinking was, we going to have to choose that hard work again and again and again.
It isn't the life, obviously, that I would have chosen.
So all I can do is choose the little things that can make it a little bit better each day.
She makes me laugh more than anyone else.
And whatever it is, the strategies that really I have found help me.
All right, so let's summarize what we've done so far.
So in module 1, we've talked about what resilience is.
We've gone over some definitions, we've surveyed the science of resilience, and covered the key ingredients, or variables that contribute to resilience.
Then we kind of focused in on optimism, one of those key variables, and we talked about the science of optimism.
We discovered that optimism predicts physical health and emotional health, it affects our relationships, it affects our performance.
I hope through this first module that you're starting to kind of reflect on your own level of optimism.
Now, some of you might have noticed that in certain areas of your life, you think very optimistically whereas in other areas of your life you lean, maybe like me, a little more towards pessimism.
Okay, so, that's what we did.
Now where are we heading?
Well, in our next module, we're going to be focusing on some styles of thinking that can really get in the way of optimism and undercut our resilience.
I call these thinking traps.
They're overly rigid patterns in our thinking that undercut our well being, our performance, our problem solving, our relationships.
And I'm going to describe to you five different thinking traps and then I'm going to teach you some strategies for challenging these thinking traps just as they're occurring.
So that you're able to think more productively and be more resilient in stressful situations.
This module's going to focus on cognitive approaches to resilience.
We're really going to drill into strategies that you can use to build optimism and to build thinking that enables resilience.
Now the first thing we're going to look at is what I call thinking traps.
And what those lines of research focus on are kind of overly rigid patterns in thinking that can undercut our effectiveness.
A lot of folks have helped us to identify what those overly rigid patterns are.
These are leaders in the field of cognitive therapy.
So let me tell you a little bit about their work and then we'll get to how I think about it from a resilience perspective.
So we've already talked about Marty Seligman's work, my mentor, his work on explanatory style.
Remember, explanatory style is how you explain the causes of the good and the bad things that happen to you.
And explanatory style is kind of habitual and reflexive.
It develops over time.
And in Explanatory Style Theory, Seligman and colleagues focus on how some of us have overly rigid ways of explaining our successes and our setbacks.
And so that's one line of research that we pulled on.
And what they helped us to understand is that many of us, particularly if we're a little run down and depleted, can make errors in logic.
And so what we've done, is we've taken the work from Dr Seligman and explanatory style.
And we've taken the work of Drs Beck and Burns, errors in logic and cognitive distortions.
And said what are the shared features in these different lines of work?
Well, the shared feature is all of those researchers are looking at the ways in which our thinking can become overly rigid.
And because it's overly rigid, what I mean by that is you enter a new situation and your thinking is almost on autopilot.
And whether it's explanatory style, or errors in logic, or cognitive distortions, all of these overly rigid patterns in thinking can make it much harder for us to see our current situation accurately.
Those habits of thinking can get in the way of problem solving because we're not seeing the situation as it is.
We're bringing to the situation our old habits of thinking, and they can undercut our ability to bounce back.
Because you'll see, as we explore these in more detail, these thinking traps, as I call them, can get in our way of having productive emotion in a situation.
All right, well, some of you might be asking why are we spending so much time thinking about our thinking.
But that foundational principle is that our thoughts, so how we think, drives our emotions, our behaviors, our physiology.
B stands for your beliefs, what you're saying to yourself about that situation, that activating event.
And C stands for consequences, the emotions and reactions.
It's what we say to ourselves, our beliefs, our thoughts about the situation that impacts how we feel, what we do, even our physiology.
So the reason we're spending so much time thinking about our thinking in a course on resilience is that, look, we can't always control the stuff that happens to us.
But what we can have more control over is our interpretations, our thoughts.
And remember back in module one, we said one of the variables that really impacts one's level of resilience is mental agility.
And these thinking traps are going to get in the way of mental agility.
So we're going to talk about the thinking traps, and then I'm going to teach you some strategies for challenging these old habits of thinking.
So you get more mental agility, you're enhancing your self-regulation, you're regulating your thoughts, and that's going to give you greater resilience.
Okay, our thoughts drive how we feel, our emotions.
Imagine that there's a fight that you just had with a loved one.
Those thoughts are going to clearly impact your emotions, are going to impact what you do, to also going to impact your body, what you feel.
You're going to have more or less fight or flight response based on how you're interpreting a situation.
So let's start by defining the five thinking traps.
And after I define it, I don't want this just to be sort of me talking at you with these definitions.
I really want you to have the opportunity to kind of hear how these thinking traps influence our in-the-moment thoughts, what we're saying to ourself just as a stressful situation unfolds.
And so after I define one of the thinking traps, then you're going to have the opportunity to click on two separate videos.
So we've got some help from some of our friends to make this a little bit more vivid for you.
So, you're going to see Dr Shannon Paoletti portray each of these five thinking traps.
I've worked with Shannon for, I think, at this point it might be approaching 20 years.
She is one of our primary instructors in our Resilience Training Program.
So Shannon travels the globe teaching resilience skills to businesses, to soldiers in the army, and so forth.
And then the other person you're going to see in these videos is Aaron Diamond Reivich, I've known him for 20 years because he's my son.
And he's going to help portray what these thinking traps might sound like in the mind of a college student.
Baime talk about the experience of anxiety.
So he's going to talk to us about how a sustained practice of mindfulness benefits not just how we deal with stress and anxiety, but how over time, it really can change the way in which we engage in the world.
Mindfulness is a particular way of paying attention.
So, when you pay attention to what's happening right now, in your present moment, you're being mindful.
So mindfulness is a behavior, it's something that you do.
Mindfulness is also a trait.
Some people, just for whatever reason, are more likely to be tuned into their present moment experience, .
To take more information that's directly coming from their senses to think less about the future and the past and more about what's happening right now.
We know actually that people who are like that are less anxious and are likely to have a more positive mood, that's really mindfulness as a trait.
So it can be a state, something that you do right now, or that happens in the moment, or a trait, a propensity that happens in a person over time.
And then there's this particular thing that is central to the way that we teach and practice mindfulness now.
And that's mindfulness as a training activity or another way of saying that is mindfulness practice.
When we practice mindfulness, we take this part of our mind that is aware, that is a portal through which we experience our life and we bring it to bear on something that's happening in the present moment.
And we know that if you do that over and over again, if you bring your attention into the present moment and rest it on something, allow it to remain here.
Over time, the neural systems that manage attention in your brain begin to change.
And you're more likely to stay in the present moment, in a way that affects both what you notice of your experience, how much you pay attention, for instance, to other people.
And also, the way in which you are less likely to be swept away by emotions, so it affects emotion regulation too.
There are a lot of things that happen as a result of learning to practice mindfulness, really learning to practice it.
In our own program, we've given more than 1,000 people, a 6 sub-scale measure of mood and well-being called the profile of mood state.
And we typically find that the reported anxiety, the anxiety score, drops by almost 50%, depression and anger drop by about a third.
And something that this instrument measures as confusion, which is kind of just not having a sense of what you're doing or what's next, also decreases significantly.
So those are just reported as mood states, but that's hardly the most important thing that happens.
Really the most important thing that happens is that people start living their life more fully.
The reward of practicing mindfulness, and the reason why people aren't just interested in it but become nuts about it.
And you probably know somebody who is nuts about it and you want them to like shut up already about the mindfulness, I heard you the last time.
One of the most common comments that I hear from someone who've just finished our eight week program is that I came because I was getting angry or I was stressed beyond what I could handle or I wasn't sleeping.
And what I found is that I was actually able to change my whole life.
I've heard that hundreds of times, literally and that's a little big and a little vague, it's hard to get your hands around it really.
But what happens is that when you're fully embodied, and awake and present in the life that you have, you notice its richness, you notice the people who you connect with and you connect with them better, you notice the sky more.
You're more sustained by and satisfied with the experience that you have.
And when you have a life that's satisfying and full of beauty and meaning and those are things that happen, the fact that you're stuck in traffic really isn't such a big deal anymore.
So mindfulness is a really powerful tool for undoing anxiety.
One aspect of it is just cognitive therapy in the sense that we teach people to recognize the distorted cognitions, the catastrophizing, exaggerations, black and white thinking, and so on that goes along with anxiety or panic.
The other part of it though is learning to feel that emotion of panic or anxiety, to become comfortable with it, which is a funny to say because it's so aversive.
But to be able to just notice it from a neutral point of view, to notice it as a sensation in the body and a kind of energy in the body that doesn't necessarily mean anything, to just view it from a little bit of distance.
And then finally we teach people through this attentional training to actually take their attention, which has been fixated or hijacked by this worry about what's going to happen.
We teach them to take that out of that focus and redirect it towards something that they have learned is stable, and comforting and safe, like the feeling of the breath in the body.
This is my very first MOOC, and so it was definitely exciting for me to get to communicate these ideas and these skills in this way.
Here's the thing.
I've been to workshops.
I know what it's like.
So, my challenge to you is to challenge yourself to identify at least one of the topics that we discussed together that really interest you.
Maybe it was thinking traps and how to use real-time resilience to fight back against those counter-productive thoughts.
Maybe it was the character strengths, information and knowing who you are at your best so that you can leverage those aspects of yourself to overcome challenges and handle stress.
Maybe it's mindfulness.
Whatever it is, I hope that you'll identify at least one topic from what we've discussed together, that you're gonna do a deeper dive into, and not just study it, but also to come up with behaviors that you can engage in, that you're gonna commit to, that are gonna enhance your well-being and your resilience over the next several weeks.
One of the things that I've learned, because I get to teach this stuff all the time, is that depending what's going on in my life, some of these skills become more relevant than other skills.
And so, I also hope that you'll keep yourself fresh on all of the skills that we've talked about so that you have them in your toolkit, so that if something happens in your life where you need one of those tools, it's there for you to grab and use.
On the discussion board, please consider: What are a few of the ways that you're going to continue to apply these resilience concepts to your personal life, to your professional life?
Share ideas with each other so that we're continuing to build our bank of examples and stories and experiences developing our resilience.
In this video, we'll discuss step five of our eight step approach.
Plan how you will end your presentation.
An effective close will leave your audience with an understanding of the key messages and benefits, and impart a call to action.
Remember, it's important to leave plenty of time for questions.
Just as with successful openings, winning conclusions includes several elements.
Of course, there are closing taboos such as announcing the conclusion.
Ending abruptly without conclusion, or reiterating the key points that support your conclusion.
Here is an example of a closing from a presentation that I recently made to a banking client.
I want to leave you with these three important points that you should take away from this presentation.
One, the channel behavior of your banking customers has changed, and the branch is no longer the primary acquisition channel.
Two, the rising industry environment means a disproportioned number of customers will be shopping for new banking relationships.
And three, the time is now.
If you wait to upgrade your digital acquisition capabilities you will lose.
So remember, your presentation closing is just as important as your intro.
Leave them with a clear understanding of the key messages and benefits, and impart call to action.
I would like to invite you to join our talent network and consider applying the skills you're learning in the course at PwC.
You can click and opt into the talent network form linked here on the screen.
Joining our talent network gives you access to special events, and targeted communications around data analytics careers and industry news.
I hope you enjoy the rest of the course.
Last week you covered the important aspects of preparing for a presentation using our eight step approach.
This week, we'll take a look at how your presence, that is the way you're seen and perceived by others, as well as how communication style, both variable and non variable, can affect your message and story.
Communication is much more than the words you're saying.
Your impact as a presenter is dependent on your ability to convey your message effectively.
Communication is a vehicle to share thoughts and ideas.
It's a way to initiate action and inspire others.
Being an effective communicator takes time and practice.
It requires self-awareness and the ability to secure and incorporate feedback on how you come across to others.
When done well, it's foundational to building relationships and your personal brand.
As we review differences in communication styles, you will begin to better understand where presentations can go awry.
We'll begin this week with a look at maximizing your professional presence.
And then examine how the way you speak and position your body can affect your presentation.
This week, we've covered several aspects of communication that are important to the success of your presentation.
Note how verbal and nonverbal communication affect the impact of their presentation.
Spend a couple of minutes observing their body language, and contemplate what works and what doesn't.
Think about the way that they speak.
What effect does their voice have on the audience?
What constructive feedback might you give the presenter?
Be aware of your professional presence, and the impressions you are making, and polish your listening and questioning skills.
The tools and skills we've discussed can be used in many other interactions and conversations, not just presentations.
I encourage you to practice them whenever you get a chance.
This week, we've reviewed the eight-step approach to preparing for your presentation, and the other aspects of communication that have an impact on how your messages are heard and received.
Next week, we'll commence building the presentation itself using PowerPoint.
This week we'll help you get more comfortable building a presentation in PowerPoint.
We'll discuss the different types of PowerPoint decks and when each should be used.
We refer to PowerPoint presentations as decks given their resemblance to stacks, or decks of playing cards.
We'll also explain the difference between inductive, deductive, and abductive types of reasoning for your storyline.
You'll learn the primary elements of a slide and be able to explain how they should be used.
These skills will allow you to own the master version of a deck and to develop an effective presentation.
High quality presentations are important because often times they are the only communication of the value your analysis delivers.
Few people outside your immediate team will see the detailed, thoughtful analysis underlying this important deliverable.
A deck is a product.
It must support and advance the value of your organization, its brand, and reputation.
The aesthetic quality of the deck gives the client or audience a first, and often only, impression of our work.
Consider each deck as a significant opportunity to enhance client relationships and the strength of your brand.
By the end of this week, you will be able to develop an effective, high quality presentation.
You'll learn to employ common tools and tricks in PowerPoint, create a storyboard to structure your deck, synthesize information into clear, effective slides, and finalize your deck for presentation.
Let's dig in then.
Hello and welcome to advanced competitive strategy.
My name is Tobias Kretschmer and I'm a professor of , strategy technology and organization at Ludwig- Maximilians-University or LMU in Munich.
We are about to start a new course and a new adventure.
Advanced competitive strategy consists of seven different modules in which you will learn how you can apply business strategy in competitive situations.
Each one of our seven modules consists of a variety of around 10 different videos all of which include one or two individual quizzes, that are going to let you test your newly acquired knowledge immediately.
And of course, they should also be fun.
There will also be a longer quiz at the end of each module.
So, once you've completed all seven modules, you can also eventually take the final exam.
And please, do check out our forum.
Because it's a brilliant opportunity to connect to fellow students, to build study groups, to openly discuss questions, and to communicate with our wonderful and knowledgeable taching assistants.
Hello and welcome to Write Professional Emails in English.
As part of our specialization, Improve your English Communication Skills, this course will go over how to write a professional email for business related purposes and how to write more accurately in English.
In the next module, we'll practice writing subject lines and general email text.
Finally in module five, we will look at how culture effects how you write emails and how your readers culture affects their understanding of your works.
As we move through the course, you'll learn about all the required parts of a professional email.
You'll practice how to plan your emails for maximum effectiveness and you'll write emails and you'll get opportunities to receive feedback about your emails from other course participants.
That way you and your classmates can learn and grow together at writing emails.
By the end of the course, you'll be able to write emails in English with more accuracy and confidence.
I hope you're excited like me to get started.
I look forward to your participation in this specialization and in my course, Professional Emails in English.
Hi everybody, welcome to our course, Write Professional Emails in English.
Since this is our first lesson, we'll take the basic parts of a professional email and focus on some thing you should do and somethings you should avoid.
By the end of this lesson, you'll have a good understanding of how a basic English email is organized.
The first thing I want you to think about is your current email, what does it look like?
Is it business appropriate?
In other words, is this an email you can use when applying for a new job, or making an important business contact?
So, here's your first do.
Make sure you have an email address that is professional looking.
My personal one looks something like this, but I know it's not suitable for business communication.
You'll notice my first and last name in the email.
I recommend that you have one similar to this.
You don't have to include your full name but something that readers can easily verify as you should be fine.
Now, let's look a little bit at the four basic of an email and how to write them.
These four are subject line, the greeting, the email text and the closing.
This may seem overly simple but looking at each part and examining it closely is well worth the effort.
We always write a subject line our heading, this is the first we always do when writing an email.
It should introduce the topic of the email and get readers mind's focus.
In our first example the topic is unclear.
The subject line should be as clear and as specific as possible.
Try to imagine that you are receiving an email, which subject line has the clearest message?
Now, here's something I don't want you to do.
Don't forget about the basics of writing in English, like spelling things correctly, and getting your grammar, punctuation, and capitalization right.
We will go over this in more detail later in the module.
Greeting should be formal and not too familiar.
If you are certain about at a few details of your reader, this makes things easier.
For instance, if the reader is a man, then call him as Ms.
But I've had students addressed emails to me after meeting me in class, mind you, and still call me Mrs.
Landers was my mother's name and it certainly can't be used to refer to me.
Look for a person's position at the company, university or office, if possible, and mention that in the greeting.
For instance, dear Professor Lee, or dear Director Smith.
If gender is the only information you have about the reader, then dear sir or dear madam will work.
Some people use to whom it may concern.
I've used this on letters of recommendation for students.
You can also use it if you are addressing a company, like FedEx, a bank or an airline.
If you're addressing a group, you could use greetings like these.
Here's another don't.
You aren't writing a book here avoid long emails all together.
You want the reader to read all of your texts so you should only include important information, essential details but remain brief and to the point.
If possible, keep the email texts to one or two paragraphs and no paragraph should be more than three for four sentences long.
If you're asking your reader to do something for you, keep that to one or two requests.
I tell my students this all the time.
Another thing I want you to avoid Is sounding like you are complaining or blaming your reader.
This puts the reader on the defensive, it makes them less likely to do what you're asking of them.
If you ask about something that is incomplete, a trick I use is what I call, self blaming.
And here's something I always want you to do, always add a word to thanks, if you make a request for information or action your asking somebody to do something for you.
Even if it's their job to do it, no busy person likes to feel like you don't appreciate their effort.
The final part of an email is your closing.
This is very short and simple.
Just add regards or best regards and leave it at that.
This is a professional email so no more than that is needed.
This is followed by the signature, your first and last name only, no title, just your name.
Add any contact information your reader will need to communicate with you.
They already have your email address, but if they need anything else To easily contact you, put in here.
Finally, I would like to add a word of caution here.
This is our last don't.
Never address your email to your reader until you have written it and checked it over, considering all that we've been over in this lesson.
It's too easy to hit send by accident before you've carefully considered how it will sound and read at the other end.
A lot of the information you'll get through this course is based on North American standards.
However, not all cultures communicate in the same way.
So the last check you must do before sending an email is to consider how your reader might understand what you've written.
We will look closer at this in our final module.
So, let's review what we've learned in this lesson.
First, there are four parts to a professionally written email, the subject line, the greeting, the email text, and the closing.
Do have a professional email.
Do make your subject line very clear and brief.
Do add words of appreciation and do consider cultural differences between you and your reader.
Now don't forget about spelling, grammar, punctuation and capitalization.
Don't write a book.
Email texts should be limited to one to two paragraphs and two requests.
Don't complain or blame.
Don't address the email until it is written and checked carefully for all the things we've learned in this lesson.
I hope you enjoyed this first lesson and feel confident to write your first email in this course.
Try and apply as many of the dos and don'ts as we've covered here.
I'll see you in our next lesson.
Hi, and welcome to this lesson on organization, style, and editing choices.
Getting these parts right can make your professional emails easy to read and understand.
Maybe it's poorly organized, sometimes it's so full of unnecessary information that it's difficult to decide what's important about the email.
Now that you have the basic elements of an email, I want to focus on how to be sure that the information you include is brief and clear.
That way the reader can understand, and respond if necessary.
First, let's look at the value of being brief.
People often try to put too much information into what they write.
Therefore, it's important that you carefully think about your most important elements in your message.
Here's the quote that can keep us focused on how to write emails.
A wise woman once said, writing is 1% inspiration and 99% elimination.
Have you ever thought about what it means to be cool?
Not cool as opposed to hot, but cool, as in people you want to be around and do things with them.
I have thought about this a lot, why?
Other times, not so much.
I wondered, why?
What people often see as cool is when other people look original and different.
Now, not everybody thinks the same people are cool, but that's the common element.
When you decide to just be yourself without worrying about what others think, that's when you begin to be cool.
How does this apply to email?
The best way to write, and remain brief is to stick to your own words and your own message.
When you use unnecessary words, you mess up the message.
When you right an email, sometimes leaving out the extra words is as important as the words you choose to leave in.
We often add adjective, and adverbs, and filler words which are not necessary.
Let me say that again, at this time with more words.
Very often when we write, we put lots of extra words, like adjectives and adverbs, which when you really think about it, are very much unnecessary.
Both sentences have the same message, but the first had less than half the words.
This is how you make a message brief and clear.
When you're writing, act like you're talking to someone you want to become friends with.
In the start of a relationship we're very careful about what we say.
Afraid of doing something wrong, we're more cautious with our words.
Look at economics, when there's a high supply of a product, the price is very low.
Things that are rare, like gold and platinum, they're expensive.
Think of words in your email in the same way.
Don't use the passive voice.
Not passive, rather precise.
Let's look at the next example.
Which one sounds more precise?
The second one is the active voice, and is always clearer.
Here's the difference.
When the verb is active, the subject performs the action.
When the verb is passive, the subject receives the action.
Which one is the active voice?
The first one is active.
Which is the active here?
That's why it's more clear.
Now, let's focus on clarity.
Your goal here is to be clear.
When you write, make sure you're keeping things in order.
When announcing a meeting or an event, for instance, you will begin with the name of the event.
Finally, exactly where is this meeting?
This can even be included in the name of the event.
The key here is to be precise with the most important information.
After you write the email, sit back and look at it carefully.
Imagine that you're getting the same email, will it give you all the needed information?
Is it easy to understand?
Finally, some words to avoid, must, should, demand, require, necessity.
Go back to the idea I used earlier.
Are these words you use when you're first meeting someone you want as a friend?
Are you likely to become friends with someone who starts to use these words towards you?
Let's look at a few examples to see which ones are clear, and easy to understand.
In these two examples, look at the first one.
The paragraphs are short, and the entire email is brief.
In the second one, look how crowded with text, and overwhelming it is.
I get emails like this all the time, and I rarely read them.
If I want to read a book, I'll buy one, or download something to read.
So to recap, we looked at how it's better to be brief, and be your own editor.
Take a short break after writing, and then come back and really concentrate on words that can be taken out without losing or changing the meaning.
Finally, we looked at words to avoid.
We want to be certain to keep from the demanding, or using forceful words in our emails.
Keep in mind how it would feel to you if someone emailed you, and said, you must do something.
You should now be comfortable applying these rules to your emails.
In our previous lesson, we looked at some of the basics of an email and at ideas to keep your emails brief and clear.
We also looked at some of the words we have to avoid.
Now, let's turn to some of the more common capitalization and punctuation errors in English.
So punctuation is the little marks in written language, like a period or common.
Just like road signs in any country, punctuation rules and symbols may be different.
So, it's important to understand the rules when your writing in English.
As for punctuation, I want to focus on six errors that are most common and easy to see quickly.
These six are the apostrophe, the exclamation point, commas, the dreaded semicolon, quotation marks.
Before we go into the details of each of these, let's quickly test your knowledge.
Now, let's get into the details of punctuation.
It is used for possession, like Suzi's laptop or Gerry's address.
Second, the exclamation point is one of the most overused symbols in punctuation.
Frankly, it should almost never be used in professional emails.
It should never be used more than once.
My nephews use these in messages on Facebook, but I almost never use them at work.
If you have time, could you pick up the coffee and snacks on your way?
If you pause, that is where a comma should go.
Look at how I wrote all of the FANBOYS.
Or for items in dates, except the month and day, like October 10, 2011 and for titles in names such as Philip Hollingsworth, MD.
This is just basic information about commas, but you can find more information all over the internet on this topic.
Fourth, this is another thing I tell my students all the time.
The semicolon is used wrong more than it's used correctly.
Even if I'm slightly unsure, I find a different way to write my thought.
But if you must use one, this is one of the main rules from the Owl website.
These are not to be used for emphasis, like in this example.
They're only supposed to be used when you're telling your reader exactly what someone said.
Take a look at this example.
The punctuation for using them is really tricky.
Again, if you absolutely must use them, you should consult the online writing lab at Purdue.
If you knew your reader well enough to send a text, you would not be sending an email.
Here's another example of how not to use the semicolon in an email.
Don't forget to add it at the end of every sentence, unless it's a question.
So we've now looked at how and when to use the apostrophe, not over using the exclamation point and where to place commas.
We've also learned about that semicolon, how to use quotation marks properly.
And finally, not using emoticons or text message type stuff in our emails.
So in the previous video we covered punctuation.
For this we will look at three main areas, proper nouns, people and their titles, and media titles.
Capitalization is important for two reasons.
First, you don't want to offend your readers by not capitalizing their name, company or city for instance.
Also, when you don't pay attention to the rules of capitalization, your reader has a negative idea about you when they see your errors in your email.
The first rule is to use capital letters at the very beginning of anything you write, and right after a period to begin the next sentence.
If a brand name like iPhone or eBay is at the start of a sentence, capitalize it anyway.
Adjectives made by using proper nouns also take capital letters.
Things like French wine, Italian sport cars, or Colombian coffee are examples of this sort of adjective.
People can be proper nouns.
This is different when you write the president will travel to California.
Do not confuse official titles with occupations, for instance, coach Ellis or Manchester United team owner Malcom Glazer.
Other things that are capitalized include newspapers, like the New York Times, or the London Herald Tribune.
Or magazines like Vanity Fair and Time.
In all of these forms of media, the prepositions are not capitalized.
For example, Lord of the Rings.
One exception of this rule is that you need to capitalize the preposition if it's at the beginning of the title.
We looked at proper nouns, people and their titles, and media titles.
You should now be more comfortable with capitalization and punctuation.
Welcome our second module of Writing Professional Emails in English.
In this module you'll learn how to write effective subject lines and email text.
This will be especially useful for you.
Because it will provide with examples of phrases and sentences that you can start using in your emails right away to improve your overall professional email communication.
Before we start, can you guess how many emails an average business person receives in a day?
For CEOs, senior executives, that number doubles at least.
These numbers are pretty high, but how many of them do you think are actually opened and read?
Probably not all of them.
So it's important that your subject line catches your reader's eyes so that they open and read your email.
In order to make your subject line stand out they need to be brief, clear, and direct.
Let's look at this in more detail.
We talked about keeping your emails brief in our previous module.
But it's also just as important to keep your subject lines brief.
Most experts will recommend that you use 50 characters or less.
However, many people now use their mobile devices to check emails which means some of subject lines could get cut off.
That means the best subject lines for all devices would be about 25-30 characters, or 3-5 words.
The next thing we'll focus on is how to keep your subject lines clear.
For this part, I have two tips.
1, include keywords related to your topic in the subject line.
And 2, put important words at the beginning.
Let's look at specific examples to practice these two points.
Imagine a situation where you need to introduce yourself.
Use the word introduce or introduction in the subject line with your name, like these examples.
If you're trying to introduce yourself in order to apply for a job, make sure those words are clearly stated.
This subject line may seem a little plain and boring, but hiring staff and managers sometimes use these exact words to filter their emails and find applicants.
So keeping it clear and simple like this can be enough.
Or maybe you would like to meet someone.
Since you're requesting someone to meet with you, use those words in the subject line.
Do you notice that all these examples include keywords showing the purpose of the email and those important words are at the beginning of the subject line?
The final part we will look at for subject lines is how to make them direct.
One way of doing this is by including specific details.
Let's go back to our job application situation.
If you have a degree or certificate directly related to the job you're applying for, include it.
If you know the exact position, include it.
Some companies have identification numbers or letters connected with the position.
So if you know the exact job ID, include that.
For their subject lines, make sure you use action verbs.
Take a look at these examples and how they introduce the action verb at the very start.
You can also be more specific by including the date and time.
Since this subject line is at 49 characters, you can make it shorter like this.
You don't have to write a complete sentence as long as the subject line has all the keywords and keeps a clear message.
You can also include your company name rather than using pronouns.
If you have the information, being more specific and direct for meeting requests can also be helpful.
Compare these examples with the one we looked at earlier.
And when canceling something, it is essential that you include specific information so the reader doesn't get confused about what you are canceling.
One last point I would like to add is to use the same capitalization rules as media titles.
This is something we learned in the last module.
Do you remember that rule?
So let's recap.
We learned that subject lines need to be effective in order to catch the reader's eye and be read.
In order to do that, you need to know that subject lines need to be brief at 50 characters, but much less for mobile device readers.
And that subject lines need to be clear using keywords at the beginning.
You also learned that direct language using active verbs and important details make subject lines much more attractive as well.
Now some experts say that you shouldn't write the subject line until you've completed the text of the email.
However, I would like to recommend that you start with the subject line for two reasons.
1, you have a clear direction for how your email text should be written.
And 2, you will never leave the subject line blank, which is a common mistake a lot of email writers make.
I look forward to seeing your new and improved subject lines in your next email assignment.
Hi everyone.
And welcome back to Writing Professional Emails in English.
In the first lesson of this module we learned about writing subject lines more effectively.
We learned that your subject lines need to be brief, clear, and direct.
In this lesson, we're going to talk about how to write the email text.
Your email text should be made up of three essential parts, the introduction, the development, and the conclusion.
Today we're going to introduce you to each of these parts, by showing examples and providing strategies so that you can write them in a clear and effective way.
Let's start talking about the first part of an email text, the introduction.
The introduction shows the reader who is writing and what the email is about.
It is expressed in the first sentence of your message.
The introduction is one of the most important parts of email text because it gives the reader a first impression of your email message.
So, to write the introduction, you need to consider the author and the purpose of your email.
Let's talk about each of them separately.
The author is the writer of the email.
Grammatically the author's the subject of your first sentence.
There are two ways to write the author.
First, by writing the name, position, or organization.
Or second, by simply writing a pronoun.
Your choice is going to depend on how many times you've written to your reader.
If you're writing an email for the first time, it's important that you write the actual name, position, and organization of the author.
Let's look at an example.
This is the first email between this writer and the reader.
This first sentence is appropriate because it includes the name, position, and the organization of the writer to clearly show who the author is.
However, if it is not the first time you're writing to the reader of your email, your topic can be presented simply with a pronoun.
In this sentence, the author is expressed as pronouns.
This is not the first time the parties involved in this conversation are talking, so there's no need to include the name, position, and organization.
Now that you're more comfortable with how to begin your introduction, we're going to talk about the second part of the introduction which we call the controlling idea.
The controlling idea is a statement about the author and talks about what you need to accomplish with your email.
More specifically, the controlling idea of your introduction expresses the purpose of your email.
Let's take a look at the previous example for reference.
In this sentence, the words following the subject are the controlling idea of the introduction.
The purpose of an email appears as part of the controlling idea.
So, now let's move on to our second topic which is email-text development.
As the name suggests, the development is the part of the email where you actually develop the purpose of your message in detail.
The best way to organize your email text development is by asking WH questions about the topic.
Let's look at the following email.
In this email, the second sentence answers the question, how often will I be sending catalogs?
And the question for third sentence would be, what is the most important part of our catalog to our customers?
So, now you know that in order to write a clear and effective email development, you can plan your email text by writing down the WH questions.
Now it is time to introduce you to the conclusion.
The conclusion of an email text normally appears is one sentence.
And it's content is normally a show of appreciation or positivity.
Expressing these ideas involves choosing from a list of verbs that are helpful to make these ideas clear.
First, to write a show of appreciation, you need to use verbs and phrases that express gratitude.
These include words like thank, appreciate, or the phrase be glad about.
These words help the email text end on a positive tone, which helps our reader have an optimistic impression of your email.
The conclusion, in this email, shows a clear example of how to show appreciation.
In this case, the word thank was used.
But if you'd rather use a positive wish, the most common verbs are hope, with, and the phrase look forward to.
For example, this example uses the verb hope.
This verb is very positive and helps you build a relationship with the reader.
It's also possible to combine a show of appreciation and positivity with the same conclusion.
Being optimistic is an important aspect of American culture, so including these verbs demonstrates cultural confidence which can help your reader have a positive view of you.
Let's recap.
In this particular video, we've covered the main components of an email text.
We talked about the introduction which should include a clear author and the controlling idea.
The development, which should consist of answers to WH questions.
In the next modules, we're going to look at emails used for specific business purposes.
We're going to show what the most common types of emails are and specific language to use for each type.
So that you can achieve your business goals with even more precision and effectiveness.
I'll see you in our next module.
Hi, and welcome to module 3.
Over the next couple of modules, we will look at different types of emails and how they should be planned and written differently depending upon their purpose.
Our first lesson will be on understanding the basic purposes and approaches to these two types of emails.
And then our next lesson will focus on the key language and how to write these emails.
We're going to start with introduction emails.
Remember a time in your life when you met someone that's now important to you?
How did that feel and how did that change your life?
Well, introduction emails can change your life if they're written the right way.
So lets find out how to do that.
In introduction emails, you may be introducing yourself or two business contacts that you think would work well together.
Either way, you want to follow a few simple rules.
As we said in an earlier lesson your subject line needs to be clear and to the point.
Let your reader know that you think the introduction will be good for them professionally.
In the body of your email, state clearly who you are and what value you can add to the reader after you meet.
How do you or your two contacts make a good match?
For example, state clearly what skills or abilities you have that will work well for your reader, or why meeting you would be good for them.
The same rules about the subject line and greeting are true.
Announcements are a way of telling other professionals about something that's new to them.
It may a product or service you offer, maybe it's the opening of a new office or change of location.
Be very clear about information you're providing and make sure it's accurate the first time.
Nothing looks less professional than having to send a correction email because you goofed up the first one.
If you're in the process of setting up a meeting or you sent out an announcement of some kind, people may request additional information.
Look closely at any questions and be sure you do not send an email with unanswered questions.
Try to think of any additional information people might need as a result of the questions or new ideas in your response.
We've looked at two different types of emails and how to keep them as clear as possible.
For both types of emails, make sure that the subject line clearly reflects the purpose of the email.
Introduction emails should include why it is important to get to know you, or the other business partner.
You should now have an improved idea of how to write introduction and announcement emails.
Over the next two lessons, you'll learn how to say things more politely, and more sincerely in order to make requests and apologize in a professional way.
In this lesson on making requests, we'll focus on expressions using please and question forms using could and would.
You'll also learn about how to use the expression would you mind or would like.
Let's start with request emails.
In business and overall professional interactions with people, making requests will be one of your top reasons for communicating through email.
There are many situations where you would need to make a request.
You could be asking for additional information on certain processes, employment opportunities, or even simply asking for directions to their office or factory.
Maybe you're asking them to send you certain files, or documents or perhaps you want to request a meeting with them.
Whichever the case, since you are asking them to do something for you, the language you use needs to be respectful and polite.
The easiest way to make your sentences sound polite is by adding the word please.
In America, children learn to use this word from a very early age.
And is the most commonly used word when making polite requests.
Let's look at the same examples, but this time in a question form.
Could you send me your resume?
Could you meet me today at 3 PM?
Would you give me directions to your office?
And if you want to be even more polite, you can add please to these questions.
Look carefully at where I put the word please.
Could you please send me your resume?
Could you please meet me today at three?
Could you please give me the directions to your office?
Where did I put please?
That's right, it's right before the verb.
Now let's look at two more polite expressions that you can use when making requests.
These expressions also include the word would.
Would you mind sending me your resume?
Would you mind meeting me today at 3 PM?
Would you mind giving me the directions to your office?
When you use this expression, notice that it is used with a verb in the I-N-G form.
In grammatical terms this is called a gerund.
Would like is the polite way of saying that you want something.
So any sentence you use with want can easily become more polite by switching the word want with would like, let's look at some examples.
What would be the polite versions of this sentence?
If you remember from our first module, I mentioned that you could make up to two requests in one email.
How should you write the second request?
Well, there are two ways to do this.
The first is to just number your requests like this.
Or you can write your requests within the paragraph without using numbers.
Simply write the second request with the word also.
Let's look at the following examples.
Could you meet me today at 3 PM?
Again, it's right before the verb.
Now that you've made your request, how do think we should conclude?
That's right, we need to add our thanks or words of appreciation.
If you want to keep things simple, you can just write thank you, or sincere thanks, or I appreciate it.
However, if you want to be more polite in your thank you message, you can add the reason why you're thankful to the reader.
In this case, you just extend the expressions we just looked at like this.
If you would like to know other ways to say thank you, check the resource page for more detailed expressions.
Now, let's recap.
In this lesson we focused on what kind of polite language to use when making requests.
We learned how to use expressions like please, could, would, would you mind, and would like.
And we learned to use the word also when writing our second request.
Before completing our email text, we learned that we need to add some words of appreciation that started with thank you, or I appreciate.
I'll see you in our next lesson on making apologies.
In our previous lesson, we learned how to write requests in your emails, and starting using more polite language to do so.
In this lesson, we're going to learn how to write apologies in our emails.
Before we start, let me ask you this.
In English, there are many ways to apologize and these expressions are used differently, depending upon how responsible you are for a certain situation.
Because of that, we're going to focus on the most common expression, I'm sorry.
But you will learn three different ways to complete your apology depending upon your level of responsibility in the matter.
The three different expression we'll learn are I'm sorry if, I'm sorry that, and I'm sorry about.
Although these three expressions look very similar, they're used for different situations, and can be very useful in their own way.
Let's start learning more about them.
First let's look at I'm sorry if.
Since email communication is not as simple as it appears and mistakes can happen for both writers and recipients, there are situations in which it's difficult to determine who was in fact responsible for the mistake or unfortunate circumstance.
In other words, you're not sure of your level of responsibility for a mistake.
In this case, write an apology using I'm sorry if with your description.
To illustrate, let's take a look at the following examples.
This apology shows how the author of an email is not sure about his or her level of responsibility for the situation and the recipient could be responsible as well.
By using this type of apology, the reader will also get a chance to realize that they should double check if he or she has some responsibility for the situation.
As I mentioned in our first module, it's often better to apologize first, and take the blame rather that to give the impression that you are blaming the other person.
Now let's talk about the second expression, using I'm sorry that.
We use this type of sentence for writing an apology when we are 100% sure of our responsibility for a situation.
Again, you will write I'm sorry followed by the word that plus a description of the mistake.
Let's take a look at the following examples.
In these cases, it's important to follow up with a clear description of the actions necessary to correct the situation which can include alternative dates in the case of this example.
For instance, the next sentences could be I have included the correct file in this email.
Finally, let's look at the expression I'm sorry about.
This expression is used to write apologies for small slip-ups or errors.
These are small mistakes which require no more than a few words to be described and corrected.
This method is particularly useful for situations in which you do not need to describe an unfortunate event in detail whether because you and the recipient are aware of it, or because it is just a small slip up.
In this example, the author gave the incorrect address to the recipient and it is apologizing for it.
Because this problem can be easily fixed, it wasn't necessary to describe the mistake in detail, and keep the apology brief.
You can always use words such as inconvenience or delay in place of confusion.
So, we've learned three different ways to say I'm sorry.
The first was, I'm sorry if, with the description to use when either party may be responsible.
The second was, I'm sorry that, with the description for when you know you made a mistake.
Writing apologies is essential to maintaining good relationship between writer and recipient.
More specifically, it is the first step to correct communication breakdowns which could mean the difference between a successful business relationship or a lost opportunity.
Well, this is it for this module.
In our next module, we're going to talk about how cultural differences can affect email communications.
I'll see you in our next module.
Hello everyone, and welcome to our final module.
Over the past several weeks, you've improved your understanding of professional emails and your use of key language for different types of emails.
Have you ever had an uncomfortable exchange with someone from a different country than you?
Well, in this lesson, you'll have the opportunity to reflect on your own cultural communication habits as well as think about how to understand your readers cultural standpoint.
To do so, we'll look at the difference between high context and low context communication in this lesson.
And think about some other factors that could change how you write your email, such as age and gender, in our next lesson.
You will also be introduced to some common cultural differences from around the world and see how these might affect communication in emails.
By the end of this lesson, you'll be able to recognize communication style differences in emails and write more culturally appropriate business emails.
Let's start off by taking a look at this email exchange.
I haven't been overseas yet.
My trip would be 50% tourism and 50% studies.
I wanted to do a crash course to get a certificate for EFL teaching.
Can you tell me where I can find one?
I'm interested in ESP.
New York City to Atlanta, Georgia, and New Orleans to Los Angeles, and Texas, San Francisco, Miami, and then finally Brazil.
I don't have a lot of money, and so I'm afraid of traveling in bad weather.
>> I've only met Rodrigo once at a conference, but this email seems way too personal, and I'm not really even sure what the real purpose of this email is.
I don't even know if I should respond or not.
What is low context communication?
Well, low context communicators are used to straight forward, concise, and efficient ways of communicating.
In general, North America and Western Europe are considered low context cultures.
In the case of our writer Rodrigo, his style reflects high context communication.
Communication in high context cultures tends to be non-explicit and include more descriptive language.
Emails also tend to be longer.
The Middle East, Asia, Africa, and South America are some examples of high context cultures.
Let's look at another example of this type of cultural exchange.
I wanted to touch base with you about the meeting we had last week.
You mentioned your boss might be interested in purchasing our new product, and I wanted to know if you talked with him about it.
Let me know the latest.
I'll talk to you soon.
Since formality is extremely important in Korean culture, the recipient of this email might feel offended by the lack of it in the email.
In this case, we have the issue of a low context culture writer mismatched with a high context culture reader.
When you know the country where your reader's from, considering whether they are high or low context communicators, is the easiest way to consider cultural differences.
If you're not sure, you can easily do a Google search about these two types of communication styles.
What about you?
Now that we know the difference between two styles, here are some tips for communication.
Low context communicators interacting with high context communicators should be aware that status and identity may be communicated non-verbally and require appropriate acknowledgment.
And that building a good relationship can contribute to effectiveness over time.
High context communicators interacting with low context communicators should be aware that efficiency and effectiveness is achieved through focusing on tasks.
And the direct questions and observations are not necessarily meant to offend, but to clarify and advance shared goals.
Let's look at this email interaction email again.
You will notice the email starts off with a personalized introduction and the overall language is more indirect and polite.
Do you notice the expressions like, would like and would you mind that we learned in our earlier lesson?
Making those small changes completely transformed the tone of the email, and is now less likely to cause any misunderstandings.
So let's review what we've covered in this lesson.
You've learned the difference between low context and high context cultures and how that can influence the style of communication.
You've also been given some tips on how to communicate with people from the opposite communication context.
Now, depending upon the relationship you have with the reader, you may not need to make a lot of changes, even if your from a different communication context.
However, knowing how to distinguish the different styles and revising your emails to match those styles will create better overall communication and strong relationships.
I'll see you in our next lesson, where we'll talk about age and gender considerations.
Hello again, and welcome to our second lesson on cultural considerations.
In our last lesson you learned the difference between low context and high context cultures, and how that can influence the style of communication.
In the lesson, we're going to consider how age and gender might affect communication.
Now, in my class, I have some students that are 18, 19 years old, but they still call me Jerry, and I prefer that.
This is also common in other classes here at the Language Institute.
In America, age does not play a crucial role in how you address someone.
Here, other things influence how you may call someone.
But if a student had never met me before and was sending me an email for the first time, I may feel uncomfortable if he called me Jerry rather than Mr.
So what about your culture?
Does age affect how you address someone?
Are there certain words you would use to address people older than you?
Let's look at this example of an email written by a German man to an American man.
George Smith, I hereby would like to make the next event within the framework of the lecture series Introduction to Business Marketing.
Seth Cohen will talk with us about marketing basics, products, promotions Marketing strategies and E-marketing.
Cohen will instruct us on executing marketing plans, the five P's of marketing and the systematic strategies of marketing.
Please find attached the flyer with more information about tomorrow's presentation and to the other lectures in this series.
Please do respond to this email and kindly let me know whether or not you will be able to attend this lecture.
But titles and attention to detail are sometimes much more important than typical American communication.
He'll probably think I'm too informal or think I don't know how to write.
>> Because every culture is different, the best way to approach age considerations is to be respectful and polite whether the person you are writing is older or younger.
if you know the gender, or use official titles if you know them.
I got teased the other day by my students because I didn't know who Kim Kardashian was.
In America, gender usually does not play a significant role in how we communicate with each other.
However, in your culture or your reader's culture, gender can make a huge difference in how you interact.
If you don't know enough about your reader's culture, the best thing to do is keep things gender neutral by avoiding gender bias thoughts or expressions.
And again, if you don't know the gender of your reader, always use greetings with titles rather than Mr., Ms., or Mrs.
Take a look at the following email.
This email was sent by Michael, who is a 50 year old man, to Susan, who is a 22 year old woman.
I want to ask you if my proposal looks good.
I don't want the boss to think I'm insensitive.
Peace!
To recap, we've considered age and gender as some other possible factors which might interrupt understanding with an email communication in this lesson.
It's always important to consider your audience when writing any type of email, but it is especially relevant in a business context.
In module one, I asked you to read through your email before sending it out.
When doing so, think about all possible factors that might effect the meaning of your email.
Throughout the course, we've talked about the basic parts that need to be in an email, as well as some editing basics.
We've also looked at key language for various types of emails, and now we've talked about cultural differences.
All of those parts need to be considered before clicking that send button.
I hope you've gained enough knowledge of professional email etiquette.
And I hope you've had enough practice writing in English to have many successful business interactions through email.
It was great having you in my course, Writing Professional Emails in English.
Welcome.
I'm going to give you now a quick introduction of my course, Functional Programming Principles in Scala, and tell you how we are going to organize it.
As usual, the course will consist of a sequence of videos which will introduce the elements of the course one by one, and the videos will also have quizzes where you are asked to fill in some questions.
Those questions could be multiple choice or also, quite often, we ask you to program something.
After the quizzes, you will always see the answer in the videos.
Besides the quizzes, there are also assignments.
And if you pass the assignments, then you will get a certificate at the end of the course.
The quizzes, by contrast, they are just for your own education.
There's a timeline for the course.
You can expect a new set of videos every Tuesday morning, and including a new assignment.
And you will have one week to hand in the assignments, or the assignments will have to be handed in Monday night the following week.
We're going to use for the programming in the course the Eclipse, IDE, Integrated Development Environment.
There's also another tool we meet for handing in the assignments that's called SBT, the Scala Build Tool.
Okay.
Once you are on the site, the first thing you could do is go to Tools Setup.
Here, you'll see detailed setup instructions how to setup Eclipse and SBT for all the major operating systems, Windows, Mac OS and Linux.
You could also simplify your life simply by looking at one of the three videos that can tell you exactly what to do to get started.
Once you've done that, you could go next to Assignments, getting, going to get started in the assignments.
That's essentially takes you through the steps of drafting an assignment, drafting an, an exercise submitting your solution to the assignment so that then when we start at the real assignments, you already know all the mechanics for that.
That's all there is to know for now.
Hello, and welcome to my Programming for Everybody course on Coursera.
My name's Charles Severance and I'm a Clinical Associate Professor in the University of Michigan School of Information.
You don't need to be a math expert.
If you can add, subtract, multiply, and divide numbers, you are ready to take this class.
But I don't just want to teach you the Python programming language.
First, I'd like to teach you how to take a programming class.
Perhaps you've even started to learn programming using Scratch or Minecraft.
And programming classes can be challenging.
My second goal is teach you how to mentor others, to help them learn programming.
Because if we're truly going to achieve programming for everybody, we need lots of mentors.
Even in this class, you will learn a great deal from the other students and Community Teaching Assistants.
And one-to-one interaction is really important.
Especially when learning complex skills like programming.
My third goal is to give everyone a kit of free and open materials so that anyone who's a teacher can teach a version of this class locally.
The book is free.
The PowerPoint files are free.
The video and audio materials are free.
And the autograder that I use in class is also free.
I provide you a link to our Open Michigan website where you can download all the materials for the class.
I would like to see the textbook for the course also made available in many different languages as well.
To sum this all up, I see Programming for Everybody as much more than a single class, I want this to become a movement that creates an expanding open ecosystem that brings us all closer together.
And helps us move towards a world where programming is truly for everybody.
See you in class.
So here we are at Mountain View, California.
>> This is, so that's Sue, our intrepid lead TA that's helped so much over the years of Internet history and Python for infomatics.
So I'm just going to kind of show you everybody.
Yeah.
So that is the world's record for office hours that we've ever had so far.
Hello, and welcome to my Programming for Everybody course on Coursera.
My name's Charles Severance and I'm a Clinical Associate Professor in the University of Michigan School of Information.
You don't need to be a math expert.
If you can add, subtract, multiply, and divide numbers, you are ready to take this class.
But I don't just want to teach you the Python programming language.
First, I'd like to teach you how to take a programming class.
Perhaps you've even started to learn programming using Scratch or Minecraft.
And programming classes can be challenging.
My second goal is teach you how to mentor others, to help them learn programming.
Because if we're truly going to achieve programming for everybody, we need lots of mentors.
Even in this class, you will learn a great deal from the other students and Community Teaching Assistants.
And one-to-one interaction is really important.
Especially when learning complex skills like programming.
My third goal is to give everyone a kit of free and open materials so that anyone who's a teacher can teach a version of this class locally.
The book is free.
The PowerPoint files are free.
The video and audio materials are free.
And the autograder that I use in class is also free.
I provide you a link to our Open Michigan website where you can download all the materials for the class.
I would like to see the textbook for the course also made available in many different languages as well.
To sum this all up, I see Programming for Everybody as much more than a single class, I want this to become a movement that creates an expanding open ecosystem that brings us all closer together.
And helps us move towards a world where programming is truly for everybody.
See you in class.
So here we are at Mountain View, California.
>> This is, so that's Sue, our intrepid lead TA that's helped so much over the years of Internet history and Python for infomatics.
So I'm just going to kind of show you everybody.
Yeah.
So that is the world's record for office hours that we've ever had so far.
In this video I'm going to talk about how to install R studio for the Mac.
It's a very simple process and it only involves just a few steps.
The one thing I'll say though is that you must have R already installed before you can install R studio.
So once you've installed R already you can go to the RStudio web site, which is rstudio.com.
And you can see down here on the lower left, there's a green button that that directs you to, to kind of download RStudio.
So here there's two versions of RStudio, Studio that you can download.
One is for the desktop and one is for the server down here.
So you just want to download the desktop version.
So that's this button right here.
So the website should detect automatically what type of operating system you're running.
So here I'm running a Mac, and so it recommends this Mac OS X version, so I'm just going to download that right now.
And you'll see the download meter go.
Once that's finished downloading you can go to the Downloads folder, and it should be the leftmost thing here.
And then just like any other Mac application, all you have to do to install it is drag it into the Applications folder, so I'm going to do that right now.
So I can just go into the Applications folder here find RStudio, double-click on it.
In this video I want to talk about two things.
So you can see I've got R started up here and the first thing you're going to want to do is figure out what your working directory is.
Because the working directory is where R finds all of its files for reading and for writing on your computer.
So you can find out what your working directory is currently set to be by using the getWD function.
Now it, the reason why it's important to know and to set your working directory, is because when you read data or when you write things out, using functions like Read or Write CSV they will be read or written to your home, your working directory.
So for example if I do something like read.csv I want to the read let's say mydata.csv.
If the file is not in my working directory you'll get an error one that looks much like this because it can't find the file in the working directory.
So one possibility is that you can, if you know where this file is, you can move it to your working directory.
So I can go to the file menu here and choose Change dir.
And I'll go to my desktop here.
So now if I type DIR, I'll get a list of the files that are on my desktop here.
So now I can see read.csv and then mydata.csv.
You can see that the data will be printed to the console because now it can find the file in my working directory.
Anytime you download something from the website or create a new file it's probably best to store it all in one folder so that you don't have to be searching all over for it.
That way you can always set your working directory to be that, to be that directory and not have to worry about changing it.
So I'm going to minimize R here for a second.
I'm going to create a folder on the desktop, called I'll just call it Coursera.
And then I'm going to use this folder for everything that I do in this course.
So if I go back to R here, I can say change working directory again, Change dir, and go to Local Disk.
Now this folder is on my desktop, so Desktop, and then it's Coursera here.
So now if I say getwd and see the working directory has changed to this Coursera folder.
So one of the things you're going to have to do a lot of in the class is to write R code.
In order to write R code, you'll need to be able to use a text editor.
So you can load up the text editor by going to File and saying New Script.
And this will give you a blank window that you can use to write R code.
So I'm going to write a simple function here.
It's going to be myFunction.
And all it's going to do, it's going to simulate some normal random variables.
It's the, I can't find the function because I haven't loaded it into R yet.
If I type LS, you'll see that there's nothing in my workspace right now.
Well there's two ways if you just have a little bit of code like this function over here, I can click into my R editor.
And just hit Ctrl+A to select all and then Ctrl+C to copy.
Then I click back into the console and I can hit Ctrl+V to paste.
If I do it again, it'll give me a slightly different number because it'll simulate a different set of numbers.
The other thing you can do is go into my R editor and you can go to the File menu.
And that loads the, all the code that is in this file.
Of course, that's just the myFunction, so I haven't done anything new here.
But let's say I want to add another function here.
Okay, so now, I've got two functions here.
I can save my file with this little disk icon.
Or I can go to file men-, the File menu, and hit Save.
Now when I type LS, you'll see that I've got this second function there, and I type second.
So if I get four again I'll say the same thing will happen.
So that's how I edit code and that's how I load the code into R.
Every time you edit your file in the editor you have to save it.
And then if you want that code to be available in R you have to use the source function to source that file back into R.
You don't have to use a single file.
You can save this to be a different file if you want so that way you can separate code for different projects or different assignments.
If you close the file here, you can always open it back up again by hitting Op, the Open button and you can see myCode is right there.
So that's how you edit code in R there's, now there's many other text editors that you might see on the web that you can download.
And those are fine to use but they're not really necessary.
The text editor that comes with R should be sufficient for this course.
I'm going to talk about two things in this video.
The first thing is how to set your working directory.
So, when you start up R you, it's important to know what your working directory is.
Because the working directory is where R reads and write files to the computer.
And if you don't know where that directory is, then you're not going to be able to, find any of the files that you save, or any of the data that you write out.
So when you start up R, you can find out what your working directory is by just typing the function getwd.
And you can see that I've loaded up R here and it, and it sets my working directory to be /Users/rdpeng, which on the Mac is just your home directory.
So this may work but in, if you store all your files in your home directory but you may want to change your working directory to be something else if happen to store all of your data and code files in a different directory maybe a sub directory.
So for example I can go to the Misc menu here and just hit, and choose Change Working Directory.
And I can choose one of these directories to be my working directory.
Now before I go, the first thing I want to mention actually is, that if you want to read a file, then that file has to be in your working directory, otherwise you'll get an error.
So for example, suppose I want to read a data file using read.csv and I want to read the mydata.csv file, okay?
So if this file is in my working directory then I'll be able to read the data, and it will load it into R.
So one thing I could do is I can change my working directory to be, to be wherever that file happens to be.
And if I type dir in this directory, it'll list all the files in this directory.
And now you can see, oh mydata.csv is in this directory.
So I'm going to, now I can read the file into R by typ, using read.csv and now you'll see that the data will appear in R.
In particular, when you save files say from the web on to your computer, you need to know where those files are stored on your computer and so that you can set your working directory to the appropriate place.
That way you don't have to worry about changing directories all the time.
One thing you can do is maybe just create a directory right here on your desktop, so I'm going to create a directory here called Coursera.
And now, when I'm in R, I can say Change Direc, Change Working Directory here.
And if I go to my desktop I can choose my Coursera folder there.
And now, when I, when I say getwd, you'll see that it has set the working directory to be my Coursera folder.
So now if you save files in there, you, they will be there, then you can, and you can read them from R.
So the one thing that you're going to have to do a lot of in this course is to write code in R, and to, and you're going to need an editor to do that.
So one nice thing about R on the Mac is that it comes with a text editor that you can use to edit code files.
So I can load up the text editor by clicking on this little button right here.
So I'm going to move this over here.
And you can start editing code right away.
And this function, is going to just take the mean of x here.
So it ignores the argument for now.
So, and then, and then one thing you're going to have to do is, is figure out how to get this code into R.
If I type ls, you'll see that there are no objects in my work space.
So, the question is, how do I get this code that I've written over here, into R?
And then Cmd+C copies the code and then I can click into my console window over here, hit a Cmd+V and and then return and it will paste my function into R.
And it will return the mean of a hundred random normal variables, which is not very interesting, but the function does work.
I can go to the File menu and I want to Save As.
So I haven't saved this file before, so I need to Save As.
And I'm going to go into my Coursera folder and I'm, I'm going to save it as myfunction and it is typical to add the .r extension for code files.
And so now, I want, I can double check my working directory, and make sure I'm in the right place here.
If I type dir, you'll see that my, the myfunction.r file is there now.
So I, so I haven't done anything new because I already cut and pasted that function.
It's going to return that.
So so what, now before I do anything, I need to, now that I've changed the file, I need to save it.
So I can just go to File > Save, or you can do Cmd+S.
And now I can source my, this, this file into R again.
So if I type this out, you'll see that's the code for it.
If I do it again, it'll be four plus a little bit of more noise.
So that's how I write code in R.
And that's how I can use the text editor, that comes with R.
If I want to create a new file, I can hit this button.
So I close this window and and that's how you can use the the text editor in R for the Mac.
The text editor that comes with R is very simple but it will definitely be sufficient for this class.
So there's even though there are other kind of custom text editors that you can, may be able to find on the web and download for free.
You don't have to do that, the text editor that comes with R should be sufficient for this class.
Hey everyone welcome to R Programming.
This is the second course in the Data Science Specialization and, as the title suggests, we will be focusing on R as a programming language.
This involves things like control structures and writing r functions and kind of doing some basic operations on data.
And then, and then we'll talk about kind of profiling your code, some of the tools for debugging and kind of how to work, how to work through longer pieces of code.
And then so after this course is done, I think you'll have a pretty solid grasp of R as a programming language.
And so that will be covered in other classes.
So, the pur, purpose of this class is to really kind of get you into R programming, in particularly or if you're not very familiar with the language and to make sure you kind of kind of get a hand, get a sense of the on the of the nuts and bolts.
So I hope you enjoy it.
And I think after this course is done you'll be ready to move on to a bunch of, to mo, to the other courses in the specialization.
And then in this lecture, I'm going to give a little overview and a very brief history of the R statistical programing environment.
So the very first question, I think is most obvious, is which is, what is R?
And the answer is actually quite simple.
It's basically R is a dialect of S.
So S was a language, or is a language that was developed by John Chambers and at the now-defunct Bell Labs.
And it was initiated in 1976 as an internal statistical analysis environment, so the, an environment that people at Bell Labs could use to analyze data.
And initially it was implemented as a series of FORTRAN libraries to kind of implement routines that were tedious to have to do over and over again, so there were FORTRAN libraries to repeat these statistical routines.
Early versions of the language did not contain functions for statistical modelling.
That did not come until roughly version three of the language.
So in 1988, the system was rewritten in the C language and to make it more portable across systems and it began to resemble the system that we have today.
So this was version three.
And there was a seminal book the, called the Statistical Models in S written by John Chambers and Trevor Hastie.
Sometimes referred to as the white book.
And that documents, all the statistical analysis functionality that came into the version, that version of the language.
Version four of the S language was released in 1998.
And its version, it's the version we more or less use today.
The book Programming with Data, which is a reference for this course, is written by John Chambers sometimes called the green book and it documents version four of the S language.
So, R is an implementation of the S language, that was originally del, developed in Bell Labs.
So, just a little bit more history here, in 1993 Bell Labs gave a corporation called StatSci which became Insightful Corporation, an exclusive license to develop and sell the S language.
In 2004, Insightful purchased the S language completely from Lucent.
So Bell Labs became Lucent Technology for $2 million, and became the current owner.
In 2006, Alcatel purchased Lucent Technologies and it's now called Alcatel-Lucent.
So Insightful developed a product which was a implementation of the S language under the product name S-PLUS.
In 2008 the Insightful Corporation was acquired a company called TIBCO for $25 million dollars and that's more or less where it stands.
TIBCO still develops as PLUS, although in a variety of different types of business analytic type products.
And it continues to this day.
So you can see the history of the language is a little bit tortured because of the various corporate acquisitions but it still survives to this day.
The basic fundamentals of the S language have not really changed since 1998 and the language that existed in 1998 looks more or less like we, like what we use today at least superficially.
And it's worth nothing that in 1998 the S language won the association for repeating machinery software system award.
A very pretigious honor.
So in a document called the stages and the evolution of S, John Chambers who was the original writer of the S language the, the original creator kind of laid out his key principal with designing the S language.
They wanted to create an interactive environment where you didn't have to think of themselves as programming, right.
Then he says then as the needs became clearer and their sophistication increased, they should be able to slide gradually into programming, when the language and system aspects would become more important.
So the basic idea is behind the S language and then later the R language is that people would enter the language in an interactive environment.
Where they could use the lang, the environment, without knowing about any sort of programming, or having to know very detailed aspects of the language.
So, they could use the environment to look at data, and do basic analyses.
They could get into learning the language aspects and learning to develop their own tools and, and the system would very kind of, would promote the kind of transition from user to programmer.
And so that was the basic philosopy of the S language.
we, let's go back to R.
So what is R about?
So basically, R is a relatively recent development.
In 1991, it was created in New Zealand by two gentleman named Ross Ihaka and Robert Gentleman.
So, and they talked about their experience developing R in a paper writ-, published in 1996 in the Journal of Computation and Graphical Statistics.
In 1993 the first announcement of R was made to the public.
1995, Martin Michler convinced Ross and Robert to use, to license R under the GNU General Public License.
And we'll talk a little bit about, more about that in a second.
And that made R what we call free software.
1996 a mailing list was developed, so there's two main mailing lists.
One called R-help, which is a general mailing list for questions.
And R-devel, which is a more specific mailing list for people who are doing development work in R.
1997, what's called the R core group was formed.
And these contained a lot of, this contained a lot of the same people.
And the core group, basically controls the source code for R.
Can only be modified by members of the R core group.
However, a number of, people who are not in the core group have suggested changes to R, and they have been accepted by the core group.
So, some of the features of R the first one, which was important back in the old days, when people were still using S+ but the syntax is very similar to S, which made it easy for S+ users to switch over.
The semantics are superficially similar to S, in that it looks like it's S, but in reality are quite different, but we'll talk more about this in the future lecture.
One of the main benefits of R is that it runs on any standard computing platform or operating system.
There is a very active development going on and so things are happening.
The software the core software of R is actually quite lean.
Its functionality is divided into modular packages, so you don't have to download and install a massive piece of software.
Whereas you can download a very small piece of fundamental core, kind of functions, and then add things on as you need them.
So it's graphics capabilities are very sophisticated and give the user a lot of control over how graphics are, are, are created, and in my opinion are better than most stat packages.
It might even be the best for the mo- kind of a general purpose statistical package.
It's very useful for interactive work as I said before, but it contains this powerful programming language.
And fundamentally, actually, for a language like this, is that there is a very active and vibrant user community.
So the mailing lists at R-help and R-devel are very active.
There's many, posts per day, and there's also a series on stack overflow where questions can be answered.
So, the user community is, is one of the most interesting aspects of R.
It's where all the R packages come from and it creates a lot of kind of interesting features.
Of course one of the, probably the most critical feature of R is that it's free.
So what I mean by that, is that it doesn't cost any money so you can download the entire software from from the web.
So, with free software there are four basic principles, right?
You have four basic freedoms that you have.
The freedom zero is the freedom to run the program for any purpose, so you don't need.
There's no restrictions on how you can run the program or when you can run the program or what you can or cannot do with it.
Freedom one is the freedom to study how the program works and adapt it to your needs.
So this happens almost every day which is that you can look at the source code for R itself.
You can sell changes to it if you want.
You can do, you can modify the program any way you want and adapt it to your needs.
Of course, so you can look at the source code for this to get freedom one.
Freedom two is that you have the freedom to redistribute copies so you can help your neighbor and so the idea is that you can give copies to other people.
You can do whatever you want with it.
Lastly you have the freedom to improve the program and release your improvements to the public so the whole community benefits, so this is freedom three.
The idea is that when people make changes to the program they can release them to the public so that everyone gets those changes.
And so these basic freedoms are outlined by the free software foundation and you can see more about it at their website there.
I won't go through all of them and probably other people have many other complaints.
But there's some basic drawbacks which are one that it's essentially based on 40 year old technology.
So the original S language developed in the 70s was based on a couple of principles, and the basic ideas have not changed too much.
Since then and so as, one of the results of that for example is that there is little built in support for dynamic or 3D graphics.
But things have improved, greatly and not on that front since the old days and there's a lot of interesting tools now packages for doing dynamic or 3D graphics.
Another drawback of R that I, I hear a lot about is that the functionality is based on consumer demand and basically user contributions.
So if no one feels like implementing your favorite message then that's your job to do.
And so you can't, there is no corporation, there's no company that you can complain to.
There's no helpline that you can call to say that, to demand a specific implementation or a specific feature.
If the feature's not there, then you have to build it.
Or at least you can pay someone to build it.
Another drawback which is a little bit more technical is that the objects that you manipulate in R have to be stored in the physical memory of the computer.
And so if the object is bigger, than the physical memory of the computer, then you can't load it into memory.
And then therefore you can't do something in R with that object.
So there have been a lot of advancements to deal with this too.
Both in the R language and also just in the hardware side there are computers now that you can buy with tremendous amounts of memory.
But nevertheless, as we enter the, kind of, big data era where you have larger and larger data sets, the model of loading objects into physical memory can be a limitation.
And finally, I'll just say that R is not ideal for all possible situations.
They expect it to be able to do everything.
So the basic R system is divided into two, what you can think as two conceptual parts.
There is the base R system that you download from a CRAN which is the comprehensive R archive network.
And that's kind of the go to place for all things R.
And so the base system contains what's called the base package which has all the kind of low level fundamental functions that you need to run the R system.
And then there are other packages contained in the base system which includes for example util stats, data sets, graphics and a bunch of other packages that are kind of fundamental packages that more or less everyone might use.
And then there are a series of recommended packages, so, boot for bootstrap, class for classification, cluster, codetools, foreign, and a variety of other packages.
These are the commonly used packages, they may not be critical packages, but they're commonly used by many people.
So all of these packages come with this, the base R system that you download from CRAN.
These packages are user contributed.
And the i-, and CRAN has a few, has a number of restrictions and standards that have to be met in order to get a package on to CRAN.
So, one of the nice things about CRAN is that there, that the packages that you download have to meet a certain level of quality.
So, so CRAN has, has a lot of different packages written by users and the number is really increasing everyday.
So it's very exciting to see all these packages on CRAN and there, and to see new ones come up everyday.
There are also packages associated with the Bioconductor project, which is a packaged, which is a project designed to implement R software for, kind of, genomic and, kind of, bio, biological data analysis.
and, of course, there are also all their packages made that people make available on their personal websites.
And there's really no reliable way to keep track of how many packages are available in this fashion.
So, there's really thousands of packages out there written by people.
So there are a couple of documents that you can find on the R website.
As you're learning to use R, you then want to flip through some of these.
One is an introduction to R, which is a relatively long PDF document now that kind of goes through the basics of how to use R, how to use the language.
There's the Writing R Extensions manual which is really only useful to read if you're thinking of developing R packages.
The R data import and export manual, which is useful for getting R's data into R and the various different ways.
The R installation administration manual is, is most useful if you want to build R from the source code, and I'll talk about that in another video.
Is is a really technical document for how R is designed.
How R is implemented at a very low level.
But if you're that kind of person, who wants to know how R works at a very, very low level, this is the document for you.
So, I'm just going to end over here with a couple of texts that are kind of standard or kind of classic texts in this area.
Of course the books by John Chambers offers data analysis and programming the data are both published by Springer.
And then there's two books by Bill Venables and Brian Ripley.
One is called Modern Applied Statistics with S, and another one's called S Programing.
Although they have the, the, they talk about S in the title, these books are all, are both very relevant for R programming too.
That's also quite useful, for R programmers too.
And finally Paul Murrell who designed the R graphic system has written a book called R Graphics and actually it's currently in its second edition right now.
So, a couple other resources, one is that Springer, the publisher Springer has a series of books called Use R, which is, which is a, a lot of very, kind of relatively short books.
How to use R for different types of topics, different application areas.
This is quite a nice series of books that you may be interested in.
And there may be a book written for you particular area of application.
And there's a longer list of books on the R website.
So, that was a brief overview of R, and the history of how it kind of came to be.
and, starting with the next video, I'll start talking about the details of the R programming language, and how we can use it to analyze data.
So once we start typing things into the R prompt, they we're going to be start, we're going to start coding and doing calculation.
So the things that we type into the R prompt are called expressions.
So for example, the symbol, which looks like a left-hand arrow and is actually the less than symbol, followed by a hyphen this is what's called the assignment operator.
So, for example, in this first expression here the symbol that I'm creating is called x, and the value that I'm assigning it is call, is 1.
So x is 1, is a, is an R expression.
And I'm passing it the symbol x so that when I print out x I get its value which, in this case is 1.
So another thing to think about x is also considered a, is an R object that is a numeric object that has one element.
So it's really a numeric vector where the first element is the number one.
So this is called, this is another way to print out an object without explicitly calling the print function.
So in the, in this expression over here, I'm creating a new symbol called message, MS, MSG.
And the first element of this character vector is the string hello.
I could add other elements to this vector if I wanted to, but they would all have to be character.
So the grammar of the language determines whether an expression is syntactically correct or not.
So for example by this type x followed by the assignment operator and I don't have anything else, that's not a, that's not a complete expression and so when I hit Enter nothing will happen because it's waiting for the expression to be completed.
The other thing I've got here is this hash symbol here.
So this hash symbol here it indicates that everything to the right of that is a comment.
And so the, the, the, the, the R engine will ignore anything that happens to the right of that symbol.
So you can put things like comments or notes to yourself in code and R will just ignore those comments.
And so, so sometimes when you evaluate an expression, nothing happens because there's nothing to really show.
It's a numeric vector and the first element's going to be five.
Now when I hit enter nothing happens because there's really nothing to show.
And so but now when I hit x and I hit enter it prints out the value five, so it prints out the value of x.
This is the same as calling the print function on that object which will just print out the value of that object.
So you can explicitly print an object or you can auto print an object.
So this is, this sounds a little complicated but it's really just the natural thing to do and it is what most people would expect.
You'll notice that when I print out the object x, there's a little one in brackets here.
And you might be wondering what that is.
So, all that indicates is that, it, it's telling you what element of the vector is being shown.
And this will make more sense when we have longer vectors to look at.
But all this is shame, saying is that the number five that you're seeing there is the first element of the vector.
So for printing you'll see that here I'm creating an x an object called x and it's the sequence one to 20, so the colon operator here that I've used is what's used to create a sequence.
And you'll see that the first line of the printout it has a one next to it, because that's the first element.
And then the, the second line has a 16 in brackets because that's, the first element of that line is the 16th element of this vector.
So it's all kind of straightforward but just that's how the printout works
In this lecture we're going to start getting into the nitty gritty and the details of R.
In particular I'm going to talk about different data types that are used in R and some basic operations on those data types.
So first it's important to kind of get the language right correctly.
So all the things that you manipulate in R, all the things that we encounter in R, are what might be called objects objects can be all different kinds, can contain all different kinds of data.
So the R has five basic atomic classes of objects.
And so the most basic object in R is called a vector.
And a vector conta-, Can contain multiple copies of, for example, of a single type of object.
It, everything in a vector has to be the same class.
Of course, with any great rule, there's always an exception, and this, this one is no exception.
So a list is represent as a vector, so there's a se, it's a sequence of objects.
But each element of that vector can be a different, can be an object of a different class.
You can have a list that's inside the list and one element of the list can be a data frame so, any element of the list can be anything.
So the list is the one exception to the ot to the.
General rule that a vectors can only contain elements of the same class.
The first argument is the class of the object, so the type of object that you want to have in the vector.
And the second argument is the length of the vector itself.
Perhaps the most important type of object in R of course is the number.
So for example, if you just enter the number 1 in R, that gives you a numeric object.
But entering 1 with a capital L next to it explicitly gives you an integer.
This distinction is not very important right now, but, it will become important later.
There's also a special number called inf, which stands for infinity and, and inf is like a real number it can be used in calculations and you will get the expected result.
So, emphasis special number, and you can also have minus infinity, too.
There's another special value called NAN or Nan.
And this represents an undefined value so you can name it as not a number.
So not every, object in R necessarily has attributes, but, but they are, but attributes can be part of an object in R.
Some of the most common types of attributes that we'll encounter are namesor dim names, or, or dimension names.
So for example, numeric objects their class is numeric and integer objects, their class is integer.
So for a vector it's quite simple the length of the object is just the number of elements in the vector.
And then there may be other user-defined attributes or metadatas which, so these are things that you can define separately, for an object using various attribute functions.
You can create integer vector by creating a sequence with colon operator, and you can also create a vector of complex numbers where the i is a special symbol, which indicates the imaginary part of the complex number.
So using the vector function you can also create, a vector of a certain type and a certain length.
So here, I'm going to create a numeric vector of length 10.
Will kind of create the least common denominator vector so, will not give you an error but what will happen is that it will coerce the vector to be the, the class that's kind of the least common denominator.
So here, in the first example, I've got in trouble concatenating number 1.7 and letter a, so clearly these are not in the same class one is numeric, and the other is character.
So the least common denominator here, is going to be character.
And so how's that happen, so and the, and by the convention in R true is represented as the number one and false is represented as the number zero.
And so what you're going to get here, is a vector 1,2.
And so the vector that you end up with is a vector where the first element is A and the second element is the string true, so T R U E.
It's not going to be illogical so you need to be a little bit aware, of the types of coercion that can occur in our, when you mix different types of elements in a vector.
And because you won't get an error, but, but the coercion will happen behind the scenes.
that, in the previous slide we talked about kind of a implicit coercion that occurs behind the scenes, but you can explicitly coerce objects from one class to another using functions that usually start with the word as.
So for example, if you want to convert something to a numeric you can use the function called as.numeric.
So this is going to, this is an integer sequence as you could see when I call class on the object but I convert it into a numeric sequence.
And so I can call as.numeric on x, and you can see that it prints out 0, 1, through 6, which look like an integer object but it's actually going to be numeric or I can convert it into a logical and so I can say as.logical on it, and what happens?
Well, as you can see, the convention is that 0 is false.
And when it doesn't work you get what are called NA values.
So for example if I take the vector ABC.
Now I mentioned lists a little bit earlier in this lecture and the idea is that they're, they're like a vector except that every element of a list could be a, an object of a different class and so that makes lists very, very handy for kind of carrying around different types of data.
And they're very useful in R and they become very common especially when in conjunction with other types of functions that we're going to learn about.
So here I'm creating a list called x by using the list function which is a, which can be used to construct the list.
And the first element is a numeric value, numeric object of one.
The second element is a character, letter a.
Third is illogical and the fourth is a complex number.
So there's, they're not a spe, a different, a separate class of objects.
Where the first number is the number of rows the matrix, and the second number is the number of columns.
And so, if I can create a matrix empty matrix with the matrix function, and I can explicitly say how many rows and how many columns there are.
This is not the only way to create a matrix, but it's one way.
And so when I auto print the matrix by typing the, the object m and hitting Enter, you'll see that it'll show me that, first of all the matrix is full, is initialized with NA values.
And you can see that there's two rows and three columns and they're labeled by the numbers in the brackets.
If I call the dim function on m, it'll give me the dimension attribute, which in this case it says there are two rows and three columns, because the first rows are number rows and the second number, sorry excuse me.
The first number is the number of rows and the second number is the number of columns.
If I call the attributes function on m, you'll see it returns a list where the first element is the dim element and it has the vector 2,3.
So these are all aspects of a matrix which is a vector that has a dimension attribute to it.
So you can think of the matrix taking a vector and all the numbers are inserted into the matrix by, by column.
So the first column gets filled and then when you hit the number of maximum number of rows, then the second column gets filled and the third column et cetera.
So if I create a matrix by taking the sequence 1 to 6 and then I say, I specifies that it has two rows and three columns.
So the first thing it happens is it takes 1, 2, and now there's only two rows, so it can only go to 2.
And then that makes the first column.
And then the third column is made up of 5 and 6.
You can also create a matrix by creating the dimension attribute on a vector.
So, for example, I can take, I can create a vector that's a sequence 1 to 10.
So here, I'm using the dim function, but I'm assigning a value to the dim attribute of m.
And so now after I've done that, I've got a matrix m, which has two rows and five columns and it's filled in the matrix column wise.
And so you, this is column, column binding and row binding can be achieved by the fu, the functions c-bind and r-bind.
So for example, suppose I have the two objects x, which is sequenced from 1 to 3 and y, which is a sequence from 10 to 12.
If I cbind those two objects, then I'll get a, I'll get a matrix where the first column is 1 to 3, and the second column is 10 to 12.
So this is kind of what you might expect would happen.
If I rbind those two objects, then the first row will be 1 to 3, and the second row will be 10 through 12.
So cbind-ing and rbind--ing is another way to create a matrix.
So, and there's two types of factor, there is unordered or ordered, so you can think of this as being, as storing data that are.
Those are categorical but they're ordered.
So one, you can think of a factor as an integer vector where each integer has a label.
So for example, you might, you can think of it as a vector as one two three, where one represents you know, high, for example high value and two represents a medium value and three represents a low value.
And underlying in R is represented by the numbers one, two, and three.
so, factors are important because they're treated specially by modeling functions like lm and glm which we'll talk about later.
But these are functions for, for, for fitting linear models.
So having a variable that has values male and female is more descriptive than having a variable that just, that just has ones and twos.
So for example, in many data sets you'll find that a var, there will be a variable that's coded as one and two and it's, and it's not.
If you use a factor variable then the coding for the labels is all, is kind of built into the variable and it's much easier to understand.
So factors can be created with the factor function, and the input into the factor function is a character vector.
And so x is a factor, you can see what, it prints out a little bit differently from a character vector, in the sense that it prints up the value, yes, yes, no, yes, no.
And then it has a separate attribute which is called the levels.
And so the levels of this factor are no and yes, okay.
So there's only two levels.
I can, I can call table on this factor and it will give me a frequency count of how many of each level there are.
So for example, it'll tell me there are two nodes.
Now, the un-class function strips out the class for fa, for a vector.
So for example, I can, if I call un-class on x it'll, it'll kind of bring it down to an integer vector, and you can see that underlying.
The factors represent as 22121 so, yes, it's coded as two and no, it's coded as one.
And so you see, it's really an integer vector with the attribute, the levels attribute of no and yes.
The order of the levels in the factor, can be set using the levels argument in factors.
And so the baseline level is just the first level in the factor, and the way this is determined by NR is critical.
It's determined using alphabetical order, so for example, if I create a factor variable.
With the, with the elements yes and no, then the base line level with be the first level that's encountered and because no comes before yes in the alphabet then no will be the base line level and yes will be the second level.
Now this may not be something that you want you might want for example a yes to be the base line level and no to be the second level and then in that case you have explicitly tell r.
That yes is going to be the first level and you can view that using the levels argument to the factor function.
So now when I print out the x object you see that the elements are still the same, still yes yes no, yes no.
because yes is the first level and no is the second level.
So there's a special type of object that we haven't talked too much about yet.
Missing values in R are denoted by either NA or NAN which we talked about before.
And so, there's a function in R called is.na which is used to test objects to see if they are NA.
So, NA values can have a class, too.
And so even though it looks like it's all NAs, the NAs can have different classes potentially.
So an NA value is not necessarily, an NAN value.
I've got a few different types of missing values listed here.
So, here I created a vector x which is 1,2, NA, 10, and 3.
And the NA value in here's going to be a numeric missing value.
So when I call is.na on x, what it returns is a, is a logical vector.
And the logical vector indicates whether each element of the vector x is missing or not.
And so, there's only one missing element in this vector, and so that's the third element.
The first two are false, the third is true, and the fourth and the fifth are false.
If I call is.NaN on this vector, you'll see that vector that's returned is all false.
Because there aren't any NaN values, or their aren't any MAN values in this vector so everything's false.
Of course, if I create a vector that has an end, a NAN value and an, and an NA value in it.
But is.nan only returns true for the for the value that's actually NAN.
The data frame is a key data type used in R and it's used to store tabular data.
So of course, tabular data make up a lot of what we use in statistics.
Data frames are very important in R.
So data frames are basically represented as a special type of list, where every element of that list has the same length.
Right, so you can think of each column of the data frame as an element of the list, and of course, in order to be a table, every column has to have the same length.
However, each column doesn't have to be the same type.
And so, data frames also have some special attributes.
First, the first special attribute is called a row name.
And so every row of a data frame has a name.
So for example, each row re, might represent a subject enrolled in a study, and then the row names would be the subject ID for example.
however, sometimes the row names are not interesting, and, and, and often you'll just use row names of 1, 2, 3, et cetera.
Data frames can be created by calling most often calling the read.table, the read.csv function and we'll get into that a little bit when I talk about reading data into R.
Now, you can't if you have a data frame that has many different types of objects, and then if you coerce that into a matrix, it's going to force so each object to be coerced so that they're all the same.
So you may get something that's not exactly expected.
The foo variable is an integer sequence from one to four, and the bar variable is a logical vector with two trues and two falses.
And then when I call the nrow function on x, I see that there's four rows in the ncall function, shows me that there are two rows
So this not true for just data frames.
It's true for all r objects.
And this can be very useful for writing readable code and self describing objects.
So for example, I'm creating a vector that's an integer sequence 1, 2, 3 and by default, there's no name.
So when I call the names function on x, it gives me a null value.
However, I can, I can give a name to each element of the vector x.
So for example, if I, I can say the first element's called food, the second element's called bar, and the third element's called norf.
So now when I print out my x vector, I get a vector 1, 2, 3 but then each one has a name over it, which is the name I just specified.
And so when I call the names function I get the, the names that are associated with each element of the vector foo, bar, and norf.
And so for example here I'm creating a list with the list function where the first element is called a, the second element is called b, and the third element is called c.
And so when I print out the list, it prints out the names of each element and the values associated with those names.
Where the first element of the list is the, is the vector of row names and the second element of the list is a vector of column names.
So here I want to name the rows a and b, and I want to name the columns c and d.
This lectures going to talk about reading and writing data in R.
So there's a few different types of ways you can do this and I want to talk about some of the primary functions that use an R to read and write data.
So there are a few principle functions that we're going to talk about for reading into R.
The first two are read.table and read.csv and these are for reading tabular data.
And they are probably the two most commonly used functions for reading data into R.
The function read lines is for reading lines of a text file so this, this can be any type of file really, it just gives you text in a, as a character vector in R.
The source function is important for reading R code, so if you have R code, for example functions or anything written get written to a file the source function will read all that code into R.
We'll talk a little more about this later.
The low and unserialized functions are for reading binary objects into R.
So the analogous functions for writing data are write.table, writeLines, dump, dput, save and serialize and those kind of pair up with their reading analog.
So, the read.table function is the most commonly used function for reading data into R.
It's important that you know kind of, how the arguments work, what the arguments are and understand what they mean.
So the first argument is pretty obvious, it's name of a file or the name of a connection, which we'll get to a little bit later.
Usually you're going to give this a file name, it's going to be a string and it's going to be a path to a certain file in your computer.
The header is a logical flag indicating whether the first line is a header line, so if the first line for example it has all the variable names in it, then that's not really a piece of data, that's just a line that has labels on it.
it's, it's a string that indicates how the columns are separated.
And so you want to tell read.table what the separator is going to be.
ColClasses is a character vector which indi wh, wh, which, whose length is the same length as the number of columns the data set.
And the character vector indicates what, what is the class of each column the data set.
So, for example, is the, if the first column is numeric and the second column is logical, and the third column is a factor, et cetera.
And so the colClass is a vector, which is not required but it, it tells the, it tells read.table what the class of the data is for each column.
So you can specify other characters to be comment characters, and the lines, lines of the file that begin with that comment character will be ignored.
Skip is the number of lines to skip from the beginning.
So sometimes there may be some header information or some non-data region at the beginning of the file, and you want to skip right over that.
And so you can tell the read.table function to skip the say the first ten lines of the first 100 lines and then only start reading data after that.
And the idea is that it, the question is whether you want to encode character variables as factors.
Anytime our read.table encounters a column of data that looks like it's a character variable, it will call, it will assume that what, what you mean to read in, is a factor variable.
If you don't me, mean to read this in as a factor variable, then you can set strings as factors equal to false.
So for small and kind of moderately sized data sets it has computers are going to get better and better everyday, the definition of small and moderate is kind of growing.
But you can use read.table usually without specifying any of the other arguments besides the file name.
So you don't have to specify any of that information if you don't feel like it.
It will figure out how many rows there are and, agai, and again it'll figure out what type of variable is in each column of the table.
So, tell it you can, that you can tell R all these things and if you want to and the reason you might do that is to make it run faster and more efficiently.
So parti, so read.csv is useful for reading csv files, this, this can usually, this stands for comma separated value.
It's usually something that you get from a spreadsheet program, like Microsoft Excel or something similar to that.
So csv is a very common format that most spreadsheet types of programs will understand.
So with larger data sets of beyond the small to moderate, then there are a couple of things you can do when reading in tabular data.
That will make your life a lot easier, and more importantly it will prevent R from totally choking.
In fact, you should probably have it memorized.
There is a lot of key hints in that help page.
Lot of useful information.
And in my opinion not enough people read this help page carefully enough.
And if I, so there's a lot of so once you've read that you'll see there's a lot of important information for kind of how to optimize read.table.
And so one of the things you're going to want to do is to make a very rough calculation.
And so that way you can get a sense of well, is there enough memory on my computer to store this data set?
R will have to, R is going to store your entire dataset in memory unless you do otherwise.
So when you call read.table or read.csv, it's reading your entire dataset into the RAM of the computer.
And so you need to know, roughly speaking, how much RAM this datasets going to require.
And we'll talk about how to calculate that in a second.
The call classes argument is actually very important.
And tries to figure out what type of data it is.
But reading each of these columns and trying to figure out what type of data it is takes time, it takes memory, and it can generally slow things down.
If you can tell R, what type of data, is in each column, then R doesn't have to spend the time to figure it out on its own.
And so, it'll, it'll generally make read.table run a lot faster.
So you can save yourself a lot of time.
So if you, if, if you have a few columns in your dataset, then then you can usually just say what, what the classes are.
But if you have, or if they are all the same, so for example if all the columns are numeric.
And if you only sent, you give it a single value, it will just assume that every column has that same value.
Otherwise what you can do if you have a huge data set, you can read in maybe the first 100 or first 1,000 rows.
And then going through each of the looping over each of the columns using sapply and calling the class function.
So the class function will give you, will tell you what class of data is in each column.
And then you can use this, and then you can save, store this information.
It doesn't necessarily make R run any faster, but it does help with memory usage.
And so, if you can tell R how many rows are going to be read in to, to the, in to, in to R.
So even if you mildly overestimate how many rows there are in the data set, that's okay.
So in general, when you're using R with large data sets, and there's lots of large data sets out there nowadays.
It's useful to have a few things, a few bits of information on hand.
These days in most computers will have on the order of a few gigabytes up to many gigabytes of physical RAM.
So are there other applications that are running on your computer that are eating up some processor time or memory?
If you're on a multi-use system, are there other users logged into the system.
What is the operating system for your computer?
So, is it a Mac?
Is it Windows?
Is it Unix?
Is it something like that?
And then, also it's useful to know whether the O, the operating system that you're running is 32-bit or 64-bit.
So if you want to do a rough calculation before you read in a table into R, using the read.table or the read.csv function.
You can just do a very quick calculation.
So here is, suppose I have a data frame here, with 1.5 million rows and 120 columns.
So this is not a particularly big data set but it's reasonable.
So, I don't have to worry about different types of data.
They're all, all the columns are numeric.
The question is how much memory is required to store this data frame in memory, okay?
So, I can do a simple calculation.
And so that's, so that's the number of elements in the data frame.
Now, if it's a numeric all the data are numeric then each number requires eight bytes of memory to store.
Because the, because the numbers are stored using 64-bit numbers and there's eight bits per byte.
So that's eight bytes of memory per numeric object.
So that's going to, so here's the number of bytes, now there's two to the 20 bytes per megabyte.
So I can divide that, the number of bytes by 2 to the 20, and that's how many megabytes I got.
And I can divide that again by 2 to the 10 to get the number of gigabytes, that's going to be roughly 1.34 gigabytes.
So the, the raw storage for this data frame, is roughly 1.34 gigabytes.
now, you're actually going to need a little bit more memory than that to read the data in.
And so, and so the rule of thumb, is to, is that you're going to need almost twice as much memory to read this dataset into R using read.table.
So if your computer only has, let's say two gigabytes of RAM eh, and you're trying to read in this 1.34 gigabyte table.
Because it, you're going to be pushing the boundaries of of memory that, that is required to read this dataset n.
Of course, if your computer has like four or eight or 16 gigabytes of RAM, then you should have no problem in terms of the memory requirements.
It will still take some time just to read it in just because it takes time to read in all the data, but you won't be running out of memory.
So doing this kind of calculation is enormously useful when you're reading in large data sets.
Because it can give you a sense of you know do I have enough memory.
Is the reason, if you grunt any errors, you'll know whether the error is because of memory, running out of memory or not.
So I encourage you to do this kind of calculation when you're going to be reading in large data sets.
And you, and you, and you know in advance kind of how big it's going to be
There are other types of formats that you can save data in beyond the tabular format, beyond, or the CSV file or text file.
These are also textual formats, but they are a little bit different for, from the tabular data that we've talked about before.
And the two main functions for writing out data and f, are dumping and dputing.
So, and, and the idea behind these types of formats is they're text formats, but they're not really, they're not really formatted in a way that's, in the same as like a table because they contain a little bit more meta-data.
So data about, for example, the type of the data in, in each class, object for example.
So if you, if you dump or dput a data frame.
It will include in the output, that the class of each column, of the data frame, so that you don't have to specify it when you read it in.
So that's one advantage of using, using a function like dump or dput to, to output data from R.
And similarly the, the, the, the functions for reading data using, fr, that haven't been outputted from dump or dput are source and, dget.
First of all, they're editable, so you can, if you want to you can edit them.
I wouldn't say this is something that I would advice, but because of you wanted something that's reproducible.
But, for example if something gets corrupted then you can look at the file to see if it's possible to recover it.
Textual formats can also work better if you're using like a version control program, like subversion or git, where you're tracking changes between documents.
and, and those types of programs tend to be much more useful with textual data rather than binary data, so that you can track changes meaningfully.
So, d, the dput function takes an arbitrary R object, and it will, use, it will take most types of R objects except for some more exotic ones, and it will create some R code that will essentially reconstruct the object in R.
And you'll see the out, if you discall dput it'll just output the results to the console.
And you can see that what I've done is that.
For example, it's creating this list that has these two elements in it.
And you can see that each element has has the data that's in it.
And it has the names embedded here, it's got the row names here.
And so, all the metadata here like the row names and the names and the class are all included in the output.
Now, of course, you generally don't want to print this to the console, that's not particularly useful, you probably want to save it to a file.
So the dput function, essentially writes R code, which can be used to reconstruct an R object.
The dump function is a lot like dget however, the difference is that dget can only be used on a single R object.
Whereas dump can be used on multiple R objects and so what you do is what you pass a dump is the character vector which contains the names of the objects.
So here I created two objects one called x, the other called y and when I pass the dump.
And I give it a file, that I want to store the da, the objects in.
And then I can remove them if I want to, but to read those objects back into R, I can call the source function on that file and you'll see that the Y object and the X object have been reconstructed.
So there are a variety of ways that you can interface between R, R, wi, with the outside world.
And generally speaking there are functions that, that are used to kind of open up the what are called connections to the outside world.
And most functions will do this in the background without you having to know what's going on.
So for example, when you call read.table with it and you pass it the name of a file, what it does behind the scenes is it opens up a file connection to that file, and then reads from that file connection.
The connection can be made to other types of objects too.
For example, you can open a connection to a webpage using the URL function.
And so, when you open a connection to a webpage, you can read data from that webpage using the URL connection.
The mechanism for connecting to different types of objects that are external to R, whether they be files, or webpages, or whatever.
So the file function is the function that opens a connection to a standard uncompressed file.
So this, this can be useful for text files, for, for reading in other types of text files.
Gzfile and bzfile, are used for opening connections to compressed data files.
Files that are compressed with gzip usually have a gz extension and files compressed with bzip2 usually have a bz2 extension.
The other options for file are not particularly important at this time.
So, connections can be very powerful and they can let you navigate files and other external objects in a more sophisticated way than just, like, reading the whole thing, for example.
And generally you don't have to deal with the connect interface in many cases, but sometimes it's useful.
So for example, so here I've got a simple example or opening a fi, a file connection to some file called foo.text, I'm going to open it for reading.
I can call read.csv on the connection, and that by default will just read the entire file then I can close the connection.
So that three line process is the same as just calling read.csv on the file.
However, sometimes a connection can be useful if you want to read parts of a file.
So for example, here I've got the readLines function which just reads lines from a text file.
And it's compressed using the gz, the gzip algorithm.
And I'm just going to read the first ten lines.
So now I'm going to re, use this connection, and to read the first ten lines.
And similarly, write lines is a, is a function that can be used to write out lines of text to a file.
And each, and what you do is pass write lines of character vector and each element of the character vector becomes a line in the text file.
And so and I'm, and then and so the lines of text that come from the connection are going to be stored in this character vector x.
So when I look at the first couple of lines from x you can see that it looks like HTML which is kind of what you would expect.
And so the URL function is useful for creating a connection to a kind of a non file object.
So this is another way to read data beyond using functions like read.table or read.csv
I'm going to continue to talk about data types, and basic operations in R.
In particular in this video I'm going to talk about subsetting objects in R.
So the sing, the basic kind of principles to remember here is that the single square bracket always returns an object of the same class as the original.
So the subset a vector, you're going to get back a vector.
If you subset a list, you're going to get back a list.
Any time you used the single bracket operator to subset an object, you'll get the same, an object of the same class back.
si, furthermore the single bracket operator can be used to select more than one element of an object.
With one ex, exception that we'll get to later.
But double bracket operator is used to extract elements of a list or a data frame.
And the class of the returned object will not necessarily be a list or a data frame.
So the idea with the double bracket operator is that, remember that lists can, can, can hold things that are of many different classes.
So, the first element might be a vec a numeric vector, the second element might be a data frame, the third element might be a complex vector, et cetera.
And so when you use the double bracket operator to extract an element of a list, the oh, the object that comes back maybe, may not be a list, it may be an object of a totally different class.
Very similar objects can have names and the reason, one of the reasons you've used names in an object is so that you can reference elements of the object by the different names.
Otherwise the, the semantics of the dollar sign are similar to the double bracket in the sense that when you use the dollar sign to extract an element of an object it may or may not be of the same class as the original object.
So, here is the first, the first example, a very simple vector, a character vector called x.
And and I'm going to use the single bracket operator to extract the first element.
So here, what I get back is a, is another character vector with the single element a in it.
If I, if I use, if I try to extract the second element of x, what I would get returned back to me is a character vector with the element b in it.
I could also extract a sequence of elements so if I say, If I, If I want to get the first four elements of x I can cre, construct the sequence one through four and then I get a, b, c, c.
So in these three examples here what I've done is I, I, is I subset the vector x using a numeric index so the numeric index is one, two or the sequence one through four.
So, in this next example here, I'm going to subset the vector x and I want, I only want all the elements were, that are greater than or equ, sorry, that are greater than the letter a, right?
So what I get returned to me is a character vector that only contains the letters that are greater than a.
So, here I've got b, c, c, and d.
So, if I print out u here I can see that the, the first element is equal to a, so it's not greater than a.
Then, the next four are greater than a, but then the last element is equal to a, so again, that's false.
So subsetting a list is a little bit different.
And the second element is named bar, and it's the number 0.6.
So this is a list of two elements in it.
And I get, when I, remember the single square bracket always returns the element that's the same class as the original.
So if x is a list, than x bracket 1 is going to be a list too.
So, so the difference here is that in the first example, I got a list that contained the sequence 1 through 4, and in the second example, I got just the sequence.
In the next example here I'm using a dollar sign.
And so I'm saying, x dollar bar.
So in that case it's the, it's a single number 0.6.
I can also use the double bracket operator and pass in a string.
So x double bracket quote bar is the same as doing as x dollar bar and it just gives me 0.6.
If I use the single bracket with the name, I can say x bracket quote bar, that gives me a list with the element bar in it.
So remember, because the single bracket always returns a list if I'm going to subset a list.
So the nice thing about being able to subset an element using its name, is that you don't have to remember where it is in the list.
So if I couldn't remember whether bar was the first element or was the second element, I don't have to remember whether, what, where it is in order to use the numeric index.
I can just use its name, and then I don't have to, then it will automatically extract that, extract that element from the list.
If you want to extract multiple elements of a list then you need to use the single bracket operator.
So for example, if I want the third, the first and the third element here, in which case, which is the foo and the baz element, I can pass a, a vector, a 1, 3, the numeric vector 1, 3 to x using the single bracket operator.
So that's how I extract multiple elements of a list.
There's, you cannot use the double bracket or the dollar sign operators when you only extract multiple elements of a list.
The nice thing about the double bracket operator, which is different from the dollar sign, is that you can use the double bracket operator to, to, to index it a list, where the index itself was computed.
So, notice that when I used the dollar sign before, I had to, I actually typed out the word bar.
But sometimes the name of the element is actually the result of some computation.
So for example here I've got a list with three elements, foo, bar, and baz.
And then I create a variable called name which is actually the string foo.
Notice that the there's no element in the list that has the name, name in it.
But there is an element in the list that has the name foo in it.
So now when I, when I pass this variable called name into the double bracket operator, it returns me the, the element that was associated with foo.
because that's what the value of the name variable is.
So if I can, if I compute the index that I want to use, then I have to use the double bracket operator.
So to use the dollar sign I need to use a literal symbol.
So if you look at this current list I've got here, with the first element a is another list which has elements 10, 12 and 14.
So suppose I wanted to extract the number 14.
Well, that's really the third element of the first element, right?
So it's the third element of the list, which happens to be the first element of the other list.
And so I can extract the 1, 3 element term by passing the vector 1, 3 to it to the x list using the double bracket operator.
And that's equivalent to kind of doing this double sub-setting of one and three.
I can also extract the first element of the second element by use, by passing the integer vector 2,1 to get 3.14
It's not particularly useful when you're pro, when you're writing out programs and functions but it's very useful when you're kind of working at the command like typing things as fast as you can.
So the idea with partial matching is that it works with the double bracket and the single, and the dollar sign operator.
And suppose typing out the word aardvark every single time is a bit of a pain so I'm just going to type the word a.
Well, the way the dollar sign works by default is that it looks for it looks for a name in this list, that matches the letter a.
In this case there's only one element.
And then it gives me the, the el, the object associated with aardvark, which is the sequence 1 through 5.
So if I use the double bracket operator things are a little bit different.
So what the double bracket operator expects, is that it's going to be, that the name that you pass it is going to be an exact match for one of the names in the list.
So now when I pass x double bracket a what happens is I get null back, because there's no element of the list that has the name a.
Last thing I want to talk about is removing missing values or NA values from an object.
This is a very common operation in, in, in data analysis because most realistic data have lots of missing values.
And so the way you can do this for, of either a vector, or a matrix, or a data frame is you want to create a logical vector which tells you where the NA's are and so that you can remove them by sub-setting.
But then there are missing elements NA in the third position and in the fifth position.
So, what I, the first thing I do is I use the is.na function to, to go through the vector and tell me which elements are NA and I create a new vector called, which I called bad here.
So, bad is going to be a logical vector which tells, which, which is true if the element is missing and false if it's not missing.
So, even though I haven't printed it here the, the, the bad vector is going to be a logical vector that has false, false, true, false, true, false.
Right, because the third and the fifth elements are missing.
Now that tells me which ones are missing but actually I don't want the ones that are missing, I want the ones that are non missing.
So what if there are a multiple vectors or multiple objects and you want to take and each one has a kind of missing values in slightly different places and you kind of, you want to take the subset of all the objects that have no missing values, all right?
Which is 1, 2, 4 and 5, and missing values scattered about.
And then y is, is a character vector with also some missing values in it.
So you can see the first two are, are both non missing.
So, of, for the both, for both vectors x and y, I want the first, the second, the fourth, and the sixth elements.
So now when I subset x, I get the good elements of that, and when I subset y, I also get the good elements of that.
So that's how I can look at multiple objects and kind of subset all the missing values out to get the good elements.
You could also remove you can also use complete cases to remove missing values from data frames.
So here I've got a simple data frame where I'm showing the first six rows.
As you can see there are six columns to this data frame so there's six variables.
And there's some missing values in the ozone variable and there's some missing values in the solar.r variable.
And so all I want is the is the, is the, are the rows of the data frame where all the values are non missing, right?
And I create a, a logical vector that I called good here, so the logical vector here tells me which rows are complete.
And then when I subset out the air quality matrix take and take out the first couple of rows you can see that I now, that none of the rows have any missing values in them.
And there, in complete cases of very handy function which is when, when you have multiple sets of vectors or dat, or large data frames or you want to subset all out, all the missing values.
So, vectorized operations, is one of the features of the R language that make it, that makes it easy to use, on the command line.
It makes very, kind of, nice to write code, without having to do lots of looping, and things like that.
Many other types of languages, like MATLAB have this kind of feature.
so, the idea with vectorized operations is, is that things can happen in parallel, when you, for example want to do a computation.
For example, suppose I got two vectors here x and y.
x is the sequence one through four and y is the sequence six through nine.
And I want to add the two vectors together.
Now, when I say I want to add them, what I mean is I want to add the first element of x to the first element of y, the second element of x to the second element of y, et cetera, the third element to the third element.
So I want to kind of do things in parallel like that.
similarly, you can use the greater than, or less than symbols to, give you logical vectors.
So well x is actually a, a vector of 4 numbers.
Well, the, the vectorized operation compares all the numbers to 2, and it gives you a vector of falses and trues depending on which numbers happen to be bigger than 2.
So you can also use greater than equal to, and that'll tell you which numbers are greater than and equal to 2, and the double equals sign, tests for equality.
So it'll take each element of y and test to see whether it's equal to 8.
other, and the other kind of, or arithmetic operations like multiplication, by the asterisk, and division, by the solidus, are all vectorized types of operation.
Similarly you can do, you can do You can add make, you can add and subtract, and multiply and divide matrices together.
So it's useful to know this because there are different types of mult matrix multiplication.
So I've created two matrices here, x and y.
X is the matrix 1 through 4, it's a two by two matrix.
So if I just do x times y, this is not a mat, matrix multiplication.
So, each element is multiplied, together in parallel.
This is not a matrix inverse or something like that, this is just dividing one matrix, literally element by element by another.
So if you want to do a true matrix multiplication, you have to use the %*%, that's the symbol for a matrix multiplication.
And for those of you who are kind of used to other types of programming languages, if you've programmed in languages where you can't do this kind of thing, it's sometimes, it's common to kind of reflexively go to something like a for loop or a while loop or whatever it is.
But in the but in a language like R, you can just use the vectorized operations to make the code a lot simpler.
Hi, everyone.
I just want to introduce a experimental feature that we've, that we've developed for the R programming class.
It's called Statistics with Interactive R Learning or SWIRL for short.
And it's, and it was developed by Nick Carchedi, who's a student here at the Johns Hopkins department of bio-statistics.
This is a system that allows you to kind of interactively learn R at your own pace.
So, rather than kind of watching a lecture and then, you know, doing an assignment and kind of doing things piece by piece, you can actually work on R right in the R console in, in a kind of guided way.
So, I think this, the SWIRL modules are really helpful and I encourage you to try to walk through them.
If you decide to complete them you'll get you'll get a little extra credit through the programming assignment.
But the, the modules are absolutely not required.
And so, you don't have to worry about doing them.
You can still do perfectly well in the class without doing the SWIRL modules.
Nevertheless, I encourage you to try it out.
I think it'll be a lot of fun.
In this lecture, I just want to get everyone on board with writing functions, because functions play a critical role in any R programming and you tend to write a lot of them when you're writing doing a lot of data analysis or doing a lot of kind of statistical analysis.
And so I just want to make sure that everyone can kind of get started writing functions and and particularly for those who are less familiar with programming languages in general.
It's kind of like the hello world so to speak of R.
So the first thing you're going to want to do is you going to want to write the function in a text file, all right.
So usually you're going to want to put your functions, in a separate file, separate from any interactive stuff that you're doing in the command line.
In the future you'll want to put your functions in an R package, which is a kind of a more structured type of kind of, kind of environment with documentation and everything, but we won't talk about that now.
Right now the first thing you're going to want to do is put your functions in a text file.
Okay, so the first thing we're going to want to do is open up our studio.
And so you can see here in R Studio there's some there's some stuff going on here from a previous project that I'm working on.
So you, that may happen to you, and generally you can either close it or you can just ignore it.
I wanted to create a new R script here, so let's create a clean script here to put our code into.
So the first function I'm going to write is really simple it's just going to take two numbers and add them together.
So the function that adds two values I'm just going to call it add two.
And and so you get it you use the function directive to start it off.
So here there's only really one expression.
So therefore its the last expression and, and it equals the sum of x and y.
I can say add two, and lets give it say three and five and hopefully I get eight.
So it adds the two numbers together, and that's that.
So it's a very simple function, and and, you've now written your first function in R.
S the next function that I want to talk about is a little slightly more complicated.
It's going to take a vector of numbers, it's going to, it's going to return the subset of the vector, that's, that's above the vector value of ten.
So any number that's bigger than ten, it's going to return those numbers for you.
so, let's bring back our original function.
Just because it gives you any number that's above ten.
And I like to open and close the curly braces right away, just so you know where the beginning and the end of the function is.
If you happen to have a lot of code in, you know, in, in a single file.
So the first thing I'm going to want to do is I want to construct a logical statement that figures out which elements of this vector x are, are greater than ten.
So I'm going to assign an object.
And I'll say x greater than ten.
So this'll return a logical vector, of trues and falses to indicating which element of x is greater than ten.
And then I'm going to subset the vector x with this logical vector.
So now this function returns, the subset of the vector x that is bigger than ten.
Of course if there are no elements of x that are bigger than ten, that it will return an empty numeric vector.
Now of course, there's really nothing special about the number ten.
I just kind of made that up, and so you may want to created a function that allows people to sub, to kind of extract the elements of a vector.
So maybe you'll want to allow the user to specify that number.
So I'll just call, I'll create a new function here.
So it doesn't have the ten encoded in it.
So let's start it off, we'll get the curly braces in there, and now I'll create a logical statement that x is greater than n.
And then I'll subset the vector x based on that logical statement.
So now if I can source this into R.
So I'll just create a vector.
Let's say x is one through 20.
And you can see it returned all the numbers that are greater than 12.
So that's kind of as we expected, and so the function appears to be working well.
So you might you want to specify a default argument so you might want to the default to be ten, so remember when I ran the function before and I didn't specify the number n.
It gave me an error or maybe you don't want people to have to encounter that error, and so you'll specify a default value n equals ten so people don't specify the cutoff value n, it will just automatically default to ten.
So now I can run this in R and now if I do above, which is x, you see I don't get the error anymore.
So it's kind of nice in R when you're writing functions to be able to specify default values like this that make the life of the user just a little bit easier, specially for very common cases, where it's not important that the user specify an argument.
So those are some very simple functions, in R that can be used to kind of process data or make do simple calculations, like adding two numbers.
The next function I want to talk about is, is just going to take a matrix or a dataframe and calculate the mean of each column.
I like to call my arguments x, you don't have to so why don't we just call it y for fun.
And so y is going to be a data frame or a matrix, and we're going to go through the columns of this data frame or matrix and calculate the mean of each column.
So the first thing I need to figure out is how many columns does this thing have, and that can be easily done.
I'll call it n c for number of columns and we can use the n call function for that.
That will calculate the number of columns, and, and then I need to initialize a vector that's going to that's going to store the means for each column.
The length of this vector has to equal the number of columns, right.
So I'll just call it means, and it'll be a numeric vector equal to the length of the number, equal to the number of columns.
And that's it, and then so for I, I haven't returned anything yet, so right now this function doesn't do anything particularly useful.
But what I want to do is return the vector of means and so I'm just going to return that.
And that's, since that's the last expression in the function that what will get returned.
I'll just take the column means of that, and see how it works.
Okay, so I, there are six, I think there are six columns in this dataset, so it gave me six means.
And that's because it, if the, if the vector has an na in it, then you can't calculate the mean.
And so the one thing you might want to do, is, by default, is throw out all of the missing values and just calculate the mean amongst the observed values.
And it will default to true, right.
And then I'll pass this argument to the mean function.
And so now I can default or remove the na's when I, calculate my column mean.
So sources send to R and with the run in the console column mean, and so now the default will be now I get my means for those columns because the default was to remove the na's.
I could say false here, and then my na's will come back.
So I can always choose to kind of go back to the old behavior if I wanted to.
So the last thing you want to do any time you're writing a function the most important thing of course is to save your file.
And give it the .r extension, and now you're code is saved to a file.
So that should get you started, just writing some simple functions in R, for your programming assignment you'll have to write a few functions that kind of go through and look at data.
But I just wanted to get you started writing your first functions so that you know kind of how the directive, the function directive works, how the arguments work, and you can play around a little bit with with more complicated ideas as you work through the assignments.
Functions represent some of the most powerful aspects of the R language.
And the basic idea is that you can type the command line and kind of explore some data, and run some code.
But eventually you'll probably get to the point where you need to do something a little bit more complex.
A little bit more than, than can be expressed in a single line or maybe in two lines.
And if you have to do this over and over again, then you're usually going to want to encode this kind of functionality in a function.
I'm going to talk about functions in three parts here.
First I'll talk just about the basics of how to write functions and how they are written, in R.
Then I'm going to talk a little bit about lexical scoping and the scoping rules, in, for the R language.
And then last, I'm going to end with a little example.
So, functions in R are created using the function directive and functions are stored as R objects just like anything else.
So, in particular, R objects, R functions are R objects that are of the class function, okay?
So, the basic instruction here is that you assign to some object, here I call it F, the, the function directive, which will take some arguments, and then inside the curly braces there is R, there is R code, which does something that the function does.
So one nice thing about R is that functions are con, considered what are called first class objects.
So you can treat a function just like you can treat pretty much any other R object.
So importantly, this means that you can pass functions as arguments to other functions.
So you can define a function inside of another function, and we'll see what the implications of this are we talk about lexical scoping.
So the return value of a function is simply the very last R expression in the function value to be evaluated.
so, there's no special expression for returning something for a function.
Although, there is a function called Return.
So functions have what are called named arguments.
And the named arguments can potentially have default values.
So, a lot of these features are useful for when you're designing functions that, that may be used by other people.
But most of the time, you don't have to change all those different arguments.
You may only care about one or two.
So it's useful for some of the arguments to have default values.
So first of all, there's the formal arguments, which are the arguments that are included in the function definition.
The formal's function actually will, takes a function as an input and returns a list of all the formal arguments of a function.
So not every function call in R makes use of all the formal arguments.
So for example, if a, if a function has ten different arguments you may not, you may not have to specify a value for all ten of those arguments.
So function arguments can be missing or they may have default values that are used when they are not specified by the users.
So when, this is very, this is key when you're writing a function and also when you're calling it.
So for example, take a look at the function sd, which calculates the standard deviation of, of, of a set of numbers.
So sd takes a input x, which is the name of the argument and which is going to be a vector of data.
And there's a second argument called na.rm and this controls whether the missing values in the data should be removed or not.
And the default value is for na.rm to be equal to false.
So by default if you have missing data in your, in the, in the set of numbers for which you want to calculate the standard deviation the missing values will not be included.
So, here I'm simulating some data and I'm just simulating a hundred normal random variables, and there's no missing data here.
So, if I just calculate sd on the vector it'll give me an estimate of the standard deviation.
If I say X equals my data that's the same thing.
So here I've named the argument but I haven't but otherwise the data are the same so it'll calculate the standard deviation.
In the first example I didn't name the argument.
So it defaulted to passing mydata to be the first argument of the function.
So in the next example here, I'm going to name both arguments.
That calculates the same thing as before.
Now when I name the arguments, I don't have to put them in any special order.
So for example, I could reverse the order of the argument here.
Now, what happens if I name one argument and don't name the other?
So for example, SD after you remove the na.rm argument only has one more argument left and so mydata would be assigned to that argument.
So all these expressions return the same exact value.
So although it's generally, all these expressions are equivalent, I don't say recommend all of them equally.
So for example, I don't necessarily recommend reversing the order of the arguments just because you can even though if you name them, it's appropriate.
so, just, just because that can lead to some confusion.
And so for example the lm function here which fits linear models to data has this argument list here.
So the first is the formula, the second is the data And then subset, the weights et cetera.
And you see that the first five arguments here don't have any default value.
So the but then the method, the model, the X argument, they all have default values so if you don't specify them they will use those values by default.
And so the following two function calls are equivalent.
I could have specified the data first and then the formula and then the model.
And then, and then, and then the subset arguments or I could specify the formula first, the data second, the subset and then say model is equal to false.
Now the reason why the first one is okay is because I, so I matched the data argument by name.
You can imagine that that's kind of taken out of the argument list now, then Y till the X doesn't, isn't specified by name.
So it's given to the first argument that hasn't already been matched.
And I, in which case that's the formula.
And then 1 through 100 has to be assigned to the argument that has not yet already been matched.
So in this case formula was already matched, data was already matched.
So 1 to 100 get's assigned to the subset argument.
But, I, I wrote it this way just to demonstrate how positional matching, and matching by name can work together.
A common usage for lm though is the second version here.
And then the next one is mydata, which the data set which you're going to grab the data from.
But then, the rest you may or may not specify and so you may, if you just want to specify one of the following arguments.
It's easier just to call it out by name.
so, most of the time, the named arguments are useful in the command line.
When you have a long argument list and you want to use the defaults for everything except for one of the arguments, which may be in the middle or near the end of the list, and you can't usually, you know, you can't remember exactly which argument it is, whether it's the fourth, or the sixth, or the tenth argument on the argument list.
And so you just call it by name, and that way you don't have to remember the order of the arguments on the argument list.
Another example where this comes in handy is for plotting, because mo, many of the plot functions have very long argument lists.
All of which have default values and you may only want to tweak one specific argument.
And so it's useful not to have to remember, you know, what the order of that argument is on the arg, on the argument list.
So the, the, the order of the operations that R uses, first it'll check for an exact match.
So if you name an argument it'll check, check to see if there's an argument that, that exactly matches that name.
If there's no exact match it'll look for a partial match.
And then if that doesn't work, it'll look for a positional match.
A, B, C and D.
B, C, and D, all have default values.
You want it if both specify the names of the arguments.
So null is a common argument.
So, one of the key features of the, our language is what's called Lazy Evaluation.
So Lazy Evaluation is a common model in a variety of programming languages.
And the way that it works is all of the arguments to a function are only evaluated as they're needed.
And so for example, if you take a look at this function over here.
And now recall that in a function, the return value whatever the last expression is evaluated.
So there's only one expression in this function.
And so it's the return value.
So if I say f(2).
Now you might be wondering what happens to B when I call (f).
I never specify what the value of b is.
And furthermore, b doesn't have a default value.
And so what happens, what, what happens is nothing happens because the function f doesn't actually use b.
And so the argument is never evaluated.
Here's another example of a function that's only slightly more complicated than the previous one.
So this is another function that takes arguments a and b, but now what the function does is it prints out a and it prints out b.
So here, what happened is that it printed out 45 because 45 was matched to the argument a, and so there was no error.
So here, but you notice that the error only occurs after the 45 was printed out.
And so the lazy evaluation applies, but because the argument is only evaluate when it's needed.
So there's a special argument, in.
And it's used to indicate a variable number of arguments that can sometimes be passed on to other functions.
So the three dots are often used when extending another function and you don't want to copy the entire argument list of the original function.
So for example you might want to extend the plot function and just to have a little bit of a tweak or to change some of the defaults, for example.
And so for example you might create a function that's called my plot.
And the my plot will replicate some of the arguments of the original plot function like x and y.
But it's going to change the default type arguments so that instead of creating circles for points.
So, but of course the default plot function has many, many other arguments.
And then though, that can used to, be used to kind of absorb all the other arguments in the plot function and then what happens is I'll take the dot dot dot and then pass it down to the original plot function, and so all those original arguments can be preserved then I don't have to retype or reconstruct all of those arguments in my extended function.
And sorry, there's another use of the dot dot dot argument, and it's for what are called generic functions so that extra arguments can be passed to the methods.
But the basic idea is that in R there, there can be special functions called generic functions which don't do anything, but what they do is they dispatch methods to put, according for different types of data.
lastly, so the dot dot dot argument is, is necessary when the number of arguments that are passive functions cannot be known in advance.
So one good example of this usage is in the paste function.
And what cat does similar to paste, it puts together, it pastes together a number of strings then it prints out the, the, the concatenated string either to a file or to a console.
So you can see that there are many other arguments to cat but the first argument is going to be the set of our objects that, that are going to be concatenated.
because, and this kind of makes sense, because otherwise there's no way for r to know whether you are passing something to the dot dot dot or whether you are passing something to a different argument.
So if I say in the first example here, where I try to paste together A and B, so A and B are going to the dot dot dot argument and then I say sep equals colon and then which means that I want to paste something together by separating them into with a colon.
However, if I try to do partial matching with set, what happens is that the partial matching gets ignored, and so, when, when I say paste a b and then s e equal to colon, well, the s e is, in another circumstance might be partially matched.
But in the pace function, it can't use partial batching.
So it gets, it just ignores that and just assumes that colon is just another string to be pieced together.
That any arguments that appear after the three dots have to be named explicitly and in full.
One topic that's important to discuss in R is a question of, you know, when a function sees a symbol in its body and it's executing inside the R environment, how does it assign a value to that symbol?
So for example, take a look at this, this function here that I've defined called lm.
So lm here is a function which takes its argument x, and it multiplies it times itself.
So you can think of it as squaring the, squaring the input.
Now, there's already a function in R called lm, so I've created an, a function here also called lm, so when I call lm somewhere else in R, maybe in another function or something like that how does R know what value to assign to the symbol lm?
And so the, the idea that R needs to bind a value to a symbol.
So in this case the, in the previous slide, the symbol was lm, and it needs to bind a value to it.
And the value is going to be a function of some sort.
It's either going to be my function or it's going to be the function in the stats package.
And so when r tries to bind a value to a symbol what it does is, it searches through a series of environments to find the appropriate value.
So environments are kind of, you can think of them as lists of objects and values or symbols and values.
And so, when you're working on the command line, and you need to retrieve a value of an R object basically, what happens is, the first thing that happens is, you search the global environment for a symbol name matching the one requested.
And so for the global environment, it's just your workspace, and it consists of all the things that you've defined or loaded into R.
And so if there's a symbol there that matches the name of the one that you're requesting then it will take that symbol and, and then retrieve the value that's associated with that symbol.
And so, because that exists, if I'm working the command line, when I call lm, it's going to find that object first.
So if there, if there's no match in the global environment, then what happens is, the, R will search the namespaces of each of the packages on the search list.
So the search list consists of all the R packages that are currently loaded into R.
And so you'll see that there, there's an order to the search list.
So, and it goes starts at the first element, which is the global environment.
Now, you can see, second on the search list is the stats package, the graphics package, the GR devices package.
All the way down at the very is the base package, okay?
And so, somewhere in this list of packages R is going to look for a function called lm.
And, of course, if it's not in the global environment, then it will eventually find it in the stats package which is the function that's used to fit linear models.
So, as I said before, the global environment is always, is equivalent to the user's workspace, and it's always the first element on the search list.
And furthermore, the base package is always the last element on the search list.
So, clearly because of the way that the search process works in terms of going down the list of packages, the order of the packages in the search list matters.
And for, and, and users can also load packages whenever they want.
So you cannot assume that there's going to be a set list of packages available or that the packages will be in any sort of order.
So they can be in different orders at any time to give depending on the user has decided to do in a given session.
The namespace of that package gets put in the second position of the search list.
So right behind the global environment.
And then everything else just kind of get pushed down one level.
So so, and then the search will kind of go down, will include that new package, including, in addition to all the other packages that were originally on the search list.
One thing to note is that R has separate namespaces for functions and non-functions, so it is possible to have an object named c somewhere and the function name c.
Of course, in your global environment, there can only be one symbol named c.
But it's possible to have for example, a vector named c, and that won't necessarily interfere with the function that already exists that's also named c.
which, which is which I think are the, is the main feature that makes it different from the original S language.
Since, since most of you probably did not use the original S language, maybe, this may not, this may be something of a moot point.
So the scoping rules determine how a value is bound to a free variable in a function.
So if you're in a function there's two types of variables.
There's the, there's the function arguments that are passed through the definition of the function, and then there may be other variables or other symbols that are found in the function that are not function arguments.
And the question is, how do you assign a value to those symbols.
And so R uses what's called lexical scoping or static scoping, and this is a common alternative to something called dynamic scoping.
And so this is, related to the scoping rules is how R uses the search list to bind a value to a symbol.
And, and one thing that's nice about lexical scoping is that it turns out to be particularly useful for simplifying things like specifically statistical calculations.
So take a look at the following function.
So, this function has two formal arguments they're called x and y.
And the body of the function, basically it squares x and it adds the ratio of y divided by z, okay?
So, x is clear, and y is clear, but where did z come from, right?
And so the question is, well, what value do we assign to z, assuming that values were inputted to the function for x and y.
And so, the scoping rules of a language determine how we assign a value to something like z, which is a free variable.
So if I were so this, lexical scoping, the rules in R, can be summarized by the following sentence.
Which is basically, the values of free variables are searched for in the environment in which the function was defined.
And so, what's an environment?
An environment is a collection of symbol-value pairs.
And, and you can think of everything in R as being pairs of symbols and values.
Right, so, a another symbol might be y, and its value is a data frame, for example.
So it's kind of like the, the environment that sits on top of it would that, that it inherits from and it's possible for an environment to have multiple children.
So there might be one parent environment and many children environment and so there's only one environment without a parent, and that's the empty environment.
And so, when, so, R uses a lot of these types of environments.
So you think of the global environment, which is your workspace that is a set of symbol-value pairs, right?
So you have a bunch of things that you've created in your workspace, and they all have names.
And each one of those things has an object associated with it.
So they might be a vector of numerics, or it might be a data frame, or it might be a list, or whatever.
And so there are all kinds of these envir, each package has a namespace, and that's like an environment.
It has a bunch of symbols and values associated with it.
And so what the, the key thing in R is that if you take a function and you associate it with an environment, then that creates what's called a closure or a function closure.
And these closures are, are key to a lot of different types of interesting operations in R.
So, if you, if you're in a function and you encounter a free variable in that function what happens?
So, the first thing you look for is the function in which the environment in which the function was defined.
So if I see a free variable in this function, what's going to happen is that if I can't figure out a value inside the function, then I'm going to look in the global environment, because that's where the function was defined.
If I can't find something in the global environment, then the search continues in what's called called the parent environment of the global environment.
And so the, what happens in the usual case, if I define a function in the global environment, then the function is defined in the global environment, and then its parent environment is the next thing down on the search list.
So, what happens is that you just go down the search list until you eventually find the value for this free variable.
And then it's going to look, if it can't find it there, then it's going to look for the parent environment.
And then if it can't find it there the search, it will keep looking at the parent environment or the parent etc, until we hit what's called the top level environment.
The top level environment is usually the global environment, however, if the function is defined in a package, then the top level environment is the namespace of that package.
So, after the base package, for example, then we hit the empty environment.
If you can't find a symbol in all these environments and we've hit the empty environment, then we throw an error saying we can't find a value for this symbol.
It's not immediately clear.
So typically the function is defined the global environment so that values of the free variables are just found in the user's workspace.
The right thing to do is kind of what most people are expecting.
If there's no, if, if there's, you can't find a value inside the function itself, you just look in the global environment.
So this is the, the idea here is that you can define things like global variables, that will be common to a lot of different functions.
so, but the key difference in R is that you can define functions inside of other functions.
'n so for example a function can return a function as the return value.
So, in most functions they'll return a list, or a vector, or a matrix, or a data frame or something like that, but it is possible for a, for a function to return another function and then that, if that's the case then the, then the function that gets returned.
So, it's an, the environment in which it was defined Is not the global environment.
It's really the, the, the insides of this other function.
So this is when things get interesting and this is when the scoping rules really have an impact on what you can do.
So, the idea that the function is constructing another function.
So, here's what I want to, I want to create a function that that defines another, called make.power.
So, and inside the make.power function I define another function called pow.
However, N is defined inside the make.power function and so since that's the environment in which the pow is defined.
The pow, the power function will find the value of n inside this, it's other environment.
So what happens is that I can call make.power and pass it a number like 3.
And, similarly, I can pass 2 to make that power and create a function that I'll call square.
So, now, when I, when I pass cube, the number 3 What is it does is it raises 3 to the 3rd power, so I get 27.
If I call square on the number 3, it, it raises three to the 2nd power, so it gives me 9.
So, how do you know what's in a function's environment?
You can look in the environment in which the function was defined, by calling the LS function.
So if I call, if I call LS on On the environment for cube.
And if I use get on N you'll see that the value of N is equal to 3.
Excuse me, that's how the cube function knows how to, knows to raise the argument to the 3rd power because it's already defined.
Similarly the environment for square, you can see it has the exact same objects in it.
But now the value of n is equal to 2, in the square function.
So, so, I want to make one brief comparison between lexical scoping, which is what R does, and dynamic scoping, which is what maybe some other function, some other programing languages implement.
Then create a function F, which takes, as an argument, X.
So, what's G?
G is another function, which takes as an argument called X, and it multiplies X times Y.
So, in the F function, Y is a free variable, and G is also a free variable.
Inside of F of or, it's, it, of, argument to F.
Then in the G function, then the var-, the symbol Y is a free variable.
And so the question is if I call f of 3 what gets returned?
So with lexical scoping, the value of Y and the function G is looked up in the environment in which the function was defined.
Which in this case was the global environment.
So that the value of Y and the G function is 10.
So with dynamic scoping the value of Y is looked up in the environment from which the function was called; sometimes called the calling environment.
So in the R the calling environment is known as is what's called the parent frame.
In this case the calling environment Y was defined to be 2 and so the value of Y would be 2.
So, in this case, X is a function is a formal argument.
A is a local variable so it's not a formal argument, but I defined it inside the function.
And then Y is a free variable, okay?
So if I call G of 2, the function G is going to look for the value of Y in the global environment.
Now if I define what Y is, say I assign it to be 3, if I call it G of 2, then it returns 8 because now it's able to find Y in the global environment.
So even though it looks like the value of Y was looked up in the calling environment, it's actually the defining environment because G happened to be defined in the global environment so, there are a number of other languages that support lexical scoping.
And of course there's a, a well known computer science theorem which is that all languages eventually converge to Lisp.
It's actually very common in a number of other programming languages.
So, one of the main consequences of lexical scoping in R is that all the objects have to be stored in memory.
So, if you're working with a programming language that has very small objects this generally speaking not a big problem.
Because of nature of the scoping rules and because of the complexity of the environment and the, the way they are all linked together, it's difficult to implement this type of model outside of physical memory, and so.
So the consequence was that, when R was originally designed.
Things are getting complicated now, because of very large types of data sets.
Everything has to be stored in memory.
Second now, so every function has a carrier pointer to its respect, to its defining environment.
and, and that defining environment could literally be anywhere because there could be functions within functions and then the, and if you do, if one function returns another function, then there has, there has to be a pointer to that piece of memory where the defining environment is stored.
And so this makes the model a little bit more complex but but, but all the more useful.
So, the, in S plus, which was kind of the original implementation of the S language, the free variable were always looked up in the workspace.
Everything could be stored on the disk, because the defining environment of all the functions was the same.
So far, we've talked about functions and the scoping rules in R, and you might be wondering why any of this information is at all useful.
So, in addition to just writing regular functions for manipulating data or for doing calculations, there's one combination of the scoping rules and functions which can be very useful in statistics, and that's for optimization.
So there are a few optimization routines in R called optim and nlm and another one called optimize.
And they all require that you pass a function to those functions, whose argument is vector parameters.
So for example there's going to be some function that you want to minimize or maximize.
and, over range of parameters, and functions like Optum and lmand take, take that kind of objective function, and try to find the minimum or the maximum.
so, the idea is that, but in statistics this objective function that we're trying to minimize or maximize, just like a log likelihood, is going to depend on other things, besides just the parameters that you're maximizing over.
So, for, in particular, it's going to depend on things like data.
And so, the question is, well, how do you specify a function.
Depend, depends on parameters and data and perhaps many, many other things.
In a clean, way and to, to write it in a, in a, in kind of readable programming style and make it easier for the user to kind of use these types of functions.
And further more, when you're doing these kinds of optimizations in many cases it's useful to hold certain parameters fixed and for example, fix a parameter to a certain value then optimize over the other parameters.
So, the basic idea with any optimization problem in r is you can create a contructor function which constructs the objective function.
And so that way you don't have to specify those things every time you call the function.
So just as a note, most of the functions in like optim and anolam and optimize and, in R, they all attempt to minimize functions by default.
And so when you write your objective functions if they're designed to be maximized, then you have to kind of take the, the negative of those functions so that you can minimize them.
So another thing is that all the code in this example all, will be on the website so you can take a look at the code and try to run it yourself if you want.
So the data is the first argument to this make.makelike function.
The second argument is a logical vector called fixed and it determines whether or not I want to have, want to fix some of the parameters.
So, now ins- inside the constructor function I have to find another function which is it takes an argument called p for the parameters.
And this is going to be the parameter vector that I want to optimize over.
So those are going to be the two parameters that I want to optimize over.
And so here I'm just defining, the law of likelihood, and taking the negative of it, so I can minimize it.
And, what, what the constructor function does is returns the function as the return value.
So,when I print out this function here,you will see that it, I see the body of the function looks like the code for the normal distribution.Its just like in the construction function before, but if you look at the environment, you will see this little tag that at the bottom that says environment.
And that's the enclosing environment for this function.
And so normally because when you define a function in the global environment, that it would just you, there wouldn't be a special environment tag down here.
And so, if you look at, this, this is, 0 x 16 5 b 1 a 4.
So if you look at the body of the nl function here, you'll see that pretty much everything here is either a local variable or its a param-, it comes with a parameter vector p.
However, there was one argument, th-, sorry, there's one variable here, the data variable, which is not an argument to the function And it's not a local variable, so it's a free variable but the data come from the make neglog like functions or constructor function which originally pass the data to that.
And so the data can be looked up in the environment that the function is defined and it knows what the data are, you don't have to tell what the data are it's already fixed in the function.
So if you look at the environment for this negative log-likelihood function by calling LS, you'll see that the the data variables there.
The fixed variable there which indicates which parameter should be fixed, and then there's also the params variable there.
Inside this negative log likelihood function, but they're defined in the defining environment.
So pretty close to the truth, remember, which was one and two.
Now I could, if I wanted to, I could fix sigma to be equal to its true value and then just optimize over mu to get the mean, and so when I call make.
So I need to reconstruct my optim, my objective function by calling make.neg log like, and here I set the fixed variable to be false from U.
Now I can just call, optimize, because optimize will minimize the function of a single variable only.
And because I only have a single variable in this, function, I can use, I can use optimize.
And you can see that it, it, it estimates made to be about 1.21 so slightly different from the previous optimization.
I can also fix mu to be one and try to optimize over over sigma and but in order, in order to do that I have to construct another function for optimization call optimize on that.
So here I'm going to make the neg, the negative log likelihood.
I'm going to fix mu to be equal to one and I'm going to plot the negative log likelihood as a function of sigma.
Similarly I can plot the negative likelihood as a function of the mean by fixing sigma to equal to two and letting mu vary.
And similarly, I create another grid of points another set of grid points and I evaluate at the NLL function on those grid points and then make a plot.
So, the nice thing about lexical scoping in R is that, if you're doing minimization or optimization of some sort, you can build these objective functions, which contain all the necessary data, and all the other kind of bells and whistles that are required, to evaluate that function.
So that when you call the objective function, you don't need to specify the data, and all those other things every single time.
They're kind of built in to the environment and they'll be automatically looked up in the right place.
That in order to evaluate the function every single time.
So this can be very useful for interactive work, and for exploratory work like for example making these plots.
And this can so the code for these types of functions can be very simple and kind of clean because you don't have to carry on these large argument lists.
Coding standards in R are really important becasue they help you, make your code readable and allow you and other people to understand what's going on in your code.
Now, of course, just like it is with any other, style whether it comes, when you, you know, whether it's your clothing or whatever it is, it's difficult to get everyone to agree on one set of ideas.
But I think there are a couple of very basic, kind of minimal standards that are important when you're coding in R.
So, the first principle that I think is very important in pretty much any programming language, not just R, is that you should always write your code using a text editor and save as a text file.
Okay, so, a text file is a kind of basic standard.
And usually, typically, typically it's going to be ASCII text, but if you're, on, in places outside the US or the UK using non-English languages there may be other standard text formats.
But the basic idea is that a text format, can be read by pretty much any basic editing program.
These days, you know, when you're writing something there's a lot different of tools that you can use to write.
If you're writing a book, or or a webpage or something like that, there's all kinds of different tools that you can use to write, to write those things.
The second principle is, which is very important for readability, is to indent your code.
So indenting is something that's often hotly debated in lots of mailing lists and other types of discussion groups in terms of how much indenting is appropriate.
But I think the most important thing is that you understand why indenting is important.
So indenting is the idea that different blocks of code should be spaced over to the right a little bit more than other blocks of code so you can see kind of how the control flow how the flow of the program goes based on the indenting alone.
So coupled with indenting, is the third principle which I think is very simple which is, limit the width of your code.
So you have indenting it's possible to kind of indent off to the right forever so you need to limit on the right hand side how wide your code is going to be and usually this is kind of determined by the number of columns of text.
So, let's take a look for, at a quick example here.
So here you can see I've got R Studio open, here with a simple code file with some R code in it.
And, first of all, let me just mention that the editor in R Studio is a text editor.
So it will always save the R files that you write as text format files.
And you can see that all the code is kind of mashed together here on the left hand side.
It's difficult to tell kind of where the if blocks are.
And so the indenting scheme kind of makes the code not very readable in this case.
If we just go up to the Preferences menu here.
And let me just change it to four.
So now you can see that the indenting is a little bit nicer now.
You can see, kind of, where the function begins and ends, you can see where the if blocks start and end, and the, kind of, structure of the program is much more obvious.
So, I'm going to change this one more time though and my, because my personal preference for indenting is to use eight spaces, so I'm going to change this to eight.
And now you can see, I prefer the eight spaces just because it really makes the structure of the code very obvious.
And it makes the code very readable in general.
So you can see that indenting is very important.
If you don't indent at all or if you only use a very small amount the code becomes kind of very mashed together.
One of the advantages of having something like an eight space indent, is coupled with an 80 character margin on the right hand side, is that it forces you to think about your code in a slightly different way.
So for example, if you have eight space indents, if you're going to have a for-loop, nested within another for-loop within another for-loop, every time you nest another for-loop, for example, you have to indent over eight spaces.
And by the time you get to maybe your fourth nested for-loop you're pretty much hitting the right hand column at the 80 column margin, right?
So, for example, with an eight space indent and 80 column margin, you might not be able to do feasibly more than two nested for loops, and, but I think that's really the, kind of, the boundary of what is readable in terms of code.
So a good indenting policy not only makes the code more readable, but it actually can force you to think about writing your code in a slightly different way.
And so that's a really nice advantage of, of having a logical indenting policy with, coupled with a, you know, a right-hand side restriction.
So the last thing I want to talk about is to limit the length of your functions.
So for example, if you're function's named read the data.
Then your function should simply read the data, it should not read the data, process it, fit a model, and then print some output, alright?
There are a couple of advantages to doing this.
If you could put all the function, the entire function on like one screen of the editor, then you can look at the whole function and see what it does all at once.
Another advantage of splitting up your code into logical sections, to logical functions, is that if you use functions like traceback, or the profiler, or the debugger, these often tell you, you know, where in the function call stack you are when a problem occurs.
And if you have multiple functions that are all logically divided in to separate pieces then when a bug occurs and you know that it occurs in a certain type of function or a certain function then you know kind of where to go fix things, right?
So if you have, but if just have a single function that just goes on forever and a bug occurs then the only thing that the debugger or the traceback or the profiler can tell you is that there's a problem in this one function.
But it, it doesn't, it, it's difficult to tell you where exactly the problem occurs.
So splitting up your functions has a secondary benefit, which is that it can help you in debugging and profiling.
So limiting the size of your functions is very useful for readability and for, kind of, debugging.
Of course, it's easy to go overboard and having, you know, a hundred different three-line functions.
So that's not really what you want to do.
So you just want to make it so that the, the separation of different functions into, is logical, and that each function kind of does, does one thing in particular.
So those are my basic guidelines for writing code in R.
There are, of course, many other things that you might be able to think about.
And so I'm not going to talk about too much more in terms of coding standards, but the basic ideas are always use a text editor, always indent your code, I'd say at least four spaces.
And and always limit the size of your functions, so that you can, so that they're, kind of grouped into logical pieces of your program.
It'll be readable to you, it'll be readable to others, and it'll make kind of writing R code much more useful to everyone.
I want to talk briefly about dates and time in R, which is a very, is a very special topic and could require a lot more time.
so R has a special way to represent dates and times.
And they're, they're represented using special data classes.
So, in the past, we talked about different data types like lists.
And, numeric vectors, and so.
This is just another type of data on top of those kinds of classes.
So dates are represented by the date class.
and, times are represented by two separate classes: the POSIXct and the POSIXlt class.
They represent a day, in a year in a month.
That particular detail is not very important but in case you're wondering you don't know how they, how the, how R actually does calculations based on dates.
That's not very important, but it maybe useful to know, sometimes.
So, the way dates in R, in R work, is you can take a character screen.
And, you'll notice that if you print out this object.
Now it's not actually a character string but it will print out that way because there's a special print method.
Now if I unclass the object here you'll see I get the number 0.
If I input January 2, 1970, then you'll see that underline is represented as a number 1, because that's 1 day after 1970 January 1st.
If you had a date that was before 1970 Then, they'd be represented as negative numbers.
You don't, you don't have to worry about the underlying representation.
Ultimately, what you need to know, is that dates are stored as objects of the date class.
Times, on the other hand, are represented as two possible types.
One is called POSIXct and the other POSIXlt.
So, POSIX is a family of computing standards for how things should be done on certain types of computers or how data should be represented and so there's a there's a family of standards for how to represent dates and times and pos and so POSIX a that's part of the POSIX standard.
Times are represented at just as very large integers.
POSIXlt stores a time as a list.
underlying, and so, and it stores a bunch of other useful information about a given time, for example what's the day of the week of that time, what's the the day of the year, the day of the month, or the month itself.
And there are a number of generic functions that operate on both dates and times.
That you can use such as the, so the weekdays functions tells you what day of the week a given time is or a given day is.
And the quarters functions gives you the quarter number.
So for example, quarter Q1 would be January through March, Q2 would be April through June, etc.
So, these generic functions operate on, on objects of class.
If you want, using the as.POSIXlt or the as.POSIXct function.
so, for example the Sys.time function here, just gives you the current time.
And you can see that when it prints out, it prints out in a year month day format.
And then the, the timezone, which is Eastern Standard Time right now.
So you can convert this di to a POSIXlt using pa, as.POSIXlt.
And, POSIXlt remember underlying is a list.
So you can look at the names of the elements.
The month is just the month your in so that's a January and then the year.
So, if I extract the sec, seconds element of this list, you'll see it's 11.86.
And so that, and so this actually gives you the seconds in in fractional seconds.
So, that's, that's the number of seconds in the time.
The POSIXct format you can see is you can also get it from the sys.time function and you can see that if I un-class the POSIXct object.
Now if I try to apply the list operator, the dollar sign to this object, you see I get an error because objects of POSIXct don't have these list elements in them.
You want to get those list elements out you have to convert it to POSIXlt using the as.POSIXlt function.
In this case it's 11.88 seconds.
Well, in this case it converts into two time objects.
So and they use what are called format strings.
So in this case I got, and so you'll see how these present signs fall by letters.
And then you can, you can look-up what these symbols mean in the help page for strptime.
Then comma and then %Y is the four-digit year.
Then %H is the hour, sort of like colon followed by %M which is the minute.
And so that's the format.
You can see that after I call I print out X, I get these time objects that are formatted, that are printed out in the standard format.
When I look at the class of this object you'll see it's in a POSIXlt format and so that's the so you can look at so that's the underlying kind of list format here.
So, but the end you need to be careful that you can't always mix different classes.
If I try to subtract the two, you'll, you'll get an error because they're not the same, type of object.
The nice thing about the date and time operators is that they keep track of very tricky things like leap years, leap seconds daylight savings and time zones.
And so the difference between March 1st and February 28th is actually a difference of two days, not a difference of one day like it is every other year.
Similarly I could take two times one which is in my, X which is in my kind of current time and then Y which is in the time zone of GMT, so Greenwich Mean Time.
So even though it looks like it should be a 5-hour difference, it's actually only a 1 hour difference because of the change in the time zones.
So one of the advantages of using the date time classes is that it will automatically take care of these kinds of irregularities.
So that was just a quick sum, kind of overview of the, the dates and the time classes in R.
So just to summerize there are special classes in R that will, that represents dates and times that'll allow you to do numerical and statistic calculations.
And then character strings can be coerced to either a date or a time class, using the strptime function or as.Date.as.POSIXlt, and POSIX, as.POSIXct.
The other thing to note, that I haven't really talked about here is that a lot of the plotting functions, will recognize date time objects.
It will recognize that object and then format the X axis in a special way so that it will have a time element to it.
So you might want to try to experiment with that a little bit to see how plots change when you use a date time class.
Loop functions are some of the most powerful functions in the R language and they make it kind of very easy to use, especially in an interactive setting.
The idea behind a loop function is you want to execute a loop over an object or a set of objects in a way that's kind of that does a lot of work in, in a very small amount of space.
That way, you don't have to type as much on the command line.
So, there are a couple of loop functions in R and they usually have the word apply in them somewhere.
So some of the key ones are lapply, sapply, apply, tapply, mapply and the real workhorse function that I, that I'd like to talk about here is lapply.
And the idea behind lapply is that you have a list of objects and you want to loop over the list of objects and apply a function to every element of that list.
And so it's a very general concept.
And it can be used very powerfully to do a lot of computations in a few, in just a little bit of typing.
Apply is a function that operates over the margins of an array.
So, this is very useful if you want to take summaries of matrices or other or, higher dimensional arrays.
Tapply is short for table apply.
And, it applies a function over subsets of a vector.
And mapply is a multivariate version of real of lapply.
There's also another function called split which doesn't actually apply anything to objects.
Basically the first argument is a list which is called X.
The second argument is a function or the name of a function and then there are other arguments that are, can be passed to the dot dot dot argument.
And the dot, dot, dot argument is used to pass arguments that go with the function that you're being, that's being applied to each of the elements in the list.
If X is not a list, then you will be coerced to a list if possible.
If it's not possible to coerce the object to a list, then you will get an error.
So the lapply function, you can see, is very simple.
Basically the func we look for the function if it's, if the object is not a list then it's coerced to a list using as.list and then the, the rest of the Lapply function is, is,is implemented internally in C code to make it a little bit faster.
So the idea with Lapply is that you're going to take this list of things.
And remember a list can contain any, any number of different types of objects.
So they could be vectors, or matrices, or data frames, or whatever it may be and you want to apply a function to each one of these elements of the list.
It may not be the same thing that it originally was on the list.
So, for example, it may take as an input, as a vector, but then it may return a scalar as a result.
So, the function's going to return something for every single object in that list, and the return values are going to be assembled in a new list.
So lapply, it's key to remember, it always returns a list.
What goes in may or may not a list but it will be coerced to a list.
I'm creating a list of two elements, the first one's called A, and it's a sequence from one to five, the second one is called B, and it's it's ten or more random variables.
So what I, and then, what I want to do is I want to loop over this lists of two elements and apply the mean function to each of those elements.
So you can see that when I call Lapply on x and I apply the mean function I get another list back, w-, and notice the list has the same names as the original list, a and b.
But now I've got the mean of the first element and the mean of the second element.
The names are preserved and notice, of course, you know, each of the elements of the original list was a vector of some, of a numeric vector of some sort.
But what I'm getting back is a vector with just a single number in it, for each element of the list.
Here I'm creating a sequence one, of x, 1 to 4, and I'm calling runif, so, which generates a uniform random variables, to, using a random number generator.
Now, the first argument to runif, is the number of uniform random variables that you want to generate.
So if I say runif 1 it's going to generate a single random variable.
If I say runif 2, it's going to generate a vector of two random variables.
So, what I'm going to get is a list where the first element is a single random number random uniform.
The second element's going to be a vector of two random uniforms.
The third element's going to be a vector of three.
And the fourth element's going to be a vector for random uniforms.
And so ret, you'll note, if you know the runif function, you'll know that it has other arguments to it beyond the, the number of uniforms to generate.
But those other arguments have default values so I don't need to specify them.
Now, suppose I want to call the runif function on each one of these elements of X but I didn't want to just generate a uniform between zero and one which is default.
Suppose I want to generate a uniform between zero and ten so now I need to pass some arguments to the runif function which are not the default values.
In particular I need to change the max value.
So now when I the, the list that I get out of this has random uniforms that are between zero and ten.
So lapply and the associated functions make heavy use of what, of what are called anonymous functions.
Anonymous functions are functions that don't have names, so you don't assign them a name of some sort but you can kind of generate them on the fly.
So here is a just a quick example, I'm going to create a list that contains two matrices in it.
The first is a mat, a two by two matrix and the second is a three by two matrix.
And suppose I want to, I want to extract the first column from each one of these matrices.
So what I can do is I can call lapply so, there's no function that, out there that already extracts the first column of a matrix but this is easy to do.
You can just write a function that just takes the first element, the first column of that matrix.
So here, when I call Lapply with this function I get the first column from A, and the first column from B.
So this function doesn't exist except within the context of Lapply, and after the Lapply function is finished, the function basically goes away.
Because unless there already exists a function that does the operation that you want to do, you're going to have to write the function kind of on the spot.
So sapply is just a variant of lapply and all it does is it tries to simplify the result of lapply if possible.
So recall that lapply always returns a list but sometimes you don't want a list, sometimes you just want something different.
So for example, if the, if the result is a list where every element is a length 1 then what sapply will do is it'll return a vector of all,of all, of all those elements.
if, if the result is a list where every element is a vector of the same length.
For example, if the, if the list comes back and every element has a length five, for example.
So that, that's often what you want to happen.
But if it, if it can't figure out how to simplify the object when it comes back, for example, if the object has many different types of things that comes back then it's just going to then it won't do anything.
So sapply called on x with the mean function gives me a vector with four numbers in it.
Of course, if I called mean on the, on the list by itself, that's not really going to work because mean is not meant to be applied to lists.
The apply function is another loop function that's used to evaluate a, a function over the margins of an array.
Usu, usually, the function's going to be an anonymous one, like we showed with lapply or it could be a function that already exists like the mean, for example.
It's usually used to apply a function to the rows or columns of a matrix.
But you may have three dimensional arrays and such.
But you, so you can use apply on general arrays such as taking the average of an array of matrices, for example.
One thing to note, and you may hear this out in the wild, occasionally, that apply, using apply is somehow better than ta, using a for loop or somehow it's faster than using a for loop.
And that's, generally speaking, not true.
It was true a long time ago in older versions of the S language in R but right now, it's not true at all.
The main reason you want to use a function like apply is that it involves less typing.
And less, less typing is always better, because good programmers are always lazy.
So, how does apply work?
So a matrix is a two dimensional array, for example.
This is a vector, an integer vector that indicates which margin should be retained.
And the last important argument is the function that you want to apply to each of the margins.
So, and then the dot dot dot argument are other arguments that you want to pass, include other arguments that you want to pass to the function.
so, in, in, in the matrix it's just normal random variables that I've generated.
So when I apply, so what I want to do is, I want to take this matrix and I want to calculate the mean of each column of the matrix.
So the way I can do this is I can apply, use the apply function on x.
I give it the margin, two, and I'll say what that means in a second.
And I pass the function, mean.
And so what happens is, I get back a vector of length ten that has the mean of each of the columns of the matrix.
So, when you apply the function, mean, over the matrix, well, the idea is that you want to keep the second dimension, which is the number of columns, and you want to collapse the first dimension, which is the rows.
It's really the first dimension that's been eliminated.
And so you get this number which this vector which has each of the means for each of the columns.
similarly, you can take the means of all the rows of the array.
And I can, I can call the apply function on x.
And then I, I, here I'm calculating the sum of each the rows, instead of the mean.
So the, so, I cast the one because it says I want to, I, because of what I mean is I want to preserve the rows and collapse the columns.
And each, and inside each and for each row, I calculate the sum of that row.
So for calculating the row sums and row means, there's the functions rowSums and rowMeans.
And similarly, there's colSums and colMeans, which do the same things for the columns.
These are equivalent to using the apply function, but they're very much faster than using the apply, because they're optimized to specifically to do those operations.
So if you want to calculate the sum or the mean of a, of a column or row of a matrix, use those functions instead.
Now you can, you know, use the apply function to apply other types of functions.
For example, suppose you have a matrix.
And suppose I want to go through each row of the matrix and calculate the twenty-fifth, and the seventy-fifth percentile of that row.
So, I can apply on x I, I get, I pass the margin of one, because it means I want to preserve the rows.
Now the quantile function needs, needs, the quantiles that you want to calculate.
So there's no default value for that, so I actually have to pass it to the quantile function through the dot dot dot argument of apply.
And I, and I give it 0.25 and 0.75 meaning I want to calculate the twenty-fifth percentile and the seventy-fifth percentile.
So what this funct, what this call does is, it goes through each row of the matrix, and for each row, it calculates the twenty-fifth and seventy-fifth percentile.
So, the so, here, I'm creating an array with, which has normal random variables and it has two rows and two columns and it's ten and the third dimension is ten.
I guess I'm not sure what you would call that dimension.
But you can imagine this.
So, the average of the, of a bunch of 2 by 2 matrices is going to be another 2 by 2 matrix, which is the mean.
And I want to keep the first, and the second dimension, but I want to collapse the third dimension.
So here, when I, when I give the margin, I give it one and two, which I want to preserve, and then three is not there, which means I want to collapse third dimension.
So here, and then the function I pass it is the mean.
mapply is a loop function that tries, is a multivariate version of the kind of lapply and sapply functions that you've seen previously.
And the idea is that it applies a function in parallel over a set of different arguments.
So one thing we have noticed about the previous functions, lapply, sapply, tapply, is that, they have only, they only apply a function over the elements of a single object.
So, for example, if you think about lapply, the input to lapply was a list.
So, what happens if you have two lists that you want to apply a function over?
And so, and suppose you have two lists, and the elements of the first list go into one argument of the function, and the elements of the second list go into another argument of the function.
So lapply and sapply can't really be used for that purpose.
So one way to do that is just to write a for loop, where the for loop will index the elements of each of the different lists, and then you can pass a function to each of those elements of the list.
Another way to do that though is with mapply, where mapply can take multiple list arguments and then apply a function to the, to the elements of those, of the multiple lists, in parallel.
So here, the first argument to mapply is the function that you want to apply.
And the function that you're going to pass to mapply has to have, the number of arguments that the function takes has to be at least as many as the number of lists that you're going to pass to mapply.
And so if you have three lists, you'll pass three objects and then your function has to take at least three arguments to it.
So, the more args, argument is just if you have more arguments and you need to pass to your function.
And a simplified argument is similar to the simplify arguments that you saw in sapply and also in in tapply.
So it's a little bit tedious to have to type something to do, even though this is a fairly artificial example, but with mapply, it's actually quite simple.
So, that's, so those are the two sets of arguments that I'm going to pass to mapply.
So mapply is, can be used to apply a function to multiple sets of arguments.
So, here's just another very simple function.
It just generates some random normal noise.
So, if I just apply noise to, with a single set of arguments, 5, 1 and 2.
However, this function doesn't work really correctly if I pass it a vector of arguments.
But, really what I want to happen is to have one, one random normal with mean 1, two random normals with mean 2, three random normals with mean 3, etc, and then five random normals with mean 5.
And, so that's what I get here, when I use the mapply function onto the and if I vectorize this noise function I give it, you know, three sets of arguments, so it's 1 through 5, 1 through 5, and then 2.
So I, I'm always going to fix the standard deviation to be 2, but I'm going to be changing the n and I'm going to be changing the mean.
So that's how I can instantly vectorize a function that doesn't allow for vector arguments.
So this is the same as, as I were to manually type out a list with these five different function calls.
Tapply is a very useful function and it's used to apply a function over subsets of a vector.
So the idea is basically, imagine you have a vector usually it's going to to be numbers, so a numeric vector.
And there are, there are pieces of this vector that you want to calculate a summary statistic over.
The idea is that for each group in the numeric vector you're going to calculate a summary statistic like a mean, or a standard deviation, or whatever.
So the basic idea behind tapply is that the first argument is a numeric vector or a vector of some sort.
The second argument is, is another vector of the same length which identifies which group each element of the numeric vector is in.
Then you need to have a factor variable which indicates, you know, which, which observations are men and which, which are women.
And so if you want to take the, the, the mean of the numeric factor within men or within women, then you can use tapply to do this.
So FUN is the function that you want to apply and so this is going to be the same as before.
It's going to be the, either a function or you can pass in an ano-, an anonymous function.
And then the simplify argument indicates whether you want to simplify the argu-, simplify the results, kind of like the sapply simplification.
So, here's a very simple example.
I'm simulating a vector of normal random variables and uniform random variables and, and there's ten normals, ten uniforms, then ten normals that have a mean of one.
So you can think of this vector as having three groups.
And each level is going to be repeated ten times.
So when I print out the factor variable here, you can see that there's ten ones, ten twos, and there's ten threes.
So each, so that the factor variable indicates kind of which group the, the observation is in.
If you don't simplify the result, then what you get back is going to be a list.
I want to calculate the mean and say simplify equals false then I get back a list with three elements and e in each element is the mean of that subgroup.
I, I can pass at slightly more complicated summary statistics.
So here, instead of calculating the mean, which, which returns one number I'm going to calculate the range of observations.
Tapply is useful because it splits up a vector into, into little pieces and it applies a, a summary statistic or function to those little pieces, and then after it applies a function it kind of brings the pieces back together again.
So it's kind of like tapply, but it, but it's like tapply but without applying the summary statistics.
So what it does, is it takes a vector, or an object x and it takes a factor variable, f.
Which again identifies levels of a group.
And then it splits the object x into the number of groups that are identified in, in factor f.
So for example, if f has three levels identifying three groups, then the split function will split x, into three groups.
And so, and then once you've got those groups split apart, you can apply, you can use lapply, or sapply to apply a function to those individual groups.
So here is, is a simpler example, similar to what I had before.
And now I'm just going to split the vector into three parts.
Because because the factor variable has three levels.
The first, I got a list back and the first element is 10 normals, the second element is 10 uniforms and the third element, which gets a little cutoff here is 10 normals again.
So, here for example, it is common to use the lapply function in conjunction with the split function, so the idea that you split something that lapply function over it.
Now, this case, this use of lapply and split is not necessary, because you can use the tapply function which will do the same exact thing.
It's not anymore efficient or any worse to do it this way but the tapply function is a little bit more compact.
But the nice thing about the split, using the split function is that it can be used to split much more complicated types of objects.
So for example, here I've got a data frame for.
So, you can see that this is the first six rows of the data, of this...
And you see there are measurements on ozone, solar radiation, wind, and temperature, and then the month and the day within that month.
And so, one thing I might want to do is, is calculate for example the mean of ozone, solar radiation, wind and temperature in, within each month.
All right, so how do I do this?
And then once I've split data frame into separate months, I can just calculate the means, the column means using either apply or call means, on those other variables.
So that's what I've done here.
What I've done is I split the airquality data frame and this, and the factor I'm going to use to split is the month variable.
So the month variable technically speaking, in the data frame is not a factor variable but it can be converted into a factor variable, because it only takes the values 5, 6, 7, 8 and 9.
Basically because the measurements are only taken in the, kind of, warmer months of the year.
An anonymous function and the anonymous function here, what it does is it takes the column means of just the ozone, solar radiation and wind.
So I'm just going to take the column means of the, those three variables for each month each column monthly data frames.
You can't see them all but you can see most of them into lapply is returning a list back, where each element of the list is a vector of length three which is, which is the mean for ozone, the mean for solar radiation and the mean for wind, within that month.
As you can see that for, for most of the months the ozone value is NA and that's because when I take the mean of that column there are, and there are missing values in that column and I can't take the mean if there are missing values.
So before I fix the missing value problem, I can also call sapply here.
They're all the same length.
So what I'll do is put, put all these numbers into a matrix.
Where the three rows and in this case 5 columns.
For each of the three variables, in a much more compact format, it's in a matrix, instead of a list.
Of course I still got NA's for a lot of them, because the missing values in the original data.
So one thing I knew is I was going to pass the na.rm argument to call means that would remove the missing values from each column, before its calculating the mean.
And that, now when I call sapply on the split list, I can get the, the means of the observed values for each of the three variables for each of the five months.
So, so split is a very handy function for splitting arbitrary objects according to the levels of the factor and then applying any type of function.
And so here I split a data frame, you can split other lists, you can, and, or other kinds of things too.
So the last thing I want to talk about is splitting on more than one level.
So you, in the past couple of examples what I've, I've only had a single factor variable.
And I've split whatever the object is with a vector or a data frame.
That has, for example, the race.
And so, you might want to look at the combination of the levels within those factors.
I've got a factor with two levels, and each repeated five times, and then I've got another factor with five levels.
So there are my kind of two category, two group, grouping variables here.
So I can use the interaction function to combine all the levels of the first one with the, all the levels of the second one.
And so because there are two levels in the first factor and there is five levels in the second factor and there is a, the total combination of 10 different levels that you can have when you combine the two together.
So when you see, when I call, when I called the interaction function I get another factor, that kind of concatenates the levels of one with the other, and you can see that it prints out that there is a total of ten levels.
So, what now I can slit my numeric vector x according to the two different levels.
So now, when I Iike, when I use, now one thing, when I use the split function I don't have to use the interaction function.
I can just pass it a list with the two factors and it will automatically call the interaction function for me, and create that 10 level interaction factor.
And then and then, and then the elements of the numeric factors that are within those 10 levels.
Now of course there are, although there are 10 levels between the two different factors, that we don't exactly observe every single combination.
And so there are some empty levels here and you can see that some of these levels have nothing in them.
But, sometimes it's a little bit handy to not have to keep these empty levels.
So, so the split function has an argument called drop.
And if you specify drop equals true, it will drop.
And, and this can be very handy, when you're, you're combining, multiple different factors.
If you're only using a single factor, then doesn't, that argument doesn't really do anything, because you'll just use all the, all the levels but, usually.
Alright, so so today's lecture is about the debugging tools that are built into R.
So how do you know that there's a problem?
So, there are a couple of indications that R, will produce that that will give you the sense that there's something going on.
But, basically there are three main types of indications.
It's just an in, it could be a diagnostic message that something happened.
But it could, it could be nothing.
And and so the message won't stop your function from executing.
There will be a message that gets printed to the screen and the execution of the function will continue and that's all.
Usually, if you're writing a function, you are choosing, you're trying to figure out, okay, what's a message and what's a warning.
furthermore, or if you're using a function and you're figuring out well what does that mean, a warning is an indication that something unexpected happened it's not necessarily a problem, and may, and many times you, you, you explicitly want to ignore warnings but there's something unexpected happened.
It wasn't enough to kill the whole thing, But it was enough to kind of trigger this warning.
So execution of the function will continue if a warning occurs but you'll get a message after the end, so once you'll get a message when the function completes execution.
So when the function comes back, when you get your console back, that's when the warning appears.
By default.
So an error is a fatal problem.
This stops execution of the function.
And and these, and error messages are produced by the stop function.
So and then there's a general notion of a condition.
Which is it's the higher level concept.
It can, all three of these things are, are conditions.
So if you have, and generally you're not going to be doing this at this level but if you have a, a, another type of of, condition that you want to, kind of trigger when something, when a special thing happens.
So it's not an error, it's not a warning, and it's not a message.
You can create your own conditions and and using some of the functions that are available.
So we won't be doing that now, but there is this notion of a condition and it's, it's generic.
You take the log of a negative number.
You can't do that, right?
It's a NaN, right?
Not a number.
So this is your typical and, and sometimes that's fine.
Because maybe you're taking a log of a bunch of numbers and maybe some of them are negative, but you don't really care and then you're going to make some sort of plot or something like that.
So so this is the kind of thing where you probably wouldn't want the function's behavior to just stop anytime it sees a negative number because sometimes these things just happen.
You get negative numbers on occasion and you want to take the log anyway.
Now I've got a little function here that I've created.
It checks to see if it's greater than zero.
If it's less than or equal to zero, you get a message saying that it's less than or equal to zero.
and, and then last I want to mention this part here.
So invisible is a function that that, that stops or I should say prevents auto printing.
So normally when you, if I if I'm at command line and I type a function, remember the, and I execute a function the, the function will return the last element of, that's in its function body, right?
So if the last sum in this function body is like is numeric vector, it will return that numeric vector.
If I call invisible on the return object, then it will still return the same object but it won't, it wont do the auto printing.
So you can call the function and the object will be returned.
So a, a, a, a, an example of a function like this is the load function.
So we haven't really used that much, but the load functions loads objects from what, from a saved work space, so it's like the opposite of of save, right?
and, but when, and when it loads the objects, it actually returns a character vector containing the names of all the objects that it loads.
But that doesn't get printed to the screen and because, it's, it's returned invisibly.
So if you have a function that returns something invisibly then the return, what happens is that the object that gets, that gets returned by that function doesn't get printed to the console and so sometimes you want that to happen and sometimes you don't.
Sometimes it doesn't matter.
So here I've, I've just added this here just so I can, you know, tell you about it.
It's not particularly important.
So when you say print X, what gets returned is a string, X.
So, so, so, so you could assign the output of print to, like, an, an object.
Generally speaking, you never do that.
No problem.
So and so what does printmessage return, just before I go on?
And so actually, if I had assigned print, the output or printmessage to some other object, it would be the number one in this case, right.
Even though it didn't printout the number one anywhere.
So now, I'm going to pass it directly an NA, right.
And so it doesn't know what to do it can't move on.
It, and so it has to error out.
So something happened there that's wrong.
Now, I'm going to to fixed this problem so to speak.
So, now I if it's NA, I'm going to print this message, right.
So when I call this, so now what, so what's something that might typically happen?
Now I'm going to printmessage on x, and I'm getting x as a missing value, right?
Because maybe I, I, I, maybe I thought that, okay, well the thing that I'm inputting into printmessage2 is, is like some positive number, so I thought I was going to get the message X is greater than zero.
So what happened right?
And so all I'm trying to say here is how do you know when something's gone wrong, right?
And sometimes it's easy to tell like in the case where you got the error message.
But sometimes it's not easy to tell because here there's no error but it's not exactly what it, what I was expecting, okay.
It's when you, when you're looking at a function, you think something's gone wrong, there's a couple questions you want to ask yourself.
To see whether there something actually is wrong, or maybe, or is there is something we call user error, okay?
So what was the input that you put?
What, what did you feed into that function?
Okay, not what you thought you fed into that function, what did you actually into that function?
Okay, so I thought I fed that function a positive number but in reality I fed it a, a NaN.
Alright, so how did you call the function?
So you, and this is important when you're asking someone for help, or you're asking someone a question.
I can't just, it's not that useful to say oh the printmessage2 to function didn't work.
How do you know it didn't work, alright?
That's how you know it doesn't work.
And then, someone could say, well you shouldn't have expected this, because that's not what that function does, or you know, or something like that.
But or you can say, okay, here's the problem.
So what were you were expecting is then very important to be able to articulate at least to yourself and maybe to other people.
What was the output that you were expecting, were the were you expecting some message that you didn't get?
So what we're expecting, and then of course, what did you actually get?
And then of course were expectations correct in the first place?
So, if you were expecting something that was, that was in fact incorrect then your notion of what is correct and incorrect is now being challenged, right?
So an important, and another key aspect of debugging of course is you have to be able to reproduce the problem, right?
Because if you can never reproduce the problem, you'll never have a chance in figuring it what went wrong, because it only happened that one time, right?
So this is very, very, very, very important.
And unless it's a very I mean unless it's like the most basic problem.
You have to be able to reproduce the problem.
You know, because you have to be able to show someone this is how I created the problem.
Because most people are not going to know if you just show them the output of the error message, or what that means, or where it came from or how you got there.
Okay, so the process by which you encounter the error or the problem is very important.
So you, you have to know how to reproduce the problem.
And, if you're not setting the seed, you will never be able to reproduce that problem, because every time you run it, it's going to be a different set of random numbers.
There are other types of problems that can be hard to reproduce.
They're usually, for example, if you're writing networking co, networking functions, you know, something, so you're doing like parallel programming, often, those kinds of problems can be very hard to reproduce because they depend on activity in other machines and things like that.
Things that, if you're getting code over the internet, and so if you're getting data over the internet, and your code is kind of interacting with things in the web, that can, problems there can sometimes be hard to reproduce because servers on the other side may change or whatever.
And so you, you can't always freeze things in time.
If it's something that's just happening on your computer it's usually going to be easier to reproduce the problems.
so, unless, I mean only under very esoteric circumstances, circumstances will it be hard to reproduce a problem on your computer.
so, what are the tools that R comes with to help you to debug a program?
Right, so there are five basic functions and a few associated ones that I want to talk about.
But the first most basic one is the traceback function.
Now, one thing I want to say, you can get pretty far in R without using any of these functions.
So, the traceback function, what does is it prints out what's called the function call stack.
So you know, typically when you call a function, you call, you call the function and that function calls another function, and then that function calls another function, and it's like, and then you're four functions deep, and then maybe the error happens way down here, right?
And so, traceback just tells you how many function calls you're in and where the error occurred, right?
And so you can try to identify where in the sequence of function calls the error occurred.
Otherwise, all you know is that you called one function and then an error occurred.
But you've no idea, you know, how many other functions are called underneath.
So the traceback function will tell you that, and I'll give you an example.
So the debug function is probably the handiest function.
It, what it does is it, as you give it a function as an argument, and it flags that function for debug mode.
Okay, what debug means, that anytime you execute that function, anytime, anywhere even if another function calls it, it will, it will halt, it will suspend execution of the function at the first line, and then you can, in what's called a browser.
And I'll show you how this works and then you can step through the function line by line.
And then you can see you can execute one line, one expression at a time, I should say inside the function.
So you can try to pinpoint, okay, if there's a specific line of code when the error occurs, you'll be able to find out which line that is, okay.
And then you can, and then you can go line by line from there.
So sometimes, for example, you don't, the debug function by the, will always start the, start the debugging, start the browser right at the top of the function.
But sometimes, you kind of want to run through the beginning and then stop it somewhere in the middle.
And so, so the browser function allows you to stick the browser call anywhere in your code and then it will run the function up until that point and then suspend it.
So so that, so there, those two are obviously related.
The trace function allows you to insert debugging code into a function without actually editing the function itself.
and, and this is handy if you are debugging someone else's code.
Right, so for example, there's code in the package or the, and you can't easily edit the code in that package, or there's code in the base R itself or there's you know, something like that.
And you don't want to go and edit that code, because you can't find the file, or whatever.
And then and, and then, and then you can kind of browse through that function, and then you can turn the trace off, and it's, and the function's back to normal.
So that, and then the recover function is the last function.
It's actually, I should put it up here, it's related to the traceback.
What recover does, so normally when you get an error you get, you usually get a message saying what the error was and then the, and then you get, and then the console kind of comes back to you.
But execution of that function stops and you get the console back.
You can change that default behavior by, by, by creating what's called, or setting what's called an error handler.
And recover is an error handler function which means that any time you encounter an error, anywhere in a function, rather than getting the console back the R interpreter will stop the execution of that function right where the error occurred, and will kind of freeze it there.
Now you're in the browser, and you can look around in the different function calls to see kind of, okay, what happened here, and happened here, what did the, how did data get corrected here and things like that.
It's a little hard to talk about in the abstract so I'll give you the example.
So there's also, so these functions kind of allow you to pick apart the kind of the details, the lines of code and try to figure out, okay, nail down where exactly the the bug may be.
You can also just put things like print, and cat, statements in your code to print out things.
And you can get a lot of mileage out by just putting in print statements.
The only problem with print statements and things like that, is that you often you'll put in like a lot of these, it's a long piece of code, you'll put in like 40 print statements.
And then I go back through and, like, delete all the print statements.
So that's, that can be a little bit kind of a pain, but you know, there's nothing terribly wrong with it.
Some people I've, I've, that I've worked with are actually against, they like, oppose the use of debugging tools.
I've ever software engineer company many years ago and there was an engineer there who was, he, he was opposed to any debugging tools.
He'd never used a debugger.
And because he thought that the use of the debugger encouraged bad habits, right?
I've seen it happen in other places.
If there's a problem, I'll just run it through the debugger.
And, and it encourages kind of a sloppy code development process because you know that if there's a problem you can just step through execution with the debugger.
It's probably better to think about your code, write it in, in a kind of intelligent way and then if there's a problem resort to the debugger.
But I use the debugger all the time.
I use the browser function, I use all these functions all the time.
So maybe I just have bad habits but that, that memory is burnin' my mem, mem, burnin' my brain for some reason.
Let's take a look, I'll just give you a couple examples and then I'll move to the actual just so you can see things.
So if you take the mean of something that doesn't exist you're clearly going to get an error.
Here it says so you get the error message this is produced by the stop function.
Well the error just occurs like right away at the top of the mean function.
And so, that's where the error occurs so, you know that may or may not be.
Many times that's just that is where the error will occur at the top level function.
One thing that's useful to, that, that the trace-back is useful for, is for when you're communicating with someone else over email, for example, me.
Its very useful if we just say use the trace-back, when I get after I get the error.
You have to call traceback immediately after the error occurs.
If you execute some other code and then call traceback it's not going to work, right?
Because the traceback will only give you the most recent error.
So you have to you've to call it right away.
Here's a slightly more interesting trace back so I call it LM, which is the linear modeling function.
So I don't expect you to understand all this but L M called e val on what's called a mono frame.
Model frame is a generic function that called a model frame default function.
So and it basically it occurred because it tried to evaluate my formula here.
And and it couldn't.
And when it evaluated the formula it couldn't find the actual value of y and x.
If you're trying to get help from someone else and you're, and you're, and you're kind of trying to debug your function together, okay?
The debug function doesn't really work well in the static format like this, but I'll show, I'll just show you that, but But, basically I could debug the l m, so you can debug any function, doesn't matter if you wrote it or not.
So I can debug the l m function, and now when I call l m y fill the x it you get this debugging in and I'll give you the the expression that you called.
And then you get this little prompt at the bottom here the browse so now you're in what's called the browser.
And the browser is just like your r workspace, actually.
you, you can think of it like a work space embedded within a work space.
Are, sorry, so the environment of that workspace in the browser is your function environment.
So the things that are in your function are what are in your environment.
So at, at the very top of this function you just actually, there's nothing in your environment except for the function arguments, right.
So I have a formula in my environment which is this y tilda x, but that's it.
So anyway so now I can well there are actually I should say there are other arguments so l'm too which are default values.
So here what I do is I press n for next and it runs the first line.
When I hit n and then enter and it runs the first line.
I just keep hitting n, n, n, so I run, and I just execute each line until I get to the line where the error occurs.
So when you get to the line where the error occurs.
But, at least you'll know where that error occurred, okay?
So and further more, suppose you want you can debug functions within the debugger, right?
So this match.call function I just kind of stepped right over it but I could have gone into this function by calling debug on match.call before executing it and then when this got executed I'd be in the third level of the browser.
So so you can, you can, you can call the debug function on functions.
The recover function, so the you can set the recover to be this kind of error handler by using the options function.
So now I'm going to what I'm trying to do is I'm going to read that csv some file that doesn't exist.
Okay, and then you get an error and you get the error message, cannot open the connection.
And now bu, but instead of getting my console back, I get a little menu here.
And this menu is the function call stack, okay.
So it's the same thing that you would get back, if you called trace back after the error.
Obviously you couldn't find the file, and that's where the error occurred, okay?
So the error occurred at the third level in the function call stacks, so what you can do, is you can press a number one, two, three and then you can kind of browse the environment of that function.
So if I want to see okay, what was the read, what was going on in read.csv, I can just press one here, and then it would show me kind of the environment of the read.csv.
And, and then I can break out of that and look at the environment for read.table, and et cetera.
And so you can, if you have a very long function call stack, you can kind of jump back and forth to see what was going on at each, at each function call.
To to try out a pinpoint kind of where the problem occurs.
So so just to summarize really quickly there's, there are basically three main indications of some sort of problem or condition.
There's the message warning error and of the three only the error will stop execution of the function.
When you're analyzing a function that has and you think has a problem make sure you can reproduce that problem.
And then you make sure you can articulate how what do your expectations and how'd and what the output are that and how the output differs from what you were expecting or I'd like to say what you are expecting.
And so that the, the interactive tools trace back, debug, browser, trace, and recover can be used.
And it's, and the keyword actually here is interactive.
You can kind of do things on the console.
And of course the debugging tools are not a substitute for thinking.
And so you should always think about writing your code before, you know, just throwing it to the wind and hoping the debugger will catch it.
This video is about the most important function in all R, the str function.
This function is really handy.
I use it all the time.
And you can use it in all kinds of situations just to help you out, to look at R objects.
So it's a very simple diagnostic function.
You can use summary which will often be very useful.
It's partic, particularly well suited for compactly displaying large lists which may contain nested lists.
And also and, and its goal is to produce roughly one line of output per basic object.
For example so if you give it a simple object like a vector, it'll give you one line of output backup.
And so the basic goal of str is to answer the question, what's in this object?
I'm going to start up R here and I'm going to just give a little demonstration of how the str function can work.
So here, you can apply str to itself and see it's a function that takes an object.
So, so you can apply str to other functions.
So let's say I want to know what the lm function does.
So here, what it gives you it gives you the, the function arguments for the lm function.
Let's say I'm going to generate some normal random variables here, 100 of them, let's say mean two variant, and standard deviation four.
So you get the mean, median that is 25th, 75th percentiles and the min and the max.
So that gives you a rough sense of kind of what the range is and how it varies.
You can also call str on x and it will give you a little bit more information.
So it'll give you a one line output.
It tells you that x is a numeric vector.
And then, and it'll give you the first five numbers in this vector.
So you can get a sense of kind of what the data looked like.
So you can apply str to other types of vectors.
So here I can create like a factor variable.
And it'll give me a one line output again.
The level, the first four of them are named 1, 2, 3 and 4.
And then here, I've said the first couple of elements of this factor are all in the, k-, all have the label, one.
You can also call summary on a factor, and you can see that the output's a little bit different.
And what this does is it, is it gives you the number of elements in each of the 40 different levels.
So that's another piece of data that's not quite as compact of output as str gives you.
So you can use str for other types of data types.
So here, I can, I can load like a data frame.
So, you know, if I look at the airquality data set, I can use the head function to look at the first six rows, or I can call str to get a little some different output.
It tells me that there's a 153 observations, so 153 rows in this data frame with, of six variables and then for each variable, it, it gives me a little output.
So it tells me that the name of the first variable is Ozone.
Variable and, and here are the first could of observations.
You can see there are some NAs there, so that's useful to know.
The second variable is called Solar.R, and it's also an integer, and you can see the, the first couple of values.
So, the Str output here is very useful for kind of just getting a quick examination of data that you might have in R and what the structure of different R objects is.
See, it will give me a little bit more information.
It'll say that it's a, it's a two-dimensional array.
That it's got 10 rows and 10 columns.
So that's going to be the first column that you're seeing there.
The last thing I'll do here is create a little list by using the split function and see how str can look at the list and give a compact summary of it.
So, I'm just going to take this air quality data frame And split it by the month.
So here I go to airquality, going to split it by the month variable.
So now if I call str on S you'll see, well there's a little bit of output that flies by.
You see now this is a list, that contains five different data frames where each data frame corresponds to the data for a given month.
And you'll see for June, here, there's 30 observations on six variables again, same six variables, of course.
And that's what the data look like there.
And then for July, the data are here.
So you can see the you can have a representation of this split list that's kind of, that's not as compact as it was before but it's about as compact as you can make it and str will provide a very nice summary.
You can take a quick look at the data.
See if there's missing values and get a sense of what to do next.
So that's the str function.
I'll, I'll repeat again, I think it's the most useful function in all of R and you can use it in all cases.
I encourage you to use it anytime you have an R object and, you don't know what's there.
I'm going to talk about simulation in this lecture.
Simulation's a very important topic for statistics and for a number of other applications, so I just want to introduce some of the functions in R that can be useful for doing simulation.
So, there are a couple of functions that are available for simulating numbers or variables from given probability distributions, probably the most important of which is the normal distribution.
And so we can generate variates from the normal distribution by specifying a mean and a standard deviation for that distribution and then calling the rnorm function.
So the rnorm function will simulate normal random variables that from a distribution has a given mean and standard deviation.
So the, there's a cor, there are corresponding functions for the R, for the normal distribution that can be used to evaluate the probability density, to evaluate the cumulative distribution function and for also for evaluating the quantile function.
So, another function for generating random variables is the rpoirs function or the, which generates Poisson random variables from a Poisson distribution with a given rate.
And so, so there are number of functions for generating random variables from the, from kind of the standard probability distributions.
So, probability distribution functions ha, there are basically four functions associated with them.
And so for any given distribution like the normal distribution there will be a function that starts with the d, a function that starts with an r, a p, and a q.
So there'll be four different functions for each distribution.
The rnorm function is for generating the, is for random number generation.
There's a dnorm function, which evaluates the density of the probability dist distribution for given mean and standard deviation.
There's the pnorm function, which evaluates the cumulative distribution.
So every distribution has these four types of functions.
So for the gamma distribution, there'll be a dgamma, an rgamma, pgamma, and a qgamma function.
And for the Poisson distribution there's the rpoise dpoise ppoise, and qpoise functions.
So working with the normal distribution re, requires these four functions.
So I mentioned there's dnorm, pnorm, qnorm, and, and rnorm, and you can see they each take a number of different parameters.
All the functions have required that you specify the mean and the standard deviation, because that's what specifies the actual probability distribution.
If you do not specify them, then the default values are a distribution, a standard normal distribution, which has mean zero and standard deviation one.
For the dnorm function the, you wa you can evaluate the density.
Most of the time, when you evaluate the density function for a normal distribution, you're going to want to use the log of that value.
But the default is false.
For the pnorm function and the qnorm function there's also an option to evaluate it on a log scale.
So the lower tail, which is the default, is the kind, if you think of it, if you look at the probability distribution it's the part that goes to the left.
Then you want to say lower tail equals false, and that will evaluate the upper tail of the distribution.
And finally for rnorm, there's only two parameters, mean and standard deviation, and an n, which is the number of random variables that you want to generate.
So if n is 100, you'll get a vector of 100 numbers that are drawn from the, from the normal distribution.
So just to be more explicit, if phi is the cumulative distribution function for the standard normal distribution, then pnorm is equal then to phi and qnorm is equal then to the inverse of phi.
You can just rnorm and pass in an integer, which is the number of variables you want to generate.
And you can see that the vector that's produced will be random, normal numbers which have mean zero and standard deviation one.
If I wanted to generate a vector that had mean 20 and standard deviation two, I, I just need to specify that explicitly in my call to rnorm.
So here, this vector has a, is, are, ten random normal vi, sorry, normal random variables and their mean is roughly 20 and their stand deviation is two.
So when you, any time you simulate random numbers wi, from any distribution for any purpose, it's very important that you set the random number generator seed.
So, what's important to know that on computers when you generate random numbers, the numbers are not actually random but they appear random and that's the important thing.
And so here I'm setting the seed to be one.
So the seed can be any integer you want.
You just pass in an integer, and that's the seed.
If I generate another five, you'll see that the vector is totally different, because it's another random sample of five.
However if I reset the seed to be one, and I draw five again, you'll see that they're exactly the same as the first five that I drew.
So anytime you, so when you set the seed it kind of sets the, the sequence of random variable that's just going to occur.
And if you reset the seed, you kind of set the sequence to go back to where you started, and then it will continue to kind of generate random variables from there.
so, this is important because it allows for you to reproduce random numbers that you generate.
Now that might sound strange, because why would you want to, to re, generate the same random numbers twice?
But in many applications you do want to generate the same random numbers twice so that people can reproduce what you've done.
And particular if there are some errors or problems in what you've done, you want to be able to get, just to kind of go back to the exact situation that produced those problems.
So whenever you do a simulation, you always want to set the random number c, so that you can go back and get the same results.
So I've demonstrated how to generate normal random variables, but of course you can generate random variables for other probability distributions.
And and so of course Poisson data are going to be integer.
And then here I'm generating ten random variables Poisson random variables with a, with a rate of 20.
And so, so for the Poisson distribution, the mean is going to be equal to the rate.
So you can see that roughly in each of these three cases, the mean is roughly equal to the rate that I specified.
I could also evaluate the cumulative distribution function for the Poisson distribution.
So here I'm in this first example I want to know what is the probability that a Poisson random variable is less than or equal to two if the rate is two.
If I wanted to know what's the probability that, that a Poisson random variable with rate two is less than four, less than or equal to four.
And here I can see the probability that a Poisson random variable is less than six.
So the cumulative distribution allows you to, to evaluate these probabilities.
The profiler in R is a really handy tool for when you're developing larger programs or, or doing really big data analyses.
and, and you're basically, essentially running R code that's taking a lot of time, or longer than, you know, than you want to wait.
And of course that's all relative depending on kind of what you're working on and what, maybe there are some other things that you can do in, while you're running a program.
But if something's taking a long time the profiler is a really handy tool to figure out exactly why it's taking so much time and how to, and to suggest kind of strategies for fixing your problem.
So I'm going to talk a little bit about using the R profiler and our, and, and kind of talking about when you might need to use it.
So, the first question you want to ask yourself is, you know, is your code actually running slowly?
And sometimes you can solve this problem by just you know, running your program then going and doing something else.
But sometimes that's not an option and you need your program to really run quickly.
And so profiling is a general, is a systematic way to examine how much time is being spent in various parts of your program.
But then sometimes these pieces get embedded in a much larger program.
And then your one little piece, which was running great when you were running it, is kind of slowing down everything else because it's being run ten thousand times.
And so now you need to make it a lot faster because it's being iterated over a lot.
So in general when it comes to optimizing your code, the, the general rule is that you shouldn't do it.
And what I mean by that is that you shouldn't think about it at first.
It should and, the first thing that you, you should think about, is is that, is kind of how, how to get the code to run, how to make it readable, how to make sure that other people can understand what you're doing.
And because, and one of the reasons is that it's often difficult to understand, where exactly your program is spending all of it's time.
And in order for you to speed up your program, you need to be able to know where it's spending it's time.
And so this can't be done without any kind of, it's difficult to do this, I should say, without a formal performance analysis or profiling.
and, and then the famous phrase is, you know, premature optimization is the root of all evil.
If you try to optimize first the chances are that you'll introduce bugs before you even have a, get a chance to kind of get things working in the first place.
Once you've decided that you want to optimize your code, though, you should, you know, act like a scientist.
Just like you would in any other context, you should collect some data.
So, the first tool I'm going to talk about is actually not the profiler it's a very simple function called system.time in R.
And what system.time does is it takes an arbitrary R expression and evaluates that expression and then tells you the amount of time it took to evaluate that expression.
Now this expression could be very simple like a single function call, or could be very complicated if it have to be wrapped in curly braces.
So, it could actually be a very long expression if you wanted to be.
So, the basic idea is that you take this expression and it gives you the time in seconds, that was, that was needed to execute the expression.
If there's an error, you know, in the code while the expression's being evaluated, then you'll get the time until the error occured.
now, there's two very important notions of time when you're exe, executing expression on, on the computer.
The first is called the user time and this is the amount of time that's charged to the CPU or CPUs for this, for running this expression.
Okay, so this is the kind of time the computer experiences, roughly speaking.
And so the two different notions of time can kind of different importance depending on what you care about.
So usually the user time and the elapsed time are relatively close, because the amount of time that the computer spends to do using, you know, executing your fu, your function or expression, is roughly equal to the amount of time you spend waiting for it, right.
however, there are times when the elapsed time will be greater than the user time, and there will be times when the elapsed time is smaller than the user time.
And, and so the CPU doesn't actually spend a lot of time working on your code, it may be spending a lot of time on other things that are going on in the background.
If the elapsed time is smaller than the user time this most commonly occurs if your machine has multiple cores or processor and is capab, and is capable of exploiting them.
So this, so most of the computers these days, have at least two, or four cores or multi core machines and so this is a very common situation.
However, it's not always that the compute, the program that you're running will be all to kind of exploit the use of multiple cores.
In particular, R, the basic R program does not use multiple cores as of yet.
So if you're doing something like regression, or a lot, a lot of these prediction routines or, or matrix computations, these all involve linear algebra libraries.
And many of these libraries have been optimized to use multiple cores.
And so they're, they're called multi-threaded BLAS libraries or, for the basic linear algebra standard libraries, subroutines libraries and on the MAC sometimes called vecLib or Accelerate.
There are more general libraries like ATLAS for AMD machines, there's ACML or ACML, and for INTEL machines there's MKL.
There's also parallel processing libraries, for example the parallel package which doesn't use, which can use multiple cores but it can also use multiple computers.
And so this will, will lead to, potentially lead to a program that takes more user time than it does elapse time, and I'll give an example of how this will work.
So, one example when elapsed time will be bigger than the user time, is if you read something from the web.
So here I'm just using the read lines function to read a web page off off, off, off a remote server.
And you can see the elapsed time is about 0.4 seconds but the user time is about 0.004 seconds.
And the second example, this is where the elapsed time is less than the user time, I've created a simple function which creates which creates a hilbert type matrix.
And I calculate the singular value decomposition of this ma, matrix with the svd.
And so you can see that the user time was roughly almost double of the elapsed time.
So the elapsed time was about 0.7 seconds and the user time was about 1.6 seconds.
And the pa, and the reason is because the the underlying linear algebra library split the computation across the two cores.
And so you can think about of it is, but basically the elapsed time was multiplied times two, because it was being executed on two different CPUs.
So the amount of time that the user, the CPU spent working on your program was actually more than the amount of time that you spent waiting for it to come back.
And you can wrap that whole thing in curly braces and call system time around it.
And you can see that here this is a very simple expression, it's not multi threaded, there's no network activity, and so the user's time and the elapsed time are basically the same.
Now the part of problem with system time is that it assumes that you know where to look.
Assumes that you know where the problem is and that you can call system time on a given expression.
And so, this may be useful for smaller programs for less complicated programs where you have a very good sense of, kind of where the bottlenecks are.
What if you don't know where the problems might be and where to start looking.
And it, an Rprof is used to start the profiler in R.
One could note is that R must be compiled with profiler support and so it's not something that's going to built in all cases.
However, and I'd say 99.9% of the cases this is the true, this is the truth, so mu, you will only, R will only be compiled without profiler support in some very cer, special circumstances.
And so I wouldn't, the chances are your version of R use, it can use the profiler.
And so the summary Rprof function is very important.
It's important to realize that you should not use the system time function and the R Profiler function together.
So you should always use one or the other and not both.
So the Rprof function keeps track, basically what it does is it keeps track of the function call stack, at regularly sampled intervals, right?
And in general, because it will never sample the function call stack.
And in general if your program is runs very quickly, the profiler is not useful.
Well, and but of course that if your program runs very quickly, you probably wouldn't think to run the profiler in the first place.
So it's usually not a problem.
But you really need to use the profiler in situations where your code is taking much longer on the order, at least on the order of seconds.
So here's just a quick example of the raw output that comes from the profiler.
Now you generally speaking you will not ever use this output, but I thought it might be interesting to look at what's going on.
And, and what happens here, as you can see, that each line of this output is the function call stack.
and, and at the very left is kind of the bottom, so to speak.
And the, so the very right, you can see that lm was called, and lm called eval, and eval called eval.
And eval called model frame, which called model frame default, which called eval again and eval in the list.
As you go further in the evaluation you can see that that the function calls that changes, so at the very bottom you can see that lm called lm.fit.
And if you're not familiar with the LM function, lm.fit is really the workhorse of this function, it does all the really kind of computation.
And so, you, you wouldn't suspect that it would spend a reasonable amount of time in the lm.fit function.
So, that kind of raw output is not particularly easy to read, so we use the sumaryRprof function to tabulate the Rprof or the output and calculate how much is spent in which function.
So, the idea is that once you see that the function call stack, you know that the, that each line of the con, the function call stack is separated out by 0.02 seconds.
So, given that you can calculate how many seconds are spent in each of the functions, because if it appears in the function call stack then you're actually spend, then you must be spending some time in it.
One is called by.total, which divides the time spent in each function by a total, by the total run time.
And by.self, which does the same thing, but at first subtracts out time spent in functions above in the call stack.
So, its important to realize that the two separate concepts here of kind of, by.total and by self.
The basic idea is that by total, I, I mean, the, the normalizing by the total amount of time spent in a function gives you basically, how much time was be, was spent that that how many basically, how many times that function appeared in the calls, in the kind of printout here.
So chances are if your function is spending a lot of time doing something, it's spending a lot of time in those helper functions which is just being called by this top function to kind of do, to do all the work.
And so often it's not very interesting to know how much is time is spent in these top level functions, because that's not where the, where the real, where the real work occurs.
All right, so you really want to know kind of how much time is spent in the top level function, but subtracting out all the low, the functions that it calls right?
So it turns out that it spends a lot of time in the top level function, but even after you subtract out all of the lower level functions, then that has something that's interesting.
But most of the time you will notice that when you subtract out all the lower level functions that get, that get called there's very little time it spends in the top level function.
And because all the work and all the kind of the computations is being done at the lower level function, so that's, that's kind of where you want to focus your efforts.
So it gives you I think a more accurate picture of, you know, which functions are really, are truly taking up the most amount of time and which functions that you might want to target for optimization, later on.
So the total time was 7.41 seconds for this run.
Of course, because lm was the top level function.
And so that was three and a half seconds, so about half of the time in that function.
Now, I think a more useful output is the by.self output which kind of subtracts out any lower level function calls from, so and calculates the amount of time spent in a, it's kind of truly spent in a given function.
And here you can see that lm.fit is the clear winner, because that's really where all the computation occurs.
The next function that takes a lot of time ap, ap, apparently, or 11% of the time is the as.list function, for the as.list.data.frame method.
It's not immediately clear why so much time is being spent in this, but, spent in this function, but it's maybe something you want to investigate.
for, and so you can kind of go down the list here and see how much time is being spent in various functions.
And then you'll see a lot of these functions don't directly pertain to computation or kind of core computation, but they're really more kind of pertain to data, formatting of the data and things like that.
The last part of the summaryRprof output is just the sample interval, so you can see how, what, what time interval the sampling took place for printing out the function call stack.
And the sampling time, which is just the total amount of time that the expression took to run.
This is the same kind of, this is so this is the, I think equivalent to the kind of elapse time in the system.time function.
And because they're not really core to the kind of, the real computation that you're working on.
So the profiler can be really useful, I think for highlighting these kinds of situations and, and often finding things that you are kind of unexpected.
The summary Rprof function summarizes the output from Rprof and gives you the percent time spent in in each functions.
And I think the by.self kind of normalization is the most useful for kind of highlighting bottlenecks in your, in your code.
One of the, one of the implications of using the profiler is that it's useful to break your code into functions.
So rather than have one massive function, it's useful to break your code into kind of logical pieces of different functions.
And so the profiler can use this information to tell you where the time is being spent.
In the function call stack to tell you kind of where the, where the code is spending the most amount of time.
So that's another little strategy that's kind of that's can be useful when you're profiling your R code.
All you will know is that some time is spent there, but you won't know any details about that.
Module one is where we start to talk about the Raspberry Pi and connecting it to the Internet.
Now, we're talking about, in this module, we just talked about connecting it to the Internet in a sort of a user way, not a programmatic way.
So, by this I mean, connecting to the Internet and using it as if you were sitting it down at a laptop or desktop, and use the computer in that way.
So you got to, that's a different, a very different interface then if you're a programmer.
Right, we'll get to programming later, or we'll start at the end, but right now, we're just going to say, hey, look, how do I connect this to the Internet?
And address, how does it join the network?
We'll talk about wired and wireless network.
Rather using it as a user, we want to write code that connects the network and access the network.
So we start getting into that by the end of this module and describing the protocols for that and how programmatically you would start controlling it.
So we have to talk a little bit about IP addressing and port addressing so that we know about that, so that we can write code that deals with that.
Thank you.
In this video I'm going to talk about how to install R studio for the Mac.
It's a very simple process and it only involves just a few steps.
The one thing I'll say though is that you must have R already installed before you can install R studio.
So once you've installed R already you can go to the RStudio web site, which is rstudio.com.
And you can see down here on the lower left, there's a green button that that directs you to, to kind of download RStudio.
So here there's two versions of RStudio, Studio that you can download.
One is for the desktop and one is for the server down here.
So you just want to download the desktop version.
So that's this button right here.
So the website should detect automatically what type of operating system you're running.
So here I'm running a Mac, and so it recommends this Mac OS X version, so I'm just going to download that right now.
And you'll see the download meter go.
Once that's finished downloading you can go to the Downloads folder, and it should be the leftmost thing here.
And then just like any other Mac application, all you have to do to install it is drag it into the Applications folder, so I'm going to do that right now.
So I can just go into the Applications folder here find RStudio, double-click on it.
In this video I want to talk about two things.
So you can see I've got R started up here and the first thing you're going to want to do is figure out what your working directory is.
Because the working directory is where R finds all of its files for reading and for writing on your computer.
So you can find out what your working directory is currently set to be by using the getWD function.
Now it, the reason why it's important to know and to set your working directory, is because when you read data or when you write things out, using functions like Read or Write CSV they will be read or written to your home, your working directory.
So for example if I do something like read.csv I want to the read let's say mydata.csv.
If the file is not in my working directory you'll get an error one that looks much like this because it can't find the file in the working directory.
So one possibility is that you can, if you know where this file is, you can move it to your working directory.
So I can go to the file menu here and choose Change dir.
And I'll go to my desktop here.
So now if I type DIR, I'll get a list of the files that are on my desktop here.
So now I can see read.csv and then mydata.csv.
You can see that the data will be printed to the console because now it can find the file in my working directory.
Anytime you download something from the website or create a new file it's probably best to store it all in one folder so that you don't have to be searching all over for it.
That way you can always set your working directory to be that, to be that directory and not have to worry about changing it.
So I'm going to minimize R here for a second.
I'm going to create a folder on the desktop, called I'll just call it Coursera.
And then I'm going to use this folder for everything that I do in this course.
So if I go back to R here, I can say change working directory again, Change dir, and go to Local Disk.
Now this folder is on my desktop, so Desktop, and then it's Coursera here.
So now if I say getwd and see the working directory has changed to this Coursera folder.
So one of the things you're going to have to do a lot of in the class is to write R code.
In order to write R code, you'll need to be able to use a text editor.
So you can load up the text editor by going to File and saying New Script.
And this will give you a blank window that you can use to write R code.
So I'm going to write a simple function here.
It's going to be myFunction.
And all it's going to do, it's going to simulate some normal random variables.
It's the, I can't find the function because I haven't loaded it into R yet.
If I type LS, you'll see that there's nothing in my workspace right now.
Well there's two ways if you just have a little bit of code like this function over here, I can click into my R editor.
And just hit Ctrl+A to select all and then Ctrl+C to copy.
Then I click back into the console and I can hit Ctrl+V to paste.
If I do it again, it'll give me a slightly different number because it'll simulate a different set of numbers.
The other thing you can do is go into my R editor and you can go to the File menu.
And that loads the, all the code that is in this file.
Of course, that's just the myFunction, so I haven't done anything new here.
But let's say I want to add another function here.
Okay, so now, I've got two functions here.
I can save my file with this little disk icon.
Or I can go to file men-, the File menu, and hit Save.
Now when I type LS, you'll see that I've got this second function there, and I type second.
So if I get four again I'll say the same thing will happen.
So that's how I edit code and that's how I load the code into R.
Every time you edit your file in the editor you have to save it.
And then if you want that code to be available in R you have to use the source function to source that file back into R.
You don't have to use a single file.
You can save this to be a different file if you want so that way you can separate code for different projects or different assignments.
If you close the file here, you can always open it back up again by hitting Op, the Open button and you can see myCode is right there.
So that's how you edit code in R there's, now there's many other text editors that you might see on the web that you can download.
And those are fine to use but they're not really necessary.
The text editor that comes with R should be sufficient for this course.
I'm going to talk about two things in this video.
The first thing is how to set your working directory.
So, when you start up R you, it's important to know what your working directory is.
Because the working directory is where R reads and write files to the computer.
And if you don't know where that directory is, then you're not going to be able to, find any of the files that you save, or any of the data that you write out.
So when you start up R, you can find out what your working directory is by just typing the function getwd.
And you can see that I've loaded up R here and it, and it sets my working directory to be /Users/rdpeng, which on the Mac is just your home directory.
So this may work but in, if you store all your files in your home directory but you may want to change your working directory to be something else if happen to store all of your data and code files in a different directory maybe a sub directory.
So for example I can go to the Misc menu here and just hit, and choose Change Working Directory.
And I can choose one of these directories to be my working directory.
Now before I go, the first thing I want to mention actually is, that if you want to read a file, then that file has to be in your working directory, otherwise you'll get an error.
So for example, suppose I want to read a data file using read.csv and I want to read the mydata.csv file, okay?
So if this file is in my working directory then I'll be able to read the data, and it will load it into R.
So one thing I could do is I can change my working directory to be, to be wherever that file happens to be.
And if I type dir in this directory, it'll list all the files in this directory.
And now you can see, oh mydata.csv is in this directory.
So I'm going to, now I can read the file into R by typ, using read.csv and now you'll see that the data will appear in R.
In particular, when you save files say from the web on to your computer, you need to know where those files are stored on your computer and so that you can set your working directory to the appropriate place.
That way you don't have to worry about changing directories all the time.
One thing you can do is maybe just create a directory right here on your desktop, so I'm going to create a directory here called Coursera.
And now, when I'm in R, I can say Change Direc, Change Working Directory here.
And if I go to my desktop I can choose my Coursera folder there.
And now, when I, when I say getwd, you'll see that it has set the working directory to be my Coursera folder.
So now if you save files in there, you, they will be there, then you can, and you can read them from R.
So the one thing that you're going to have to do a lot of in this course is to write code in R, and to, and you're going to need an editor to do that.
So one nice thing about R on the Mac is that it comes with a text editor that you can use to edit code files.
So I can load up the text editor by clicking on this little button right here.
So I'm going to move this over here.
And you can start editing code right away.
And this function, is going to just take the mean of x here.
So it ignores the argument for now.
So, and then, and then one thing you're going to have to do is, is figure out how to get this code into R.
If I type ls, you'll see that there are no objects in my work space.
So, the question is, how do I get this code that I've written over here, into R?
And then Cmd+C copies the code and then I can click into my console window over here, hit a Cmd+V and and then return and it will paste my function into R.
And it will return the mean of a hundred random normal variables, which is not very interesting, but the function does work.
I can go to the File menu and I want to Save As.
So I haven't saved this file before, so I need to Save As.
And I'm going to go into my Coursera folder and I'm, I'm going to save it as myfunction and it is typical to add the .r extension for code files.
And so now, I want, I can double check my working directory, and make sure I'm in the right place here.
If I type dir, you'll see that my, the myfunction.r file is there now.
So I, so I haven't done anything new because I already cut and pasted that function.
It's going to return that.
So so what, now before I do anything, I need to, now that I've changed the file, I need to save it.
So I can just go to File > Save, or you can do Cmd+S.
And now I can source my, this, this file into R again.
So if I type this out, you'll see that's the code for it.
If I do it again, it'll be four plus a little bit of more noise.
So that's how I write code in R.
And that's how I can use the text editor, that comes with R.
If I want to create a new file, I can hit this button.
So I close this window and and that's how you can use the the text editor in R for the Mac.
The text editor that comes with R is very simple but it will definitely be sufficient for this class.
So there's even though there are other kind of custom text editors that you can, may be able to find on the web and download for free.
You don't have to do that, the text editor that comes with R should be sufficient for this class.
Hey everyone welcome to R Programming.
This is the second course in the Data Science Specialization and, as the title suggests, we will be focusing on R as a programming language.
This involves things like control structures and writing r functions and kind of doing some basic operations on data.
And then, and then we'll talk about kind of profiling your code, some of the tools for debugging and kind of how to work, how to work through longer pieces of code.
And then so after this course is done, I think you'll have a pretty solid grasp of R as a programming language.
And so that will be covered in other classes.
So, the pur, purpose of this class is to really kind of get you into R programming, in particularly or if you're not very familiar with the language and to make sure you kind of kind of get a hand, get a sense of the on the of the nuts and bolts.
So I hope you enjoy it.
And I think after this course is done you'll be ready to move on to a bunch of, to mo, to the other courses in the specialization.
And then in this lecture, I'm going to give a little overview and a very brief history of the R statistical programing environment.
So the very first question, I think is most obvious, is which is, what is R?
And the answer is actually quite simple.
It's basically R is a dialect of S.
So S was a language, or is a language that was developed by John Chambers and at the now-defunct Bell Labs.
And it was initiated in 1976 as an internal statistical analysis environment, so the, an environment that people at Bell Labs could use to analyze data.
And initially it was implemented as a series of FORTRAN libraries to kind of implement routines that were tedious to have to do over and over again, so there were FORTRAN libraries to repeat these statistical routines.
Early versions of the language did not contain functions for statistical modelling.
That did not come until roughly version three of the language.
So in 1988, the system was rewritten in the C language and to make it more portable across systems and it began to resemble the system that we have today.
So this was version three.
And there was a seminal book the, called the Statistical Models in S written by John Chambers and Trevor Hastie.
Sometimes referred to as the white book.
And that documents, all the statistical analysis functionality that came into the version, that version of the language.
Version four of the S language was released in 1998.
And its version, it's the version we more or less use today.
The book Programming with Data, which is a reference for this course, is written by John Chambers sometimes called the green book and it documents version four of the S language.
So, R is an implementation of the S language, that was originally del, developed in Bell Labs.
So, just a little bit more history here, in 1993 Bell Labs gave a corporation called StatSci which became Insightful Corporation, an exclusive license to develop and sell the S language.
In 2004, Insightful purchased the S language completely from Lucent.
So Bell Labs became Lucent Technology for $2 million, and became the current owner.
In 2006, Alcatel purchased Lucent Technologies and it's now called Alcatel-Lucent.
So Insightful developed a product which was a implementation of the S language under the product name S-PLUS.
In 2008 the Insightful Corporation was acquired a company called TIBCO for $25 million dollars and that's more or less where it stands.
TIBCO still develops as PLUS, although in a variety of different types of business analytic type products.
And it continues to this day.
So you can see the history of the language is a little bit tortured because of the various corporate acquisitions but it still survives to this day.
The basic fundamentals of the S language have not really changed since 1998 and the language that existed in 1998 looks more or less like we, like what we use today at least superficially.
And it's worth nothing that in 1998 the S language won the association for repeating machinery software system award.
A very pretigious honor.
So in a document called the stages and the evolution of S, John Chambers who was the original writer of the S language the, the original creator kind of laid out his key principal with designing the S language.
They wanted to create an interactive environment where you didn't have to think of themselves as programming, right.
Then he says then as the needs became clearer and their sophistication increased, they should be able to slide gradually into programming, when the language and system aspects would become more important.
So the basic idea is behind the S language and then later the R language is that people would enter the language in an interactive environment.
Where they could use the lang, the environment, without knowing about any sort of programming, or having to know very detailed aspects of the language.
So, they could use the environment to look at data, and do basic analyses.
They could get into learning the language aspects and learning to develop their own tools and, and the system would very kind of, would promote the kind of transition from user to programmer.
And so that was the basic philosopy of the S language.
we, let's go back to R.
So what is R about?
So basically, R is a relatively recent development.
In 1991, it was created in New Zealand by two gentleman named Ross Ihaka and Robert Gentleman.
So, and they talked about their experience developing R in a paper writ-, published in 1996 in the Journal of Computation and Graphical Statistics.
In 1993 the first announcement of R was made to the public.
1995, Martin Michler convinced Ross and Robert to use, to license R under the GNU General Public License.
And we'll talk a little bit about, more about that in a second.
And that made R what we call free software.
1996 a mailing list was developed, so there's two main mailing lists.
One called R-help, which is a general mailing list for questions.
And R-devel, which is a more specific mailing list for people who are doing development work in R.
1997, what's called the R core group was formed.
And these contained a lot of, this contained a lot of the same people.
And the core group, basically controls the source code for R.
Can only be modified by members of the R core group.
However, a number of, people who are not in the core group have suggested changes to R, and they have been accepted by the core group.
So, some of the features of R the first one, which was important back in the old days, when people were still using S+ but the syntax is very similar to S, which made it easy for S+ users to switch over.
The semantics are superficially similar to S, in that it looks like it's S, but in reality are quite different, but we'll talk more about this in the future lecture.
One of the main benefits of R is that it runs on any standard computing platform or operating system.
There is a very active development going on and so things are happening.
The software the core software of R is actually quite lean.
Its functionality is divided into modular packages, so you don't have to download and install a massive piece of software.
Whereas you can download a very small piece of fundamental core, kind of functions, and then add things on as you need them.
So it's graphics capabilities are very sophisticated and give the user a lot of control over how graphics are, are, are created, and in my opinion are better than most stat packages.
It might even be the best for the mo- kind of a general purpose statistical package.
It's very useful for interactive work as I said before, but it contains this powerful programming language.
And fundamentally, actually, for a language like this, is that there is a very active and vibrant user community.
So the mailing lists at R-help and R-devel are very active.
There's many, posts per day, and there's also a series on stack overflow where questions can be answered.
So, the user community is, is one of the most interesting aspects of R.
It's where all the R packages come from and it creates a lot of kind of interesting features.
Of course one of the, probably the most critical feature of R is that it's free.
So what I mean by that, is that it doesn't cost any money so you can download the entire software from from the web.
So, with free software there are four basic principles, right?
You have four basic freedoms that you have.
The freedom zero is the freedom to run the program for any purpose, so you don't need.
There's no restrictions on how you can run the program or when you can run the program or what you can or cannot do with it.
Freedom one is the freedom to study how the program works and adapt it to your needs.
So this happens almost every day which is that you can look at the source code for R itself.
You can sell changes to it if you want.
You can do, you can modify the program any way you want and adapt it to your needs.
Of course, so you can look at the source code for this to get freedom one.
Freedom two is that you have the freedom to redistribute copies so you can help your neighbor and so the idea is that you can give copies to other people.
You can do whatever you want with it.
Lastly you have the freedom to improve the program and release your improvements to the public so the whole community benefits, so this is freedom three.
The idea is that when people make changes to the program they can release them to the public so that everyone gets those changes.
And so these basic freedoms are outlined by the free software foundation and you can see more about it at their website there.
I won't go through all of them and probably other people have many other complaints.
But there's some basic drawbacks which are one that it's essentially based on 40 year old technology.
So the original S language developed in the 70s was based on a couple of principles, and the basic ideas have not changed too much.
Since then and so as, one of the results of that for example is that there is little built in support for dynamic or 3D graphics.
But things have improved, greatly and not on that front since the old days and there's a lot of interesting tools now packages for doing dynamic or 3D graphics.
Another drawback of R that I, I hear a lot about is that the functionality is based on consumer demand and basically user contributions.
So if no one feels like implementing your favorite message then that's your job to do.
And so you can't, there is no corporation, there's no company that you can complain to.
There's no helpline that you can call to say that, to demand a specific implementation or a specific feature.
If the feature's not there, then you have to build it.
Or at least you can pay someone to build it.
Another drawback which is a little bit more technical is that the objects that you manipulate in R have to be stored in the physical memory of the computer.
And so if the object is bigger, than the physical memory of the computer, then you can't load it into memory.
And then therefore you can't do something in R with that object.
So there have been a lot of advancements to deal with this too.
Both in the R language and also just in the hardware side there are computers now that you can buy with tremendous amounts of memory.
But nevertheless, as we enter the, kind of, big data era where you have larger and larger data sets, the model of loading objects into physical memory can be a limitation.
And finally, I'll just say that R is not ideal for all possible situations.
They expect it to be able to do everything.
So the basic R system is divided into two, what you can think as two conceptual parts.
There is the base R system that you download from a CRAN which is the comprehensive R archive network.
And that's kind of the go to place for all things R.
And so the base system contains what's called the base package which has all the kind of low level fundamental functions that you need to run the R system.
And then there are other packages contained in the base system which includes for example util stats, data sets, graphics and a bunch of other packages that are kind of fundamental packages that more or less everyone might use.
And then there are a series of recommended packages, so, boot for bootstrap, class for classification, cluster, codetools, foreign, and a variety of other packages.
These are the commonly used packages, they may not be critical packages, but they're commonly used by many people.
So all of these packages come with this, the base R system that you download from CRAN.
These packages are user contributed.
And the i-, and CRAN has a few, has a number of restrictions and standards that have to be met in order to get a package on to CRAN.
So, one of the nice things about CRAN is that there, that the packages that you download have to meet a certain level of quality.
So, so CRAN has, has a lot of different packages written by users and the number is really increasing everyday.
So it's very exciting to see all these packages on CRAN and there, and to see new ones come up everyday.
There are also packages associated with the Bioconductor project, which is a packaged, which is a project designed to implement R software for, kind of, genomic and, kind of, bio, biological data analysis.
and, of course, there are also all their packages made that people make available on their personal websites.
And there's really no reliable way to keep track of how many packages are available in this fashion.
So, there's really thousands of packages out there written by people.
So there are a couple of documents that you can find on the R website.
As you're learning to use R, you then want to flip through some of these.
One is an introduction to R, which is a relatively long PDF document now that kind of goes through the basics of how to use R, how to use the language.
There's the Writing R Extensions manual which is really only useful to read if you're thinking of developing R packages.
The R data import and export manual, which is useful for getting R's data into R and the various different ways.
The R installation administration manual is, is most useful if you want to build R from the source code, and I'll talk about that in another video.
Is is a really technical document for how R is designed.
How R is implemented at a very low level.
But if you're that kind of person, who wants to know how R works at a very, very low level, this is the document for you.
So, I'm just going to end over here with a couple of texts that are kind of standard or kind of classic texts in this area.
Of course the books by John Chambers offers data analysis and programming the data are both published by Springer.
And then there's two books by Bill Venables and Brian Ripley.
One is called Modern Applied Statistics with S, and another one's called S Programing.
Although they have the, the, they talk about S in the title, these books are all, are both very relevant for R programming too.
That's also quite useful, for R programmers too.
And finally Paul Murrell who designed the R graphic system has written a book called R Graphics and actually it's currently in its second edition right now.
So, a couple other resources, one is that Springer, the publisher Springer has a series of books called Use R, which is, which is a, a lot of very, kind of relatively short books.
How to use R for different types of topics, different application areas.
This is quite a nice series of books that you may be interested in.
And there may be a book written for you particular area of application.
And there's a longer list of books on the R website.
So, that was a brief overview of R, and the history of how it kind of came to be.
and, starting with the next video, I'll start talking about the details of the R programming language, and how we can use it to analyze data.
So once we start typing things into the R prompt, they we're going to be start, we're going to start coding and doing calculation.
So the things that we type into the R prompt are called expressions.
So for example, the symbol, which looks like a left-hand arrow and is actually the less than symbol, followed by a hyphen this is what's called the assignment operator.
So, for example, in this first expression here the symbol that I'm creating is called x, and the value that I'm assigning it is call, is 1.
So x is 1, is a, is an R expression.
And I'm passing it the symbol x so that when I print out x I get its value which, in this case is 1.
So another thing to think about x is also considered a, is an R object that is a numeric object that has one element.
So it's really a numeric vector where the first element is the number one.
So this is called, this is another way to print out an object without explicitly calling the print function.
So in the, in this expression over here, I'm creating a new symbol called message, MS, MSG.
And the first element of this character vector is the string hello.
I could add other elements to this vector if I wanted to, but they would all have to be character.
So the grammar of the language determines whether an expression is syntactically correct or not.
So for example by this type x followed by the assignment operator and I don't have anything else, that's not a, that's not a complete expression and so when I hit Enter nothing will happen because it's waiting for the expression to be completed.
The other thing I've got here is this hash symbol here.
So this hash symbol here it indicates that everything to the right of that is a comment.
And so the, the, the, the, the R engine will ignore anything that happens to the right of that symbol.
So you can put things like comments or notes to yourself in code and R will just ignore those comments.
And so, so sometimes when you evaluate an expression, nothing happens because there's nothing to really show.
It's a numeric vector and the first element's going to be five.
Now when I hit enter nothing happens because there's really nothing to show.
And so but now when I hit x and I hit enter it prints out the value five, so it prints out the value of x.
This is the same as calling the print function on that object which will just print out the value of that object.
So you can explicitly print an object or you can auto print an object.
So this is, this sounds a little complicated but it's really just the natural thing to do and it is what most people would expect.
You'll notice that when I print out the object x, there's a little one in brackets here.
And you might be wondering what that is.
So, all that indicates is that, it, it's telling you what element of the vector is being shown.
And this will make more sense when we have longer vectors to look at.
But all this is shame, saying is that the number five that you're seeing there is the first element of the vector.
So for printing you'll see that here I'm creating an x an object called x and it's the sequence one to 20, so the colon operator here that I've used is what's used to create a sequence.
And you'll see that the first line of the printout it has a one next to it, because that's the first element.
And then the, the second line has a 16 in brackets because that's, the first element of that line is the 16th element of this vector.
So it's all kind of straightforward but just that's how the printout works
In this lecture we're going to start getting into the nitty gritty and the details of R.
In particular I'm going to talk about different data types that are used in R and some basic operations on those data types.
So first it's important to kind of get the language right correctly.
So all the things that you manipulate in R, all the things that we encounter in R, are what might be called objects objects can be all different kinds, can contain all different kinds of data.
So the R has five basic atomic classes of objects.
And so the most basic object in R is called a vector.
And a vector conta-, Can contain multiple copies of, for example, of a single type of object.
It, everything in a vector has to be the same class.
Of course, with any great rule, there's always an exception, and this, this one is no exception.
So a list is represent as a vector, so there's a se, it's a sequence of objects.
But each element of that vector can be a different, can be an object of a different class.
You can have a list that's inside the list and one element of the list can be a data frame so, any element of the list can be anything.
So the list is the one exception to the ot to the.
General rule that a vectors can only contain elements of the same class.
The first argument is the class of the object, so the type of object that you want to have in the vector.
And the second argument is the length of the vector itself.
Perhaps the most important type of object in R of course is the number.
So for example, if you just enter the number 1 in R, that gives you a numeric object.
But entering 1 with a capital L next to it explicitly gives you an integer.
This distinction is not very important right now, but, it will become important later.
There's also a special number called inf, which stands for infinity and, and inf is like a real number it can be used in calculations and you will get the expected result.
So, emphasis special number, and you can also have minus infinity, too.
There's another special value called NAN or Nan.
And this represents an undefined value so you can name it as not a number.
So not every, object in R necessarily has attributes, but, but they are, but attributes can be part of an object in R.
Some of the most common types of attributes that we'll encounter are namesor dim names, or, or dimension names.
So for example, numeric objects their class is numeric and integer objects, their class is integer.
So for a vector it's quite simple the length of the object is just the number of elements in the vector.
And then there may be other user-defined attributes or metadatas which, so these are things that you can define separately, for an object using various attribute functions.
You can create integer vector by creating a sequence with colon operator, and you can also create a vector of complex numbers where the i is a special symbol, which indicates the imaginary part of the complex number.
So using the vector function you can also create, a vector of a certain type and a certain length.
So here, I'm going to create a numeric vector of length 10.
Will kind of create the least common denominator vector so, will not give you an error but what will happen is that it will coerce the vector to be the, the class that's kind of the least common denominator.
So here, in the first example, I've got in trouble concatenating number 1.7 and letter a, so clearly these are not in the same class one is numeric, and the other is character.
So the least common denominator here, is going to be character.
And so how's that happen, so and the, and by the convention in R true is represented as the number one and false is represented as the number zero.
And so what you're going to get here, is a vector 1,2.
And so the vector that you end up with is a vector where the first element is A and the second element is the string true, so T R U E.
It's not going to be illogical so you need to be a little bit aware, of the types of coercion that can occur in our, when you mix different types of elements in a vector.
And because you won't get an error, but, but the coercion will happen behind the scenes.
that, in the previous slide we talked about kind of a implicit coercion that occurs behind the scenes, but you can explicitly coerce objects from one class to another using functions that usually start with the word as.
So for example, if you want to convert something to a numeric you can use the function called as.numeric.
So this is going to, this is an integer sequence as you could see when I call class on the object but I convert it into a numeric sequence.
And so I can call as.numeric on x, and you can see that it prints out 0, 1, through 6, which look like an integer object but it's actually going to be numeric or I can convert it into a logical and so I can say as.logical on it, and what happens?
Well, as you can see, the convention is that 0 is false.
And when it doesn't work you get what are called NA values.
So for example if I take the vector ABC.
Now I mentioned lists a little bit earlier in this lecture and the idea is that they're, they're like a vector except that every element of a list could be a, an object of a different class and so that makes lists very, very handy for kind of carrying around different types of data.
And they're very useful in R and they become very common especially when in conjunction with other types of functions that we're going to learn about.
So here I'm creating a list called x by using the list function which is a, which can be used to construct the list.
And the first element is a numeric value, numeric object of one.
The second element is a character, letter a.
Third is illogical and the fourth is a complex number.
So there's, they're not a spe, a different, a separate class of objects.
Where the first number is the number of rows the matrix, and the second number is the number of columns.
And so, if I can create a matrix empty matrix with the matrix function, and I can explicitly say how many rows and how many columns there are.
This is not the only way to create a matrix, but it's one way.
And so when I auto print the matrix by typing the, the object m and hitting Enter, you'll see that it'll show me that, first of all the matrix is full, is initialized with NA values.
And you can see that there's two rows and three columns and they're labeled by the numbers in the brackets.
If I call the dim function on m, it'll give me the dimension attribute, which in this case it says there are two rows and three columns, because the first rows are number rows and the second number, sorry excuse me.
The first number is the number of rows and the second number is the number of columns.
If I call the attributes function on m, you'll see it returns a list where the first element is the dim element and it has the vector 2,3.
So these are all aspects of a matrix which is a vector that has a dimension attribute to it.
So you can think of the matrix taking a vector and all the numbers are inserted into the matrix by, by column.
So the first column gets filled and then when you hit the number of maximum number of rows, then the second column gets filled and the third column et cetera.
So if I create a matrix by taking the sequence 1 to 6 and then I say, I specifies that it has two rows and three columns.
So the first thing it happens is it takes 1, 2, and now there's only two rows, so it can only go to 2.
And then that makes the first column.
And then the third column is made up of 5 and 6.
You can also create a matrix by creating the dimension attribute on a vector.
So, for example, I can take, I can create a vector that's a sequence 1 to 10.
So here, I'm using the dim function, but I'm assigning a value to the dim attribute of m.
And so now after I've done that, I've got a matrix m, which has two rows and five columns and it's filled in the matrix column wise.
And so you, this is column, column binding and row binding can be achieved by the fu, the functions c-bind and r-bind.
So for example, suppose I have the two objects x, which is sequenced from 1 to 3 and y, which is a sequence from 10 to 12.
If I cbind those two objects, then I'll get a, I'll get a matrix where the first column is 1 to 3, and the second column is 10 to 12.
So this is kind of what you might expect would happen.
If I rbind those two objects, then the first row will be 1 to 3, and the second row will be 10 through 12.
So cbind-ing and rbind--ing is another way to create a matrix.
So, and there's two types of factor, there is unordered or ordered, so you can think of this as being, as storing data that are.
Those are categorical but they're ordered.
So one, you can think of a factor as an integer vector where each integer has a label.
So for example, you might, you can think of it as a vector as one two three, where one represents you know, high, for example high value and two represents a medium value and three represents a low value.
And underlying in R is represented by the numbers one, two, and three.
so, factors are important because they're treated specially by modeling functions like lm and glm which we'll talk about later.
But these are functions for, for, for fitting linear models.
So having a variable that has values male and female is more descriptive than having a variable that just, that just has ones and twos.
So for example, in many data sets you'll find that a var, there will be a variable that's coded as one and two and it's, and it's not.
If you use a factor variable then the coding for the labels is all, is kind of built into the variable and it's much easier to understand.
So factors can be created with the factor function, and the input into the factor function is a character vector.
And so x is a factor, you can see what, it prints out a little bit differently from a character vector, in the sense that it prints up the value, yes, yes, no, yes, no.
And then it has a separate attribute which is called the levels.
And so the levels of this factor are no and yes, okay.
So there's only two levels.
I can, I can call table on this factor and it will give me a frequency count of how many of each level there are.
So for example, it'll tell me there are two nodes.
Now, the un-class function strips out the class for fa, for a vector.
So for example, I can, if I call un-class on x it'll, it'll kind of bring it down to an integer vector, and you can see that underlying.
The factors represent as 22121 so, yes, it's coded as two and no, it's coded as one.
And so you see, it's really an integer vector with the attribute, the levels attribute of no and yes.
The order of the levels in the factor, can be set using the levels argument in factors.
And so the baseline level is just the first level in the factor, and the way this is determined by NR is critical.
It's determined using alphabetical order, so for example, if I create a factor variable.
With the, with the elements yes and no, then the base line level with be the first level that's encountered and because no comes before yes in the alphabet then no will be the base line level and yes will be the second level.
Now this may not be something that you want you might want for example a yes to be the base line level and no to be the second level and then in that case you have explicitly tell r.
That yes is going to be the first level and you can view that using the levels argument to the factor function.
So now when I print out the x object you see that the elements are still the same, still yes yes no, yes no.
because yes is the first level and no is the second level.
So there's a special type of object that we haven't talked too much about yet.
Missing values in R are denoted by either NA or NAN which we talked about before.
And so, there's a function in R called is.na which is used to test objects to see if they are NA.
So, NA values can have a class, too.
And so even though it looks like it's all NAs, the NAs can have different classes potentially.
So an NA value is not necessarily, an NAN value.
I've got a few different types of missing values listed here.
So, here I created a vector x which is 1,2, NA, 10, and 3.
And the NA value in here's going to be a numeric missing value.
So when I call is.na on x, what it returns is a, is a logical vector.
And the logical vector indicates whether each element of the vector x is missing or not.
And so, there's only one missing element in this vector, and so that's the third element.
The first two are false, the third is true, and the fourth and the fifth are false.
If I call is.NaN on this vector, you'll see that vector that's returned is all false.
Because there aren't any NaN values, or their aren't any MAN values in this vector so everything's false.
Of course, if I create a vector that has an end, a NAN value and an, and an NA value in it.
But is.nan only returns true for the for the value that's actually NAN.
The data frame is a key data type used in R and it's used to store tabular data.
So of course, tabular data make up a lot of what we use in statistics.
Data frames are very important in R.
So data frames are basically represented as a special type of list, where every element of that list has the same length.
Right, so you can think of each column of the data frame as an element of the list, and of course, in order to be a table, every column has to have the same length.
However, each column doesn't have to be the same type.
And so, data frames also have some special attributes.
First, the first special attribute is called a row name.
And so every row of a data frame has a name.
So for example, each row re, might represent a subject enrolled in a study, and then the row names would be the subject ID for example.
however, sometimes the row names are not interesting, and, and, and often you'll just use row names of 1, 2, 3, et cetera.
Data frames can be created by calling most often calling the read.table, the read.csv function and we'll get into that a little bit when I talk about reading data into R.
Now, you can't if you have a data frame that has many different types of objects, and then if you coerce that into a matrix, it's going to force so each object to be coerced so that they're all the same.
So you may get something that's not exactly expected.
The foo variable is an integer sequence from one to four, and the bar variable is a logical vector with two trues and two falses.
And then when I call the nrow function on x, I see that there's four rows in the ncall function, shows me that there are two rows
So this not true for just data frames.
It's true for all r objects.
And this can be very useful for writing readable code and self describing objects.
So for example, I'm creating a vector that's an integer sequence 1, 2, 3 and by default, there's no name.
So when I call the names function on x, it gives me a null value.
However, I can, I can give a name to each element of the vector x.
So for example, if I, I can say the first element's called food, the second element's called bar, and the third element's called norf.
So now when I print out my x vector, I get a vector 1, 2, 3 but then each one has a name over it, which is the name I just specified.
And so when I call the names function I get the, the names that are associated with each element of the vector foo, bar, and norf.
And so for example here I'm creating a list with the list function where the first element is called a, the second element is called b, and the third element is called c.
And so when I print out the list, it prints out the names of each element and the values associated with those names.
Where the first element of the list is the, is the vector of row names and the second element of the list is a vector of column names.
So here I want to name the rows a and b, and I want to name the columns c and d.
So, that's kind of a whirlwind tour of the different basic data types in R.
So far, we've talked about the atomic classes in numeric, logical, character, integer, and complex vectors.
We talked about how vectors can only have elements of the same class and the main exception to that is lists which can have elements of different classes.
Data frames are used to store tabular data or each COM can be of a different class.
This lectures going to talk about reading and writing data in R.
So there's a few different types of ways you can do this and I want to talk about some of the primary functions that use an R to read and write data.
So there are a few principle functions that we're going to talk about for reading into R.
The first two are read.table and read.csv and these are for reading tabular data.
And they are probably the two most commonly used functions for reading data into R.
The function read lines is for reading lines of a text file so this, this can be any type of file really, it just gives you text in a, as a character vector in R.
The source function is important for reading R code, so if you have R code, for example functions or anything written get written to a file the source function will read all that code into R.
We'll talk a little more about this later.
The low and unserialized functions are for reading binary objects into R.
So the analogous functions for writing data are write.table, writeLines, dump, dput, save and serialize and those kind of pair up with their reading analog.
So, the read.table function is the most commonly used function for reading data into R.
It's important that you know kind of, how the arguments work, what the arguments are and understand what they mean.
So the first argument is pretty obvious, it's name of a file or the name of a connection, which we'll get to a little bit later.
Usually you're going to give this a file name, it's going to be a string and it's going to be a path to a certain file in your computer.
The header is a logical flag indicating whether the first line is a header line, so if the first line for example it has all the variable names in it, then that's not really a piece of data, that's just a line that has labels on it.
it's, it's a string that indicates how the columns are separated.
And so you want to tell read.table what the separator is going to be.
ColClasses is a character vector which indi wh, wh, which, whose length is the same length as the number of columns the data set.
And the character vector indicates what, what is the class of each column the data set.
So, for example, is the, if the first column is numeric and the second column is logical, and the third column is a factor, et cetera.
And so the colClass is a vector, which is not required but it, it tells the, it tells read.table what the class of the data is for each column.
So you can specify other characters to be comment characters, and the lines, lines of the file that begin with that comment character will be ignored.
Skip is the number of lines to skip from the beginning.
So sometimes there may be some header information or some non-data region at the beginning of the file, and you want to skip right over that.
And so you can tell the read.table function to skip the say the first ten lines of the first 100 lines and then only start reading data after that.
And the idea is that it, the question is whether you want to encode character variables as factors.
Anytime our read.table encounters a column of data that looks like it's a character variable, it will call, it will assume that what, what you mean to read in, is a factor variable.
If you don't me, mean to read this in as a factor variable, then you can set strings as factors equal to false.
So for small and kind of moderately sized data sets it has computers are going to get better and better everyday, the definition of small and moderate is kind of growing.
But you can use read.table usually without specifying any of the other arguments besides the file name.
So you don't have to specify any of that information if you don't feel like it.
It will figure out how many rows there are and, agai, and again it'll figure out what type of variable is in each column of the table.
So, tell it you can, that you can tell R all these things and if you want to and the reason you might do that is to make it run faster and more efficiently.
So parti, so read.csv is useful for reading csv files, this, this can usually, this stands for comma separated value.
It's usually something that you get from a spreadsheet program, like Microsoft Excel or something similar to that.
So csv is a very common format that most spreadsheet types of programs will understand.
So with larger data sets of beyond the small to moderate, then there are a couple of things you can do when reading in tabular data.
That will make your life a lot easier, and more importantly it will prevent R from totally choking.
In fact, you should probably have it memorized.
There is a lot of key hints in that help page.
Lot of useful information.
And in my opinion not enough people read this help page carefully enough.
And if I, so there's a lot of so once you've read that you'll see there's a lot of important information for kind of how to optimize read.table.
And so one of the things you're going to want to do is to make a very rough calculation.
And so that way you can get a sense of well, is there enough memory on my computer to store this data set?
R will have to, R is going to store your entire dataset in memory unless you do otherwise.
So when you call read.table or read.csv, it's reading your entire dataset into the RAM of the computer.
And so you need to know, roughly speaking, how much RAM this datasets going to require.
And we'll talk about how to calculate that in a second.
The call classes argument is actually very important.
And tries to figure out what type of data it is.
But reading each of these columns and trying to figure out what type of data it is takes time, it takes memory, and it can generally slow things down.
If you can tell R, what type of data, is in each column, then R doesn't have to spend the time to figure it out on its own.
And so, it'll, it'll generally make read.table run a lot faster.
So you can save yourself a lot of time.
So if you, if, if you have a few columns in your dataset, then then you can usually just say what, what the classes are.
But if you have, or if they are all the same, so for example if all the columns are numeric.
And if you only sent, you give it a single value, it will just assume that every column has that same value.
Otherwise what you can do if you have a huge data set, you can read in maybe the first 100 or first 1,000 rows.
And then going through each of the looping over each of the columns using sapply and calling the class function.
So the class function will give you, will tell you what class of data is in each column.
And then you can use this, and then you can save, store this information.
It doesn't necessarily make R run any faster, but it does help with memory usage.
And so, if you can tell R how many rows are going to be read in to, to the, in to, in to R.
So even if you mildly overestimate how many rows there are in the data set, that's okay.
So in general, when you're using R with large data sets, and there's lots of large data sets out there nowadays.
It's useful to have a few things, a few bits of information on hand.
These days in most computers will have on the order of a few gigabytes up to many gigabytes of physical RAM.
So are there other applications that are running on your computer that are eating up some processor time or memory?
If you're on a multi-use system, are there other users logged into the system.
What is the operating system for your computer?
So, is it a Mac?
Is it Windows?
Is it Unix?
Is it something like that?
And then, also it's useful to know whether the O, the operating system that you're running is 32-bit or 64-bit.
So if you want to do a rough calculation before you read in a table into R, using the read.table or the read.csv function.
You can just do a very quick calculation.
So here is, suppose I have a data frame here, with 1.5 million rows and 120 columns.
So this is not a particularly big data set but it's reasonable.
So, I don't have to worry about different types of data.
They're all, all the columns are numeric.
The question is how much memory is required to store this data frame in memory, okay?
So, I can do a simple calculation.
And so that's, so that's the number of elements in the data frame.
Now, if it's a numeric all the data are numeric then each number requires eight bytes of memory to store.
Because the, because the numbers are stored using 64-bit numbers and there's eight bits per byte.
So that's eight bytes of memory per numeric object.
So that's going to, so here's the number of bytes, now there's two to the 20 bytes per megabyte.
So I can divide that, the number of bytes by 2 to the 20, and that's how many megabytes I got.
And I can divide that again by 2 to the 10 to get the number of gigabytes, that's going to be roughly 1.34 gigabytes.
So the, the raw storage for this data frame, is roughly 1.34 gigabytes.
now, you're actually going to need a little bit more memory than that to read the data in.
And so, and so the rule of thumb, is to, is that you're going to need almost twice as much memory to read this dataset into R using read.table.
So if your computer only has, let's say two gigabytes of RAM eh, and you're trying to read in this 1.34 gigabyte table.
Because it, you're going to be pushing the boundaries of of memory that, that is required to read this dataset n.
Of course, if your computer has like four or eight or 16 gigabytes of RAM, then you should have no problem in terms of the memory requirements.
It will still take some time just to read it in just because it takes time to read in all the data, but you won't be running out of memory.
So doing this kind of calculation is enormously useful when you're reading in large data sets.
Because it can give you a sense of you know do I have enough memory.
Is the reason, if you grunt any errors, you'll know whether the error is because of memory, running out of memory or not.
So I encourage you to do this kind of calculation when you're going to be reading in large data sets.
And you, and you, and you know in advance kind of how big it's going to be
There are other types of formats that you can save data in beyond the tabular format, beyond, or the CSV file or text file.
These are also textual formats, but they are a little bit different for, from the tabular data that we've talked about before.
And the two main functions for writing out data and f, are dumping and dputing.
So, and, and the idea behind these types of formats is they're text formats, but they're not really, they're not really formatted in a way that's, in the same as like a table because they contain a little bit more meta-data.
So data about, for example, the type of the data in, in each class, object for example.
So if you, if you dump or dput a data frame.
It will include in the output, that the class of each column, of the data frame, so that you don't have to specify it when you read it in.
So that's one advantage of using, using a function like dump or dput to, to output data from R.
And similarly the, the, the, the functions for reading data using, fr, that haven't been outputted from dump or dput are source and, dget.
First of all, they're editable, so you can, if you want to you can edit them.
I wouldn't say this is something that I would advice, but because of you wanted something that's reproducible.
But, for example if something gets corrupted then you can look at the file to see if it's possible to recover it.
Textual formats can also work better if you're using like a version control program, like subversion or git, where you're tracking changes between documents.
and, and those types of programs tend to be much more useful with textual data rather than binary data, so that you can track changes meaningfully.
So, d, the dput function takes an arbitrary R object, and it will, use, it will take most types of R objects except for some more exotic ones, and it will create some R code that will essentially reconstruct the object in R.
And you'll see the out, if you discall dput it'll just output the results to the console.
And you can see that what I've done is that.
For example, it's creating this list that has these two elements in it.
And you can see that each element has has the data that's in it.
And it has the names embedded here, it's got the row names here.
And so, all the metadata here like the row names and the names and the class are all included in the output.
Now, of course, you generally don't want to print this to the console, that's not particularly useful, you probably want to save it to a file.
So the dput function, essentially writes R code, which can be used to reconstruct an R object.
The dump function is a lot like dget however, the difference is that dget can only be used on a single R object.
Whereas dump can be used on multiple R objects and so what you do is what you pass a dump is the character vector which contains the names of the objects.
So here I created two objects one called x, the other called y and when I pass the dump.
And I give it a file, that I want to store the da, the objects in.
And then I can remove them if I want to, but to read those objects back into R, I can call the source function on that file and you'll see that the Y object and the X object have been reconstructed.
So there are a variety of ways that you can interface between R, R, wi, with the outside world.
And generally speaking there are functions that, that are used to kind of open up the what are called connections to the outside world.
And most functions will do this in the background without you having to know what's going on.
So for example, when you call read.table with it and you pass it the name of a file, what it does behind the scenes is it opens up a file connection to that file, and then reads from that file connection.
The connection can be made to other types of objects too.
For example, you can open a connection to a webpage using the URL function.
And so, when you open a connection to a webpage, you can read data from that webpage using the URL connection.
The mechanism for connecting to different types of objects that are external to R, whether they be files, or webpages, or whatever.
So the file function is the function that opens a connection to a standard uncompressed file.
So this, this can be useful for text files, for, for reading in other types of text files.
Gzfile and bzfile, are used for opening connections to compressed data files.
Files that are compressed with gzip usually have a gz extension and files compressed with bzip2 usually have a bz2 extension.
The other options for file are not particularly important at this time.
So, connections can be very powerful and they can let you navigate files and other external objects in a more sophisticated way than just, like, reading the whole thing, for example.
And generally you don't have to deal with the connect interface in many cases, but sometimes it's useful.
So for example, so here I've got a simple example or opening a fi, a file connection to some file called foo.text, I'm going to open it for reading.
I can call read.csv on the connection, and that by default will just read the entire file then I can close the connection.
So that three line process is the same as just calling read.csv on the file.
However, sometimes a connection can be useful if you want to read parts of a file.
So for example, here I've got the readLines function which just reads lines from a text file.
And it's compressed using the gz, the gzip algorithm.
And I'm just going to read the first ten lines.
So now I'm going to re, use this connection, and to read the first ten lines.
And similarly, write lines is a, is a function that can be used to write out lines of text to a file.
And each, and what you do is pass write lines of character vector and each element of the character vector becomes a line in the text file.
And so and I'm, and then and so the lines of text that come from the connection are going to be stored in this character vector x.
So when I look at the first couple of lines from x you can see that it looks like HTML which is kind of what you would expect.
And so the URL function is useful for creating a connection to a kind of a non file object.
So this is another way to read data beyond using functions like read.table or read.csv
I'm going to continue to talk about data types, and basic operations in R.
In particular in this video I'm going to talk about subsetting objects in R.
So the sing, the basic kind of principles to remember here is that the single square bracket always returns an object of the same class as the original.
So the subset a vector, you're going to get back a vector.
If you subset a list, you're going to get back a list.
Any time you used the single bracket operator to subset an object, you'll get the same, an object of the same class back.
si, furthermore the single bracket operator can be used to select more than one element of an object.
With one ex, exception that we'll get to later.
But double bracket operator is used to extract elements of a list or a data frame.
And the class of the returned object will not necessarily be a list or a data frame.
So the idea with the double bracket operator is that, remember that lists can, can, can hold things that are of many different classes.
So, the first element might be a vec a numeric vector, the second element might be a data frame, the third element might be a complex vector, et cetera.
And so when you use the double bracket operator to extract an element of a list, the oh, the object that comes back maybe, may not be a list, it may be an object of a totally different class.
Very similar objects can have names and the reason, one of the reasons you've used names in an object is so that you can reference elements of the object by the different names.
Otherwise the, the semantics of the dollar sign are similar to the double bracket in the sense that when you use the dollar sign to extract an element of an object it may or may not be of the same class as the original object.
So, here is the first, the first example, a very simple vector, a character vector called x.
And and I'm going to use the single bracket operator to extract the first element.
So here, what I get back is a, is another character vector with the single element a in it.
If I, if I use, if I try to extract the second element of x, what I would get returned back to me is a character vector with the element b in it.
I could also extract a sequence of elements so if I say, If I, If I want to get the first four elements of x I can cre, construct the sequence one through four and then I get a, b, c, c.
So in these three examples here what I've done is I, I, is I subset the vector x using a numeric index so the numeric index is one, two or the sequence one through four.
So, in this next example here, I'm going to subset the vector x and I want, I only want all the elements were, that are greater than or equ, sorry, that are greater than the letter a, right?
So what I get returned to me is a character vector that only contains the letters that are greater than a.
So, here I've got b, c, c, and d.
So, if I print out u here I can see that the, the first element is equal to a, so it's not greater than a.
Then, the next four are greater than a, but then the last element is equal to a, so again, that's false.
So subsetting a list is a little bit different.
And the second element is named bar, and it's the number 0.6.
So this is a list of two elements in it.
And I get, when I, remember the single square bracket always returns the element that's the same class as the original.
So if x is a list, than x bracket 1 is going to be a list too.
So, so the difference here is that in the first example, I got a list that contained the sequence 1 through 4, and in the second example, I got just the sequence.
In the next example here I'm using a dollar sign.
And so I'm saying, x dollar bar.
So in that case it's the, it's a single number 0.6.
I can also use the double bracket operator and pass in a string.
So x double bracket quote bar is the same as doing as x dollar bar and it just gives me 0.6.
If I use the single bracket with the name, I can say x bracket quote bar, that gives me a list with the element bar in it.
So remember, because the single bracket always returns a list if I'm going to subset a list.
So the nice thing about being able to subset an element using its name, is that you don't have to remember where it is in the list.
So if I couldn't remember whether bar was the first element or was the second element, I don't have to remember whether, what, where it is in order to use the numeric index.
I can just use its name, and then I don't have to, then it will automatically extract that, extract that element from the list.
If you want to extract multiple elements of a list then you need to use the single bracket operator.
So for example, if I want the third, the first and the third element here, in which case, which is the foo and the baz element, I can pass a, a vector, a 1, 3, the numeric vector 1, 3 to x using the single bracket operator.
So that's how I extract multiple elements of a list.
There's, you cannot use the double bracket or the dollar sign operators when you only extract multiple elements of a list.
The nice thing about the double bracket operator, which is different from the dollar sign, is that you can use the double bracket operator to, to, to index it a list, where the index itself was computed.
So, notice that when I used the dollar sign before, I had to, I actually typed out the word bar.
But sometimes the name of the element is actually the result of some computation.
So for example here I've got a list with three elements, foo, bar, and baz.
And then I create a variable called name which is actually the string foo.
Notice that the there's no element in the list that has the name, name in it.
But there is an element in the list that has the name foo in it.
So now when I, when I pass this variable called name into the double bracket operator, it returns me the, the element that was associated with foo.
because that's what the value of the name variable is.
So if I can, if I compute the index that I want to use, then I have to use the double bracket operator.
So to use the dollar sign I need to use a literal symbol.
So if you look at this current list I've got here, with the first element a is another list which has elements 10, 12 and 14.
So suppose I wanted to extract the number 14.
Well, that's really the third element of the first element, right?
So it's the third element of the list, which happens to be the first element of the other list.
And so I can extract the 1, 3 element term by passing the vector 1, 3 to it to the x list using the double bracket operator.
And that's equivalent to kind of doing this double sub-setting of one and three.
I can also extract the first element of the second element by use, by passing the integer vector 2,1 to get 3.14
It's not particularly useful when you're pro, when you're writing out programs and functions but it's very useful when you're kind of working at the command like typing things as fast as you can.
So the idea with partial matching is that it works with the double bracket and the single, and the dollar sign operator.
And suppose typing out the word aardvark every single time is a bit of a pain so I'm just going to type the word a.
Well, the way the dollar sign works by default is that it looks for it looks for a name in this list, that matches the letter a.
In this case there's only one element.
And then it gives me the, the el, the object associated with aardvark, which is the sequence 1 through 5.
So if I use the double bracket operator things are a little bit different.
So what the double bracket operator expects, is that it's going to be, that the name that you pass it is going to be an exact match for one of the names in the list.
So now when I pass x double bracket a what happens is I get null back, because there's no element of the list that has the name a.
Last thing I want to talk about is removing missing values or NA values from an object.
This is a very common operation in, in, in data analysis because most realistic data have lots of missing values.
And so the way you can do this for, of either a vector, or a matrix, or a data frame is you want to create a logical vector which tells you where the NA's are and so that you can remove them by sub-setting.
But then there are missing elements NA in the third position and in the fifth position.
So, what I, the first thing I do is I use the is.na function to, to go through the vector and tell me which elements are NA and I create a new vector called, which I called bad here.
So, bad is going to be a logical vector which tells, which, which is true if the element is missing and false if it's not missing.
So, even though I haven't printed it here the, the, the bad vector is going to be a logical vector that has false, false, true, false, true, false.
Right, because the third and the fifth elements are missing.
Now that tells me which ones are missing but actually I don't want the ones that are missing, I want the ones that are non missing.
So what if there are a multiple vectors or multiple objects and you want to take and each one has a kind of missing values in slightly different places and you kind of, you want to take the subset of all the objects that have no missing values, all right?
Which is 1, 2, 4 and 5, and missing values scattered about.
And then y is, is a character vector with also some missing values in it.
So you can see the first two are, are both non missing.
So, of, for the both, for both vectors x and y, I want the first, the second, the fourth, and the sixth elements.
So now when I subset x, I get the good elements of that, and when I subset y, I also get the good elements of that.
So that's how I can look at multiple objects and kind of subset all the missing values out to get the good elements.
You could also remove you can also use complete cases to remove missing values from data frames.
So here I've got a simple data frame where I'm showing the first six rows.
As you can see there are six columns to this data frame so there's six variables.
And there's some missing values in the ozone variable and there's some missing values in the solar.r variable.
And so all I want is the is the, is the, are the rows of the data frame where all the values are non missing, right?
And I create a, a logical vector that I called good here, so the logical vector here tells me which rows are complete.
And then when I subset out the air quality matrix take and take out the first couple of rows you can see that I now, that none of the rows have any missing values in them.
And there, in complete cases of very handy function which is when, when you have multiple sets of vectors or dat, or large data frames or you want to subset all out, all the missing values.
So, vectorized operations, is one of the features of the R language that make it, that makes it easy to use, on the command line.
It makes very, kind of, nice to write code, without having to do lots of looping, and things like that.
Many other types of languages, like MATLAB have this kind of feature.
so, the idea with vectorized operations is, is that things can happen in parallel, when you, for example want to do a computation.
For example, suppose I got two vectors here x and y.
x is the sequence one through four and y is the sequence six through nine.
And I want to add the two vectors together.
Now, when I say I want to add them, what I mean is I want to add the first element of x to the first element of y, the second element of x to the second element of y, et cetera, the third element to the third element.
So I want to kind of do things in parallel like that.
similarly, you can use the greater than, or less than symbols to, give you logical vectors.
So well x is actually a, a vector of 4 numbers.
Well, the, the vectorized operation compares all the numbers to 2, and it gives you a vector of falses and trues depending on which numbers happen to be bigger than 2.
So you can also use greater than equal to, and that'll tell you which numbers are greater than and equal to 2, and the double equals sign, tests for equality.
So it'll take each element of y and test to see whether it's equal to 8.
other, and the other kind of, or arithmetic operations like multiplication, by the asterisk, and division, by the solidus, are all vectorized types of operation.
Similarly you can do, you can do You can add make, you can add and subtract, and multiply and divide matrices together.
So it's useful to know this because there are different types of mult matrix multiplication.
So I've created two matrices here, x and y.
X is the matrix 1 through 4, it's a two by two matrix.
So if I just do x times y, this is not a mat, matrix multiplication.
So, each element is multiplied, together in parallel.
This is not a matrix inverse or something like that, this is just dividing one matrix, literally element by element by another.
So if you want to do a true matrix multiplication, you have to use the %*%, that's the symbol for a matrix multiplication.
And for those of you who are kind of used to other types of programming languages, if you've programmed in languages where you can't do this kind of thing, it's sometimes, it's common to kind of reflexively go to something like a for loop or a while loop or whatever it is.
But in the but in a language like R, you can just use the vectorized operations to make the code a lot simpler.
Hi, everyone.
I just want to introduce a experimental feature that we've, that we've developed for the R programming class.
It's called Statistics with Interactive R Learning or SWIRL for short.
And it's, and it was developed by Nick Carchedi, who's a student here at the Johns Hopkins department of bio-statistics.
This is a system that allows you to kind of interactively learn R at your own pace.
So, rather than kind of watching a lecture and then, you know, doing an assignment and kind of doing things piece by piece, you can actually work on R right in the R console in, in a kind of guided way.
So, I think this, the SWIRL modules are really helpful and I encourage you to try to walk through them.
If you decide to complete them you'll get you'll get a little extra credit through the programming assignment.
But the, the modules are absolutely not required.
And so, you don't have to worry about doing them.
You can still do perfectly well in the class without doing the SWIRL modules.
Nevertheless, I encourage you to try it out.
I think it'll be a lot of fun.
In this lecture, I just want to get everyone on board with writing functions, because functions play a critical role in any R programming and you tend to write a lot of them when you're writing doing a lot of data analysis or doing a lot of kind of statistical analysis.
And so I just want to make sure that everyone can kind of get started writing functions and and particularly for those who are less familiar with programming languages in general.
It's kind of like the hello world so to speak of R.
So the first thing you're going to want to do is you going to want to write the function in a text file, all right.
So usually you're going to want to put your functions, in a separate file, separate from any interactive stuff that you're doing in the command line.
In the future you'll want to put your functions in an R package, which is a kind of a more structured type of kind of, kind of environment with documentation and everything, but we won't talk about that now.
Right now the first thing you're going to want to do is put your functions in a text file.
Okay, so the first thing we're going to want to do is open up our studio.
And so you can see here in R Studio there's some there's some stuff going on here from a previous project that I'm working on.
So you, that may happen to you, and generally you can either close it or you can just ignore it.
I wanted to create a new R script here, so let's create a clean script here to put our code into.
So the first function I'm going to write is really simple it's just going to take two numbers and add them together.
So the function that adds two values I'm just going to call it add two.
And and so you get it you use the function directive to start it off.
So here there's only really one expression.
So therefore its the last expression and, and it equals the sum of x and y.
I can say add two, and lets give it say three and five and hopefully I get eight.
So it adds the two numbers together, and that's that.
So it's a very simple function, and and, you've now written your first function in R.
S the next function that I want to talk about is a little slightly more complicated.
It's going to take a vector of numbers, it's going to, it's going to return the subset of the vector, that's, that's above the vector value of ten.
So any number that's bigger than ten, it's going to return those numbers for you.
so, let's bring back our original function.
Just because it gives you any number that's above ten.
And I like to open and close the curly braces right away, just so you know where the beginning and the end of the function is.
If you happen to have a lot of code in, you know, in, in a single file.
So the first thing I'm going to want to do is I want to construct a logical statement that figures out which elements of this vector x are, are greater than ten.
So I'm going to assign an object.
And I'll say x greater than ten.
So this'll return a logical vector, of trues and falses to indicating which element of x is greater than ten.
And then I'm going to subset the vector x with this logical vector.
So now this function returns, the subset of the vector x that is bigger than ten.
Of course if there are no elements of x that are bigger than ten, that it will return an empty numeric vector.
Now of course, there's really nothing special about the number ten.
I just kind of made that up, and so you may want to created a function that allows people to sub, to kind of extract the elements of a vector.
So maybe you'll want to allow the user to specify that number.
So I'll just call, I'll create a new function here.
So it doesn't have the ten encoded in it.
So let's start it off, we'll get the curly braces in there, and now I'll create a logical statement that x is greater than n.
And then I'll subset the vector x based on that logical statement.
So now if I can source this into R.
So I'll just create a vector.
Let's say x is one through 20.
And you can see it returned all the numbers that are greater than 12.
So that's kind of as we expected, and so the function appears to be working well.
So you might you want to specify a default argument so you might want to the default to be ten, so remember when I ran the function before and I didn't specify the number n.
It gave me an error or maybe you don't want people to have to encounter that error, and so you'll specify a default value n equals ten so people don't specify the cutoff value n, it will just automatically default to ten.
So now I can run this in R and now if I do above, which is x, you see I don't get the error anymore.
So it's kind of nice in R when you're writing functions to be able to specify default values like this that make the life of the user just a little bit easier, specially for very common cases, where it's not important that the user specify an argument.
So those are some very simple functions, in R that can be used to kind of process data or make do simple calculations, like adding two numbers.
The next function I want to talk about is, is just going to take a matrix or a dataframe and calculate the mean of each column.
I like to call my arguments x, you don't have to so why don't we just call it y for fun.
And so y is going to be a data frame or a matrix, and we're going to go through the columns of this data frame or matrix and calculate the mean of each column.
So the first thing I need to figure out is how many columns does this thing have, and that can be easily done.
I'll call it n c for number of columns and we can use the n call function for that.
That will calculate the number of columns, and, and then I need to initialize a vector that's going to that's going to store the means for each column.
The length of this vector has to equal the number of columns, right.
So I'll just call it means, and it'll be a numeric vector equal to the length of the number, equal to the number of columns.
And that's it, and then so for I, I haven't returned anything yet, so right now this function doesn't do anything particularly useful.
But what I want to do is return the vector of means and so I'm just going to return that.
And that's, since that's the last expression in the function that what will get returned.
I'll just take the column means of that, and see how it works.
Okay, so I, there are six, I think there are six columns in this dataset, so it gave me six means.
And that's because it, if the, if the vector has an na in it, then you can't calculate the mean.
And so the one thing you might want to do, is, by default, is throw out all of the missing values and just calculate the mean amongst the observed values.
And it will default to true, right.
And then I'll pass this argument to the mean function.
And so now I can default or remove the na's when I, calculate my column mean.
So sources send to R and with the run in the console column mean, and so now the default will be now I get my means for those columns because the default was to remove the na's.
I could say false here, and then my na's will come back.
So I can always choose to kind of go back to the old behavior if I wanted to.
So the last thing you want to do any time you're writing a function the most important thing of course is to save your file.
And give it the .r extension, and now you're code is saved to a file.
So that should get you started, just writing some simple functions in R, for your programming assignment you'll have to write a few functions that kind of go through and look at data.
But I just wanted to get you started writing your first functions so that you know kind of how the directive, the function directive works, how the arguments work, and you can play around a little bit with with more complicated ideas as you work through the assignments.
Functions represent some of the most powerful aspects of the R language.
And the basic idea is that you can type the command line and kind of explore some data, and run some code.
But eventually you'll probably get to the point where you need to do something a little bit more complex.
A little bit more than, than can be expressed in a single line or maybe in two lines.
And if you have to do this over and over again, then you're usually going to want to encode this kind of functionality in a function.
I'm going to talk about functions in three parts here.
First I'll talk just about the basics of how to write functions and how they are written, in R.
Then I'm going to talk a little bit about lexical scoping and the scoping rules, in, for the R language.
And then last, I'm going to end with a little example.
So, functions in R are created using the function directive and functions are stored as R objects just like anything else.
So, in particular, R objects, R functions are R objects that are of the class function, okay?
So, the basic instruction here is that you assign to some object, here I call it F, the, the function directive, which will take some arguments, and then inside the curly braces there is R, there is R code, which does something that the function does.
So one nice thing about R is that functions are con, considered what are called first class objects.
So you can treat a function just like you can treat pretty much any other R object.
So importantly, this means that you can pass functions as arguments to other functions.
So you can define a function inside of another function, and we'll see what the implications of this are we talk about lexical scoping.
So the return value of a function is simply the very last R expression in the function value to be evaluated.
so, there's no special expression for returning something for a function.
Although, there is a function called Return.
So functions have what are called named arguments.
And the named arguments can potentially have default values.
So, a lot of these features are useful for when you're designing functions that, that may be used by other people.
But most of the time, you don't have to change all those different arguments.
You may only care about one or two.
So it's useful for some of the arguments to have default values.
So first of all, there's the formal arguments, which are the arguments that are included in the function definition.
The formal's function actually will, takes a function as an input and returns a list of all the formal arguments of a function.
So not every function call in R makes use of all the formal arguments.
So for example, if a, if a function has ten different arguments you may not, you may not have to specify a value for all ten of those arguments.
So function arguments can be missing or they may have default values that are used when they are not specified by the users.
So when, this is very, this is key when you're writing a function and also when you're calling it.
So for example, take a look at the function sd, which calculates the standard deviation of, of, of a set of numbers.
So sd takes a input x, which is the name of the argument and which is going to be a vector of data.
And there's a second argument called na.rm and this controls whether the missing values in the data should be removed or not.
And the default value is for na.rm to be equal to false.
So by default if you have missing data in your, in the, in the set of numbers for which you want to calculate the standard deviation the missing values will not be included.
So, here I'm simulating some data and I'm just simulating a hundred normal random variables, and there's no missing data here.
So, if I just calculate sd on the vector it'll give me an estimate of the standard deviation.
If I say X equals my data that's the same thing.
So here I've named the argument but I haven't but otherwise the data are the same so it'll calculate the standard deviation.
In the first example I didn't name the argument.
So it defaulted to passing mydata to be the first argument of the function.
So in the next example here, I'm going to name both arguments.
That calculates the same thing as before.
Now when I name the arguments, I don't have to put them in any special order.
So for example, I could reverse the order of the argument here.
Now, what happens if I name one argument and don't name the other?
So for example, SD after you remove the na.rm argument only has one more argument left and so mydata would be assigned to that argument.
So all these expressions return the same exact value.
So although it's generally, all these expressions are equivalent, I don't say recommend all of them equally.
So for example, I don't necessarily recommend reversing the order of the arguments just because you can even though if you name them, it's appropriate.
so, just, just because that can lead to some confusion.
And so for example the lm function here which fits linear models to data has this argument list here.
So the first is the formula, the second is the data And then subset, the weights et cetera.
And you see that the first five arguments here don't have any default value.
So the but then the method, the model, the X argument, they all have default values so if you don't specify them they will use those values by default.
And so the following two function calls are equivalent.
I could have specified the data first and then the formula and then the model.
And then, and then, and then the subset arguments or I could specify the formula first, the data second, the subset and then say model is equal to false.
Now the reason why the first one is okay is because I, so I matched the data argument by name.
You can imagine that that's kind of taken out of the argument list now, then Y till the X doesn't, isn't specified by name.
So it's given to the first argument that hasn't already been matched.
And I, in which case that's the formula.
And then 1 through 100 has to be assigned to the argument that has not yet already been matched.
So in this case formula was already matched, data was already matched.
So 1 to 100 get's assigned to the subset argument.
But, I, I wrote it this way just to demonstrate how positional matching, and matching by name can work together.
A common usage for lm though is the second version here.
And then the next one is mydata, which the data set which you're going to grab the data from.
But then, the rest you may or may not specify and so you may, if you just want to specify one of the following arguments.
It's easier just to call it out by name.
so, most of the time, the named arguments are useful in the command line.
When you have a long argument list and you want to use the defaults for everything except for one of the arguments, which may be in the middle or near the end of the list, and you can't usually, you know, you can't remember exactly which argument it is, whether it's the fourth, or the sixth, or the tenth argument on the argument list.
And so you just call it by name, and that way you don't have to remember the order of the arguments on the argument list.
Another example where this comes in handy is for plotting, because mo, many of the plot functions have very long argument lists.
All of which have default values and you may only want to tweak one specific argument.
And so it's useful not to have to remember, you know, what the order of that argument is on the arg, on the argument list.
So the, the, the order of the operations that R uses, first it'll check for an exact match.
So if you name an argument it'll check, check to see if there's an argument that, that exactly matches that name.
If there's no exact match it'll look for a partial match.
And then if that doesn't work, it'll look for a positional match.
A, B, C and D.
B, C, and D, all have default values.
You want it if both specify the names of the arguments.
So null is a common argument.
So, one of the key features of the, our language is what's called Lazy Evaluation.
So Lazy Evaluation is a common model in a variety of programming languages.
And the way that it works is all of the arguments to a function are only evaluated as they're needed.
And so for example, if you take a look at this function over here.
And now recall that in a function, the return value whatever the last expression is evaluated.
So there's only one expression in this function.
And so it's the return value.
So if I say f(2).
Now you might be wondering what happens to B when I call (f).
I never specify what the value of b is.
And furthermore, b doesn't have a default value.
And so what happens, what, what happens is nothing happens because the function f doesn't actually use b.
And so the argument is never evaluated.
Here's another example of a function that's only slightly more complicated than the previous one.
So this is another function that takes arguments a and b, but now what the function does is it prints out a and it prints out b.
So here, what happened is that it printed out 45 because 45 was matched to the argument a, and so there was no error.
So here, but you notice that the error only occurs after the 45 was printed out.
And so the lazy evaluation applies, but because the argument is only evaluate when it's needed.
So there's a special argument, in.
And it's used to indicate a variable number of arguments that can sometimes be passed on to other functions.
So the three dots are often used when extending another function and you don't want to copy the entire argument list of the original function.
So for example you might want to extend the plot function and just to have a little bit of a tweak or to change some of the defaults, for example.
And so for example you might create a function that's called my plot.
And the my plot will replicate some of the arguments of the original plot function like x and y.
But it's going to change the default type arguments so that instead of creating circles for points.
So, but of course the default plot function has many, many other arguments.
And then though, that can used to, be used to kind of absorb all the other arguments in the plot function and then what happens is I'll take the dot dot dot and then pass it down to the original plot function, and so all those original arguments can be preserved then I don't have to retype or reconstruct all of those arguments in my extended function.
And sorry, there's another use of the dot dot dot argument, and it's for what are called generic functions so that extra arguments can be passed to the methods.
But the basic idea is that in R there, there can be special functions called generic functions which don't do anything, but what they do is they dispatch methods to put, according for different types of data.
lastly, so the dot dot dot argument is, is necessary when the number of arguments that are passive functions cannot be known in advance.
So one good example of this usage is in the paste function.
And what cat does similar to paste, it puts together, it pastes together a number of strings then it prints out the, the, the concatenated string either to a file or to a console.
So you can see that there are many other arguments to cat but the first argument is going to be the set of our objects that, that are going to be concatenated.
because, and this kind of makes sense, because otherwise there's no way for r to know whether you are passing something to the dot dot dot or whether you are passing something to a different argument.
So if I say in the first example here, where I try to paste together A and B, so A and B are going to the dot dot dot argument and then I say sep equals colon and then which means that I want to paste something together by separating them into with a colon.
However, if I try to do partial matching with set, what happens is that the partial matching gets ignored, and so, when, when I say paste a b and then s e equal to colon, well, the s e is, in another circumstance might be partially matched.
But in the pace function, it can't use partial batching.
So it gets, it just ignores that and just assumes that colon is just another string to be pieced together.
That any arguments that appear after the three dots have to be named explicitly and in full.
One topic that's important to discuss in R is a question of, you know, when a function sees a symbol in its body and it's executing inside the R environment, how does it assign a value to that symbol?
So for example, take a look at this, this function here that I've defined called lm.
So lm here is a function which takes its argument x, and it multiplies it times itself.
So you can think of it as squaring the, squaring the input.
Now, there's already a function in R called lm, so I've created an, a function here also called lm, so when I call lm somewhere else in R, maybe in another function or something like that how does R know what value to assign to the symbol lm?
And so the, the idea that R needs to bind a value to a symbol.
So in this case the, in the previous slide, the symbol was lm, and it needs to bind a value to it.
And the value is going to be a function of some sort.
It's either going to be my function or it's going to be the function in the stats package.
And so when r tries to bind a value to a symbol what it does is, it searches through a series of environments to find the appropriate value.
So environments are kind of, you can think of them as lists of objects and values or symbols and values.
And so, when you're working on the command line, and you need to retrieve a value of an R object basically, what happens is, the first thing that happens is, you search the global environment for a symbol name matching the one requested.
And so for the global environment, it's just your workspace, and it consists of all the things that you've defined or loaded into R.
And so if there's a symbol there that matches the name of the one that you're requesting then it will take that symbol and, and then retrieve the value that's associated with that symbol.
And so, because that exists, if I'm working the command line, when I call lm, it's going to find that object first.
So if there, if there's no match in the global environment, then what happens is, the, R will search the namespaces of each of the packages on the search list.
So the search list consists of all the R packages that are currently loaded into R.
And so you'll see that there, there's an order to the search list.
So, and it goes starts at the first element, which is the global environment.
Now, you can see, second on the search list is the stats package, the graphics package, the GR devices package.
All the way down at the very is the base package, okay?
And so, somewhere in this list of packages R is going to look for a function called lm.
And, of course, if it's not in the global environment, then it will eventually find it in the stats package which is the function that's used to fit linear models.
So, as I said before, the global environment is always, is equivalent to the user's workspace, and it's always the first element on the search list.
And furthermore, the base package is always the last element on the search list.
So, clearly because of the way that the search process works in terms of going down the list of packages, the order of the packages in the search list matters.
And for, and, and users can also load packages whenever they want.
So you cannot assume that there's going to be a set list of packages available or that the packages will be in any sort of order.
So they can be in different orders at any time to give depending on the user has decided to do in a given session.
The namespace of that package gets put in the second position of the search list.
So right behind the global environment.
And then everything else just kind of get pushed down one level.
So so, and then the search will kind of go down, will include that new package, including, in addition to all the other packages that were originally on the search list.
One thing to note is that R has separate namespaces for functions and non-functions, so it is possible to have an object named c somewhere and the function name c.
Of course, in your global environment, there can only be one symbol named c.
But it's possible to have for example, a vector named c, and that won't necessarily interfere with the function that already exists that's also named c.
which, which is which I think are the, is the main feature that makes it different from the original S language.
Since, since most of you probably did not use the original S language, maybe, this may not, this may be something of a moot point.
So the scoping rules determine how a value is bound to a free variable in a function.
So if you're in a function there's two types of variables.
There's the, there's the function arguments that are passed through the definition of the function, and then there may be other variables or other symbols that are found in the function that are not function arguments.
And the question is, how do you assign a value to those symbols.
And so R uses what's called lexical scoping or static scoping, and this is a common alternative to something called dynamic scoping.
And so this is, related to the scoping rules is how R uses the search list to bind a value to a symbol.
And, and one thing that's nice about lexical scoping is that it turns out to be particularly useful for simplifying things like specifically statistical calculations.
So take a look at the following function.
So, this function has two formal arguments they're called x and y.
And the body of the function, basically it squares x and it adds the ratio of y divided by z, okay?
So, x is clear, and y is clear, but where did z come from, right?
And so the question is, well, what value do we assign to z, assuming that values were inputted to the function for x and y.
And so, the scoping rules of a language determine how we assign a value to something like z, which is a free variable.
So if I were so this, lexical scoping, the rules in R, can be summarized by the following sentence.
Which is basically, the values of free variables are searched for in the environment in which the function was defined.
And so, what's an environment?
An environment is a collection of symbol-value pairs.
And, and you can think of everything in R as being pairs of symbols and values.
Right, so, a another symbol might be y, and its value is a data frame, for example.
So it's kind of like the, the environment that sits on top of it would that, that it inherits from and it's possible for an environment to have multiple children.
So there might be one parent environment and many children environment and so there's only one environment without a parent, and that's the empty environment.
And so, when, so, R uses a lot of these types of environments.
So you think of the global environment, which is your workspace that is a set of symbol-value pairs, right?
So you have a bunch of things that you've created in your workspace, and they all have names.
And each one of those things has an object associated with it.
So they might be a vector of numerics, or it might be a data frame, or it might be a list, or whatever.
And so there are all kinds of these envir, each package has a namespace, and that's like an environment.
It has a bunch of symbols and values associated with it.
And so what the, the key thing in R is that if you take a function and you associate it with an environment, then that creates what's called a closure or a function closure.
And these closures are, are key to a lot of different types of interesting operations in R.
So, if you, if you're in a function and you encounter a free variable in that function what happens?
So, the first thing you look for is the function in which the environment in which the function was defined.
So if I see a free variable in this function, what's going to happen is that if I can't figure out a value inside the function, then I'm going to look in the global environment, because that's where the function was defined.
If I can't find something in the global environment, then the search continues in what's called called the parent environment of the global environment.
And so the, what happens in the usual case, if I define a function in the global environment, then the function is defined in the global environment, and then its parent environment is the next thing down on the search list.
So, what happens is that you just go down the search list until you eventually find the value for this free variable.
And then it's going to look, if it can't find it there, then it's going to look for the parent environment.
And then if it can't find it there the search, it will keep looking at the parent environment or the parent etc, until we hit what's called the top level environment.
The top level environment is usually the global environment, however, if the function is defined in a package, then the top level environment is the namespace of that package.
So, after the base package, for example, then we hit the empty environment.
If you can't find a symbol in all these environments and we've hit the empty environment, then we throw an error saying we can't find a value for this symbol.
It's not immediately clear.
So typically the function is defined the global environment so that values of the free variables are just found in the user's workspace.
The right thing to do is kind of what most people are expecting.
If there's no, if, if there's, you can't find a value inside the function itself, you just look in the global environment.
So this is the, the idea here is that you can define things like global variables, that will be common to a lot of different functions.
so, but the key difference in R is that you can define functions inside of other functions.
'n so for example a function can return a function as the return value.
So, in most functions they'll return a list, or a vector, or a matrix, or a data frame or something like that, but it is possible for a, for a function to return another function and then that, if that's the case then the, then the function that gets returned.
So, it's an, the environment in which it was defined Is not the global environment.
It's really the, the, the insides of this other function.
So this is when things get interesting and this is when the scoping rules really have an impact on what you can do.
So, the idea that the function is constructing another function.
So, here's what I want to, I want to create a function that that defines another, called make.power.
So, and inside the make.power function I define another function called pow.
However, N is defined inside the make.power function and so since that's the environment in which the pow is defined.
The pow, the power function will find the value of n inside this, it's other environment.
So what happens is that I can call make.power and pass it a number like 3.
And, similarly, I can pass 2 to make that power and create a function that I'll call square.
So, now, when I, when I pass cube, the number 3 What is it does is it raises 3 to the 3rd power, so I get 27.
If I call square on the number 3, it, it raises three to the 2nd power, so it gives me 9.
So, how do you know what's in a function's environment?
You can look in the environment in which the function was defined, by calling the LS function.
So if I call, if I call LS on On the environment for cube.
And if I use get on N you'll see that the value of N is equal to 3.
Excuse me, that's how the cube function knows how to, knows to raise the argument to the 3rd power because it's already defined.
Similarly the environment for square, you can see it has the exact same objects in it.
But now the value of n is equal to 2, in the square function.
So, so, I want to make one brief comparison between lexical scoping, which is what R does, and dynamic scoping, which is what maybe some other function, some other programing languages implement.
Then create a function F, which takes, as an argument, X.
So, what's G?
G is another function, which takes as an argument called X, and it multiplies X times Y.
So, in the F function, Y is a free variable, and G is also a free variable.
Inside of F of or, it's, it, of, argument to F.
Then in the G function, then the var-, the symbol Y is a free variable.
And so the question is if I call f of 3 what gets returned?
So with lexical scoping, the value of Y and the function G is looked up in the environment in which the function was defined.
Which in this case was the global environment.
So that the value of Y and the G function is 10.
So with dynamic scoping the value of Y is looked up in the environment from which the function was called; sometimes called the calling environment.
So in the R the calling environment is known as is what's called the parent frame.
In this case the calling environment Y was defined to be 2 and so the value of Y would be 2.
So, in this case, X is a function is a formal argument.
A is a local variable so it's not a formal argument, but I defined it inside the function.
And then Y is a free variable, okay?
So if I call G of 2, the function G is going to look for the value of Y in the global environment.
Now if I define what Y is, say I assign it to be 3, if I call it G of 2, then it returns 8 because now it's able to find Y in the global environment.
So even though it looks like the value of Y was looked up in the calling environment, it's actually the defining environment because G happened to be defined in the global environment so, there are a number of other languages that support lexical scoping.
And of course there's a, a well known computer science theorem which is that all languages eventually converge to Lisp.
It's actually very common in a number of other programming languages.
So, one of the main consequences of lexical scoping in R is that all the objects have to be stored in memory.
So, if you're working with a programming language that has very small objects this generally speaking not a big problem.
Because of nature of the scoping rules and because of the complexity of the environment and the, the way they are all linked together, it's difficult to implement this type of model outside of physical memory, and so.
So the consequence was that, when R was originally designed.
Things are getting complicated now, because of very large types of data sets.
Everything has to be stored in memory.
Second now, so every function has a carrier pointer to its respect, to its defining environment.
and, and that defining environment could literally be anywhere because there could be functions within functions and then the, and if you do, if one function returns another function, then there has, there has to be a pointer to that piece of memory where the defining environment is stored.
And so this makes the model a little bit more complex but but, but all the more useful.
So, the, in S plus, which was kind of the original implementation of the S language, the free variable were always looked up in the workspace.
Everything could be stored on the disk, because the defining environment of all the functions was the same.
So far, we've talked about functions and the scoping rules in R, and you might be wondering why any of this information is at all useful.
So, in addition to just writing regular functions for manipulating data or for doing calculations, there's one combination of the scoping rules and functions which can be very useful in statistics, and that's for optimization.
So there are a few optimization routines in R called optim and nlm and another one called optimize.
And they all require that you pass a function to those functions, whose argument is vector parameters.
So for example there's going to be some function that you want to minimize or maximize.
and, over range of parameters, and functions like Optum and lmand take, take that kind of objective function, and try to find the minimum or the maximum.
so, the idea is that, but in statistics this objective function that we're trying to minimize or maximize, just like a log likelihood, is going to depend on other things, besides just the parameters that you're maximizing over.
So, for, in particular, it's going to depend on things like data.
And so, the question is, well, how do you specify a function.
Depend, depends on parameters and data and perhaps many, many other things.
In a clean, way and to, to write it in a, in a, in kind of readable programming style and make it easier for the user to kind of use these types of functions.
And further more, when you're doing these kinds of optimizations in many cases it's useful to hold certain parameters fixed and for example, fix a parameter to a certain value then optimize over the other parameters.
So, the basic idea with any optimization problem in r is you can create a contructor function which constructs the objective function.
And so that way you don't have to specify those things every time you call the function.
So just as a note, most of the functions in like optim and anolam and optimize and, in R, they all attempt to minimize functions by default.
And so when you write your objective functions if they're designed to be maximized, then you have to kind of take the, the negative of those functions so that you can minimize them.
So another thing is that all the code in this example all, will be on the website so you can take a look at the code and try to run it yourself if you want.
So the data is the first argument to this make.makelike function.
The second argument is a logical vector called fixed and it determines whether or not I want to have, want to fix some of the parameters.
So, now ins- inside the constructor function I have to find another function which is it takes an argument called p for the parameters.
And this is going to be the parameter vector that I want to optimize over.
So those are going to be the two parameters that I want to optimize over.
And so here I'm just defining, the law of likelihood, and taking the negative of it, so I can minimize it.
And, what, what the constructor function does is returns the function as the return value.
So,when I print out this function here,you will see that it, I see the body of the function looks like the code for the normal distribution.Its just like in the construction function before, but if you look at the environment, you will see this little tag that at the bottom that says environment.
And that's the enclosing environment for this function.
And so normally because when you define a function in the global environment, that it would just you, there wouldn't be a special environment tag down here.
And so, if you look at, this, this is, 0 x 16 5 b 1 a 4.
So if you look at the body of the nl function here, you'll see that pretty much everything here is either a local variable or its a param-, it comes with a parameter vector p.
However, there was one argument, th-, sorry, there's one variable here, the data variable, which is not an argument to the function And it's not a local variable, so it's a free variable but the data come from the make neglog like functions or constructor function which originally pass the data to that.
And so the data can be looked up in the environment that the function is defined and it knows what the data are, you don't have to tell what the data are it's already fixed in the function.
So if you look at the environment for this negative log-likelihood function by calling LS, you'll see that the the data variables there.
The fixed variable there which indicates which parameter should be fixed, and then there's also the params variable there.
Inside this negative log likelihood function, but they're defined in the defining environment.
So pretty close to the truth, remember, which was one and two.
Now I could, if I wanted to, I could fix sigma to be equal to its true value and then just optimize over mu to get the mean, and so when I call make.
So I need to reconstruct my optim, my objective function by calling make.neg log like, and here I set the fixed variable to be false from U.
Now I can just call, optimize, because optimize will minimize the function of a single variable only.
And because I only have a single variable in this, function, I can use, I can use optimize.
And you can see that it, it, it estimates made to be about 1.21 so slightly different from the previous optimization.
I can also fix mu to be one and try to optimize over over sigma and but in order, in order to do that I have to construct another function for optimization call optimize on that.
So here I'm going to make the neg, the negative log likelihood.
I'm going to fix mu to be equal to one and I'm going to plot the negative log likelihood as a function of sigma.
Similarly I can plot the negative likelihood as a function of the mean by fixing sigma to equal to two and letting mu vary.
And similarly, I create another grid of points another set of grid points and I evaluate at the NLL function on those grid points and then make a plot.
So, the nice thing about lexical scoping in R is that, if you're doing minimization or optimization of some sort, you can build these objective functions, which contain all the necessary data, and all the other kind of bells and whistles that are required, to evaluate that function.
So that when you call the objective function, you don't need to specify the data, and all those other things every single time.
They're kind of built in to the environment and they'll be automatically looked up in the right place.
That in order to evaluate the function every single time.
So this can be very useful for interactive work, and for exploratory work like for example making these plots.
And this can so the code for these types of functions can be very simple and kind of clean because you don't have to carry on these large argument lists.
Coding standards in R are really important becasue they help you, make your code readable and allow you and other people to understand what's going on in your code.
Now, of course, just like it is with any other, style whether it comes, when you, you know, whether it's your clothing or whatever it is, it's difficult to get everyone to agree on one set of ideas.
But I think there are a couple of very basic, kind of minimal standards that are important when you're coding in R.
So, the first principle that I think is very important in pretty much any programming language, not just R, is that you should always write your code using a text editor and save as a text file.
Okay, so, a text file is a kind of basic standard.
And usually, typically, typically it's going to be ASCII text, but if you're, on, in places outside the US or the UK using non-English languages there may be other standard text formats.
But the basic idea is that a text format, can be read by pretty much any basic editing program.
These days, you know, when you're writing something there's a lot different of tools that you can use to write.
If you're writing a book, or or a webpage or something like that, there's all kinds of different tools that you can use to write, to write those things.
The second principle is, which is very important for readability, is to indent your code.
So indenting is something that's often hotly debated in lots of mailing lists and other types of discussion groups in terms of how much indenting is appropriate.
But I think the most important thing is that you understand why indenting is important.
So indenting is the idea that different blocks of code should be spaced over to the right a little bit more than other blocks of code so you can see kind of how the control flow how the flow of the program goes based on the indenting alone.
So coupled with indenting, is the third principle which I think is very simple which is, limit the width of your code.
So you have indenting it's possible to kind of indent off to the right forever so you need to limit on the right hand side how wide your code is going to be and usually this is kind of determined by the number of columns of text.
So, let's take a look for, at a quick example here.
So here you can see I've got R Studio open, here with a simple code file with some R code in it.
And, first of all, let me just mention that the editor in R Studio is a text editor.
So it will always save the R files that you write as text format files.
And you can see that all the code is kind of mashed together here on the left hand side.
It's difficult to tell kind of where the if blocks are.
And so the indenting scheme kind of makes the code not very readable in this case.
If we just go up to the Preferences menu here.
And let me just change it to four.
So now you can see that the indenting is a little bit nicer now.
You can see, kind of, where the function begins and ends, you can see where the if blocks start and end, and the, kind of, structure of the program is much more obvious.
So, I'm going to change this one more time though and my, because my personal preference for indenting is to use eight spaces, so I'm going to change this to eight.
And now you can see, I prefer the eight spaces just because it really makes the structure of the code very obvious.
And it makes the code very readable in general.
So you can see that indenting is very important.
If you don't indent at all or if you only use a very small amount the code becomes kind of very mashed together.
One of the advantages of having something like an eight space indent, is coupled with an 80 character margin on the right hand side, is that it forces you to think about your code in a slightly different way.
So for example, if you have eight space indents, if you're going to have a for-loop, nested within another for-loop within another for-loop, every time you nest another for-loop, for example, you have to indent over eight spaces.
And by the time you get to maybe your fourth nested for-loop you're pretty much hitting the right hand column at the 80 column margin, right?
So, for example, with an eight space indent and 80 column margin, you might not be able to do feasibly more than two nested for loops, and, but I think that's really the, kind of, the boundary of what is readable in terms of code.
So a good indenting policy not only makes the code more readable, but it actually can force you to think about writing your code in a slightly different way.
And so that's a really nice advantage of, of having a logical indenting policy with, coupled with a, you know, a right-hand side restriction.
So the last thing I want to talk about is to limit the length of your functions.
So for example, if you're function's named read the data.
Then your function should simply read the data, it should not read the data, process it, fit a model, and then print some output, alright?
There are a couple of advantages to doing this.
If you could put all the function, the entire function on like one screen of the editor, then you can look at the whole function and see what it does all at once.
Another advantage of splitting up your code into logical sections, to logical functions, is that if you use functions like traceback, or the profiler, or the debugger, these often tell you, you know, where in the function call stack you are when a problem occurs.
And if you have multiple functions that are all logically divided in to separate pieces then when a bug occurs and you know that it occurs in a certain type of function or a certain function then you know kind of where to go fix things, right?
So if you have, but if just have a single function that just goes on forever and a bug occurs then the only thing that the debugger or the traceback or the profiler can tell you is that there's a problem in this one function.
But it, it doesn't, it, it's difficult to tell you where exactly the problem occurs.
So splitting up your functions has a secondary benefit, which is that it can help you in debugging and profiling.
So limiting the size of your functions is very useful for readability and for, kind of, debugging.
Of course, it's easy to go overboard and having, you know, a hundred different three-line functions.
So that's not really what you want to do.
So you just want to make it so that the, the separation of different functions into, is logical, and that each function kind of does, does one thing in particular.
So those are my basic guidelines for writing code in R.
There are, of course, many other things that you might be able to think about.
And so I'm not going to talk about too much more in terms of coding standards, but the basic ideas are always use a text editor, always indent your code, I'd say at least four spaces.
And and always limit the size of your functions, so that you can, so that they're, kind of grouped into logical pieces of your program.
It'll be readable to you, it'll be readable to others, and it'll make kind of writing R code much more useful to everyone.
I want to talk briefly about dates and time in R, which is a very, is a very special topic and could require a lot more time.
so R has a special way to represent dates and times.
And they're, they're represented using special data classes.
So, in the past, we talked about different data types like lists.
And, numeric vectors, and so.
This is just another type of data on top of those kinds of classes.
So dates are represented by the date class.
and, times are represented by two separate classes: the POSIXct and the POSIXlt class.
They represent a day, in a year in a month.
That particular detail is not very important but in case you're wondering you don't know how they, how the, how R actually does calculations based on dates.
That's not very important, but it maybe useful to know, sometimes.
So, the way dates in R, in R work, is you can take a character screen.
And, you'll notice that if you print out this object.
Now it's not actually a character string but it will print out that way because there's a special print method.
Now if I unclass the object here you'll see I get the number 0.
If I input January 2, 1970, then you'll see that underline is represented as a number 1, because that's 1 day after 1970 January 1st.
If you had a date that was before 1970 Then, they'd be represented as negative numbers.
You don't, you don't have to worry about the underlying representation.
Ultimately, what you need to know, is that dates are stored as objects of the date class.
Times, on the other hand, are represented as two possible types.
One is called POSIXct and the other POSIXlt.
So, POSIX is a family of computing standards for how things should be done on certain types of computers or how data should be represented and so there's a there's a family of standards for how to represent dates and times and pos and so POSIX a that's part of the POSIX standard.
Times are represented at just as very large integers.
POSIXlt stores a time as a list.
underlying, and so, and it stores a bunch of other useful information about a given time, for example what's the day of the week of that time, what's the the day of the year, the day of the month, or the month itself.
And there are a number of generic functions that operate on both dates and times.
That you can use such as the, so the weekdays functions tells you what day of the week a given time is or a given day is.
And the quarters functions gives you the quarter number.
So for example, quarter Q1 would be January through March, Q2 would be April through June, etc.
So, these generic functions operate on, on objects of class.
If you want, using the as.POSIXlt or the as.POSIXct function.
so, for example the Sys.time function here, just gives you the current time.
And you can see that when it prints out, it prints out in a year month day format.
And then the, the timezone, which is Eastern Standard Time right now.
So you can convert this di to a POSIXlt using pa, as.POSIXlt.
And, POSIXlt remember underlying is a list.
So you can look at the names of the elements.
The month is just the month your in so that's a January and then the year.
So, if I extract the sec, seconds element of this list, you'll see it's 11.86.
And so that, and so this actually gives you the seconds in in fractional seconds.
So, that's, that's the number of seconds in the time.
The POSIXct format you can see is you can also get it from the sys.time function and you can see that if I un-class the POSIXct object.
Now if I try to apply the list operator, the dollar sign to this object, you see I get an error because objects of POSIXct don't have these list elements in them.
You want to get those list elements out you have to convert it to POSIXlt using the as.POSIXlt function.
In this case it's 11.88 seconds.
Well, in this case it converts into two time objects.
So and they use what are called format strings.
So in this case I got, and so you'll see how these present signs fall by letters.
And then you can, you can look-up what these symbols mean in the help page for strptime.
Then comma and then %Y is the four-digit year.
Then %H is the hour, sort of like colon followed by %M which is the minute.
And so that's the format.
You can see that after I call I print out X, I get these time objects that are formatted, that are printed out in the standard format.
When I look at the class of this object you'll see it's in a POSIXlt format and so that's the so you can look at so that's the underlying kind of list format here.
So, but the end you need to be careful that you can't always mix different classes.
If I try to subtract the two, you'll, you'll get an error because they're not the same, type of object.
The nice thing about the date and time operators is that they keep track of very tricky things like leap years, leap seconds daylight savings and time zones.
And so the difference between March 1st and February 28th is actually a difference of two days, not a difference of one day like it is every other year.
Similarly I could take two times one which is in my, X which is in my kind of current time and then Y which is in the time zone of GMT, so Greenwich Mean Time.
So even though it looks like it should be a 5-hour difference, it's actually only a 1 hour difference because of the change in the time zones.
So one of the advantages of using the date time classes is that it will automatically take care of these kinds of irregularities.
So that was just a quick sum, kind of overview of the, the dates and the time classes in R.
So just to summerize there are special classes in R that will, that represents dates and times that'll allow you to do numerical and statistic calculations.
And then character strings can be coerced to either a date or a time class, using the strptime function or as.Date.as.POSIXlt, and POSIX, as.POSIXct.
The other thing to note, that I haven't really talked about here is that a lot of the plotting functions, will recognize date time objects.
It will recognize that object and then format the X axis in a special way so that it will have a time element to it.
So you might want to try to experiment with that a little bit to see how plots change when you use a date time class.
Loop functions are some of the most powerful functions in the R language and they make it kind of very easy to use, especially in an interactive setting.
The idea behind a loop function is you want to execute a loop over an object or a set of objects in a way that's kind of that does a lot of work in, in a very small amount of space.
That way, you don't have to type as much on the command line.
So, there are a couple of loop functions in R and they usually have the word apply in them somewhere.
So some of the key ones are lapply, sapply, apply, tapply, mapply and the real workhorse function that I, that I'd like to talk about here is lapply.
And the idea behind lapply is that you have a list of objects and you want to loop over the list of objects and apply a function to every element of that list.
And so it's a very general concept.
And it can be used very powerfully to do a lot of computations in a few, in just a little bit of typing.
Apply is a function that operates over the margins of an array.
So, this is very useful if you want to take summaries of matrices or other or, higher dimensional arrays.
Tapply is short for table apply.
And, it applies a function over subsets of a vector.
And mapply is a multivariate version of real of lapply.
There's also another function called split which doesn't actually apply anything to objects.
Basically the first argument is a list which is called X.
The second argument is a function or the name of a function and then there are other arguments that are, can be passed to the dot dot dot argument.
And the dot, dot, dot argument is used to pass arguments that go with the function that you're being, that's being applied to each of the elements in the list.
If X is not a list, then you will be coerced to a list if possible.
If it's not possible to coerce the object to a list, then you will get an error.
So the lapply function, you can see, is very simple.
Basically the func we look for the function if it's, if the object is not a list then it's coerced to a list using as.list and then the, the rest of the Lapply function is, is,is implemented internally in C code to make it a little bit faster.
So the idea with Lapply is that you're going to take this list of things.
And remember a list can contain any, any number of different types of objects.
So they could be vectors, or matrices, or data frames, or whatever it may be and you want to apply a function to each one of these elements of the list.
It may not be the same thing that it originally was on the list.
So, for example, it may take as an input, as a vector, but then it may return a scalar as a result.
So, the function's going to return something for every single object in that list, and the return values are going to be assembled in a new list.
So lapply, it's key to remember, it always returns a list.
What goes in may or may not a list but it will be coerced to a list.
I'm creating a list of two elements, the first one's called A, and it's a sequence from one to five, the second one is called B, and it's it's ten or more random variables.
So what I, and then, what I want to do is I want to loop over this lists of two elements and apply the mean function to each of those elements.
So you can see that when I call Lapply on x and I apply the mean function I get another list back, w-, and notice the list has the same names as the original list, a and b.
But now I've got the mean of the first element and the mean of the second element.
The names are preserved and notice, of course, you know, each of the elements of the original list was a vector of some, of a numeric vector of some sort.
But what I'm getting back is a vector with just a single number in it, for each element of the list.
Here I'm creating a sequence one, of x, 1 to 4, and I'm calling runif, so, which generates a uniform random variables, to, using a random number generator.
Now, the first argument to runif, is the number of uniform random variables that you want to generate.
So if I say runif 1 it's going to generate a single random variable.
If I say runif 2, it's going to generate a vector of two random variables.
So, what I'm going to get is a list where the first element is a single random number random uniform.
The second element's going to be a vector of two random uniforms.
The third element's going to be a vector of three.
And the fourth element's going to be a vector for random uniforms.
And so ret, you'll note, if you know the runif function, you'll know that it has other arguments to it beyond the, the number of uniforms to generate.
But those other arguments have default values so I don't need to specify them.
Now, suppose I want to call the runif function on each one of these elements of X but I didn't want to just generate a uniform between zero and one which is default.
Suppose I want to generate a uniform between zero and ten so now I need to pass some arguments to the runif function which are not the default values.
In particular I need to change the max value.
So now when I the, the list that I get out of this has random uniforms that are between zero and ten.
So lapply and the associated functions make heavy use of what, of what are called anonymous functions.
Anonymous functions are functions that don't have names, so you don't assign them a name of some sort but you can kind of generate them on the fly.
So here is a just a quick example, I'm going to create a list that contains two matrices in it.
The first is a mat, a two by two matrix and the second is a three by two matrix.
And suppose I want to, I want to extract the first column from each one of these matrices.
So what I can do is I can call lapply so, there's no function that, out there that already extracts the first column of a matrix but this is easy to do.
You can just write a function that just takes the first element, the first column of that matrix.
So here, when I call Lapply with this function I get the first column from A, and the first column from B.
So this function doesn't exist except within the context of Lapply, and after the Lapply function is finished, the function basically goes away.
Because unless there already exists a function that does the operation that you want to do, you're going to have to write the function kind of on the spot.
So sapply is just a variant of lapply and all it does is it tries to simplify the result of lapply if possible.
So recall that lapply always returns a list but sometimes you don't want a list, sometimes you just want something different.
So for example, if the, if the result is a list where every element is a length 1 then what sapply will do is it'll return a vector of all,of all, of all those elements.
if, if the result is a list where every element is a vector of the same length.
For example, if the, if the list comes back and every element has a length five, for example.
So that, that's often what you want to happen.
But if it, if it can't figure out how to simplify the object when it comes back, for example, if the object has many different types of things that comes back then it's just going to then it won't do anything.
So sapply called on x with the mean function gives me a vector with four numbers in it.
Of course, if I called mean on the, on the list by itself, that's not really going to work because mean is not meant to be applied to lists.
The apply function is another loop function that's used to evaluate a, a function over the margins of an array.
Usu, usually, the function's going to be an anonymous one, like we showed with lapply or it could be a function that already exists like the mean, for example.
It's usually used to apply a function to the rows or columns of a matrix.
But you may have three dimensional arrays and such.
But you, so you can use apply on general arrays such as taking the average of an array of matrices, for example.
One thing to note, and you may hear this out in the wild, occasionally, that apply, using apply is somehow better than ta, using a for loop or somehow it's faster than using a for loop.
And that's, generally speaking, not true.
It was true a long time ago in older versions of the S language in R but right now, it's not true at all.
The main reason you want to use a function like apply is that it involves less typing.
And less, less typing is always better, because good programmers are always lazy.
So, how does apply work?
So a matrix is a two dimensional array, for example.
This is a vector, an integer vector that indicates which margin should be retained.
And the last important argument is the function that you want to apply to each of the margins.
So, and then the dot dot dot argument are other arguments that you want to pass, include other arguments that you want to pass to the function.
so, in, in, in the matrix it's just normal random variables that I've generated.
So when I apply, so what I want to do is, I want to take this matrix and I want to calculate the mean of each column of the matrix.
So the way I can do this is I can apply, use the apply function on x.
I give it the margin, two, and I'll say what that means in a second.
And I pass the function, mean.
And so what happens is, I get back a vector of length ten that has the mean of each of the columns of the matrix.
So, when you apply the function, mean, over the matrix, well, the idea is that you want to keep the second dimension, which is the number of columns, and you want to collapse the first dimension, which is the rows.
It's really the first dimension that's been eliminated.
And so you get this number which this vector which has each of the means for each of the columns.
similarly, you can take the means of all the rows of the array.
And I can, I can call the apply function on x.
And then I, I, here I'm calculating the sum of each the rows, instead of the mean.
So the, so, I cast the one because it says I want to, I, because of what I mean is I want to preserve the rows and collapse the columns.
And each, and inside each and for each row, I calculate the sum of that row.
So for calculating the row sums and row means, there's the functions rowSums and rowMeans.
And similarly, there's colSums and colMeans, which do the same things for the columns.
These are equivalent to using the apply function, but they're very much faster than using the apply, because they're optimized to specifically to do those operations.
So if you want to calculate the sum or the mean of a, of a column or row of a matrix, use those functions instead.
Now you can, you know, use the apply function to apply other types of functions.
For example, suppose you have a matrix.
And suppose I want to go through each row of the matrix and calculate the twenty-fifth, and the seventy-fifth percentile of that row.
So, I can apply on x I, I get, I pass the margin of one, because it means I want to preserve the rows.
Now the quantile function needs, needs, the quantiles that you want to calculate.
So there's no default value for that, so I actually have to pass it to the quantile function through the dot dot dot argument of apply.
And I, and I give it 0.25 and 0.75 meaning I want to calculate the twenty-fifth percentile and the seventy-fifth percentile.
So what this funct, what this call does is, it goes through each row of the matrix, and for each row, it calculates the twenty-fifth and seventy-fifth percentile.
So, the so, here, I'm creating an array with, which has normal random variables and it has two rows and two columns and it's ten and the third dimension is ten.
I guess I'm not sure what you would call that dimension.
But you can imagine this.
So, the average of the, of a bunch of 2 by 2 matrices is going to be another 2 by 2 matrix, which is the mean.
And I want to keep the first, and the second dimension, but I want to collapse the third dimension.
So here, when I, when I give the margin, I give it one and two, which I want to preserve, and then three is not there, which means I want to collapse third dimension.
So here, and then the function I pass it is the mean.
mapply is a loop function that tries, is a multivariate version of the kind of lapply and sapply functions that you've seen previously.
And the idea is that it applies a function in parallel over a set of different arguments.
So one thing we have noticed about the previous functions, lapply, sapply, tapply, is that, they have only, they only apply a function over the elements of a single object.
So, for example, if you think about lapply, the input to lapply was a list.
So, what happens if you have two lists that you want to apply a function over?
And so, and suppose you have two lists, and the elements of the first list go into one argument of the function, and the elements of the second list go into another argument of the function.
So lapply and sapply can't really be used for that purpose.
So one way to do that is just to write a for loop, where the for loop will index the elements of each of the different lists, and then you can pass a function to each of those elements of the list.
Another way to do that though is with mapply, where mapply can take multiple list arguments and then apply a function to the, to the elements of those, of the multiple lists, in parallel.
So here, the first argument to mapply is the function that you want to apply.
And the function that you're going to pass to mapply has to have, the number of arguments that the function takes has to be at least as many as the number of lists that you're going to pass to mapply.
And so if you have three lists, you'll pass three objects and then your function has to take at least three arguments to it.
So, the more args, argument is just if you have more arguments and you need to pass to your function.
And a simplified argument is similar to the simplify arguments that you saw in sapply and also in in tapply.
So it's a little bit tedious to have to type something to do, even though this is a fairly artificial example, but with mapply, it's actually quite simple.
So, that's, so those are the two sets of arguments that I'm going to pass to mapply.
So mapply is, can be used to apply a function to multiple sets of arguments.
So, here's just another very simple function.
It just generates some random normal noise.
So, if I just apply noise to, with a single set of arguments, 5, 1 and 2.
However, this function doesn't work really correctly if I pass it a vector of arguments.
But, really what I want to happen is to have one, one random normal with mean 1, two random normals with mean 2, three random normals with mean 3, etc, and then five random normals with mean 5.
And, so that's what I get here, when I use the mapply function onto the and if I vectorize this noise function I give it, you know, three sets of arguments, so it's 1 through 5, 1 through 5, and then 2.
So I, I'm always going to fix the standard deviation to be 2, but I'm going to be changing the n and I'm going to be changing the mean.
So that's how I can instantly vectorize a function that doesn't allow for vector arguments.
So this is the same as, as I were to manually type out a list with these five different function calls.
Tapply is a very useful function and it's used to apply a function over subsets of a vector.
So the idea is basically, imagine you have a vector usually it's going to to be numbers, so a numeric vector.
And there are, there are pieces of this vector that you want to calculate a summary statistic over.
The idea is that for each group in the numeric vector you're going to calculate a summary statistic like a mean, or a standard deviation, or whatever.
So the basic idea behind tapply is that the first argument is a numeric vector or a vector of some sort.
The second argument is, is another vector of the same length which identifies which group each element of the numeric vector is in.
Then you need to have a factor variable which indicates, you know, which, which observations are men and which, which are women.
And so if you want to take the, the, the mean of the numeric factor within men or within women, then you can use tapply to do this.
So FUN is the function that you want to apply and so this is going to be the same as before.
It's going to be the, either a function or you can pass in an ano-, an anonymous function.
And then the simplify argument indicates whether you want to simplify the argu-, simplify the results, kind of like the sapply simplification.
So, here's a very simple example.
I'm simulating a vector of normal random variables and uniform random variables and, and there's ten normals, ten uniforms, then ten normals that have a mean of one.
So you can think of this vector as having three groups.
And each level is going to be repeated ten times.
So when I print out the factor variable here, you can see that there's ten ones, ten twos, and there's ten threes.
So each, so that the factor variable indicates kind of which group the, the observation is in.
If you don't simplify the result, then what you get back is going to be a list.
I want to calculate the mean and say simplify equals false then I get back a list with three elements and e in each element is the mean of that subgroup.
I, I can pass at slightly more complicated summary statistics.
So here, instead of calculating the mean, which, which returns one number I'm going to calculate the range of observations.
Tapply is useful because it splits up a vector into, into little pieces and it applies a, a summary statistic or function to those little pieces, and then after it applies a function it kind of brings the pieces back together again.
So it's kind of like tapply, but it, but it's like tapply but without applying the summary statistics.
So what it does, is it takes a vector, or an object x and it takes a factor variable, f.
Which again identifies levels of a group.
And then it splits the object x into the number of groups that are identified in, in factor f.
So for example, if f has three levels identifying three groups, then the split function will split x, into three groups.
And so, and then once you've got those groups split apart, you can apply, you can use lapply, or sapply to apply a function to those individual groups.
So here is, is a simpler example, similar to what I had before.
And now I'm just going to split the vector into three parts.
Because because the factor variable has three levels.
The first, I got a list back and the first element is 10 normals, the second element is 10 uniforms and the third element, which gets a little cutoff here is 10 normals again.
So, here for example, it is common to use the lapply function in conjunction with the split function, so the idea that you split something that lapply function over it.
Now, this case, this use of lapply and split is not necessary, because you can use the tapply function which will do the same exact thing.
It's not anymore efficient or any worse to do it this way but the tapply function is a little bit more compact.
But the nice thing about the split, using the split function is that it can be used to split much more complicated types of objects.
So for example, here I've got a data frame for.
So, you can see that this is the first six rows of the data, of this...
And you see there are measurements on ozone, solar radiation, wind, and temperature, and then the month and the day within that month.
And so, one thing I might want to do is, is calculate for example the mean of ozone, solar radiation, wind and temperature in, within each month.
All right, so how do I do this?
And then once I've split data frame into separate months, I can just calculate the means, the column means using either apply or call means, on those other variables.
So that's what I've done here.
What I've done is I split the airquality data frame and this, and the factor I'm going to use to split is the month variable.
So the month variable technically speaking, in the data frame is not a factor variable but it can be converted into a factor variable, because it only takes the values 5, 6, 7, 8 and 9.
Basically because the measurements are only taken in the, kind of, warmer months of the year.
An anonymous function and the anonymous function here, what it does is it takes the column means of just the ozone, solar radiation and wind.
So I'm just going to take the column means of the, those three variables for each month each column monthly data frames.
You can't see them all but you can see most of them into lapply is returning a list back, where each element of the list is a vector of length three which is, which is the mean for ozone, the mean for solar radiation and the mean for wind, within that month.
As you can see that for, for most of the months the ozone value is NA and that's because when I take the mean of that column there are, and there are missing values in that column and I can't take the mean if there are missing values.
So before I fix the missing value problem, I can also call sapply here.
They're all the same length.
So what I'll do is put, put all these numbers into a matrix.
Where the three rows and in this case 5 columns.
For each of the three variables, in a much more compact format, it's in a matrix, instead of a list.
Of course I still got NA's for a lot of them, because the missing values in the original data.
So one thing I knew is I was going to pass the na.rm argument to call means that would remove the missing values from each column, before its calculating the mean.
And that, now when I call sapply on the split list, I can get the, the means of the observed values for each of the three variables for each of the five months.
So, so split is a very handy function for splitting arbitrary objects according to the levels of the factor and then applying any type of function.
And so here I split a data frame, you can split other lists, you can, and, or other kinds of things too.
So the last thing I want to talk about is splitting on more than one level.
So you, in the past couple of examples what I've, I've only had a single factor variable.
And I've split whatever the object is with a vector or a data frame.
That has, for example, the race.
And so, you might want to look at the combination of the levels within those factors.
I've got a factor with two levels, and each repeated five times, and then I've got another factor with five levels.
So there are my kind of two category, two group, grouping variables here.
So I can use the interaction function to combine all the levels of the first one with the, all the levels of the second one.
And so because there are two levels in the first factor and there is five levels in the second factor and there is a, the total combination of 10 different levels that you can have when you combine the two together.
So when you see, when I call, when I called the interaction function I get another factor, that kind of concatenates the levels of one with the other, and you can see that it prints out that there is a total of ten levels.
So, what now I can slit my numeric vector x according to the two different levels.
So now, when I Iike, when I use, now one thing, when I use the split function I don't have to use the interaction function.
I can just pass it a list with the two factors and it will automatically call the interaction function for me, and create that 10 level interaction factor.
And then and then, and then the elements of the numeric factors that are within those 10 levels.
Now of course there are, although there are 10 levels between the two different factors, that we don't exactly observe every single combination.
And so there are some empty levels here and you can see that some of these levels have nothing in them.
But, sometimes it's a little bit handy to not have to keep these empty levels.
So, so the split function has an argument called drop.
And if you specify drop equals true, it will drop.
And, and this can be very handy, when you're, you're combining, multiple different factors.
If you're only using a single factor, then doesn't, that argument doesn't really do anything, because you'll just use all the, all the levels but, usually.
Alright, so so today's lecture is about the debugging tools that are built into R.
So how do you know that there's a problem?
So, there are a couple of indications that R, will produce that that will give you the sense that there's something going on.
But, basically there are three main types of indications.
It's just an in, it could be a diagnostic message that something happened.
But it could, it could be nothing.
And and so the message won't stop your function from executing.
There will be a message that gets printed to the screen and the execution of the function will continue and that's all.
Usually, if you're writing a function, you are choosing, you're trying to figure out, okay, what's a message and what's a warning.
furthermore, or if you're using a function and you're figuring out well what does that mean, a warning is an indication that something unexpected happened it's not necessarily a problem, and may, and many times you, you, you explicitly want to ignore warnings but there's something unexpected happened.
It wasn't enough to kill the whole thing, But it was enough to kind of trigger this warning.
So execution of the function will continue if a warning occurs but you'll get a message after the end, so once you'll get a message when the function completes execution.
So when the function comes back, when you get your console back, that's when the warning appears.
By default.
So an error is a fatal problem.
This stops execution of the function.
And and these, and error messages are produced by the stop function.
So and then there's a general notion of a condition.
Which is it's the higher level concept.
It can, all three of these things are, are conditions.
So if you have, and generally you're not going to be doing this at this level but if you have a, a, another type of of, condition that you want to, kind of trigger when something, when a special thing happens.
So it's not an error, it's not a warning, and it's not a message.
You can create your own conditions and and using some of the functions that are available.
So we won't be doing that now, but there is this notion of a condition and it's, it's generic.
You take the log of a negative number.
You can't do that, right?
It's a NaN, right?
Not a number.
So this is your typical and, and sometimes that's fine.
Because maybe you're taking a log of a bunch of numbers and maybe some of them are negative, but you don't really care and then you're going to make some sort of plot or something like that.
So so this is the kind of thing where you probably wouldn't want the function's behavior to just stop anytime it sees a negative number because sometimes these things just happen.
You get negative numbers on occasion and you want to take the log anyway.
Now I've got a little function here that I've created.
It checks to see if it's greater than zero.
If it's less than or equal to zero, you get a message saying that it's less than or equal to zero.
and, and then last I want to mention this part here.
So invisible is a function that that, that stops or I should say prevents auto printing.
So normally when you, if I if I'm at command line and I type a function, remember the, and I execute a function the, the function will return the last element of, that's in its function body, right?
So if the last sum in this function body is like is numeric vector, it will return that numeric vector.
If I call invisible on the return object, then it will still return the same object but it won't, it wont do the auto printing.
So you can call the function and the object will be returned.
So a, a, a, a, an example of a function like this is the load function.
So we haven't really used that much, but the load functions loads objects from what, from a saved work space, so it's like the opposite of of save, right?
and, but when, and when it loads the objects, it actually returns a character vector containing the names of all the objects that it loads.
But that doesn't get printed to the screen and because, it's, it's returned invisibly.
So if you have a function that returns something invisibly then the return, what happens is that the object that gets, that gets returned by that function doesn't get printed to the console and so sometimes you want that to happen and sometimes you don't.
Sometimes it doesn't matter.
So here I've, I've just added this here just so I can, you know, tell you about it.
It's not particularly important.
So when you say print X, what gets returned is a string, X.
So, so, so, so you could assign the output of print to, like, an, an object.
Generally speaking, you never do that.
No problem.
So and so what does printmessage return, just before I go on?
And so actually, if I had assigned print, the output or printmessage to some other object, it would be the number one in this case, right.
Even though it didn't printout the number one anywhere.
So now, I'm going to pass it directly an NA, right.
And so it doesn't know what to do it can't move on.
It, and so it has to error out.
So something happened there that's wrong.
Now, I'm going to to fixed this problem so to speak.
So, now I if it's NA, I'm going to print this message, right.
So when I call this, so now what, so what's something that might typically happen?
Now I'm going to printmessage on x, and I'm getting x as a missing value, right?
Because maybe I, I, I, maybe I thought that, okay, well the thing that I'm inputting into printmessage2 is, is like some positive number, so I thought I was going to get the message X is greater than zero.
So what happened right?
And so all I'm trying to say here is how do you know when something's gone wrong, right?
And sometimes it's easy to tell like in the case where you got the error message.
But sometimes it's not easy to tell because here there's no error but it's not exactly what it, what I was expecting, okay.
It's when you, when you're looking at a function, you think something's gone wrong, there's a couple questions you want to ask yourself.
To see whether there something actually is wrong, or maybe, or is there is something we call user error, okay?
So what was the input that you put?
What, what did you feed into that function?
Okay, not what you thought you fed into that function, what did you actually into that function?
Okay, so I thought I fed that function a positive number but in reality I fed it a, a NaN.
Alright, so how did you call the function?
So you, and this is important when you're asking someone for help, or you're asking someone a question.
I can't just, it's not that useful to say oh the printmessage2 to function didn't work.
How do you know it didn't work, alright?
That's how you know it doesn't work.
And then, someone could say, well you shouldn't have expected this, because that's not what that function does, or you know, or something like that.
But or you can say, okay, here's the problem.
So what were you were expecting is then very important to be able to articulate at least to yourself and maybe to other people.
What was the output that you were expecting, were the were you expecting some message that you didn't get?
So what we're expecting, and then of course, what did you actually get?
And then of course were expectations correct in the first place?
So, if you were expecting something that was, that was in fact incorrect then your notion of what is correct and incorrect is now being challenged, right?
So an important, and another key aspect of debugging of course is you have to be able to reproduce the problem, right?
Because if you can never reproduce the problem, you'll never have a chance in figuring it what went wrong, because it only happened that one time, right?
So this is very, very, very, very important.
And unless it's a very I mean unless it's like the most basic problem.
You have to be able to reproduce the problem.
You know, because you have to be able to show someone this is how I created the problem.
Because most people are not going to know if you just show them the output of the error message, or what that means, or where it came from or how you got there.
Okay, so the process by which you encounter the error or the problem is very important.
So you, you have to know how to reproduce the problem.
And, if you're not setting the seed, you will never be able to reproduce that problem, because every time you run it, it's going to be a different set of random numbers.
There are other types of problems that can be hard to reproduce.
They're usually, for example, if you're writing networking co, networking functions, you know, something, so you're doing like parallel programming, often, those kinds of problems can be very hard to reproduce because they depend on activity in other machines and things like that.
Things that, if you're getting code over the internet, and so if you're getting data over the internet, and your code is kind of interacting with things in the web, that can, problems there can sometimes be hard to reproduce because servers on the other side may change or whatever.
And so you, you can't always freeze things in time.
If it's something that's just happening on your computer it's usually going to be easier to reproduce the problems.
so, unless, I mean only under very esoteric circumstances, circumstances will it be hard to reproduce a problem on your computer.
so, what are the tools that R comes with to help you to debug a program?
Right, so there are five basic functions and a few associated ones that I want to talk about.
But the first most basic one is the traceback function.
Now, one thing I want to say, you can get pretty far in R without using any of these functions.
So, the traceback function, what does is it prints out what's called the function call stack.
So you know, typically when you call a function, you call, you call the function and that function calls another function, and then that function calls another function, and it's like, and then you're four functions deep, and then maybe the error happens way down here, right?
And so, traceback just tells you how many function calls you're in and where the error occurred, right?
And so you can try to identify where in the sequence of function calls the error occurred.
Otherwise, all you know is that you called one function and then an error occurred.
But you've no idea, you know, how many other functions are called underneath.
So the traceback function will tell you that, and I'll give you an example.
So the debug function is probably the handiest function.
It, what it does is it, as you give it a function as an argument, and it flags that function for debug mode.
Okay, what debug means, that anytime you execute that function, anytime, anywhere even if another function calls it, it will, it will halt, it will suspend execution of the function at the first line, and then you can, in what's called a browser.
And I'll show you how this works and then you can step through the function line by line.
And then you can see you can execute one line, one expression at a time, I should say inside the function.
So you can try to pinpoint, okay, if there's a specific line of code when the error occurs, you'll be able to find out which line that is, okay.
And then you can, and then you can go line by line from there.
So sometimes, for example, you don't, the debug function by the, will always start the, start the debugging, start the browser right at the top of the function.
But sometimes, you kind of want to run through the beginning and then stop it somewhere in the middle.
And so, so the browser function allows you to stick the browser call anywhere in your code and then it will run the function up until that point and then suspend it.
So so that, so there, those two are obviously related.
The trace function allows you to insert debugging code into a function without actually editing the function itself.
and, and this is handy if you are debugging someone else's code.
Right, so for example, there's code in the package or the, and you can't easily edit the code in that package, or there's code in the base R itself or there's you know, something like that.
And you don't want to go and edit that code, because you can't find the file, or whatever.
And then and, and then, and then you can kind of browse through that function, and then you can turn the trace off, and it's, and the function's back to normal.
So that, and then the recover function is the last function.
It's actually, I should put it up here, it's related to the traceback.
What recover does, so normally when you get an error you get, you usually get a message saying what the error was and then the, and then you get, and then the console kind of comes back to you.
But execution of that function stops and you get the console back.
You can change that default behavior by, by, by creating what's called, or setting what's called an error handler.
And recover is an error handler function which means that any time you encounter an error, anywhere in a function, rather than getting the console back the R interpreter will stop the execution of that function right where the error occurred, and will kind of freeze it there.
Now you're in the browser, and you can look around in the different function calls to see kind of, okay, what happened here, and happened here, what did the, how did data get corrected here and things like that.
It's a little hard to talk about in the abstract so I'll give you the example.
So there's also, so these functions kind of allow you to pick apart the kind of the details, the lines of code and try to figure out, okay, nail down where exactly the the bug may be.
You can also just put things like print, and cat, statements in your code to print out things.
And you can get a lot of mileage out by just putting in print statements.
The only problem with print statements and things like that, is that you often you'll put in like a lot of these, it's a long piece of code, you'll put in like 40 print statements.
And then I go back through and, like, delete all the print statements.
So that's, that can be a little bit kind of a pain, but you know, there's nothing terribly wrong with it.
Some people I've, I've, that I've worked with are actually against, they like, oppose the use of debugging tools.
I've ever software engineer company many years ago and there was an engineer there who was, he, he was opposed to any debugging tools.
He'd never used a debugger.
And because he thought that the use of the debugger encouraged bad habits, right?
I've seen it happen in other places.
If there's a problem, I'll just run it through the debugger.
And, and it encourages kind of a sloppy code development process because you know that if there's a problem you can just step through execution with the debugger.
It's probably better to think about your code, write it in, in a kind of intelligent way and then if there's a problem resort to the debugger.
But I use the debugger all the time.
I use the browser function, I use all these functions all the time.
So maybe I just have bad habits but that, that memory is burnin' my mem, mem, burnin' my brain for some reason.
Let's take a look, I'll just give you a couple examples and then I'll move to the actual just so you can see things.
So if you take the mean of something that doesn't exist you're clearly going to get an error.
Here it says so you get the error message this is produced by the stop function.
Well the error just occurs like right away at the top of the mean function.
And so, that's where the error occurs so, you know that may or may not be.
Many times that's just that is where the error will occur at the top level function.
One thing that's useful to, that, that the trace-back is useful for, is for when you're communicating with someone else over email, for example, me.
Its very useful if we just say use the trace-back, when I get after I get the error.
You have to call traceback immediately after the error occurs.
If you execute some other code and then call traceback it's not going to work, right?
Because the traceback will only give you the most recent error.
So you have to you've to call it right away.
Here's a slightly more interesting trace back so I call it LM, which is the linear modeling function.
So I don't expect you to understand all this but L M called e val on what's called a mono frame.
Model frame is a generic function that called a model frame default function.
So and it basically it occurred because it tried to evaluate my formula here.
And and it couldn't.
And when it evaluated the formula it couldn't find the actual value of y and x.
If you're trying to get help from someone else and you're, and you're, and you're kind of trying to debug your function together, okay?
The debug function doesn't really work well in the static format like this, but I'll show, I'll just show you that, but But, basically I could debug the l m, so you can debug any function, doesn't matter if you wrote it or not.
So I can debug the l m function, and now when I call l m y fill the x it you get this debugging in and I'll give you the the expression that you called.
And then you get this little prompt at the bottom here the browse so now you're in what's called the browser.
And the browser is just like your r workspace, actually.
you, you can think of it like a work space embedded within a work space.
Are, sorry, so the environment of that workspace in the browser is your function environment.
So the things that are in your function are what are in your environment.
So at, at the very top of this function you just actually, there's nothing in your environment except for the function arguments, right.
So I have a formula in my environment which is this y tilda x, but that's it.
So anyway so now I can well there are actually I should say there are other arguments so l'm too which are default values.
So here what I do is I press n for next and it runs the first line.
When I hit n and then enter and it runs the first line.
I just keep hitting n, n, n, so I run, and I just execute each line until I get to the line where the error occurs.
So when you get to the line where the error occurs.
But, at least you'll know where that error occurred, okay?
So and further more, suppose you want you can debug functions within the debugger, right?
So this match.call function I just kind of stepped right over it but I could have gone into this function by calling debug on match.call before executing it and then when this got executed I'd be in the third level of the browser.
So so you can, you can, you can call the debug function on functions.
The recover function, so the you can set the recover to be this kind of error handler by using the options function.
So now I'm going to what I'm trying to do is I'm going to read that csv some file that doesn't exist.
Okay, and then you get an error and you get the error message, cannot open the connection.
And now bu, but instead of getting my console back, I get a little menu here.
And this menu is the function call stack, okay.
So it's the same thing that you would get back, if you called trace back after the error.
Obviously you couldn't find the file, and that's where the error occurred, okay?
So the error occurred at the third level in the function call stacks, so what you can do, is you can press a number one, two, three and then you can kind of browse the environment of that function.
So if I want to see okay, what was the read, what was going on in read.csv, I can just press one here, and then it would show me kind of the environment of the read.csv.
And, and then I can break out of that and look at the environment for read.table, and et cetera.
And so you can, if you have a very long function call stack, you can kind of jump back and forth to see what was going on at each, at each function call.
To to try out a pinpoint kind of where the problem occurs.
So so just to summarize really quickly there's, there are basically three main indications of some sort of problem or condition.
There's the message warning error and of the three only the error will stop execution of the function.
When you're analyzing a function that has and you think has a problem make sure you can reproduce that problem.
And then you make sure you can articulate how what do your expectations and how'd and what the output are that and how the output differs from what you were expecting or I'd like to say what you are expecting.
And so that the, the interactive tools trace back, debug, browser, trace, and recover can be used.
And it's, and the keyword actually here is interactive.
You can kind of do things on the console.
And of course the debugging tools are not a substitute for thinking.
And so you should always think about writing your code before, you know, just throwing it to the wind and hoping the debugger will catch it.
This video is about the most important function in all R, the str function.
This function is really handy.
I use it all the time.
And you can use it in all kinds of situations just to help you out, to look at R objects.
So it's a very simple diagnostic function.
You can use summary which will often be very useful.
It's partic, particularly well suited for compactly displaying large lists which may contain nested lists.
And also and, and its goal is to produce roughly one line of output per basic object.
For example so if you give it a simple object like a vector, it'll give you one line of output backup.
And so the basic goal of str is to answer the question, what's in this object?
I'm going to start up R here and I'm going to just give a little demonstration of how the str function can work.
So here, you can apply str to itself and see it's a function that takes an object.
So, so you can apply str to other functions.
So let's say I want to know what the lm function does.
So here, what it gives you it gives you the, the function arguments for the lm function.
Let's say I'm going to generate some normal random variables here, 100 of them, let's say mean two variant, and standard deviation four.
So you get the mean, median that is 25th, 75th percentiles and the min and the max.
So that gives you a rough sense of kind of what the range is and how it varies.
You can also call str on x and it will give you a little bit more information.
So it'll give you a one line output.
It tells you that x is a numeric vector.
And then, and it'll give you the first five numbers in this vector.
So you can get a sense of kind of what the data looked like.
So you can apply str to other types of vectors.
So here I can create like a factor variable.
And it'll give me a one line output again.
The level, the first four of them are named 1, 2, 3 and 4.
And then here, I've said the first couple of elements of this factor are all in the, k-, all have the label, one.
You can also call summary on a factor, and you can see that the output's a little bit different.
And what this does is it, is it gives you the number of elements in each of the 40 different levels.
So that's another piece of data that's not quite as compact of output as str gives you.
So you can use str for other types of data types.
So here, I can, I can load like a data frame.
So, you know, if I look at the airquality data set, I can use the head function to look at the first six rows, or I can call str to get a little some different output.
It tells me that there's a 153 observations, so 153 rows in this data frame with, of six variables and then for each variable, it, it gives me a little output.
So it tells me that the name of the first variable is Ozone.
Variable and, and here are the first could of observations.
You can see there are some NAs there, so that's useful to know.
The second variable is called Solar.R, and it's also an integer, and you can see the, the first couple of values.
So, the Str output here is very useful for kind of just getting a quick examination of data that you might have in R and what the structure of different R objects is.
See, it will give me a little bit more information.
It'll say that it's a, it's a two-dimensional array.
That it's got 10 rows and 10 columns.
So that's going to be the first column that you're seeing there.
The last thing I'll do here is create a little list by using the split function and see how str can look at the list and give a compact summary of it.
So, I'm just going to take this air quality data frame And split it by the month.
So here I go to airquality, going to split it by the month variable.
So now if I call str on S you'll see, well there's a little bit of output that flies by.
You see now this is a list, that contains five different data frames where each data frame corresponds to the data for a given month.
And you'll see for June, here, there's 30 observations on six variables again, same six variables, of course.
And that's what the data look like there.
And then for July, the data are here.
So you can see the you can have a representation of this split list that's kind of, that's not as compact as it was before but it's about as compact as you can make it and str will provide a very nice summary.
You can take a quick look at the data.
See if there's missing values and get a sense of what to do next.
So that's the str function.
I'll, I'll repeat again, I think it's the most useful function in all of R and you can use it in all cases.
I encourage you to use it anytime you have an R object and, you don't know what's there.
I'm going to talk about simulation in this lecture.
Simulation's a very important topic for statistics and for a number of other applications, so I just want to introduce some of the functions in R that can be useful for doing simulation.
So, there are a couple of functions that are available for simulating numbers or variables from given probability distributions, probably the most important of which is the normal distribution.
And so we can generate variates from the normal distribution by specifying a mean and a standard deviation for that distribution and then calling the rnorm function.
So the rnorm function will simulate normal random variables that from a distribution has a given mean and standard deviation.
So the, there's a cor, there are corresponding functions for the R, for the normal distribution that can be used to evaluate the probability density, to evaluate the cumulative distribution function and for also for evaluating the quantile function.
So, another function for generating random variables is the rpoirs function or the, which generates Poisson random variables from a Poisson distribution with a given rate.
And so, so there are number of functions for generating random variables from the, from kind of the standard probability distributions.
So, probability distribution functions ha, there are basically four functions associated with them.
And so for any given distribution like the normal distribution there will be a function that starts with the d, a function that starts with an r, a p, and a q.
So there'll be four different functions for each distribution.
The rnorm function is for generating the, is for random number generation.
There's a dnorm function, which evaluates the density of the probability dist distribution for given mean and standard deviation.
There's the pnorm function, which evaluates the cumulative distribution.
So every distribution has these four types of functions.
So for the gamma distribution, there'll be a dgamma, an rgamma, pgamma, and a qgamma function.
And for the Poisson distribution there's the rpoise dpoise ppoise, and qpoise functions.
So working with the normal distribution re, requires these four functions.
So I mentioned there's dnorm, pnorm, qnorm, and, and rnorm, and you can see they each take a number of different parameters.
All the functions have required that you specify the mean and the standard deviation, because that's what specifies the actual probability distribution.
If you do not specify them, then the default values are a distribution, a standard normal distribution, which has mean zero and standard deviation one.
For the dnorm function the, you wa you can evaluate the density.
Most of the time, when you evaluate the density function for a normal distribution, you're going to want to use the log of that value.
But the default is false.
For the pnorm function and the qnorm function there's also an option to evaluate it on a log scale.
So the lower tail, which is the default, is the kind, if you think of it, if you look at the probability distribution it's the part that goes to the left.
Then you want to say lower tail equals false, and that will evaluate the upper tail of the distribution.
And finally for rnorm, there's only two parameters, mean and standard deviation, and an n, which is the number of random variables that you want to generate.
So if n is 100, you'll get a vector of 100 numbers that are drawn from the, from the normal distribution.
So just to be more explicit, if phi is the cumulative distribution function for the standard normal distribution, then pnorm is equal then to phi and qnorm is equal then to the inverse of phi.
You can just rnorm and pass in an integer, which is the number of variables you want to generate.
And you can see that the vector that's produced will be random, normal numbers which have mean zero and standard deviation one.
If I wanted to generate a vector that had mean 20 and standard deviation two, I, I just need to specify that explicitly in my call to rnorm.
So here, this vector has a, is, are, ten random normal vi, sorry, normal random variables and their mean is roughly 20 and their stand deviation is two.
So when you, any time you simulate random numbers wi, from any distribution for any purpose, it's very important that you set the random number generator seed.
So, what's important to know that on computers when you generate random numbers, the numbers are not actually random but they appear random and that's the important thing.
And so here I'm setting the seed to be one.
So the seed can be any integer you want.
You just pass in an integer, and that's the seed.
If I generate another five, you'll see that the vector is totally different, because it's another random sample of five.
However if I reset the seed to be one, and I draw five again, you'll see that they're exactly the same as the first five that I drew.
So anytime you, so when you set the seed it kind of sets the, the sequence of random variable that's just going to occur.
And if you reset the seed, you kind of set the sequence to go back to where you started, and then it will continue to kind of generate random variables from there.
so, this is important because it allows for you to reproduce random numbers that you generate.
Now that might sound strange, because why would you want to, to re, generate the same random numbers twice?
But in many applications you do want to generate the same random numbers twice so that people can reproduce what you've done.
And particular if there are some errors or problems in what you've done, you want to be able to get, just to kind of go back to the exact situation that produced those problems.
So whenever you do a simulation, you always want to set the random number c, so that you can go back and get the same results.
So I've demonstrated how to generate normal random variables, but of course you can generate random variables for other probability distributions.
And and so of course Poisson data are going to be integer.
And then here I'm generating ten random variables Poisson random variables with a, with a rate of 20.
And so, so for the Poisson distribution, the mean is going to be equal to the rate.
So you can see that roughly in each of these three cases, the mean is roughly equal to the rate that I specified.
I could also evaluate the cumulative distribution function for the Poisson distribution.
So here I'm in this first example I want to know what is the probability that a Poisson random variable is less than or equal to two if the rate is two.
If I wanted to know what's the probability that, that a Poisson random variable with rate two is less than four, less than or equal to four.
And here I can see the probability that a Poisson random variable is less than six.
So the cumulative distribution allows you to, to evaluate these probabilities.
The profiler in R is a really handy tool for when you're developing larger programs or, or doing really big data analyses.
and, and you're basically, essentially running R code that's taking a lot of time, or longer than, you know, than you want to wait.
And of course that's all relative depending on kind of what you're working on and what, maybe there are some other things that you can do in, while you're running a program.
But if something's taking a long time the profiler is a really handy tool to figure out exactly why it's taking so much time and how to, and to suggest kind of strategies for fixing your problem.
So I'm going to talk a little bit about using the R profiler and our, and, and kind of talking about when you might need to use it.
So, the first question you want to ask yourself is, you know, is your code actually running slowly?
And sometimes you can solve this problem by just you know, running your program then going and doing something else.
But sometimes that's not an option and you need your program to really run quickly.
And so profiling is a general, is a systematic way to examine how much time is being spent in various parts of your program.
But then sometimes these pieces get embedded in a much larger program.
And then your one little piece, which was running great when you were running it, is kind of slowing down everything else because it's being run ten thousand times.
And so now you need to make it a lot faster because it's being iterated over a lot.
So in general when it comes to optimizing your code, the, the general rule is that you shouldn't do it.
And what I mean by that is that you shouldn't think about it at first.
It should and, the first thing that you, you should think about, is is that, is kind of how, how to get the code to run, how to make it readable, how to make sure that other people can understand what you're doing.
And because, and one of the reasons is that it's often difficult to understand, where exactly your program is spending all of it's time.
And in order for you to speed up your program, you need to be able to know where it's spending it's time.
And so this can't be done without any kind of, it's difficult to do this, I should say, without a formal performance analysis or profiling.
and, and then the famous phrase is, you know, premature optimization is the root of all evil.
If you try to optimize first the chances are that you'll introduce bugs before you even have a, get a chance to kind of get things working in the first place.
Once you've decided that you want to optimize your code, though, you should, you know, act like a scientist.
Just like you would in any other context, you should collect some data.
So, the first tool I'm going to talk about is actually not the profiler it's a very simple function called system.time in R.
And what system.time does is it takes an arbitrary R expression and evaluates that expression and then tells you the amount of time it took to evaluate that expression.
Now this expression could be very simple like a single function call, or could be very complicated if it have to be wrapped in curly braces.
So, it could actually be a very long expression if you wanted to be.
So, the basic idea is that you take this expression and it gives you the time in seconds, that was, that was needed to execute the expression.
If there's an error, you know, in the code while the expression's being evaluated, then you'll get the time until the error occured.
now, there's two very important notions of time when you're exe, executing expression on, on the computer.
The first is called the user time and this is the amount of time that's charged to the CPU or CPUs for this, for running this expression.
Okay, so this is the kind of time the computer experiences, roughly speaking.
And so the two different notions of time can kind of different importance depending on what you care about.
So usually the user time and the elapsed time are relatively close, because the amount of time that the computer spends to do using, you know, executing your fu, your function or expression, is roughly equal to the amount of time you spend waiting for it, right.
however, there are times when the elapsed time will be greater than the user time, and there will be times when the elapsed time is smaller than the user time.
And, and so the CPU doesn't actually spend a lot of time working on your code, it may be spending a lot of time on other things that are going on in the background.
If the elapsed time is smaller than the user time this most commonly occurs if your machine has multiple cores or processor and is capab, and is capable of exploiting them.
So this, so most of the computers these days, have at least two, or four cores or multi core machines and so this is a very common situation.
However, it's not always that the compute, the program that you're running will be all to kind of exploit the use of multiple cores.
In particular, R, the basic R program does not use multiple cores as of yet.
So if you're doing something like regression, or a lot, a lot of these prediction routines or, or matrix computations, these all involve linear algebra libraries.
And many of these libraries have been optimized to use multiple cores.
And so they're, they're called multi-threaded BLAS libraries or, for the basic linear algebra standard libraries, subroutines libraries and on the MAC sometimes called vecLib or Accelerate.
There are more general libraries like ATLAS for AMD machines, there's ACML or ACML, and for INTEL machines there's MKL.
There's also parallel processing libraries, for example the parallel package which doesn't use, which can use multiple cores but it can also use multiple computers.
And so this will, will lead to, potentially lead to a program that takes more user time than it does elapse time, and I'll give an example of how this will work.
So, one example when elapsed time will be bigger than the user time, is if you read something from the web.
So here I'm just using the read lines function to read a web page off off, off, off a remote server.
And you can see the elapsed time is about 0.4 seconds but the user time is about 0.004 seconds.
And the second example, this is where the elapsed time is less than the user time, I've created a simple function which creates which creates a hilbert type matrix.
And I calculate the singular value decomposition of this ma, matrix with the svd.
And so you can see that the user time was roughly almost double of the elapsed time.
So the elapsed time was about 0.7 seconds and the user time was about 1.6 seconds.
And the pa, and the reason is because the the underlying linear algebra library split the computation across the two cores.
And so you can think about of it is, but basically the elapsed time was multiplied times two, because it was being executed on two different CPUs.
So the amount of time that the user, the CPU spent working on your program was actually more than the amount of time that you spent waiting for it to come back.
And you can wrap that whole thing in curly braces and call system time around it.
And you can see that here this is a very simple expression, it's not multi threaded, there's no network activity, and so the user's time and the elapsed time are basically the same.
Now the part of problem with system time is that it assumes that you know where to look.
Assumes that you know where the problem is and that you can call system time on a given expression.
And so, this may be useful for smaller programs for less complicated programs where you have a very good sense of, kind of where the bottlenecks are.
What if you don't know where the problems might be and where to start looking.
And it, an Rprof is used to start the profiler in R.
One could note is that R must be compiled with profiler support and so it's not something that's going to built in all cases.
However, and I'd say 99.9% of the cases this is the true, this is the truth, so mu, you will only, R will only be compiled without profiler support in some very cer, special circumstances.
And so I wouldn't, the chances are your version of R use, it can use the profiler.
And so the summary Rprof function is very important.
It's important to realize that you should not use the system time function and the R Profiler function together.
So you should always use one or the other and not both.
So the Rprof function keeps track, basically what it does is it keeps track of the function call stack, at regularly sampled intervals, right?
And in general, because it will never sample the function call stack.
And in general if your program is runs very quickly, the profiler is not useful.
Well, and but of course that if your program runs very quickly, you probably wouldn't think to run the profiler in the first place.
So it's usually not a problem.
But you really need to use the profiler in situations where your code is taking much longer on the order, at least on the order of seconds.
So here's just a quick example of the raw output that comes from the profiler.
Now you generally speaking you will not ever use this output, but I thought it might be interesting to look at what's going on.
And, and what happens here, as you can see, that each line of this output is the function call stack.
and, and at the very left is kind of the bottom, so to speak.
And the, so the very right, you can see that lm was called, and lm called eval, and eval called eval.
And eval called model frame, which called model frame default, which called eval again and eval in the list.
As you go further in the evaluation you can see that that the function calls that changes, so at the very bottom you can see that lm called lm.fit.
And if you're not familiar with the LM function, lm.fit is really the workhorse of this function, it does all the really kind of computation.
And so, you, you wouldn't suspect that it would spend a reasonable amount of time in the lm.fit function.
So, that kind of raw output is not particularly easy to read, so we use the sumaryRprof function to tabulate the Rprof or the output and calculate how much is spent in which function.
So, the idea is that once you see that the function call stack, you know that the, that each line of the con, the function call stack is separated out by 0.02 seconds.
So, given that you can calculate how many seconds are spent in each of the functions, because if it appears in the function call stack then you're actually spend, then you must be spending some time in it.
One is called by.total, which divides the time spent in each function by a total, by the total run time.
And by.self, which does the same thing, but at first subtracts out time spent in functions above in the call stack.
So, its important to realize that the two separate concepts here of kind of, by.total and by self.
The basic idea is that by total, I, I mean, the, the normalizing by the total amount of time spent in a function gives you basically, how much time was be, was spent that that how many basically, how many times that function appeared in the calls, in the kind of printout here.
So chances are if your function is spending a lot of time doing something, it's spending a lot of time in those helper functions which is just being called by this top function to kind of do, to do all the work.
And so often it's not very interesting to know how much is time is spent in these top level functions, because that's not where the, where the real, where the real work occurs.
All right, so you really want to know kind of how much time is spent in the top level function, but subtracting out all the low, the functions that it calls right?
So it turns out that it spends a lot of time in the top level function, but even after you subtract out all of the lower level functions, then that has something that's interesting.
But most of the time you will notice that when you subtract out all the lower level functions that get, that get called there's very little time it spends in the top level function.
And because all the work and all the kind of the computations is being done at the lower level function, so that's, that's kind of where you want to focus your efforts.
So it gives you I think a more accurate picture of, you know, which functions are really, are truly taking up the most amount of time and which functions that you might want to target for optimization, later on.
So the total time was 7.41 seconds for this run.
Of course, because lm was the top level function.
And so that was three and a half seconds, so about half of the time in that function.
Now, I think a more useful output is the by.self output which kind of subtracts out any lower level function calls from, so and calculates the amount of time spent in a, it's kind of truly spent in a given function.
And here you can see that lm.fit is the clear winner, because that's really where all the computation occurs.
The next function that takes a lot of time ap, ap, apparently, or 11% of the time is the as.list function, for the as.list.data.frame method.
It's not immediately clear why so much time is being spent in this, but, spent in this function, but it's maybe something you want to investigate.
for, and so you can kind of go down the list here and see how much time is being spent in various functions.
And then you'll see a lot of these functions don't directly pertain to computation or kind of core computation, but they're really more kind of pertain to data, formatting of the data and things like that.
The last part of the summaryRprof output is just the sample interval, so you can see how, what, what time interval the sampling took place for printing out the function call stack.
And the sampling time, which is just the total amount of time that the expression took to run.
This is the same kind of, this is so this is the, I think equivalent to the kind of elapse time in the system.time function.
And because they're not really core to the kind of, the real computation that you're working on.
So the profiler can be really useful, I think for highlighting these kinds of situations and, and often finding things that you are kind of unexpected.
The summary Rprof function summarizes the output from Rprof and gives you the percent time spent in in each functions.
And I think the by.self kind of normalization is the most useful for kind of highlighting bottlenecks in your, in your code.
One of the, one of the implications of using the profiler is that it's useful to break your code into functions.
So rather than have one massive function, it's useful to break your code into kind of logical pieces of different functions.
And so the profiler can use this information to tell you where the time is being spent.
In the function call stack to tell you kind of where the, where the code is spending the most amount of time.
So that's another little strategy that's kind of that's can be useful when you're profiling your R code.
All you will know is that some time is spent there, but you won't know any details about that.
What do you do when you just can't figure something out?
For zombies, it's pretty simple.
They can just keep bashing their brains against the wall.
But living brains are a lot more complex.
It turns out, though, that if you understand just a little bit of some of the basics about how your brain works, you can learn more easily and be less frustrated.
Researchers have found that we have two fundamentally different modes of thinking.
Here, I'll call them the Focused and the Diffuse modes.
It's when you concentrate intently on something you're trying to learn or to understand.
But we're not so familiar with diffuse thinking.
Turns out that this more relaxed thinking style is related to a set of neural resting states.
We're going to use an analogy of the game of pinball to help us understand these two thinking modes.
Incidentally, both metaphor and analogy are really helpful when you're trying to learn something new.
If you remember, a pinball game works by, you pull back on the plunger, release it, and a ball goes boinking out, bouncing around on the rubber bumpers, and that's how you get points.
So, here's your brain, with the ears right here, and the eyes looking upwards.
And we can lay that pinball machine right down inside it.
There's the analogy for the focused mode.
It represents a familiar thought pattern.
Maybe involving something simple like adding some numbers, or more advanced ideas like literary criticism or calculating electromagnetic flows.
You think a thought, boom, it takes off, moves smoothly along.
And then, as it's bouncing around on the bumpers, you're able to figure out the problem you're trying to solve, or.
So look at how that thought moves smoothly around on the fuzzy underlying orange neural pathway.
In some sense it's as if it's traveling along a familiar, nicely paved road.
But what if the problem you're working on needs new ideas or approaches?
Concepts you haven't thought of before.
That's symbolized here by this neural pattern towards the bottom of the pinball machine area.
But if you haven't thought that thought before, you don't even know how that pattern feels or where it is.
So how are you going to develop that new thought in the first place?
Not only do you not know where the pattern is or what the pattern looks like, but see all the rubber bumpers that are blocking your access whatever direction you do decide to move in?
To get to this new thought pattern, you need a different way of thinking.
And that's represented here, by the diffuse mode.
It could travel a long way before being interrupted by hitting a bumper.
In this diffuse mode of thinking, you can look at things broadly from a very different, big-picture perspective.
You can make new neural connections traveling along new pathways.
You can't focus in as tightly as you often need to, to finalize any kind of problem solving.
But you can at least get to the initial place you need to be in to home in on a solution.
Now as far as neuroscientists know right now, you're either in the focused mode or the diffuse mode of thinking.
It seems you can't be in both thinking modes at the same time.
It's kind of like a coin.
We can see either one side, or the other side of the coin.
But not both sides at the same time.
Being in one mode seems to limit your access to the other mode's way of thinking.
In our next video we're going to see how some extraordinary people access their diffuse ways of thinking to do great things.
Perhaps the greatest gift that our brains give us is the ability to learn new things every day.
On my way here, I thought about the journey that will take us to the last day of the course, and how much we will learn along the way.
Our goal is to give you a better understanding of how we learn, so that your brain becomes a better learner.
These insights are based on solid research from neuroscience, from cognitive psychology, and also from dozens of leading instructors and practitioners in difficult-to-learn subjects.
Whether you're a novice or an expert, you will find great new ways to improve your skills and techniques for learning, especially related to math and science.
This course is meant to help you reframe how you think about learning, to help reduce your frustration, and increase your understanding.
We approach things a little differently.
You're not expected to have an in-depth background in any particular subject.
Instead, you're expected to take these ideas and apply them to whatever subject you're trying to learn or improve in, to help you learn more deeply, effectively, and with less frustration.
You'll hear experts from a variety of different disciplines talking about their best tips for learning more effectively.
You can benefit from these ideas whether you're struggling in high school or soaring through math and science at graduate levels at a university.
I'm a co-director of a Science and Learning Center that is sponsored by the National Science Foundation based here in La Hoya.
In recent years, we've made great strides from research and discovering how to learn most effectively.
Finding a way to simply and effectively share these ideas with you has been a big undertaking, but we feel it's well worth doing.
You will see that many of these ideas, although simple, are incredibly powerful.
And along the way, we will also learn a lot in the process of teaching you.
You'll see how you can fool yourself about whether you actually know the material.
You'll discover new ways to hold your focus and embed the material more deeply and powerfully in your mind, and you'll learn to condense key ideas you're learning about, so you can grasp them more easily.
Master the simple practical approaches outlined here, including simple tips to help prevent procrastination, and you'll be able to learn more effectively and with less frustration.
This course is meant to enrich both your learning and your life.
You'll be able to get what you want from this material.
So, welcome to the course and happy learning
So, let's take a look at some famous people from history who used their different thinking modes to help them with their problem solving.
He was the very definition of a wild and crazy guy.
Dalí used to have an interesting technique to help him come up with his fantastically creative Surrealist paintings.
He'd relax in a chair and let his mind go free, often still vaguely thinking about what he had previously been focusing on.
Now, you might think, well, you know that's okay for an artist.
But what does it have to do with more scientific or mathematical kinds of thinking?
Well, if you look down here, this guy was Thomas Edison, one of the most brilliant inventors ever.
According to legend, what Edison used to do was he'd sit and relax in his chair, holding ball bearings in his hand.
Although, it would often noodle back in a much more relaxed way to what he'd been focusing on previously.
When Edison would fall asleep, the ball bearings would drop and clatter to the ground just as with Dalí, and it would wake Edison up, and off he'd go with his ideas from the diffuse mode ready to take them into the focus mode and build on them.
So, the bottom line is, when you're learning something new, especially something that's a little more difficult, your mind needs to be able to go back and forth between the two different learning modes.
You might think of it as a bit analogous to building your strength by lifting weights.
You would never plan to compete in a weightlifting competition by waiting until the very day before a meet and then spending the entire day working out like a fiend.
I mean, it just doesn't happen that way.
To gain muscular structure, you need to do a little work every day, gradually allowing your muscles to grow.
Similarly, to build neural structure, you need to do a little work every day, gradually allowing yourself to grow a neuro-scaffold to hang your thinking on a little bit, every day, and that's the trick.
In summary then, we learned that analogies provide powerful techniques for learning.
We learned about how the brain's two different thinking modes focused and diffuse, each helps us learn but in very different ways.
Finally, we learned that learning something difficult can take time.
Your brain needs to alternate it's ways of learning as it grapples with and assimilates the new material.
Everybody has some issues with procrastination.
Because if you're working on something, it means you're not working, on a lot of other things.
But some people have more issues with procrastination than others.
In this video, we're going to give you a little insight into procrastination.
Why it arises, and a powerful little tool to help you address it.
When you look at something that you really rather not do, it seems that you activate the areas of your brain associated with pain.
Your brain, naturally enough, looks for a way to stop that negative stimulation by switching your attention to something else.
But here's the trick.
Researchers discovered that not long after people might start actually working out what they didn't like, that neurodiscomfort disappeared.
So it seems what happens when you procrastinate, is something like this.
First, you observe, and get a cue about something that causes a tiny bit of unease.
You don't like it, so to make the sensation go away you turn your attention from whatever caused that unease.
The result, you feel happier, temporarily.
But in the mean, time I'm going to let you in on a handy little mental tool.
It was invented by Francesco Cirillo, in the early 1980's.
All you need to do, is set a timer to 25 minutes, turn off all interruptions, and then focus.
That's it!
Most anybody can focus for 25 minutes.
The only last important thing is to give yourself a little reward when you're done.
A few minutes of web surfing, a cup of coffee, or a bite of chocolate, even just stretching or chatting mindlessly, allowing your brain to enjoyably change its focus for a while.
You'll find that using the Pomodoro technique is very effective.
It's a little like doing an intense 25 minute workout at a mental gym.
Give it a try.
Next, we're going to see how one very shy ten year old, changed her brain.
This week, we're going to be talking about chunks, compact packages of information that your mind can easily access.
How you can use them to improve your understanding of, and creativity with the material, and how chunks can help you do better on tests.
We will also talk about illusions of competence in learning.
We'll cover what those less effective study methods are and tell you what methods research has shown will work better to help you in your studies.
You can make your study time more valuable by interleaving, providing intelligent variety in your studies.
This week, we're going to be talking about two seemingly different ideas: procrastination and memory.
But the two topics are intimately related, why?
Because building solid council long-term memory, chunks that are easily accessible by your short term memory takes time.
It's not the kind of thing you want to be putting off until the last minute.
Then we'll move on to talking about some of the best ways to access your brain's most powerful long-term memory systems.
Hello and welcome.
Thanks for deciding to join our Business English course in the Business Communication Skills Specialization.
This is our second course in the series, Meetings.
In this course, we'll be focusing on something the whole businesses have in common, meetings.
We don't know if you love or hate meetings, but without a doubt, if you're in business, you'll have to deal with meetings.
And by taking this course, we hope that you'll become more confident because you'll know the appropriate behavior for participating in and running meetings in English.
So, let's take a look at what we'll be covering in this course.
In the first week, you'll learn about different types of meetings and what makes a successful meeting.
In week two, you'll learn about participating in and running meetings in the Language of Meetings.
In the third week, you'll learn how to give a report in a meeting and what to do at the end of a meeting, to summarize what has been decided.
In the final week, you'll look at how to write a proposal based on the decision of a meeting.
During this course, you'll also hear from business people and find out about several companies from the Seattle area.
So, are you ready?
So we've learned how to write an agenda for a meeting and how to send an email announcing the meeting.
In this lesson, we'll look at a few situations where you might need to respond to that meeting announcement.
You will learn how to respond by asking a question about the agenda.
Next you will see how to respond by saying that you can't attend the meeting.
And finally, how to write a simple email, rescheduling a meeting.
At the end of this week, you'll be able to demonstrate what you have learned by writing an email announcing a meeting.
And then by responding to another email saying you cannot attend.
So let's get started.
Welcome to calculus.
We are about to begin the course Calculus in a single variable.
Welcome to calculus.
I'm Professor Ghrist and for the next 13 weeks I'll be your calculus professor.
One of the loftiest achievements of human thought with thousands of years in the making.
Whether you are at the beginning of your studies, or whether you've come back to deepen your understanding, my course will give you a novel experience.
This course is built on the main objects of calculus, functions, limits, derivatives, and integrals, both continuous and discreet.
You'll learn how to compute with these objects, but you'll also learn what they mean.
And how they are useful in the engineering, biological, social, and physical sciences.
Are you ready?
Let's go!
You may be wondering, what do you need in order to be successful in this course?
Well, there are several things that you do not need.
Mathematics is difficult and it takes time to work through the homework assignments, to think about what you are doing.
This is a hard course and you're going to need time and perseverance to get through it.
It's assumed that you know the basics, such as algebra.
Sometimes we'll be doing some of the basic algebra off-screen and it's going to be up to you to fill those steps in.
You're going to have some background in basic geometry.
Knowing about things like curves and circles, volumes, areas of basic shapes.
We'll be reviewing things like sine, cosine and tangent, but you will need to have some prior exposure, likewise, in pre-calculus.
It's assumed that you've seen the exponential function, e to the x, and the natural logarithm, l n of x.
We'll review this a little bit, but you're going to want to make sure that it's not your first time seeing that.
And even though this is a calculus course, it is not your first calculus course.
I'm going to assume that you've seen some of the basics such as differentiation or integration of polynomials and exponential functions before.
You need to know, or at least have seen, a definition of a derivative, maybe in terms of slopes.
And it will be helpful if you've seen a definition of an integral in terms of, say, an area under a curve.
Now we're going to go through all of that material again and make your understanding deeper and clearer.
But, if it's your first time seeing this, then this might not be the course for you.
What you're going to see over the next 13 weeks.
The course is broken into five chapters.
The first chapter is on functions and beginning with a simple function, e to the x, we're going to reconsider functions from the perspective of series.
We'll learn a new asymptotic language for understanding growth.
And then, in chapter two, we'll put that language and that intuition to work by reconsidering rates of change and our notion of differentiation.
From there we'll turn in chapter three to the notion of an anti-derivitive.
Motivated by applied problems in differential equations we will build up integrals both indefinite and then definite.
In chapter 4, we'll take what we've learned about derivatives and integrals and put them to use considering applications in the physical, social, engineering and biological sciences.
Finally, in chapter five we'll revisit everything that we have done in the course, rebuilding calculus in a discrete setting.
A calculus four sequences.
Your next step should be to take the diagnostic exam and see if you remember all of those prerequisites.
Watch the lecture, and then go to the homework assignments.
One, a set of core or basic problems, and then a set of challenge problems that are optional, for those who want to go deeper.
Now, when you get to the homeworks, you may or may not encounter some difficulty.
But even better, you can go to the discussion forums.
As you complete homework assignments, move on to the next lectures and repeat.
When you get to the end of a chapter, then there will be a quiz.
You can see the schedule on the website for the course.
Eventually, when we're done with all five chapters, we'll get to the final exam and, if you make it to the end, you will be done.
It is by no means an easy path to get to the end of this course, it is a difficult subject and is only learned by means of hard work.
You are going to have to work hard and persevere to get to the end.
But I am confident that together, we can make it.
I want you to make it to the end.
Your next step should be to take the diagnostic exam, and make sure that this is the right place.
Then, start with lesson one, and move lesson by lesson.
Don't skip around a lot.
This course has a flow.
I want you to see that story.
I want you to live that story.
This course is going to be an odyssey, a long and difficult journey, but if you work hard, you'll make it to the end with something you can be really proud of.
Wander through the darkness, erasing all the light.
>> Okay stop there we have, we have another issue here which is really closely related to the thing we've been talking about which is the relationship between notes and syllables.
Here instead of talking about notes and syllables, the other responsibility that a songwriter has about phrasing and preserving the natural shape of the language, is here we have wander through the darkness, that's told the musical phrase, right?
>> Erasing all the lines, that's another musical phrase, right?
>> Okay, now with the road map that the melody is laying out is saying, idea, idea, idea.
And what the grammar is saying is, wander through the darkness one idea.
Erasing all the lines of the border and the boundaries they defined, second thing.
And so your grammar is saying, I have two independent ideas.
And yet your music now is saying, oh, hold it, let's take that second idea and slice it into two pieces and separate them, and put them each behind their own fence though they're longing to embrace.
And so you have two choices here.
Number 1, you can create one long musical phrase, wander through the darkness, erasing all the lines of the boundaries, and you can do that.
So I want you to sing it the way you've got it now first, then I want to make a little change.
>> Oh, by the way, wander through the darkness not wander through the darkness.
Anyway, try again.
>> Okay so now what I want you to do, is simply substitute for the word of, I want you to substitute all.
All the borders and the boundaries they define.
>> Wander through the darkness, erasing all the lies of the borders and the boundaries they define.
>> Wander through the darkness, erasing all the lights, all the borders and the boundaries they define.
Leave behind a trail, that paints your picture in the sky.
Your hiding in a big rain cloud, painting silently but no one stops to see you.
Leave behind a trail that paints your picture in the sky.
Welcome to module one.
First, let's look at small talk.
Now, what is small talk?
It's just short conversations about every day topics, but those short conversations can lead to longer and more important ones.
And in the working world being able to make small talk, feeling comfortable making small talk, often leads to greater professional success.
So that's why as you work on becoming a better English speaker, you want to have many, many small talk conversations.
Small talk is where conversations begin, but how do you start?
And how do you keep the conversation going?
Take a minute and think about how you begin conversations in your own language.
What kind of greetings do you use?
What do you talk about?
While every conversation is different, you can probably think of many ways they are the same.
It's the same in English.
In this video, we're going to look at examples of small talk conversations.
First, let's look at how you can introduce yourself to someone new.
And often, when you introduce yourself first, it's makes the other person feel more comfortable talking to you.
Nice to meet you, Ben.
What's next?
Make a connection and ask some questions.
This is a great event, isn't it?
What brings you here?
>> I'm here for work and you?
What kind of work do you do?
>> Now that you've made a connection, listen, listen and listen.
Here's a chance to learn a little bit more about the person.
Find out what you have in common and keep the conversation going.
Smile and keep your eyes on the person you're talking to.
What do you think about my new phone?
Hobbies, family, news, sports, just to name a few.
And remember, the more detail you add to a conversation, the easier it is to keep it going.
Don't just answer yes or no.
And as you find yourself coming to the end of a conversation, keep it going with a plan to see that person again.
Have you tried that new restaurant across the street?
So, what do you need to do to make your small talk meaningful?
Ask questions.
Be a good listener.
Show your interest and find out what you, and the other person have in common.
Small talk could be the start of a new friendship, a new job and an interesting connection.
Making small talk confidently is a key skill and one I hope you'll practice and enjoy more and more.
Welcome to lesson two.
In this video, I'll review key pronunciation skills to help you improve your fluency when you speak English.
I'll discuss word and sentence stress and intonation.
By the end of this video, you'll know which syllable to stress in a word in which words to stress in a sentence.
First, what is word stress?
In English we stress just one syllable in every word.
We say that one syllable more loudly, we say it higher and we make it last longer.
Let's look and listen to some words with two or more syllables.
Chicago, grandmother, technology.
Why is word stress so important?
Word stress is like a magic key to clear English.
As you talk to people, listen to the news, watch movies, you must listen for and practice word stress.
It will help you to understand what you hear and it will let others understand you.
In the resources for this lesson, you will find materials to practice word stress.
Use an audio dictionary to listen to each of the words and mark which syllable gets the stress.
Now let's look at the second key pronunciation skill, sentence stress.
Sentence stress gives English its rhythm and its beat.
How do we create it?
When we say a sentence, some words are strong, and others are weak.
The last word is the strongest and longest.
This combination of strong and weak words creates rhythm in each sentence.
Let's see if you can hear it.
So why were the verb, buy and the nouns, pair and jeans, stressed?
To put it simply, those are the important words, the keywords in the sentence and we always stress the important words.
We call them content words.
Try and choose the content words in the next sentences.
What about the words we don't stress?
We use them to construct our sentences, but they don't carry a lot of meaning, and we don't stress them.
We can leave them out, and our listeners will still be able to understand us.
What do you need to remember about sentence stress?
If you take them out, the sentence will make no sense.
On the other hand, we do not stress the structure words, often the little words in sentences.
So by saying the content words loudly, and make them last longer and the structure words softly and shorter, we create the rhythm of English.
Now, let's add intonation to what we've learned about word and sentence stress.
What is it?
Questions like, do you have the letter?
Did you make the call?
Rising intonation tells your listener you're asking a question and want yes or no for an answer.
Intonation is also the way your voice rises and falls when you make a statement or ask an information question.
For example, summer weather in Atlanta is hot and humid.
In rising and falling intonation, your voice rises and falls on the last important words of the sentence.
It's their time to say something or to answer your question.
Let's do a quick review of what we've learned.
First, word stress.
We stressed one syllable in every word.
Second, we looked at sentence stress.
In every sentence we stress the content words, but not the structure words.
And last, we discuss rising and falling intonation.
The best way to improve these skills is to listen and practice.
In this lesson, you will work on something called an elevator speech.
And after this lesson, you will create, deliver and post your own personal elevator speech.
In the professional world, networking or getting to know others in your field is very important.
At events like conferences and parties or in every day chance encounters, you will have the opportunity to network and create important personal connections.
Let's look at what can happen when you meet somebody important and have a great opportunity to make a connection.
And finally, I can reach you.
Nice to see you.
So, what is the best way to make the connection?
In today's business world, the elevator speech has become the way to both introduce yourself and make the other person want to talk more with you.
We call them elevator speeches, because they are short like an elevator ride.
Yes, they can take place in an elevator.
But in reality, they happen everywhere.
So what exactly should an Elevator Speech include?
Like any successful speech, it should tell a story, your story.
It gives your listeners facts about who you are and makes you someone they want to know.
It tells them how you are important to them.
At the end of your elevator speech, the person you're talking to should want to know more about you.
Finally, end your elevator speech by telling your listener, you will contact them soon to continue the conversation.
What else should you remember when making your elevator speech?
Like every face to face encounter, how you sound and how you look is even more important than what you say.
What will help you sound and look good?
In addition to rhythm and intonation, you want to think about and practice speed and volume.
How fast should you speak?
Speak slowly, so your listeners understand you.
When you speak slowly, you show that you are aware of your listeners and are trying hard to connect with them.
Second, you pauses or short stops to highlight important information and help your listeners to hear key points.
As you speak louder and softer to emphasize important words or phrases it helps if your listeners understand you and connect to what you're saying.
Lastly, what else makes you look good?
Your body's nonverbal way of communicating.
Use it to let listeners know that you are confident, enthusiastic, friendly, knowledgeable and organized.
Although body language is different in different cultures, some is universal.
When you smile and look friendly, your listeners know how you feel.
Just like your voice, your face shows your energy.
Add hand gestures to emphasize important points and look natural to your listeners.
Use your body language to present your best self, friendly, enthusiastic and confident.
In this lesson, we identified what an elevator speech is and why we make them?
Let's take a minute and review by looking at a successful elevator speech.
Hello, Mrs.
I'm so happy to meet you.
My name is Roosevelt and I've been working in the accounting department for about two years.
I've studied new software applications and I think they will be great for us.
I would love to introduce them to you.
Thanks so much.
It told a story and made us want to learn more.
It led to a future encounter.
It was easy to understand and it was friendly, energetic and natural.
Before you make your own elevator speech, find one you really like on YouTube and watch it a few times.
Finally, for your last assignment in this module, create your own elevator speech.
Record a one to two minute video role play of an elevator speech and introduce yourself to the class.
Catch our attention, give us information about yourself and make us want to get to know you better.
Before you submit your speech, practice, practice, practice.
Do it in front of a mirror.
Do it for a family member or a friend.
Record and listen to it.
Put your best forward and have fun.
I look forward to seeing your elevator speech.
Welcome to Module 2 of Speak English Professionally in person, online, and on the phone.
In Lesson 1, we'll look at the basics of meeting online.
In Lesson Two, we'll identify and classify expressions, vocabulary, and body language to use during online group discussions.
And, in Lesson 3, we'll practice applying these group discussion language in various situations.
In this lesson, I'm going to introduce video conferencing, what it is, how we use it, when we use it, and why we use it.
You'll have a chance to explore the many video conferencing websites and apps found online.
At the end of this lesson, you'll set up your own online video conferencing account.
It is communication through the Internet, which lets people at different places come together for a meeting.
It can involve just two people getting together from their offices, or many people in many different places connecting.
Whether or not you already conference online, you know that today's work world is becoming more and more global.
Professionals like you, from many different places, are working together and building relationships, even when they cannot physically be together.
They are meeting, talking, and sharing information by using online conferencing tools.
In fact, some Georgia Tech students are interviewed through a video conference before enrolling.
During a video conference, participants can also share PowerPoint presentations, videos, and documents.
Additionally, the meetings can be recorded so that participants have a permanent record for their use.
You'll need to plan what you'll say and practice.
Your voice can sound different when you use a microphone or be more difficult to understand, so it's very important to pay extra attention to the pronunciation skills we looked at in Module 1.
Let's quickly review some of the important points.
Practice speaking slowly and at a steady volume.
When we speak fast, it's very hard to understand us, especially online, and if people can't hear you, it doesn't matter what you say.
Next, practice word stress, check the pronunciation of key words you'll be using.
If you mispronounce important words, your listeners will not understand your message.
Finally, what do you need to do to speak rhythmically?
As you practice, remember the rhythm of English.
Stress the important words in your sentences, say the structure words softer and shorter.
This will make you easy to understand.
Once you've practiced what you plan to say, think about the people you'll be meeting with and what they might need.
During the meeting, respect the other participants and watch how long you're speaking.
Be sure everyone has a turn to speak, and when you're not talking, remember to turn off your microphone.
Never forget that you're on camera, and everyone can see what you're doing, even if you're not speaking.
Your face is what people will see, so you want to look engaged and friendly, both while you're speaking and while you're listening.
Now, what video conferencing sites should you use?
I'm only going to mention free sites, some or all of which you may already be familiar with.
These include Google Hangouts, Skype for Business, Fuze, WebEx, GoToMeeting, and Meeting Burner.
Before you move on, take some time to explore some of the sites and then choose one and set up an account.
If you have an account with one tool already, how about trying a different one to explore other services?
To recap, online video conferencing is an important tool for today's working professionals.
It makes it possible to meet and share information easily around the world, and it requires special attention to pronunciation skills to guarantee that you'll be understood and your online meetings will be the success that you want them to be.
Online video conferencing blends 21st Century technology with your experience and English language skills, and creates opportunities for your success.
So, keep in mind everything we've talked about in your next video conference.
This lesson will be about the language to use within a group discussion.
But before we begin, I want to take a poll.
What online video conferencing site did you sign up with, after our last session?
And my second question, why that tool?
Whichever one you chose, I hope you'll become familiar with it enough to do a video conference through it by the end of this module.
Now, let's turn back to this lesson.
Whether your group discussion takes place in person or online, you will use similar vocabulary, so the expressions you learn in this lesson will be very useful.
Let's start with the language we use for agreeing and disagreeing.
In the first conversation, the meeting begins and everyone agrees with the agenda.
Does everyone agree with our plan?
But when we want our need to disagree, we can feel less comfortable.
Fortunately, there are many ways to disagree and still remain polite and positive.
Let's now look at how to clarify information.
During a discussion, it's very important to be sure that you are following the conversation.
Can you hear everyone?
Do you understand what the others are saying and what they mean?
When you don't, you can use one of these expressions to let speakers know you would like them to clarify by repeating or explaining something that they have just said to you, so that you better understand it.
Could you say it again?
>> Excuse me, could you tell me what that means?
While you might feel uncomfortable and not want to ask for clarification, it's a normal part of discussion.
It's better to ask, than to let discussion continue without understanding.
Finally, you can let the other person know by saying you understand, or actually restating the information.
>> Thank you, it's a lot clearer to me now.
Restating is a great way to confirm that everyone in the discussion understands.
You can use these types of expressions.
>> I see, our first step is to look at how much money we have and how much money we can spend.
Let's listen to ways you can let others know that you have something to say.
Can I say something here?
>> Sorry to interrupt, but I'd like to say something here.
>> Can you give me your thoughts on this?
Lastly, it is important to show that you are interested in what the other person is saying.
Now, as the others add their opinions and more information, you can continue to show your interest with a friendly face and positive comments like, that's interesting.
These help the other people in the group know that you are following the discussion and that you are interested.
By including these expressions, you can agree, disagree, clarify, restate, interrupt, include everyone and show interest.
Practice these expressions and you'll be on your way to fluent participation in group discussions.
Welcome to Module Three of Speak English Professionally.
Wait a minute.
I've got to see who this is.
And you probably have a phone like this, too.
While you may not use your phones for talking as much as you do for texting, surfing the web, and listening to music, phone conversations still play a vital role in today's work world.
So in this module, Powerful Phone Talk, we'll review, practice and acquire language and pronunciation skills to speak English clearly on the phone.
And because you'll be speaking to people from different cultures, we'll look at phone practices to improve understanding and avoid misunderstandings.
In lesson two you will practice and develop your pronunciation of numbers and the modals can and can't.
This will make it easier for you to speak on the phone and make your speech easier to understand.
Finally in lesson three you will devise and practice question and answers for a variety of phone conversations in different settings and situations.
When you begin a phone conversation with someone new, it's important to state your name, who you are, and the purpose for the call.
If you already know the person, just your name and purpose will do.
The same introduction is appropriate if you have to leave a message.
I work at ABC Company, and I'm calling about my order.
>> Now that you've started the conversation, what do you do to continue?
I work at ABC company and I'm calling about my order.
Could you give me more information about this?
Do you have a minute to review this?
Would you mind going over this with me?
>> And you can use these expressions to respond if the other speaker asks you for information or has a request for you.
First, let's look at the different ways to say yes.
Certainly, what would you like to know?
>> Now there may be situations when you need to reject a request or you don't have an answer for the request, so here's some polite ways to say no.
Sorry, I'm busy right now, but will be happy to call you back.
You've called someone new.
You've made the initial contact, you've asked for information or responded to requests, and everything is going smoothly.
Then, suddenly, you can't understand what the person is saying.
It might be a problem with the phone or connection.
Or there might be too much noise around you, maybe it's a language problem, or because you can't see the other person.
Whatever the reason an easy conversation has now become a difficult one.
But don't panic and don't hang up.
Likewise, the other speaker might ask you to repeat or clarify.
As I mentioned in module two, when you clarify, you make something clear or easier to understand.
So don't be shy to do so.
Here's what you can say.
I didn't catch what you just said.
I'm not sure I understand.
Use a professional, friendly expression that let's the other person know you've enjoyed the call and want to continue the relationship.
Efficient, productive phone calls today involve clear introductions and exchange of information, no misunderstandings, and friendly closings.
Put all of the this together and your business phone calls with have the potential to contribute to your success.
In this lesson, we'll practice the language and pronunciation skills that we learned in our previous lessons and apply them to a variety of specific scenarios or situations that you might actually have through phone roleplay.
As I mentioned in a previous lesson, we use phones today in many different ways than in the past and may actually speak on them less and less.
How much do you talk on the phone today for business?
Whether you talk less than an hour or for several hours throughout the day, the phone conversation is still a very valuable business tool.
Unlike texting or emailing, it is direct and personal.
Often, it can be the fastest way to answer questions, make a request, or solve a problem.
In addition, phone calls tell your listener that you're really interested in them.
Also, many people prefer to discuss more serious issues or more personal ones on the phone.
There's another part of phone conversations that make them especially valuable, and that's the message you give your listener just with the tone of your voice.
Like body language which we discussed in modules one and two, tone of voice gives lots of information about you to your listener.
It lets them know how you feel about something or about them.
Tone of voice shows you're agreeable, friendly, and helpful.
Like body language, our tone of voice actually tells our listeners more than what we say.
If we don't get the chance to talk with a person, voicemail makes it easy to leave a complete and clear message and allows listeners to hear our tone as well as our words.
Since we still use the phone for many work in business transactions, it's important to feel comfortable and competent while on the phone.
Let's think about our first scenario.
In this situation, a customer calls to place an order and a salesperson responds.
Listen carefully to how the speakers clarify some critical information.
Hello, this is Andy Ramos.
I'm sorry, did you say 50?
The product number is 6-0-1-6.
It's better to clarify and repeat than to get the information wrong.
Remember, that positive tone of voice, signals a positive message to your listener.
What would you like to know?
I'd like to find out a little bit more about your company.
Yes?
In this next scenario, a worker calls his manager to ask for help with a problem at work.
Actually, I'm having a problem with one of my team members.
I really appreciate your help with this.
In lesson one, we looked at phone language, and in lesson two, how to pronounce keywords and numbers.
In this final lesson, we practice those points through role-play to better prepare you for different situations.
Before you move into your assignment for this week, think about some situations that you've had in your own business exchanges.
Did you say the right things with the right tone?
If you are using your first language, how would you say the same sentences in English?
If you can, write up a dialog as you've seen in this lesson and see if you're using the right type of language for each situation.
Phone role-play is a great way to practice these scenarios in English.
With practice, every one of them will help you to communicate your message and reach your speaking goals.
See you in our next module.
Hello, everyone, and welcome to our fourth module.
Are you getting ready for your first job interview, or your fifth?
Do you need to interview new employees for your company?
Do you want to make a good impression on a future employer or employee?
This module on keys to a strong interview, will help you with all of these situations.
Over the next three lessons, you will focus on improving personal skills, pronunciation for -ed and -s endings, and key language that produce successful interviews.
So let's start with our fist lesson on getting ready for the interview.
Whether you are conducting your interview or being interviewed, you want to be prepared.
And because interviews are all about making a great first impression, your body language, which includes all of the non-verbal ways we communicate, should be your first focus and our focus for this lesson.
So how can you use your body language to make that great first impression?
As we discussed and practiced in module one, our body language communicates a lot about us, even more than what we actually say.
Before we even say one word our body language sends lots of messages to the people we're with.
And in an interview, we want to be very sure that the first impressions we give are positive.
And because we're talking about interviews in English, rather than your local language, you might find that the situation be more challenging because body language varies from culture to culture, and place to place.
But it's not that difficult to avoid mistakes or misunderstandings if you prepare.
How can you prepare when it comes to body language?
First, always be aware of your body language.
Your posture, facial expressions, hand gestures and tone of voice.
Look at pictures of yourself in different situations.
Practice talking about yourself in front of a mirror, or even better, practice it in a real situation and film yourself.
In North America, standing or sitting tall, smiling, using hands expressively and politely and keeping a positive tone of voice all contribute to making a strong and lasting impression.
Would that be considered positive body language for you?
Think about body language that might be specific to your own culture, and decide if it's appropriate in others.
What else can you do to be sure your body language is helping and not hurting you?
One solution is to observe the people at the interview and mirror or copy their body language.
Think about what you do when someone smiles at you.
You smile back.
This natural mirroring brings us closer to people and helps us make connections with others.
It's the same in an interview.
I want to discuss another aspect of body language in this lesson.
How our body language affects how we feel about ourselves and how we can build confidence through better body language.
In her now very famous TED talk, social psychologist, Amy Cuddy of Harvard University, talked about the question she wanted to answer with her research.
Can you change how you feel about yourself through your body language?
Can your body change your mind?
Her answer?
According to Cuddy, the research was very simple.
They practiced for only two minutes.
Then, those same people were filmed in a job interview situation.
Finally, other people looked at the films and decided who they would hire for a job.
Every person who they picked had practiced a high-power pose before they filmed the interview In the resource materials for this lesson, you'll find more information about Amy Cuddy and her famous talk.
I encourage you to practice our recommendation, particularly power posing.
In this lesson, we discussed how to get ready for an interview by reflecting on our body language, or all of the other non-verbal ways we communicate.
As you work through this module, keep in mind that positive, productive, nonverbal communication is the first step in a successful interview.
In this lesson, we're going to look at what pronunciation practice you can do to improve your speaking during an interview.
We will focus especially on two of the most common pronunciation challenges for all English language learners, which are the correct pronunciation of -ed and -s endings.
Correct pronunciation of the regular past tense endings, the -ed ending in the words such as worked, designed, or conducted, is so important in interviews because so much of what you say during an interview is about what you did in the past.
So naturally, many of the verbs you will use will be in the past tense.
So we need to say these words correctly if we want to be understood.
Listen again to the three verbs I mentioned earlier, worked, designed, conducted.
Let's look at these sample sentences for a minute.
You could use any of these verbs to talk about yourself during an interview.
R in prepare, v in solve, g in manage, m in program.
Let's look at some other sentences.
All of these verbs end in voiceless sounds.
Pay attention to how I pronounce the past tense in these sentences.
I invented an app.
After t or d, we add an extra syllable and pronounce -ed as /id/.
Just like -ed endings, the final s can be challenging for English language learners.
With practice, you will easily master correct pronunciation of s endings.
Words like books, computers, asks, pays.
You want to say them loud and clear when you talk about your current work or education.
Listen to the next sentences.
That's right, a /z/.
When a noun or verb base word ends with a vowel sound or a voice sound, we say .
Listen and repeat as I say some nouns and verbs with -s endings.
Now, put each word in its correct place on the chart like this one.
After this lesson, spend some time and think about the words you may use at your next interview.
When you've figured out the ending sounds, add them to this chart.
In this lesson, we identified and practiced correct pronunciation of word endings.
There are more activities for both -ed and -s endings in the resource materials for this lesson.
Read the sentences out loud, record yourself and check your pronunciation.
With practice, you can improve your pronunciation of these word endings and increase your clarity and fluency.
Welcome to the final lesson in this module.
This is your chance to impress for success.
In this lesson we'll look at the most common job interview questions and how to answer them appropriately.
At the end, you'll have the opportunity to post an interview role play for your classmates to get feedback on.
I will be introducing a typically North American interview style and questions.
However, keep in mind that depending on the culture of the people in the interview, the questions may vary.
So while you prepare, be ready with answers for all kinds of questions.
If you will be the one interviewing someone, pay close attention to the types of questions for each part.
As always, preparation is the key to success.
So, how do you prepare for an interview?
Most interviews feature three categories or types of questions about, your ability, your willingness, which means how much you want to work with the company, and how well you'll fit in with the new job and organization Let's start with ability.
Let's look at some examples of questions in this category.
What is your greatest strength?
What are your best skills?
What qualifications do you have that would make you successful here?
To answer these questions, you must learn as much as you can about the organization that you are applying to.
It may be an international company with offices all over the world or a small local business.
It could be a technology startup or a nonprofit which is a company that works to help people.
You will feel more comfortable and interviewers will see that you are really interested and can talk easily about the organization.
And show how your strengths and skills are good for their organization.
You also want to know about the actual job that you're applying for.
You may even be ask to solve problems similar to the problems on the job.
When you know what the job requires you can talk more easily about how you can do the job Next, let's look at willingness.
What kind of student were you?
How do you handle problems and setbacks?
For these types of questions, your personal experience is key.
You want to be ready to show the interviewer that you work hard and you don't give up easily.
You want to be prepared with actual examples that show your initiative and desire to be successful and your willingness to overcome problems These will help you stand out among others applying for the same job.
Finally, employers want to know if you'll be a good fit for their organization.
Do you belong there?
What's important to you in a work situation?
Do you think you're a natural leader?
How do you adjust to new situations?
Again, knowing about the organization and the job will help you answer these questions in the most positive way.
You want every answer you give to support your chance at getting the job, and even if you have to give a negative answer, think of ways to turn it into a positive.
Now let's look at some answers for the questions we looked at.
It gives a direct answer and it refers to the actual job the employer is trying to fill.
How about this one?
>> This answer works, because telling a story is a key way to catch someone's attention, and it gives you a chance to share a personal experience that says a lot about you.
Let's try one more.
>> Do you think you're a natural leader?
>> I'm a leader, but I don't think I'm a natural at it.
This is a good answer because it shows how a negative can become a positive.
Preparation.
You must be ready to answer the question and to match your answer to the job and the organization.
At the end of an interview, employers often ask for your questions.
For this situation also, you must be ready.
Prepare a question or two to show both your interests in the company and that you want to learn more.
Could you tell me a little more about it?
What are some characteristics of your most successful employees?
What can I do next to get this position?
You'll also want to review and practice the body language and word ending skills we discussed in lessons one and two.
You'll then be ready to complete the last assignment in this module, the roleplay interview.
In this lesson, we reviewed some typical interview questions and how to answer them.
Whether you are interviewing someone or being interviewed, we all know that interviews in any language are a challenge, but with careful preparation and lots of practice, you can make them opportunities to impress for success.
Well this is it for this module.
I'll see you on our next module soon.
Welcome to the final module of our course, Speak English Professionally.
We'll look at how to put a pitch together in Lesson 1 and how to deliver it in Lesson 2.
Then in the final peer assessment, you'll have the chance to show and tell me and your course mates everything you've practiced and developed in this course.
Appropriate body language, improved fluency and increased vocabulary.
First, how do you organize a presentation?
In English, especially American English, we organize presentations in a simple, direct way.
I like to think of it as the three tells.
First, tell your audience what you're going to talk about.
And third, tell it again.
Or you can think about a presentation having three parts, introduction, body, conclusion.
In the first tell, the introduction, you reach out and grab your audience attention.
How do you do this?
In many ways, it's a lot like your elevator speech.
Be prepared with information that will make the audience sit up and listen.
If possible, have your product available for your audience to see, touch, and connect to.
Or include a strong visual, a photo, a graph, a number that will help your audience connect to you and your product.
Next, preview clearly and simply what your product or service is and how it's right for the audience.
Use active language and state clearly what you have to offer.
At the end of your first tell, your introduction, your audience should know what the product is and what they are going to learn about.
Most of all, they should feel connected to you and want to know more.
Steve Jobs, one of the world's most accomplished speakers, really nailed this when he introduced the MacBook Air, how?
He named the product, previewed its advantages and revealed it dramatically.
Look at this.
What does the product do?
How does the product work?
Why is it valuable?
Talk about your product or service so your audience understands how they can use it, and why it's important for them.
Keep your language direct and clear as you move from one point to the next.
Use words like first, second, third, or first, next, and finally.
Here's where you include facts and figures, quotes from customers, or a story about your product to prove how great your product is.
Again, include a visual to enhance your presentation.
Every detail you give about your product must help your audience understand you and your product or service better.
Steve Jobs after his dramatic reveal of the MacBook Air, opened his second tell with these words.
Finally, in the last tell, the conclusion, repeat your main points.
Tell your audience again what your product is and why they want it.
This is your last chance to secure your audience's interest.
Motivate them to want to be a part of your world.
And then, in the conclusion of his famous presentation, he lists everything he's already described and leaves his audience with a powerful image of his product.
I recommend you view this great presentation through YouTube.
Just do a search for Steve Jobs, MacBook Air intro.
In this lesson, we've looked at how to organize an effective presentation.
How do we do it?
Tell your audience what you're going to tell them.
Pull them in and get them excited about what you're going to show them.
Go over your important points and add the details and evidence that make your product stand out.
Tell the audience what you told them.
Summarize your main points and leave them with a strong, powerful message about you and your product.
For every presentation, ask yourself, do I have the three tells, intro, body, conclusion?
If you do, you're ready to start talking.
Welcome to Lesson 2, Perfect Your Pronunciation.
In this lesson, we are going to focus on ways to increase your fluency and make your English pronunciation even better.
First I'll discuss more about word stress, and then review other ways to help you speak more effectively.
First, let's learn more about word stress.
I hope you remember what I said back in Module 1, that word stress is the magic key to clear English.
More than anything else, when you speak, it is your word stress that helps people understand what you are saying.
For example, this word is pronounced garage in America, but in in England it's pronounced garage.
In Module 1, we looked at the basic of word stress.
We stress only one syllable in every word, and we say that one syllable longer and louder.
In Module 3, we practiced correct word word stress for numbers with teens and tens.
Remember the difference between fourteen and forty?
In this lesson I'm going to introduce you to a few more guidelines to help you decide which syllable to stress.
We will look at regular and proper compound nouns, at nouns and verbs that look alike but have different stress, and finally at suffixes that change word stress.
First, regular compound nouns, a compound noun is a combination of two words.
Some are just one word with two parts, like basketball or network.
Basketball, coffee cup, driver's license, and network.
Yes, on the first word of each compound noun.
Another type of compound noun is the compound proper noun.
These are the names of a particular person, place, or thing, and they usually begin with a capital letter.
Names like Georgia Tech or Delta Airlines, unlike regular compound nouns, compound proper nouns receive stress on the last segment.
Whether the proper noun is two, three, or even four words, the stress will always fall on the last segment.
Listen to a few, New York City, Martin Luther King, The Golden Gate Bridge.
Now let's look and listen to nouns and verbs that are similar.
They have different word stress.
We stress the first syllable in the nouns, and the second syllable in the verbs.
Let's look at, and listen to, a few more examples.
Last, let's look at some common suffixes, and how they affect word stress.
A suffix is a group of letters on the end of a word that changes the word form.
For example, adding r after the verb drive forms the noun driver.
Adding ness after the adjective good forms the noun goodness.
When you add ness, ful, ment, or to a word the stress remains the same.
Listen to how the stress moves right to the syllable immediately before the suffix.
Adding this to major, it becomes majority.
Adding this to economy, it becomes economic.
Adding this to mechanism becomes mechanical.
And adding this to electric becomes electrician.
Having these guidelines for word stress can help you to identify the correct word stress to use, and they're helpful.
Over time and the more you listen and speak, the better and more accurate your word stress will be.
Now, I'd like to review a few more points to remember as you practice and improve your fluency.
Sentence stress, in every sentence focus on the content words, the important words in the sentence.
Be aware of your intonation, the rise and fall of your voice at the end of sentences.
As your voice rises and falls at the end of statements and information questions, your listener can more easily follow what you were saying.
Pauses and full stops are also very important when you are speaking.
You know what you're going to say but your listener doesn't.
Pauses give your listeners time to think and understand.
And the more they understand, the better you sound.
Move your hands to give meaning to what you are saying.
Lean into your audience, this shows that you are engaged and confident.
And remember, the more you practice, I should say practice, practice, practice, the easier it will become to speak fluently and effectively.
I look forward to hearing your next recording.
This brings us to the end of our course, Speak English Professionally In Person, Online, and On the Phone.
I have really enjoyed teaching this course and watching your progress through the modules.
I look forward to working with you again in the Capstone course.
Hello!
Shimboni!
This week, as any week, there will be a lecture, a tutorial, and a homework session.
We will watch children play in the sand and adults play on the Monte Carlo Heliport.
They will teach us a crucial lesson about sampling.
This week's tutorial, Tutorial 1, will analyze Monte Carlo algorithms and their convergence.
We will derive a crucial theorem about the convergence of Monte Carlo algorithms using this 3x3 pebble game.
Finally, this week's homework session, Homework Session 1, will be all about practical computing.
We will download, take apart, and put back together simple Python programs.
We will, so-to-speak, get out hands dirty, and we will learn about a crucial rule of thumb, the famous one half rule.
that will teach us how to choose the parameters of our Monte Carlo computations.
So, let's get started, with Statistical Mechanics: Algorithms and Computations.
In the sand, they draw a square and a circle.
In fact, the children on the Monte Carlo beach do a direct sampling Monte Carlo simulation.
They compute the number pi from the ratio of the area of the circle to the area of the square.
In the limit of an infinitely long beach party, of an infinite number of pebbles, the exact value of pi will indeed be computed.
In Python, this gives the following program its key element are the two random numbers random.uniform, they give a random position in x between -1 and 1, and a random position in y between -1 and 1, in total, a random pebble position inside the square.
So, here again is the children's game in Python, in a version which allows us to do many runs, one afternoon of 4000 pebbles, followed by another afternoon of 4000 pebbles, and so on and so on..
Output of this program is shown here.
Before moving on, please take a moment to download, run and modify some programs.
On the Coursera website, you will find the program direct_pi.py, that allows you to do one game of the children's play.
You will also find the program direct_pi_multirun.py, that allows you to do many runs of the children's game, or, if you like, many afternoons on the sunny Monte Carlo beach.
In Monte Carlo, it is not only children who play at pebble games, adults also play at their version of pebble game on the local heliport.
After storing away all the helicopters, they wander around the square-shaped landing pad, that looks just like the children's game, only larger.
No one can throw a pebble randomly into such a big field, so the algorithm must be modified.
This algorithm will work, but what should we do when we throw a pebble outside of the square?
Should we continue inside the square, as if nothing has happened?
Or should we climb over the fence of the heliport, and continue outside of the square until eventually we will come back?
We should ask somebody to bring us the outfielder, and place it on top of the pebble already present, then we should pull out a new pebble and do a new throw.
If this is again an outfielder, we should again have it brought and place it on top of the pile.
Eventually we will move on, visit other areas of the heliport, and also come close to the center, where there are no rejections.
Close to the boundaries, and especially close to the corners, there are piles, corresponding to rejected moves.
This is quite mind-boggling for us today, and it was even more so in 1953, when this famous Metropolis algorithm was invented.
Before studying why this program is correct, please take a moment to download, run and modify the relevant programs.
On the Coursera website you will find the program markov_pi.py, that allows you to run one party on the Monte Carlo heliport.
The key element of this program is as follows.
At position x and y, you move by little random displacement delta_x and delta_y that can be positive or negative.
When the move is rejected, you simply remain where you are, that means, you build a little pile.
On the website, you also find the program markov_pi_multirun.py, that allows you to simulate many heliport parties.
Output of this program is shown here.
You see that although the strategy of piling up pebbles seems a bit strange, the output comes out just right.
We left the Monte Carlo heliport a few moments ago, without clarifying the reason for this pile-up of pebbles, especially near the boundaries.
Remember, we want to spread out the pebbles evenly on the heliport square so the strategy of making piles appears very strange indeed.
Now, we consider that we have run this program for a long time.
in fact, we suppose that we have reached a steady state.
The probability pi_a to be at configuration a is then given by the probability to be at a and to remain on that site, plus the probability pi_b to be at configuration b times the probability to move from b to a, plus the probability pi_c to be at configuration c and to make a transition from c to a Putting these two equations together, we find..
What does the detailed balance condition mean?
in our 3x3 pebble game, we want to sweep out evenly all the configurations we want to have pi_a equals to pi_b equals to pi_c, and so on this implies that we need to have probabilities p(a->b) equal to p(b->a), and p(a->c) equal to p(c->a) How can we implement this?
Well, very simply.
By moving from any configuration with probability 1/4 to the right, up ,to the left and down.
This is a simple solution and it involves rejections.
If we are at configuration a, we reject the moves to the right and up.
At t=1, the configuration will be as follows Question 2: at t=1, with the pebble in the upper middle position, we again roll a die (right, up, left, down).
Yes, clearly, we should stay where we are.
At time t=2, we are again in the upper middle configuration.
Note that we count this configuration a second time, that we build a pile, so to speak.
What should we do?
Clearly, we should move down.
At time t=3 we are in the center of the square.
Question 4, final question: at time t=3, in the central configuration what will be the rejection probability of the next move?
The numbers indicate the statistical weights of the configurations.
and the pebble should be twice as often on the upper right corner than on the site in the middle on the top row.
and four times as often on the upper left corner than on the site just below it.
To devise a Markov chain Monte Carlo algorithm for the inhomogeneous pebble game, we must visit again the detailed balance condition where probabilities pi_a and pi_b are the numbers written up here.
we would now violate the detailed balance condition if we move with the same probability from site a to site b as from site b to site a Metropolis et al., in 1953, proposed their famous Metropolis acceptance probability to handle the case when the probabilities pi_a on the sites are no longer constant.
they proposed the rule shown here In this rule either the transition probability p(a->b) or the transition probability p(b->a) is equal to one.
an in both cases, the detailed balance condition is ok Let us illustrate this most important Metropolis acceptance probability in the pebble game.
Suppose we are in the upper right corner, and we want to move to the left.
we should accept this move with the probability minimum(1, 0.5/1), which is equal to 1/2.
so we should accept this move from the corner to the middle with a probability 1/2, otherwise we should stay where we are.
In conclusion, we have plunged in this lecture 1 of Statistical Mechanics: Algorithms and Computations, into the field of Monte Carlo algorithms the key concept is sampling, obtaining the pebble positions.
we have studied two basic approaches to sampling: direct sampling in the children's algorithm and Markov chain sampling in the adults game on the heliport.
In this second week, we move on to study and to simulate model systems in physics particle with positions, velocities and interactions using a statistical approach that this is at all possible and exact is one of the great legacies of physics.
The entire program of this week is to motivate, define and illustrate the statistical approach in the very famous model of two dimensional hard spheres so called hard disks.
We will see that in the statistical approach any two configurations of hard disks must be sampled with equal probability just as we did last week for pebbles on the heliport or on the Monte Carlo beach.
In Tutorial 2, we will connect the equiprobability concept - a basic version of the celebrated Boltzmann distribution - with the central notions of statistical mechanics namely the partition function, the free energy, the phase space volume and the virial expansion.
In Homework session 2 our main concern will be - just like last week - on practical computation.
We will actually check that the Newtonian dynamics of four hard disks perfectly agrees with the statistical approach.
We'll move to the central notion of statistical mechanics but we will discover and develop all the concepts using our algorithmic approach.
We will remain perfectly self-contained and you don't have to have already taken a course in statistical physics or thermal physics in order to follow.
So, let's get started with week 2 of Statistical Mechanics: Algorithms and Computations.
What you see here is a configuration of four disks red, blue, yellow and green with given positions and velocities at time t=0 in a box going in x from 0 to 1 and in y from 0 to 1.
Here is the time evolution of the disks moving about the box, like billiard balls.
The dynamics of this system - for example from a configuration at t=0 - consists in straight line evolution up to the next event.
Like with real disks, there are also pair collisions where the velocities change according to the rules of an idealized billiard without the complications of real systems such as torque or friction.
Let us now describe in detail the event-driven molecular dynamics algorithm invented by Alder and Wainwright in 1957.
It solves the Newtonian dynamics of the system without any approximation.
Starting from an initial configuration - at t=0 - we must compute the next event.
This event may be a wall collision or a pair collision.
If it is a wall collision its time is given by the minimum of the wall collision times of the red, the blue, the yellow and the green disks, taken individually.
Look here, the red disk is moving down and to the left.
Its wall-collision time - disregarding the three other particles - is the minimum of the times at which it would hit the line x=0 and y=0.
The second type of events is a pair collision, for example here of the red and the blue disks.
A pair collision takes place when at some future time the distance between the two disks is equal to twice their radius.
We can compute this time using a quadratic equation.
When the two disks are approaching each other, the pair collision time is the minimum of the two positive solutions of this quadratic equation, otherwise the pair collision time is infinite.
The minimum of the six pair collision times and the four wall collision times gives us the next event in the system, here, at time t=0.45813 a number that we can compute to as high precision as we want.
To conclude our description of the event-driven molecular dynamics algorithm, we realize that we must not collect events, but rather make a movie going from time t to t+delta_t t+2 delta_t, ..
Let us now ask a few questions Question 1 why is Alder and Wainwright's algorithm for molecular dynamics called event-driven?
Is it because Answer 1: its invention was a major event in the history of science?
or is it (Answer 2) because the algorithm moves forth in a sequence of collisions called events?
Answer 1: the probability is equal to zero, exactly.
Answer 2: the probability is very small, between 1% and 10%, depending on the time interval between frames.
Common sense and powerful mathematical theorems tell us that there is a finite number of events per unit time interval so the probability to have an event at time equal to 1.00000 and so on or at time 16.000000 and so on is exactly equal to zero.
You will not see any collision event in these frames taken at integer times.
Question 3: in the event-driven molecular dynamics algorithm we suppose that a pair collision or a collision of a particle with a wall constitute the next event.
Isn't it possible that the next event is rather a collision of three disks or a pair collision taking place at exactly the same time as another wall collision?
No, this is not possible Common sense and powerful mathematical theorems again - just like in Question 2 - tell us that the probability of one event taking place exactly at the same time as another event is equal to zero.
With finite precision arithmetic on our computers these exceptional events may have to be taken into account in the treatment of errors.
The event-driven molecular dynamics algorithm exactly solves the hard disks equations of motion under the assumption that the calculation of collision times velocity changes, positions and so on..
This cannot really be achieved on a computer but the question arises whether it matters that in Python - as in other languages - real numbers are truncated to finite precision.
It is easiest to answer this question by pitting different versions of the same event-driven molecular dynamics algorithm against each other.
The two versions of the four disks molecular dynamics calculations that are identical at t=0 remain very similar at initial collisions but then completely get out of step after a few dozens collisions.
This is an extremely small number compared to the millions or so collisions that we can compute on our computers per second.
This is quite strange.
Our results for computing times as small as a few microseconds are exact yet uncontrolled.
But this strategy cannot defeat the onset of chaos, that is: cure the extreme sensitivity of our calculations to the numerical precision.
This magnifies small differences of the trajectory at each pair collision and is very well known to whoever has played billiards.
On the other hand, chaos is the main reason why even for finite system of hard disks we can describe it by statistical mechanics, as we will discuss in a few minutes.
Before moving on to the statistical approach, please take a moment to download, run and modify the programs.
On the Coursera website, you'll find the program event_disks_box.py which computes the time evolution and the program event_disks_box_movie.py which produced the nice graphic output that you saw all along this section.
Both the wall collisions and the pair collisions are programmed in a few lines, and there are absolutely no approximations besides the finite precision of our calculations.
The event-driven molecular dynamics algorithm of the last section can be written down in a few dozens lines - as we saw - and it allows us to follow the ballet of disks approaching and flying away from each other, along intricate, even unpredictable trajectories.
In doing so however, we engage on a computational project which is much more complicated than what we need.
To continue, we again consider the configurations that we generated just a few moments ago.
From a physical point of view, these configurations have kinetic energy - as we will discuss two weeks from now - but their potential energy is zero if they have no overlap, and is infinite if they have an overlap.
Configurations with overlaps are simply forbidden.
We sampled this pebble positions with a random number in x and a random number in y.
Now, we generalize from the children's algorithm on the beach to a direct sampling Monte Carlo algorithm for hard disks.
We first place the red disk as a random number in x between sigma (the radius) and 1-sigma and y: another random number between sigma and 1-sigma.
Congratulations!
We have placed the four disks at random positions.
In total, we have produced a random configuration of the four disks, as called for by Ludwig Boltzmann.
Let's do it again.
Let's place the red disk at a new random position inside the box.
Then the blue disk, then the green disk, ouch!
What should we do now?
You might be tempted by simply taking away the green disk and trying to place it again but this is wrong.
The correct solution is called 'tabula rasa' It consists in wiping out the whole configuration and in starting again from an empty box with the red, the blue, the green, the yellow disks until you succeed.
We will spend a good part of this week's tutorial to make sure we completely understand why we have to implement the tabula rasa rule and why this allows us to sample a random configuration of hard disks.
Before moving on, please take a moment to download, run and modify the programs.
It samples one configuration of four disks its key element are the random positions in x and in y, between sigma and 1-sigma.
Four times we generate such a random position and check for the minimum distance with the disks we placed earlier.
If this minimum distance is smaller than (2 x sigma) - twice the radius - we know that we have an overlap.
I can ensure you that the sequence of configurations that you see here is equivalent to the output of the molecular dynamics calculation if you erase time information, scramble the sequence and also erase the velocities.
Then, these two sequences are equivalent and we have arrived at the center of statistical mechanics.
Detailed balance imposed that the transition probability from a to b had to be equal to the transition probability from b to a in order to satisfy equiprobability pi(a) = pi(b).
Let us now apply the same reasoning to hard disks.
Consider here configuration a of four hard disks the move consists in picking one of the four disks - for example the blue disk - and making a little displacement delta_x and delta_y - that can be again positive or negative - to a configuration b.
The detailed balance condition is satisfied - with pi(a)=pi(b) - if we move with the same probability from a to b as we move from b to a.
It can also happen that the move from configuration a is rejected, as it creates an overlap.
In that case, we remain at the configuration a for the next iteration.
In Python this gives the following program markov_disks_box.py that you should download from the Coursera website, run and modify.
The key element is the random choice of one disk whose coordinates we modify a little bit.
The new configuration is tested for overlap and if two disks are getting too close or if we have an overlap with the wall we simply remain with the configuration a otherwise let's add the new configuration This precise algorithm for this model of hard disks was introduced by Metropolis et al.
in a famous article of 1953.
On the website you'll also find the program markov_disk_box_movie.py that produces nice graphics output shown here.
This algorithm samples the same distribution as the direct_disks algorithm.
As discussed in last week's tutorial by Vivien, we must check - in addition to the detailed balance condition - that we satisfy irreducibility and aperiodicity.
Aperiodicity is trivial to check, for our algorithm but in order to satisfy irreducibility we must avoid situations as the one shown here where the blue disk remains in the upper right corner up to infinite times.
For small systems, with a small number of particles, we must go to small disk radii as shown here where the disks move around the whole system But for larger system this is not a problem and the markov_disks algorithm remains irreducible up to very high densities.
In this week's homework session, you will show - using numerical simulations - and up to the numerical precision that the event-driven molecular dynamics calculations and the Monte Carlo simulation give equivalent result for thermodynamic quantities.
This means that the equiprobability hypothesis formulated by Boltzmann is satisfied.
This equivalence between Newtonian deterministic mechanics and statistical mechanics is called the ergodicity hypothesis.
It certainly does not follow from simple principles like time-reversal invariance or detailed balance.
The proof of equiprobability has presented a formidable mathematical challenge.
It was once believed to hold only in the limit of infinite number of particles.
Mathematical research has gone very far in actually proving the ergodicity hypothesis for the special case of hard disks and hard spheres and already for finite number of particles.
The first milestone was obtained by Sinai in 1970.
He proved that for two disks with periodic boundary conditions the hypothesis was actually satisfied.
Very recently, mathematicians like Simanyi have proven that a finite number number of hard disks have to satisfy the ergodicity hypothesis.
In conclusion we have plunged, in Lecture 2 of Statistical Mechanics: Algorithms and Computations, into the foundations of statistical mechanics.
The hard disk model that we have studied is special in that all legal configurations have the same potential energy and therefore the same statistical weight.
This model has been instrumental for the development of statistical mechanics and also for the development of molecular dynamics and of the Monte Carlo method.
Next week, we will study the very rich phenomenology of this model which is at the basis of the physics of liquids, among others.
In the meantime, have fun with Tutorial 2 and with this week's homework.
It remains for me to thank you for your attention for this session See you again in other sessions of Statistical Mechanics: Algorithms and Computations.
Last week we discussed how the statistical approach provided an exact description for physical systems.
As you found out by yourself in Homework Session 2, this statistical approach captures the system even for finite number of particles.
The equivalence between Newton and Boltzmann is one of the great miracles of the natural sciences.
It is also a breakthrough in mathematics, because there are now mathematical theorems that back up our numerical findings, at least for hard spheres systems.
For us, believe it or not, it will be the key for deep insights into physics.
We place a first one randomly on a washing line between two poles like this and a second one like this and a third one like this and so on, until N clothes-pins have been placed onto the line.
Each arrangement of N clothes-pins is equally likely and we use the tabula rasa rule to wipe-out a configuration that presents an overlap.
What is the probability for a pin to be at position x?
This simple question will get us to the heart of liquid and soft-matter physics.
We will discover that although apparently the pin positions are independent, pins in fact experience a strong force: a force that can be seen in neutron scattering experiments or in X-ray diffraction, and that can be measured.
This famous interaction was discovered by Asakura and Oosawa in 1954, and it is so important that some people take it to be the fifth force in nature.
In this week's lecture we will study this interaction.
It comes out of nowhere and it exists even though there are no charges, no currents, no mechanical strains.
This is why it is called an entropic interaction.
It can be so strong that it introduces phase transitions from the liquid to the solid.
The clothes-pins model corresponds to one-dimensional hard disks.
Remember: last week we had trouble simulating four hard disks in a square..
This week we can study so large systems that we can even approach the infinite-system limit: the thermodynamic limit.
As you will see several times in this course, a great algorithmic success (the fact that we can directly sample thousands or millions of particles without rejections) is mirrored by the fact that we can solve this model analytically.
This is what you will do in the tutorial of this week.
The analytic solution allows us to drive home essential messages about liquids and solids, and about the phase transition between them.
The providential Monte Carlo algorithm that we alluded to works only in one dimension.
In two dimensions and higher (for hard disks or hard spheres) we must resort to the tools of last week: Markov chain Monte Carlo algorithms or Molecular Dynamics.
At small densities, everybody understands that the system of hard disks or spheres is a liquid.
In this week's homework session you will retrace these classic papers.
Our algorithms and our very simple Python implementations are just good enough to get a flavor of what is going on in the system and to observe our first phase transition.
So let's get started with week 3 of Statistical Mechanics: Algorithms and Computations.
This is what allows us to sample configurations x_0, .., x_(N-1) with a probability pi=constant if the configuration is legal, and pi=0 if it is illegal.
As we are on a line (that is, one dimension) it is more efficient to sample the position x_0, x_1, x_2, x_3 and so on then to sort them such that x_0 < x_1 < x_2 < ..
So we check for the distance between x_1 and x_0, x_2 and x_1, x_3 and x_2, and so on.
Output of this program for 5 pins of radius sigma=0.075 on a line of length 1, (that is with 75% of the line occupied by clothes-pins) is shown here.
Each line shows an accepted configuration with the 5 positions x of the centers of the clothes-pins.
For N=10, it will be really interesting to see that rejection rate will be so high that you accept only one out of 500000 samples.
Output will be really interesting for N=15, but don't try to obtain it with this algorithm you will accept only one legal configuration out of 500000000 trials.
Wait until Michael - in this week's tutorial - shows you how to sample this configuration for any N (as you like: hundred, thousand and millions) or any density, without any effort.
Now, let us analyze these data and the way to do it is to do a histogram of all the x-positions in this table.
everybody finds this outcome counterintuitive and difficult to understand.
How can it be that close to the poles we have 4 to 5 times more particles than in the center?
The poles actually attract the particles.
Furthermore, what you see here is not a mere boundary effect.
What we see here (attraction of particles to a wall or the attraction of particles with the others) is what Asakura and Oosawa found in 1954 in their famous paper and this is what we will study in a moment.
Before doing so, please take a moment to download, run and modify the two programs we discussed in this section.
And please be patient, for the direct sampling algorithm without rejections (direct_pins_noreject.py) that we will discuss in this week's tutorial.
When drawing configurations of pins we must realize that there are two types of excluded regions.
But we must realize that the position of the pin is given by its center and this creates a second type of excluded region that we call the halo.
The center of another particle can penetrate neither into the halo nor into the core.
The total core area of our N pins is fixed: it is equal to (2 N sigma).
This means that the configuration to the right has a higher probability than the configuration to the left or that the particle is attracted to the boundaries.
You can also say that there is a force between the boundary and the pin.
Let us now see for ourselves whether the halo picture predicts interactions between particles.
We will consider a line of length L, with a pole to the left and a pole to the right and two pins, with radius sigma, which means core area 2 sigma.
Question 1 what is the available space for other particles if we place our two pins far from each other and far from the poles?
Answer: for two pins that are far from each other and are far from the poles the available space for other particles is equal to (L - 10 sigma), as you can see from this figure.
Question 2 what is the available space for other particles if we place the two pins close together but far from the poles?
Answer: the available space for the other particles is equal to L - 8 sigma, as you see in this figure.
Third question: what is the available space for the other particles if we put one pin close to the left pole and another pin close to the right pole?
Answer: the available space for the other particles is equal to (L - 6 sigma), as you see here.
Final question: the halo picture, can it fully describe the density profile that we obtained earlier?
The answer is no, the halo picture nicely describes the increase of density close to the boundaries but it cannot account for the intricate oscillations of the profile.
Please be patient for this week's tutorial, where we will derive an analytical formula which exactly describes this density profile that we obtained from numerical simulations.
The halo picture, although it is approximate, applies in any dimension and it explains why in Homework Session 2 (last week's homework) you obtained an inhomogeneous density profile for the 4 hard disks in a box.
For a disk of radius sigma, there is a ring of radius sigma that forms the halo No other center of disks can penetrate into the halo or the core area.
Here, on the screen, you see three configurations of two disks in a box.
In configuration c, the two disks are in the corners and the available space for other particles is much larger than for configuration b, but configuration a has the least accessible space for other particles.
If we have two particles already in configuration c, that means in the corners, we have much more available space for the other particles, and a lower chance to undergo a tabula rasa wipe-out.
This means we expect a higher density in the corner of the box than in the center and this is exactly what you observed in last week's homework but you probably concluded that these inhomogeneities were a boundary effect.
Consider the configuration b: the two particles attract each other.
In the one dimensional clothes-pin model, the oscillations that you see here decay exponentially on the scale of a few clothes-pins.
This means that the boundary effects and the pair correlations decay on the scale of a few sigma and this implies that the Asakura-Oosawa interaction leads to local modulations of densities and pair correlations.
On long length scales, the system is completely homogeneous and this is what defines the liquid state.
The clothes-pin model is an example of a very general class of physical systems with short range interactions.
Powerful mathematical theorems exclude the possibility of a phase transition in this systems in one spatial dimension.
The question is now whether these interactions that we discussed can be strong enough in 2 and higher dimensions to be seen on arbitrary length scales and whether they can introduce phase transitions.
This will be the subject of the next section and also of this week's homework session.
In this week's tutorial, we will continue our detailed study of the random clothes-pin model, but here let me put what we have done and what we will do in the tutorial into a wider prospective.
And I will start from a discussion of the two extremes the close-packed limit and the dilute system considering systems with periodic boundary conditions.
In two dimensions, that is for systems of hard disks, the close-packed density is equal to pi / (2 sqrt(3)) and this is about 0.907.
And the close-packing configuration is hexagonal, as shown here in the picture.
The mathematician Laszlo Fejes Toth proved in 1940 that no other configuration than the hexagonal packing exists at this density pi / (2 sqrt(3)).
So we are sure to have long range positional and orientational order in this system, at the close-packing density.
There are no other mathematical results about this system, besides the fact that at very small density the system is liquid.
To find out what is going on at intermediate densities we have to resort to numerical simulations: Markov chain Monte Carlo simulations and Molecular Dynamics simulations allow us to sample this.
For example here you see a system of 256 disks at density 0.48, again with periodic boundary conditions in x and y.
Here, the Asakura-Oosawa depletion interaction is at work, and it produces some unconnected local arrangements of disks, that resemble the close-packing limit at density 0.907.
At higher density, look here, the system all of a sudden changes.
What you see here on the right is qualitatively different, from the configuration on the left.
The discovery of this phase transition from the configuration on the left (the liquid one) to a denser phase is a computational fact, a computational achievement, and it also been observed in many experiments.
This transition at a finite density, below close-packing, takes place in two dimensions, but also in three dimensions for hard spheres.
The existence of such a transition was first suggested in theoretical works by Kirkwood and Monroe in 1941.
In conclusion, please note that in Lecture 3 of Statistical Mechanics: Algorithms and Computations we have remained within the tight conceptual framework of the equal probability principle.
What a simple principle but what far reaching consequences and rich and surprising phenomena!
And what a nice interplay between algorithms and theory!
In coming weeks, we will continue to develop the conceptual framework, the consequences, and the algorithms.
I hope to keep up your interest in Statistical Mechanics: Algorithms and Computations.
In the meantime, let me thank you for listening.
This week we will advance our understanding along two directions from the physical point of view, we have so far thoroughly studied the first pillar of statistical mechanics: the equiprobability principle.
Time has come to consider the second pillar which comes from the Maxwell distribution of velocities and gives the Boltzmann distribution of energy.
This second pillar will allow us to heal the dissimmetry between the molecular dynamics simulations that is the solution of Newton's equations of motion and the Monte Carlo approach.
What we learn today will allow us to overcome the dissimmetry between molecular dynamics and Monte Carlo.
To get there, we must deepen our understanding of sampling and this is the second direction along which we will advance this week.
So far, sampling meant that we threw pebbles, placed disks, or fixed clothes-pins on a washing line.
Now, we will connect this sampling problem with the underlying process of integration.
The sampling problem will accompany us also in this week's tutorial, tutorial 4.
We will start with a very simple Saturday night problem on your free evening you have many options and you can give them probabilities you can go out with friend, see your family, do homework, do sports.
The difficult part is doing the sampling.
All of these are central subjects of daily life at work or study but - as you see - also for the night life.
In this week's homework, homework session 4, you will be concerned again with the connection between sampling and integration.
You will learn for yourself how the sampling approach really goes at top speed in high dimensions and how you can evaluate an integral there.
You see, there are lots of exciting developments in week 4 of our course, so let's get started.
More precisely, we find that the number of hits divided by the number of trials is approximately equal to the ratio of two integrals.
The integral over dx and dy on the square of O(x,y) pi(x,y) divided by the integral over the square of pi(x,y).
By throwing pebbles, we in fact compute the integral in dx dy pi(x,y).
But notice: on the left side the probability distribution pi(x,y) is absent it is the samples that are drawn from this distribution.
Furthermore the dimension of the integral (the fact that the integral on the right is in two dimensions) does not appear on the left: there are no multiple sums along all dimensions.
This explains why Monte Carlo sampling methods excel in high dimensions.
And we we'll next see how these changes of variables relate to the sampling approach.
Our example will be the Gaussian integral integral from (-infinity) to infinity in dx over sqrt(2 pi) exp(- x^2 / 2).
x = r cos(phi), and y = r sin(phi) This gives the following integral.
We can do these two integrals, and confirms that I^2=1, which means that I=1.
But in fact we don't care about the value of this integral what we do is to use our relationship between integration and sampling.
Let us discuss as what it really is, namely an algorithm gauss_test.py Its graphic version (gauss_test_movie.py) allows you to see that the flat input distributions of phi and Upsilon get transformed into distributions of x and y that are Gaussians.
So we have a distribution exp(-x^2/2) and a distribution exp(-y^2/2) and the two are independent.
So what you see here allows you to understand that the substitution rules (the changes of variables in integrals) also apply to the samples.
Before going on, please take a moment to download, run and modify the programs we just discussed.
Understand that phi and Upsilon are numbers, samples, and that these samples are transformed into numbers, samples of x and y taken from a Gaussian distribution.
Check that this is actually uniform.
Check it out, and compare it to the analytical calculation we did a few minutes ago.
Now let us consider vectors or lists of Gaussians not just a single one.
We start in two dimensions, with x and y two independent Gaussians.
It uses basically the same algorithm, called the Box-Muller method.
You see a first sample, a second sample, a third sample, and so on.
Each point is an independent Gaussian in x and an independent Gaussian in y.
And note that the distribution (the cloud) is isotropic, it is invariant under rotations.
This situation is unique, there's only Gaussians that can do it.
Another of choice of phi would simply rotate the point x,y along the origin.
You can directly check this also in out little crab walk we took a few minutes ago.
You see we arrived from independent distributions x and y at a distribution integral from 0 to (2 pi) dphi over (2 pi), times an integral in r There is no function depending on phi, which means that the variable phi is independent.
We will considerably deepen and generalize this for higher dimensions in a few minutes.
Gaussians are unique in that independent distributions in x and y give an isotropic distribution in two dimensions.
This property is general for Gaussians in any dimensions.
The 3D case is shown here in gauss_3d.py each point is a vector x,y,z, and all three are independent Gaussians.
You see that the distribution is isotropic.
And in the movie version we can even turn around the distribution and look at it from all angles.
Does this make more adventurous?
Yes of course, let's give this distribution a haircut.
And as the distribution initially was isotropic, it remains isotropic on the unit sphere.
So we found an algorithm to put random pebbles onto the surface of the sphere.
Understand that isotropy does not simply mean that the points are on the surface of the sphere they are so by construction because we renormalized each point x,y,z to have a radius = 1.
Isotropy means that the distribution of points (the probability distribution) is uniform on the surface of the sphere.
So here is the program direct_surface.py in general dimensions.
It puts points randomly with a uniform distribution on the surface of the hypersphere in d dimensions.
Now, let us follow mathematically what is going on.
We have to use the concept of sample transformation.
Remember: sample transformation means that the changes of variables in the integral apply directly to the samples.
Integrated over the whole space, dOmega gives (2 pi) in two dimensions and (4 pi) in three dimensions.
So now see that the integrand depends only on r, it is equal to exp(-r^2 /2) and the differential dx_0 dx_1 ..
dx_(d-1) yields r^(d-1) dOmega dr.
So, for our d Gaussians, we end up with a distribution integral dr r^(d-1) exp(-r^2 / 2) integral over dOmega.
It is two independent integrals one in r, one in Omega.
There's no function depending on Omega, which shows that we are isotropic in angles on the surface of the sphere in d dimensions.
Finally, let's do a trick let's renormalize the radius r to be on a surface: r=1 and then blow it up again to have a distribution pi(r) = r^(d-1) between 0 and 1 rather than r^(d-1) exp(-r^2/2) from 0 to infinity.
What you obtain is written in this program: direct_sphere_3d.py and it is a random point inside the three dimensional unit sphere.
There's also a general program that allows you to sample a random point inside the d-dimensional hypersphere.
Before continuing, please take a moment to download, run and modify the programs we discussed in this section that means: take them apart and put them back together.
Molecular dynamics concerns positions and velocities, whereas the Monte Carlo method considers only the positions.
Why the velocities disappear from our Monte Carlo program and how we can make them come back deserves a most thorough answer.
To incorporate velocities into statistical mechanics, we again use the equiprobability principle.
For hard-disks in a box, during an event-driven molecular dynamics simulation, the energy is equal to the kinetic energy and it is fixed.
The equiprobability principle applied to these velocities means that the statistical weight pi(v_0, v_1, .., v_(N-1)) must be a constant if the vector (v_0..
v_(N-1)) is on the surface of these hypersphere, and 0 otherwise.
This means that the set of velocities is a random vector on the surface of the 2N-dimensional hypersphere.
Fortunately, we just became expert in the subject of sampling a random point on the surface of a hypersphere, using 2N independent Gaussian random numbers.
Remember that the algorithm direct_surface.py involves a rescaling of velocities.
but that this rescaling became unnecessary in high dimension if the variance of the Gaussian was chosen correctly.
This is the Maxwell distribution.
The total kinetic energy divided by d N is the mean energy per degree of freedom and it is equal to one half kB times T where T is the temperature in Kelvin and kB is the famous Boltzmann constant.
So finally let us look again at the Maxwell distribution which has the form exp(- energy / kB T) this is for one particle and one component but it also applies to a subsystem of particles inside a larger simulation box, for example cut-off by boxes that allow exchange of energy and momentum.
What we discussed here will be considerably deepened in this week's tutorial and homework sessions.
Next week we'll take out first steps into the field of quantum physics and quantum statistical mechanics.
In the meantime, have fun with tutorial 4 and homework session 4.
And see you again next week at Statistical Mechanics: Algorithms and Computations.
For four weeks now, we have concentrated on classical Statistical Mechanics, and from the equiprobability principle, we have just arrived at the Boltzmann distribution.
We will go even farther, into the world of quantum statistical mechanics, where we have at the same time the quantum wave functions and the Boltzmann distribution of thermal equilibrium.
In this lecture, lecture 5, we introduce to one of the basic models in quantum physics, namely a particle in a harmonic potential, described by energy levels and wave functions that we know exactly.
Here is the groundstate wavefunction of the particle, at energy E = 1/2.
The square of the wavefunction gives the probability for the particle to be at position x...
And here is the first excited state, with energy 3/2: the second excited state with energy 5/2 and so on and so on...
Wait a few moments to create all these states by yourself!
At a given temperature, these energy levels are subjet to the equiprobability principle and to the Boltzmann distribution.
In the lecture, in just a few moments, we will discuss exactly how this works, and this will lead us very quickly to the density matrix and the celebrated Feynman path integral that describes the spread of the wavefunctions through the fluctuations of a path.
We all know that at high temperature, the world is not really governed by quantum physics.
The essence of our approach to quantum statistical mechanics is a certain transformation called the Trotter decomposition, that iteratively brings us from the semiclassical world at high temperature down to the full quantum world at low-temperatures.
How this works exactly will be explained in this week's tutorial.
We will also discuss the time evolution and program the quantum equivalent of molecular dynamics for simple quantum systems.
The quantum mechanical harmonic oscillator describes a particle of mass m in a potential 1/2 m omega^2 x^2 governed by the Schrödinger equation.
Let us simplify this equation by putting Planck's constant h_bar = 1, the mass of the particle = 1 and the oscillator constant omega = 1.
This is not a restriction, and Michael, Alberto, Vivien, and I will present the most important equations both with and without the constants.
Its solutions, we saw them before, are the ground state wavefunction of energy 1/2, the first excited state of energy 3/2, the second excited state of energy 5/2, and so on, and so on...
In addition, they are normalized, which means that their integral from -infinity to infinity of psi_n squared is equal to one.
Finally, the wavefunctions are orthogonal.
You can check this for yourself.
To do so let's rewrite the Schrödinger equation as H psi / psi is equal to E, and let's write a little program "harmonic_wavefunctions_check.py" with a discrete approximations for the second derivative.
And for the first excited state, we find H psi_1 / psi_1 equals to 3/2 everywhere.
Now let us move right away into Quantum Statistical Mechanics.
Quantum means that for a particle in the state n, the probability to be at the position x is given by the absolute value of psi_n(x)^2.
Now let's put the two pieces together, and we find that the probability to be in state n and at position x is proportional to exp(-beta E_n) * | psi_n(x)|^2.
Before plunging into this subject, please take a moment to download, run and modify the two programs we discussed in this section.
There is also the nice program harmonic_wavefunctions_check.py that checks that the Schrödinger equation is solved, that the wavefunctions are normalized, and that they are orthogonal.
As we discussed a few moments ago, the probability to be in state n and at position x is proportional to e^-(beta * En) psi_n(x) psi_n*(x).
In this equation, the asterisk refers to the complex conjugate.
Notice that in this equation, we have two different types of probabilities.
We have the thermal probability of the Boltzmann distribution, and the quantum-mechanical probability of the wavefunctions: two completely separate worlds meet in this equation.
However, the energy levels and wave functions cannot *normally* be computed , and this expression leads nowhere, even for simple problems!
We also consider a more general object, the non-diagonal density matrix, which is equal to rho(x, x', beta) = Σ_n psi_n(x) psi_n*(x').
This is the central object of Quantum Statistical Mechanics.
For example, the partition function Z(beta) is given by the Trace of the density matrix.
As discussed in previous weeks, the partition function Z is the sum of the probabilities π_n; but here the n are no longer positions in space, but the energy levels.
We next discuss the three fundamental properties of the density matrix: First of all, each density matrix possesses the convolution property.
This means that the integral over x' of rho(x, x', beta_1)*rho(x', x'', beta_2) can be written as an integral over x' over a double sum over n and m.
This can be exchanged into a double sum over n and m over the integral in x'.
We find that the integral over x' of rho(x, x', beta)*rho(x', x'', beta) is equal to the density matrix rho(x, x'', 2beta).
So in this equation we compute the density matrix at 2beta, that means at low temperature, through a product over density matrices at high temperature.
We can use this equation if we know the density matrix at high temperature, to compute it at twice lower temperature.
The second property is the free density matrix.
Finally, the third property of the density matrix concerns the high-temperature limit for a Hamiltonian H = H_free plus a potential V, the density matrix at small beta (high temperature) is given by rho(x, x', beta) = e^(-beta/2 V(x)) * rho_free(x, x', beta) e^(-beta/2 V(x')).
So you see, at high temperature, the correction of the density matrix to the free density matrix is given by a simple Boltzmann factor e^(-beta V(x)) split into half between x and x'.
But notice that through this expression, we have an explicit formula for the density matrix rho(x, x', beta) without solving the Schrödinger equation, for any potential.
So this is the density matrix at high temperature (small beta).
So now, let us involve the convolution property, and from this density matrix at temperature beta, let's compute it at inverse temperature 2beta, 4beta, 8beta, 16beta, and so on...
We can reach the full quantum regime.
Please take a moment to download and to run this program as written, for the harmonic oscillator.
You can then modify it for other potentials by just changing an exponential factor, not by solving a new Schrödinger equation.
We will pursue this great story further in this week's homework session.
In matrix squaring, the subject of the last section, we convoluted two density matrices at temperature T to obtain a new density matrix at temperature T/2.
By iterating this process, we could go to lower and lower temperatures starting from the high-temperature quasi-classical limit.
Normally, however, we cannot do this matrix squaring analytically.
For a large number of particles, we soon ran out of space to store a reasonable discretized approximation of rho(x, x', beta) on the computer, so we cannot do the matrix squaring numerically here.
We now see how the Feynman path integral overcomes this problem, how it leads to the use of Monte-Carlo methods and to the idea of path sampling.
Instead of evaluating the convolution integrals one after the other, as we did in matrix squaring, let us write them out all together.
Each of the density matrices at beta/2 can be written as an integral over two density matrices at temperature beta/4.
This gives an integral over dx'', dx''', dx'''' of rho on temperature beta/4, beta/4, beta/4 and beta/4.
The idea we are pursuing is great, but we are having a notational nightmare..
Let us write {x0, x1, x2, x3 ...} instead of the cumbersome {x, x', x'', x'''...}.
For the partition function, which is the trace of the density matrix as we discussed before, we find that...
Density matrices and partition functions can thus be expressed as multiple integrals over paths variables, so called paths integrals.
In Markov-chain Monte-Carlo, we can move from one path configuration to the next by choosing one position x_k and making a little displacement delta x that can be positive or negative.
We compute the weight after the move and before the move and accept this move with the Metropolis acceptance probability.
Note that we can also move x0 which is between x1 and x(N-1) so that the path can move as a whole.
Configurations of a Markov chain simulation for the Harmonic oscillator are shown here.
In Python this gives the program naive_harmonic_path.py, that I ask you to download and to run from the Coursera website.
You will modify this program in this week's homework where you will do your own Markov-chain Monte Carlo simulation of a Quantum system, or a Path-Integral Monte-Carlo simulation.
In conclusion, we have plunged in this session of Statistical Mechanics: Algorithms and Computations into the world of quantum physics and quantum statistical mechanics.
The solution of the Schrödinger equation needs a new technique for each potential, and Feynman Path Integral is more general.
It is for this reason that it is so famous.
It naturally leads to the idea of Monte Carlo simulations, and Path integral Monte Carlo algorithms.
As we are becoming to be great experts in Monte Carlo simulation, of course this approach is just for us...
Finally, let me thank you for your attention, and see you again, in further sessions of this lecture course.
Welcome to the the seventh week of Statistical Mechanics: Algorithms and Computations from the Physics Department of Ecole normale supérieure.
This lecture is the third and last one on quantum statistical mechanics, and the lecture and the entire program of this week is dedicated to a discussion, and even a celebration of quantum-indiscernability and Bose-Einstein condensation.
Finally, in this week's homework session, you will take over yourself the path integral Monte-Carlo program that I present here and analyze its output at high and low temperature.
Before starting, let me explain our goals for this week.
Our discussion of Bose-Einstein condensation will result in a short Python program that produces the following output: you see configurations x, y and z of about 1000 ideal bosons in an harmonic trap at termperature T.
At a well defined temperature, Bosons clump together in the center of the trap: this is Bose-Einstein condensation.
You will create yourself the Bose-Einstein condensates later in this week, and you will also modify and analyze the program.
One thing you can do by just changing 2 lines in your program is to turn off the bosonic nature of particles and make them distinguishable.
So you see that Bose-Einstein condensation is due to the bosonic nature of particles, as the name indicates.
You can look at your Bose-Einstein condensates just like the atomic physicist who controls the atomic cloud through lasers.
don't forget to wear your glasses to protect youself against the powerful laser light!
To follow what we discuss here, you only need to understand what we discussed during the last 2 weeks: the density matrix, and the Levy quantum path in a harmonic potential.
So, let's get started, with week 7 of Statistical Mechanics: Algorithms and Computations.
Before running a quantum Monte-Carlo simulation for Bosons, we must understand the bosonic density matrix.
Let's go back to a single particle.
The partition function of a single particle at temperature T is given by....
or in other words, by the sum of all the paths from x to x, integrated over x.
Naturally, x can be a position in a 3-dimensional space, and the paths are independent paths in x, y and z.
The statistical weight of a position x = (x0, x1) involves a density matrix as before and the paths are now from x0 to x0 and from x1 to x1.
For non-interacting particles, we are already done: the partition function is the trace - the integral over dx0 dx1...
These paths are independent.
Now, interacting systems are described by paths whose weight is modified through the Trotter decomposition: this correlates the paths.
and we see that with this formalism, we describe in fact distinguishable quantum particles.
To go from distinguishable to indistiguishable particles is very easy, and we will restrict ourselves to bosons.
The partition function again involves positions, here on the bottom, and the same positions on the top.
This formula can be rigorously derived using symmetric wavefunctions, but its spirit is very clear.
For interacting particles, we can now cut up the density matrix into little slices, and interfere with the Trotter decomposition.
So here, we have a multiple integral over paths, and a sum over permuations.
The structure shown here is completely general, and the only simplification of the ideal Bose gas, is the fact that the many-body density matrix breaks up into a product over single-particle density matrices, or in other words, the fact that the paths are independent.
In this week's tutorial, we will analytically describe the partition function described in the last section.
But here, let us consider the sampling problem.
Let us consider the sampling of the permutations first, and let us radically simplify the problem discussed here by replacing everything that depends of space by 1, so instead of sampling bosonic permutations, we consider for a few minutes the permutations of n elements in a list.
At each step, we may exchange two random elements.
This random transposition algorithm, a Markov-Chain algorithm, is contained in the algorithm permutation_sample.py.
Look here, at the two indices i and j, and here, the exchange of L.
Ouput of this program is shown here.
The second element of our simulation program is the sampling of positions.
We can represent this permutation graphically, and you see there is one cycle of length 1, and one cycle of length 3: the cycle 1->3->2->1.
This cycle has a curious action.
Have you seen this before?
The integral over x3 is just like it was in the convolution theorem.
It gives the density matrix rho(x1, x2) at 2 beta.
and the integral over x2 again can be used in the convolution theorem.
So in this permutation part of the partition function, we have one particle, the particle 0, at temperature beta, and the particles on the cycle of length three, 1, 3 and 2, are in fact at temperature 3 beta, this means at three times lower temperature.
Analogously, we may sample the position x1 from the diagonal density matrix rho_harmonic of x1, x1, 3 beta.
The positions of x3 and x2 are the intermediate points in a Lévy construction at inverse termperature 3 beta with 3 slices at temperature beta and 2 beta.
In contrast, we must sample the permutations with the metropolis acceptance probability.
For example, in our permutation 0->0, 1->3, 2->1 and 3->2, let us pick 2 random elements, for example 1 and 2, and exchange where they point to.
The old weight of the permutation is proportional to...
and the new weight is proprtional to...
We accept this move with the Metropolis acceptance probability min(1, pi_new/pi_old).
For what follows, please take a moment to download, run and modify the program discussed in this section.
We have provided it again today.
To simulate ideal bosons in a 3D harmonic trap, we start with the identity permutation and with random positions sampled from the diagonal harmonic density matrix in x, y and z.
For each particle move, we sample a random particle, identify its permutation cycle, and sample a new Lévy quantum path for the entire cycle.
In Python, this gives the following program, markov_harmonic_boson.py This program has 2 functions: the first function, levy_harmonic_path, is used at multiples of the inverse temperature beta, corresponding to the length of the permutation cycle.
We use it to resample the positions of the entire cycle.
The second function computes the off-diagonal harmonic density matrix.
We use it to organize the exchange of two elements.
And here is the second part of this program.
After an initialization, exactly as announced, we enter a short iteration loop.
Then, we simply resample the entire path of the cycle from the Lévy quantum path.
And here, we pick two particles and attempt an exhange.
This is all there is to this program.
In this very short program, there are no particle indices.
The "values" of this dictionary are the positions at tau=beta, the positions of the permutation partners.
Output of markov_harmonic_bosons.py is show here.
At high temperature, particles are quite far from each other, and attempts to perform a transposition are usually rejected.
The transpositions are accepted and particles are on long permutation cycles.
In fact, they are in the ground state.
This is the essence of Bose-Einstein condensation.
We will treat it again in more detail in this week's tutorial.
In this week's homework session, you will take over the steering wheel of this beautiful program, and run it at high and at low temperature.
Notice this program is short enough for you to gain complete understanding of how it works.
So in conclusion, we have studied in this lecture Bose-Einstein condensation, and set up a really compact Path Integral Monte-Carlo simulation for hundreds and thousands of bosons.
More details will be provided in this week's tutorial and homework session.
So now, finally, let me thank you for your attention and see you again later on this week and in further sessions of Statistical Mechanics: Algorithms and Computations.
Welcome to the eighth week of Statistical Mechanics: Algorithms and Computations from the Physics Department of Ecole normale supérieure.
In this week's lecture, after a short introduction, we will treat Monte-Carlo algorithms for the Ising Monte-Carlo.
First, a local metropolis algorithm, and then, a global cluster algorithm.
Cluster Monte-Carlo algorithms originated here in the Ising Model, and they have since revolutionized computations in many fields of classical and quantum physics.
In the tutorial, we will consider the Heatbath algorithm, and illustrate one of its surprising features, namely that it couples and that it allows for perfect simulations.
So, let's get started, with the Statistical mechanics, and computational physics of the Ising model, and with week 8 of Statistical Mechanics: algorithms and computations.
The Ising model describes classical spins sigma that can be +1 or -1 on a lattice like the two-dimentionnal square lattice shown here.
We consider the ferromagnetic Ising model, where neighbooring spins prefer to be aligned.
Two neighbooring up spins or two neighbooring down spins have an energy -1, whereas two spins like this or like that have energy +1.
This gives an energy of each configuration like this, where the sum is over all pairs.
But attention: we count each pair only once.
For concreteness, here is a list of the 16 configurations of the 2 by 2 Ising model in two dimensions.
Without periodic boundary conditions, these two configurations have energy +4, these two have an energy -4, and all other configurations have energy 0.
For small systems, we can enumerate all configurations explicitely, and a nice little algorithm implementing Gray code enumeration is shown here.
Each configuration differs from the previous one on a single site only, and we don't have to recalculate the energy from scratch at each step.
It is sufficient to compute the field H on the spin that is going to flip and the new energy is then equal to the old energy plus 2*H*sigma.
Keeping track of the energy like this, we can compute the partition function as a function of the temperature, the mean energy, the mean square energy, and the specific heat: the change of the mean energy with temperature.
There are 2 things to notice: first of all, the specific heat, altough it is a derivative with temperature of the energy, does not have to be computed by numerical derivation.
It is simply given by a quantity that is proportional to the variance of the energy.
Secondly, to compute the thermodynamic quantities, it is not necessary to do the enumeration at all temperatures.
It's a lot better to compute the number of configurations per energy, the density of states.
We can do our enumerations up to system sizes of 4*4, or, with a little bit of effort, to 6*6.
But our pure Python program is a bit to slow for real number crunshing so, let's go ahead, and consider the sampling approach.
Before doing so, however, please take a moment to download, run and modify the programs that we discussed so far.
There is this nice little program enumerate_ising.py, that uses the Grey code enumeration for all the configurations.
Try to understand what the Grey code does, you may need it later.
In the Ising model, we can get very far by counting configurations even tough the listing of them becomes very difficult.
But in general, for large systems and systems that don't exactly correspond to the Ising energy - sigma_i sigma_j, the sampling approach is more reasonable.
Analogously to what we did for hard disks, we select one site and attempt to flip that spin on that site.
The move from configuration a to the flipped configuration b must be accepted with the Metropolis acceptance probability...
This program can be checked against the exact enumeration for small lattices, but I can assure you that everything comes out all right.
This program also very easily recovers the phase transition that takes place between the ferromagnet and the paramagnetic phase at a temperature just above 2.
You can trace this phase transition by plotting the absolute mean magnetization as a function of the temperature, even though there are more expert ways of locating Tc that you will discover in this week's homework session.
You can also simply look at the configurations as a function of the temperature, and you see a very clear qualitative difference between the paramagnetic regime at high temperature, and the ferromagnetic regime a lower temperatures.
Close to the critical temperature, the local Monte-Carlo algorithm slows down increasingly.
In a nutshell, this is due to the increase of the correlation length in the system, and to the fact that turning around a spin in a larger correlated region becomes increasingly difficult.
The large-scale correlations of the local Monte-Carlo algorithm close to the phase transition is also known in experiments and it is called critical slowing down.
Critical slowing down is overcomed by the cluster algorithms that we next discuss.
But vefore going to the next session, please take a moment to download, run ad to modify the programs that we just discussed: this is the algorithm markov-ising.py, with a local Markov-Chain Monte-Carlo algorithm, and its graphics version, markov_ising_movie.py.
Rather than flipping a spin indiviually at each timesteps, these algorithms construct larger ensembles, clusters, of the length scale of the system, and flip them in one step.
Suppose that, starting from a random initial site, rather than flipping the site on that site, we attempted to construct a cluster of connected up spins and flip them later.
Clearly, we cannot construct a cluster from all the connected up-spins, flip then, then construct a cluster of all the connected down spins, and flip them again.
Very soon, we would be flipping between the all-up and the all-down configuration and the Boltzmann probabilities would be violated.
So, from a spin already in a cluster, we should accept a spin outside of the cluster with probability p: sometimes we grow the cluster and sometimes we dont.
So here, in this example, we added all three new spins to the site already present all of them with probability p.
We added them to the cluster and also to a pocket, just to remember that we haven't checked their neighboors yet.
At some moment, the pocket is empty, for example for the cluster shown here.
You see, and can count for yourself, that accross the boundaries of the cluster, there are 18 links plus-minus and 14 links plus-plus.
For each of these 14 links, the extension of the cluster was rejected because at some time, a random number was drawn and was larger than p.
So then, we can flip this cluster and arrive from the configuration a to the configuration b.
Now you must take into account the detailed balance condition The statistical weight of configuration b times the probability to move from a to b must be equal to the statistical weight of configuration b times the probability to move from b to a.
The game is really played at the boundary: the probability to stop the cluster construction here in a differs from the probability to stop cluster construction in b.
So, each site on the boundary of the cluster in a was once a pocket site, and the construction of this cluster came to a halt because none of the edges accross the cluster was accepted, precisely, in this cluster a, they are 14 edges plus-plus and the extension was rejected with a probability 1-p for each of them.
So the a-priori probability from a to b is proportional to (1-p)^14.
There are 18 minus-minus edges in b, so the a-priori probability from b to a is proportional to (1-p)^18.
There are terms inside the cluster, also they are the same in a and b.
Now, in configuration a, threy are 18 terms plus-minus, hence 18 terms +1 and 14 terms -1 in the energy, or if we write N1 instead of +1 and N2 instead of the terms plus-plus, the energy accross the boundary is N1-N2 in a, and it is N2-N1 in b.
So with this value of p, we may simply construct the cluster, then start another one, construct the cluster and flip it, another construction flip, and so on.
This is the famous cluster algorithm by Wolff from 1989.
For each of the neighboors, you check wether it is not already in the cluster, wether it has the same sign, and wether a random number between 0 and 1 is smaller than p.
If these 3 conditions are satisfied, you add the new spin to the cluster and to the pocket.
Once you have checked all the neighboors of this spin, you take it out of the pocket.
Once the pocket is empty, you flip the entire cluster This is all there is to one of the most influencial algorithms in all statistical physics.
An example of how this cluster algorithm works is shown here.
Close to the transition temperature of the Ising model, enormous clusters are constructed, and they are flipped without thinking twice.
Very important it is to realize that the speedup it realizes with respect to markov_ising.py increases with system size, so for a small system it may be 10 times faster, for a larger system 100, 1000, 1000000...
So before continuing, please take a moment to go over a derivation of this cluster algorithm and then to download, run and modify cluster_ising.py, to see how these simple ideas are implemented in Python.
In conclusion, we have introduced in this lecture to the Ising model and its associated Monte-Carlo algorithm.
What we have presented here, and what we can program in just over a dozen lines today, has taken several decades to develop.
But there is a second reason, and the second reason is that the observables of the infinite systems are quite different from the observables in the finite system.
The extrapolation from the finite system where we can do our calculations to the infinite system which we are really interested in, is halas non trivial.
The second crucial period of Monte-Carlo calculations came in the 1980, when it was found out that critical slowing down was not an inescapable faith for algorithms as it is for experiments, and this was realized when the first cluster algorthms came out.
These cluster algorithms realized non-physical dynamics but they satisfied detailed balance, so there final state is exactly the same as the one of the local algorithm.
As we have seen, they do through configurations at breathtaking speed without suffering from the critical slowing down.
We will immerse ourselves farther in this fascinating subject in this week's tutorial and homework session but for the time being, let me thank you once again for your attention.
See you again next week, in week 9 in Statistical Mechanics: Algorithms and Computations, for faster-than-the-clock algorithms.
So good luck with this week's homework session, homework session 8.
This week's lecture is devoted to a discussion of the alpha and the omega of Monte Carlo.
The alpha will be Count Buffon's legendary needle-throwing experiment that has fascinated many people children and adults, learning circles and noble courts ever since its invention in 1777.
The omega will be Levy's stable distributions, that anybody interested in statistics and especially in Monte Carlo algorithms has to be at least aware of.
It will lead us to a discussion of the case when the variance of an observable is infinite.
So this week's tutorial will contain a short review of all the material covered in these ten weeks, and then we'll have a party.
So, let's get started right away with this week of Statistical Mechanics: Algorithms and Computations.
The experiment consists in randomly throwing needles of lengths a, onto a wooden floor with cracks that are a distance b apart.
So, let us introduce variables.
x and y (clearly y is irrelevant to the problem) and r_center and phi.
All the cracks in the floor are equivalent and there's a symmetry between the tip and the eye of the needle and there's also a symmetry between phi and -phi.
So we may look at a reduced problem, where phi goes from 0 to pi/2, that means to 90°, and x_center goes from 0 to b/2.
Now, the x variable of the tip is given by x_center - (a/2) cos(phi) and if x of the tip is smaller than 0, we have a hit.
More precisely, the number of hits of a needle centered at x and oriented along phi is given by N_hits(x,phi) which is given by this formula.
And the average that we want to compute is given by the integral (as we have many times in this course) over x from 0 to b/2 over phi from 0 to pi/2 N_hits(x,phi) divided by the normalizing integral dx from 0 to b/2 dphi from 0 to pi/2.
This gives the following integral.
So, we have the solution of our problem under the condition that we know how to integrate dx from 0 to 1 of arccos(x).
Well, think about it twice and you'll find out that it would have been wiser to first integrate over x and then integrate over phi.
And we find that the expected number of hits is proportional to an integral dphi from 0 to pi/2 of cos(phi), and this integral we know how to do it, it is equal to 1.
So we end up with the result that the expected number of hits is (a/b)(2/pi).
So in the special case when the length of the needle a is equal to the distance between the floor boards, we find that the number of hits is equal to 2/pi.
This is what has fascinated many people since 1777.
We can now write a program to do the Buffon experiment ourselves.
So now we can do Buffon's experiment for as many needles as we want and you see here the output for 2000 needles being thrown on the parquet.
Let's look at this program, the output, and let's ask a question: how do the needles hit the cracks?
Do they hit the cracks more at the tip?
Can you tell from this picture?
Mathematically speaking we can introduce an internal variable l, that goes from 0 to a and N_hits can be written as an integral over l from 0 to a, of N_hits(l).
Now, we can go into a mathematical argument and a probabilistic reasoning.
But it is much easier to look at this question experimentally.
So now, in order to find out whether we have more hits at the eye, at the center or at the tip, and in order to avoid getting into probabilistic arguments let's take a second needle.
Here, and let's make a little gadget.
All right, you see that the center coordinate of one of the needles is equal to the eye coordinate of the other.
You see that the number of hits at the tip of one of the needles must be equal to the number of hits at the center of the other needle.
But because these needles are equivalent, we have proven, more or less, that the probability or the mean number of hits at the center must be equal to the mean number of hits at the tip.
Now, we could glue together the needles at different parts..
and we prove like this that the hitting probability N_hits(l) must be independent on l.
And by this we can prove that N_hits is equal to a constant times the length of the needle.
And this we already saw in our starting calculation, because the number of hits was proportional to a, the length of the needle.
So now, can we compute Upsilon without doing a complicated calculation and computing the integral of arccos(x)?
Indeed we can.
Because the world of gadgets is not limited to straight gadgets: we can glue together the two needles, like this, at an angle.
All right, so this is my gadget number 2: it is a needle, a bent needle that also has an internal variable l that goes from 0 to the length of the needle, and I can throw this gadget.
And this remains true even if the needle itself was not just the joint of two straight needles, but even if it was a curved needle.
So we find a very strong generalization that the mean number of hits is equal to Upsilon times the length of the needle, independently of the shape of the needle.
So now this has a very strong consequence, that was first found out by Barbier in 1860.
He considered throwing needles of length pi times b.
Now, we can do the same experiment with needles of lengths pi but of different shape, we can take round needles of length pi, and let's throw them: first, second, third, fourth and so on..
But for the round needles, we also have the law that the mean number of hits, which is equal to two, is equal to Upsilon times the length of the needle.
But this length of the needle is pi.
And you see that Barbier was able to compute for us the outcome of the original needle experiment without ever doing the experiment.
He found without any calculation that N_hits must be equal to 2/pi times a/b, and that is the final result.
But now, wait a minute.
wait a minute, we find that the outcome of the round needle experiment is the same as the outcome of the straight needle experiment?
No, of course not.
So for the straight-needle experiment, as a function of x and phi, we see that we can have 0 hits, 1 hit, 2 hits, 3 hits and 4 hits, and we find out that the mean number of hits is equal to 2.
This would be quite a complicated calculation, if we did it ourselves.
And it would be quite a complicated Monte Carlo simulation, because we would have a lot of fluctuations.
Now, let's look at the landing pad of the round-needle experiment.
Again we have the variables x and phi and the number of hits is 2 everywhere.
We have no fluctuations and the outcome also is 2, but the two experiments are of course different.
So if we are only interested in computing the mean number of hits, we are much better off in changing our experimental set-up and doing the round needles, rather than the straight needles.
What I explained here in a very simple setting but the very famous setting of the Buffon-Barbier needle experiment, has many applications and it is called variance reduction.
So this variance reduction is a powerful concept, it means that we will re-do a new calculation and think about a new set-up of our algorithm for any observable that we want to compute.
So before continuing, please take a moment to download, run and modify the two programs that we discussed in this section.
And especially try to think over this amazing algorithm by Barbier, telling us that the mean number of hits is proportional to the length of the needle, independent of the shape.
This is called Barbier's theory.
All during this course, we have insisted on the relationship between sampling and integration.
We call it the gamma integral: integral from 0 to 1 of x to the gamma.
So let's do this integral by sampling.
Simply take x as a random number between 0 and 1 and compute this random number to the power of gamma.
This is done in the program direct_gamma.py.
And we are adding a few lines to do the error analysis.
We compute the mean value, we compute the mean square value, and afterwards we output the value of the gamma integral +/- the error.
Notice that here we have direct sampling algorithm, not a Markov chain sampling algorithm, so that the Gaussian error analysis is ok.
So, output of this program direct_gamma.py is shown here for gamma=2 1, 0, -0.2, -0.4, -0.8.
You see that most of the times the outcome of the integral +/- the error agrees with the analytical result.
But for gamma=-0.8, where the programs runs just fine, we get the result that the gamma integral is equal to 4 +/- 0.1.
So, all during a very long simulation, we output what would be the current estimate of the gamma integral, by computing the sum of the observables the random number to the power of gamma, divided by the length of the run.
We see initially we have very unpredictable results, and then for very long time the simulation zeros in on a result which is different from 5, the exact value.
So here we see that we approach wrong result and all of a sudden we go through the roof and we continue our calculation.
So, clearly because the running average is constant we also have an error estimate the average over dx of x^(2*gamma), which comes out much too small.
Now let us analyze what is the problem here.
Clearly the situation is very difficult to analyze in the absence of an analytical solution.
Now we continue in two steps to analyze the gamma integral.
What we'll do in the first program, direct_gamma_average.py, is to take the average Sigma/N and to compute the probability distribution of Sigma/N as function of the length of the interval over which we average.
We take N=1, 10, 100, 1000, 10000..
for N=1, we have the original integral and its probability distribution is given by pi(Sigma/N) =(Sigma/N)^(-1+1/gamma) as we discussed previously in lecture 4.
All the averages are equal to 5 but the most probable values only very slowly approach 5.
So finally, let me give you without justification a way to rescale all these curves onto one universal curve.
So this rescaling is the following, instead of considering the probability distribution of Sigma/N, we consider Sigma/N minus the mean value divided by N^(-1-gamma).
In our case gamma=-0.8, and the mean value is equal to 5.
So we have to look at the histogram of the mean value Sigma/N minus 5, divided by N to the -0.2.
And you see that the same data that depended so much on N, fall onto the same curve approximately for large N.
This is written up in the program direct_gamma_average_rescaled.py which also contains the analytically known limiting distribution in the limit N going to infinity.
And what Levy showed in the 1930s is that this very erratic distributions, as we saw in our initial calculations, satisfy very strict laws and obey in the limit N going to infinity if they are properly rescaled, they obey these stable distributions.
So before concluding this lecture and this whole lecture series, please take a moment to download, run and modify the programs we discussed in this lecture.
Then there was direct_gamma_running.py, the program that computed the running average and had this point going through the roof.
So let me thank you for all of your interest and very active participation during this course.
My name is Erick Hyde, the university connection councilor at the English language programs of the University of Pennsylvania.
As you work your way through this course, you're going to learn all about the US application and admission process.
From how schools evaluate applications to how to research colleges and universities to how to find the right school for you, and much more.
We created applying to US universities especially for international undergraduate applicants by building the course on the most common questions, misunderstandings, and myths among international students.
And there are a lot of them.
Before we really get into the course, we want to share some perspective on one of the biggest misconceptions.
The idea that applying to US universities is a complicated competition to win an acceptance to a very limited number of top schools.
Because attending one of these schools Is the only way to ensure a bright future.
This idea is mistaken and misguided.
Why do we believe the myths of US admission?
Why do we believe that the US admission process is a competition?
Why do we believe that the process has to be brutal and stressful?
Why do we believe we have such limited options?
The answer is easy.
That's what we're told all the time.
When you look at articles, websites, movies, everything tells us that admission is an impossible, stressful competition that rarely ends well.
Schools like the Ivy League, Stanford, MIT, and other familiar names that accept a small fraction of their applicants.
Media helps to create the focus, but its parents friends and society that reinforce that narrow focus.
When I was a kid my mom bought me a Yale sweatshirt.
I no idea what a Yale was but I wore it.
I didn't go to Yale, but I still remember the sweatshirt.
Take a look at this graphic from the college board.
US colleges and universities are divided according to the percentage of applicants that they accept.
That almost invisible 2% of the pie represents schools that accept less than 25% of their applicants.
That means 85% of US colleges and universities accept half, or more than half, of the students that apply to their school.
This graphic always puts thing in perspective by reminding me that highly selective schools are literally the smallest piece of the pie even though they get the biggest amount of attention.
Speaking of fighting for a small piece of the pie.
Check out this information specifically about international students.
This report provides information about international students studying in the US.
According to the open doors report, 69% of international students in the US are clustered at only 5% of the schools in the US.
So just over 200 US colleges and universities host a majority of the international students attending school in the US.
The reality is that the US admission process is what you make it.
If you or your parents choose to focus on the smallest slice of the pie, or those same 200 plus schools that most international students go to, then you and your admission experience are falling right into the mitts.
However, if you look beyond the 2%, if you look beyond those 200 schools, you're going to be pleasantly surprised by what you find.
Another reality is that you, possibly encouraged by your parents, will probably chose to apply to those schools where the competition for admission is the toughest.
In fact, as you'll see later on this course, we encourage students to aim high and apply to highly selective schools.
If those schools are a good fit for you.
What I am asking you to do, is remember that there is a much bigger piece of the pie that you should also consider.
The good news is that this course will help you, no matter what type of school you're applying to.
We're going to help you understand the application and admission process for them all.
Because the reality is that US colleges and universities want you as a student and a member of their campus community.
You can treat the process like a competition.
You can choose to be anxious and stressed about admission.
Or, you can choose to understand the process.
You can explore the possibilities and treat the process like an adventure.
You can choose to be optimistic and positive about admission.
No matter what, this course is going to help you.
One very crucial aspect of sustainable development is economic well-being and prosperity.
There have been great gains in material well-being.
In average income per person, in other indicators of material life, such as health and life expectancy, over the course of recent decades.
We'll see, of course, that these are not gains enjoyed by everybody within a country, certainly not in all parts of the world.
But on average there have been very notable gains in economic well-being achieved through decades of economic growth.
Perhaps their, their greatest goal is to achieve economic growth so that they can narrow the gap in material conditions that they face today with respect to the richer countries.
If those countries living in extreme poverty today where, that they can hardly meet their basic needs, are aiming to live like more of the world that increasingly has assurance of basic needs, and many parts of the world that live with remarkably high standards of living.
Another aspect of this material change is that in a world of greater production greater ability to grow food greater productivity in manufacturing, in transport, in power and in other key parts of the economy.
It's roughly tripled since then, absolutely extraordinary to around 7.2 billion people today, and the numbers are continuing to rise.
Roughly an increase of 75 to 80 million people added to the world's population each year.
Meaning that it won't be long, probably around 2024, 2025, when another billion people will be on the planet when we'll reach the 8 billionth person.
Let's look at what growth really means and there has been no, exemplar of economic growth more remarkable than China.
Of course, it's the world's most populous country, with 1.3 billion people.
So anything major that happens in China is earth shaking.
But also China has been among the fastest growing economies in world history.
Since China undertook some basic market reforms, after 1978 until just about the last couple of years when growth has begun to slow a little bit, China was averaging roughly 10% per year economic growth.
Absolutely astounding, and it's very handy, you know, something that I'll refer to many times to use what we call the rule of 70.
Take the number 70, divide it by the growth rate in this case 10, 70 divided by 10 is 7.
The rule of 70 says 70 divided by the growth rate gives you the number of years to double the size of the economy.
Well, what does that mean?
Shenzhen is a city very close to Hong Kong in southern China.
And in 1980, or so, when you receive this picture, Shenzhen was a small village, mainly rural not very many people perhaps 30,000 people living in Shenzhen.
Now, take a look at Shenzhen today, nearly 10 million people, Shenzhen has become a modern metropolis, it's a major manufacturing hub for the world.
From rural agricultural livelihoods to modern urban manufacturing and services and in a matter of three decades.
While most of the world's not going to experience a Shenzhen like change.
But that basic pattern of economic growth a transition from poor, small-holder farming to modern manufacturing, especially modern service economy, is part of the normal pathway of economic growth.
And while very few places grow at the rate of 10% per year with a seven year doubling time, it's still is the case that many parts of the world, even many of the poorest parts of the world today are experiencing significant economic growth, and with that a significant transition to urbanization.
Any significant transition from agriculture, to manufacture and especially to services.
If you look at the next graph, you see something also, absolutely astounding that we really need to keep in mind, and that's demography.
In other words, change of world population.
Now, this is a graph that shows you the long, long haul over the last couple million years, even before there was the modern human species.
But let's just take the human part of this and what we call the neolithic era, that's since the age of agriculture began around 10,000 years ago.
Well, the human population for a long time if you look at the picture from 10,000 years ago, maybe 7 or 8,000 years BC, was less than a half a billion people.
Of course, nobody knows but maybe, 300 million people of all the people on the planet.
That number did not change very much for a very, very long time the graph is quite flat numbers rising, and maybe to 4 or 500 million people in 1AD.
And that tells you that over much of human history since the beginning of agriculture, human population did not change very much.
But take a look at the right hand side of the graph, all of a sudden, the population begins to soar.
Just about the time of major breakthroughs in technology around the industrial revolution the beginning of the era of the steam engine in 1750 or so, we see the population curve turning up and turning up remarkably steeply.
Around 1830, humanity reached the great milestone of a billion people on the planet.
So for thousands and thousands of years, the population was under 1 billion.
Then from 1830 to 1930 just in one century, the second billion was added.
But then the numbers really started to soar, because from 1930 to 1960, just 30 years, the third billion was added.
We're on track to go from 7 billion, reached in the year 2011, to 8 billion, probably around 2024 or 2025, 9 billion sometime in the 2040s.
So this change of population is absolutely astounding.
Our age is an age of economic growth combined with rapid population growth, and together, those two dynamics have meant a massive expansion of economic activity, of total output produced on the planet each year, and of course, alongside that, a massive increase of humanity's impact on the planet.
And that is one of the great challenges in sustainable development.
Now, another bright spot of recent development, is that alongside that economic growth, and alongside the rise in population numbers, has also come improved health.
Around 1950, for every 1,000 children who were born, an estimated 134 out of the 1,000 would not survive till their first birthday.
It tells us how many children won't make it to the first birthday.
37 children still don't make it to their first birthday, dying of malaria or, pneumonia, or other preventable diseases.
Millions of children, dying before their first birthday, still of preventable and treatable causes.
We'll talk about that.
But taking the historic trends, to drop from 134 to 37, is a real accomplishment.
And one that has improved the quality of life and certainly eliminated a lot of the tragedy and anguish that was part of humanities existence until the improvements of public health, and modern medical care.
With more children surviving and with health improving at older ages as well, the good news is that our life expectancy is also rising, and rising very considerably.
Take a look at what's happened to what we call life expectancy at birth.
That is statistically the, the average length of a life span taking into account the risks of death at each age.
In the middle of the last century in the period 1950 to 1955, the average life expectancy you know, for people on the planet was around 47 years.
Pretty short.
As of today, the estimated life expectancy at birth is more than 70 years.
Or roughly 71 years.
And in the high income countries, around 80 years.
This is another example of economic growth and material progress, and an example of the kind of progress that is being achieved in most parts of the world.
What's the lesson?
The lesson is that this first pillar of sustainable development, economic well being, is something that's achievable, and being achieved in large parts of the planet.
There are fewer tragic deaths of young children, and greater health and longevity for most of us, with life expectancy rising several decades from what was experienced in the middle of the last century until now.
This shows, while economic development can improve lives, lives in which one can have the confidence that their children will also grow up healthy, survive, and have good prospects in life.
So that the progress itself doesn't cut our natural life support systems of biodiversity, food productions, safe climate productive oceans.
Because if we do that, the gains that we've made will turn out to be fleeting and evanescent, that could lead to real tragedy.
So it's that holistic approach of ensuring, that economic growth and material improvement, is socially inclusive and environmentally sustainable, that is the great challenge.
A billion people roughly live in the high income world.
Another billion, roughly, that live in the poor countries, the low income world.
And then another 5 billion, 5 7ths of humanity are in between, in the middle income countries.
How did this vast difference unfold?
How is it that we have countries like the United States, or some even richer at $50,000.00 per person, per year of income or higher?
And some countries like Mali, or Malawi, or Niger at under $500.00 per person per year, less than 100th the income levels of the high income countries?
We certainly didn't start this way a couple of centuries ago.
If you look back to the period just before the great take off of modern economic growth, just before what we call the industrial revolution, the world was fairly equal.
Just about every part of the world was rural.
Just about every part of the world had its population and its workforce engage in trying to stay alive as peasant farmers.
When it was a bad season, bad rains, heat wave, drought people not only suffered, they died.
And that kind of extreme poverty was pervasive.
It was in Europe, as well as in Africa.
The world was in a condition of not complete but nearly complete equality but equality of poverty.
The story of today's inequality therefore is also the story of modern economic development what has been called the era of modern economic growth.
That's the period since the start of the Industrial Revolution when some parts of the world were able to experience sustained increases of gross domestic product per person.
So much so that they transformed themselves from rural to urban, from peasant agriculture to modern industry and, increasingly these days, to a modern, high tech, knowledge intensive, information and communications technology intensive, service economy.
How did this happen?
And why did it happen in some places in the world, but obviously not in all parts of the world?
From two centuries ago they started poor and by and large, they remained poor.
Other parts of the world started poor and by today are very rich.
We need to understand the nature of that economic growth.
And of course why it has varied so much across the world.
And what can be done to unlock that economic growth in today's low income and especially today's least developed countries.
All this takeoff of modern economic growth, the Industrial Revolution and all that followed, is a new event from the point of view of human history.
We are about 10,000 years as civilized Homo sapiens, meaning living in communities dependent on sedentary agriculture rather than as nomads hunting and gathering.
So the neolithic revolution which brought us agriculture is about 10,000 years ago.
But for a very long time, from the advent of agriculture into the Industrial Revolution itself, progress was very, very gradual, almost imperceptible.
We see that very starkly in the depiction, as best it can be estimated, of the growth of the world economy.
Have a look at this graph.
The line of the world output is essentially flat, nearly at zero, for thousands of years.
And then it shoots up if we are looking at the total production for the world til today.
When you think about the total output of the world, which is the sum of the gross domestic product in each country, we can think of that as having two parts.
Was it due to rising output per person, or was it due to a rise in the number of people?
What do I mean by yes?
Both factors have played a huge role, and strangely enough, nearly simultaneously.
The world population went up and down by small amounts for 2,000 years, roughly half a billion people, on the planet.
But it was very stable, fluctuating around a narrow range.
Starting in the middle of the 18th century just like the picture for the total world output when we'd look at the picture for the world population, it just turns steeply upward.
Well, it's obviously related to the fact that because of changes in the economy, changes of know how, more people could be supported because more food could be grown.
Economic growth in the sense of a rise of gross product per person.
Starting around the middle of the 18th century, just as with the population and with the size of the overall world economy, that graph shoots upward.
Suddenly, the world shows a sustained and significant increase decade after decade in the output per person.
Of course I have to caution, these are estimates, from various kinds of evidence, of what the world looked like before 1750.
But it was not a world of economic growth.
It was not a world of wealth and poverty.
It was a world of poverty.
It was a world that could produce great monuments beautiful treasures for human history.
The Great Wall of China or Hagia Sophia in Constantinople today's Istanbul.
But it was a world in which most people lived difficult lives, scratching out an existence, trying to grow enough food to survive season by season.
One of the greatest economists of a modern history one of the leading thinkers of the 20th century, John Maynard Keynes, wrote a quite remarkable description of this long, long period of near stasis.
Near stability and unchanging technology from the time of the Roman Empire until the onset of the Industrial Revolution.
And I'd like to quote from one of his great essays, Economic Possibilities for our Grandchildren, written in the great depression of the last century, saying how powerful technology can be to help humankind improve its lot.
Keynes wrote, and I'm quoting, from the earliest times of which we have the record, back say to 2,000 years before Christ, down to the beginning of the 18th century there was no very great change in the standard of life of the average man living in the civilized centers of the earth.
Almost everything which really matters and which the world possessed at the commencement of the modern age was already known to man at the dawn of history.
Wheat, barley, the vine and the olive, the plow, the wheel, the oar, the sail, leather, linens and cloth, bricks and pots, gold and silver, copper, tin and lead, and iron was added to the list before 1000 BC.
Banking, statecraft, mathematics, astronomy, and religion.
Same techniques, similar living standards a world that would have looked quite the same over a span of 17 centuries.
But then dramatically everything changes and that is our next subject.
To understand the Industrial Revolution, how it began and how it changed human history and human destiny.
The industrial revolution had occurred.
The new era of modern economic growth was underway and markets drove this process.
First in a highly uneven way, where just a few parts of the world were party to this new form of industrial economy.
This is the period that the great economic historian and great conceptualizer of economic growth, Simon Kuznets called the era of modern growth.
Now we have defined economic growth as the sustained increase of gross domestic product per person.
Or if we look at the whole world, we can call it the gross world product, which is the sum of the gross domestic products of all countries divided by the world population.
And in the era of modern economic growth, the period studied by Simon Kuznets.
That world output per capita has increased on a sustained basis for more than 200 years now in a very, very uneven way, however.
Some places have achieved marked economic growth for nearly two centuries.
Some remained poor almost until the current day and some very particular places in the world, the world's poorest, of course are places that have not yet achieved that takeoff of modern economic growth.
We need to understand that process and in order to do so, we need to make a quite basic distinction of two kinds of economic growth.
One kind of growth is the growth of the technological leaders in the world.
In the early 19th century that was certainly England, this is where the industrial revolution occurred.
In the 20th century, the United States was by far, the most technologically dynamic part of the entire world though, a number of other countries certainly and inventors in different parts of the world contributed to the world wide stock of technological knowledge.
But for those leaders, there is a very particular kind of economic growth driven by technological advance.
By new discoveries, innovations, new ways to do things that then spread and give an impulse of sustained growth to the economy.
That's what happened after James Watt invented his improved steam engine in 1776.
It was taken up in factories.
It was taken up in mines in the locomotives of steam engines, in steam ships and in many other technologies.
There's a second kind of economic growth.
That's the economic growth of a country that for whatever reason of history and geography, perhaps resource-based, perhaps just bad luck or bad policy stayed back as those leaders charged ahead.
And so a country like China, for example, did not industrialize in the 19th century.
Where England and the United States and Germany and other countries partook of the Industrial Revolution and developed industrial economies.
At some point, countries like China and we could say, any of the emerging economies today.
And those laggard countries had to solve a problem.
How do we catch up?
And that gave rise to a different kind of growth.
And that is the kind of economic growth where a country that is lagging in technology and in income per capita makes a tremendous advance quite rapidly in narrowing the technological gap with the leader.
These two different mechanisms of growth.
And the second one based on closing a gap that has opened up by taking on the technologies of those advanced countries that have already been able to use them form the two major ways that economic growth proceeds in the world.
The failure to understand these differences leads to all sorts of confusion in the discussion of economic development.
Because the kinds of institutions that countries need to innovate, for example, to have that first kind of growth, endogenous growth.
Those kinds of institutions, where the goal is to close a gap as fast as possible with the countries in the lead.
For those institutions, a stronger role of government, for example, can often be a major spur to a rapid, rapid push of economic growth to close the gap that has already opened up.
You don't need so much innovation, but you do need widespread investments.
And so understanding the two kinds of growth, and therefore the two kinds of institutions that are needed to solve the growth problem, is tremendously important.
I wanna focus first on endogenous growth, the growth of the technological leaders.
It's the kind of growth, where one good thing leads to the next.
Economists sometimes call this an increasing returns to scale process and you get an ongoing process out of that, that can be very dynamic.
Clearly, in the case of modern technology, going back to the onset of the Industrial Revolution.
There have been many theorists of those waves.
Kondratiev, the Russian technology historian was one of them with great influence in thinking from his writings until now.
And one can think about the era of modern economic growth from the middle of the 18th century until now, having a series of waves.
Some people say, three waves of industrial revolution, others date them as four waves.
But the notion is that these waves of technological change in the leading countries are the drivers of this process of endogenous economic growth.
The first of these Kondratiev waves in this particular classification puts the steam engine at the core from 1780 to 1830, roughly from the time of James Watt's invention to its widespread application.
The second of these waves is the great burst of railway and steel.
And even if the technological roots of railways and steel come before 1830, the takeoff of those industries could be dated roughly to that time.
The third of these waves is the age of electricity.
Again, the discoveries of electricity date back to Benjamin Franklin, flying the kite and understanding electricity in the atmosphere.
Static electricity to Michael Faraday and the discovery of induction and the beginning of understanding of electromagnetism like in the first half of the 19th century.
After the age of electricity, which is put 1880 to 1930 is a fourth wave led in this classification by automobiles and petrochemicals.
Plastics and new polymers and new materials industries and much more.
One could add, of course, the age of modern aviation.
Again, the underlying technologies for the automobile date to the end of the 19th century.
But the economic, dramatic application began in the early years of the 20th century with the Model T, with Henry Ford's inventions of modern production processes on the factory line.
And with the mass production of automobiles, which absolutely transformed the way we live, where we live, how we produce.
This is the knowledge economy, the age of computers.
The great advent first of the huge mainframe computers in the 1930s and 1940s.
And then the discovery of the transistor at the end of the 1940s and the invention of the integrated circuit, which gave rise to the modern computing age, mobile phones and all of the rest of industry that has been made possible by Moore's law.
This means that the ability to process, to store, to transmit data has roughly doubled or the cost of doing so has roughly fallen by half every 18 to 24 months.
Well, you do that over a period of more than 50 years and you arrive at roughly a billion time improvement in the ability to process, store, and transmit information.
And we know that is revolutionizing the world in this great fifth wave of the information and communications technology driven era.
Ways to produce energy, ways to mobilize energy.
We've had now 250 years of modern economic growth.
We've had waves of great technological change.
And we need to enter a new era, a new wave of technology of sustainable development technologies in the way we live, the way we protect the planet.
And also grab on to some of the great scientific and technological insights that we have at hand to give us hope and confidence and determination to move forward to that next great wave of endogenous growth.
Thanks to Susan for posting question four which was about how to engage younger students in social media appropriately.
How can we actually set the tone of the conversation?
How can we make sure the language is appropriate?
So, there's some really interesting questions, particularly with younger students.
So, I don't know if, necessarily, the answer needs to be focused on younger students but to any students.
So, I think the question was around, so you're using some sort of social media tool, or maybe even a discussion forum at that.
They're engaged but they're, I don't know, maybe talking about a party on the weekend or something completely irrelevant to your course.
And how can you go about dealing with that, and I don't think that just happens amongst younger students.
I'm not sure what younger was referring to in the post, but- >> 12, 13.
But could also potentially happen amongst undergraduate students as well.
So I would say that for designing your activity, you want to make sure, and I think Claire brought it up in the thread as well.
What's the etiquette behind it, and I know sometimes people call this Netiquette.
What you would talk about in the forum, staying on the topic for example, and what would be appropriate for that but at the same time, realizing that the students need a place to also potentially have some of that social conversation that's not on topic necessarily.
And particularly, I suppose because the post was about 12 or 13 year-olds, who might necessarily be allowed yet to be on Facebook, where, like I said in one of the previous questions this week, a lot of students set up for those kind of conversations.
>> because the interesting thing is, I've wanted to say something for awhile.
>> The interesting thing is that I think Susan was saying that she has given the students guidelines.
>> But it just doesn't seem to work for them.
And I think that point you made about allowing them to have a control, the outlet for that, because when the people get together, they're going to chat about things.
So, making sure that it is contained, but you have very specific expectations about what happens in the other places, is really important.
I'm not sure if you are in this space with the students, participating.
But what I've found, and admittedly it's with older students, but what I've found is when I'm in there setting the tone, using certain language, that the depth of the response that I give, the students actually tend to follow that.
So that's one of the most important things, I think is that expectation, but the demonstration of how it works in reality.
And Eddie, I think, in the thread, also mentioned something about building digital literacy within the students.
And that is part of the expectations, but also, I guess, an understanding of appropriateness of behavior in these different places.
There will be those expectations of what happens in these online spaces.
They're changing all the time, but I think it's important to start bringing that in.
So yeah, in terms of making sure they do that, I don't think we have all the answers because no, not any students, there'll always be ones that don't participate the way you want them to.
I think those are some good suggestions that we've got, and other people have shared in that thread too.
Today is the first day, or, first week, actually, of the class.
And, I talked about the various aspects of the class that previous session.
But, just to give you a sense of my style, I'm hyper, I'm nuts, I love this stuff.
And I talk about life and so on as we go along, and the good news is you can always skip parts you don't enjoy.
Whereas if you were in the class you'd have to suffer me throughout the class.
So what I'm going to do today is I'm going to start off with the content.
And this is what I do in class too.
The first week, if it's left just introductory, I don't think it's right.
And I will stop the topic.
One important aspect I want you to recognize, is that typically, in real time, when you're teaching classes like this, the amount of exposure the students have to a teacher, or the classroom time, if you may, is a lot more than on video and video is very intense, there's very few interruptions.
But on the other hand as I said you can keep learning from others and you can keep going back to the video.
I want to emphasize this every time, is that the good news is you have the video and I want the video to be self-contained.
In fact, I encourage you if you really wanted to learn, and I've thought about this a lot.
I was inclined to give you a lot of material.
So we'll talk, start talking about the time value of money today and we'll continue this in the next week.
And the reason is, time value of money is central to understanding finance.
So let's get started.
I want to pitch the beauty of finance.
If you remember, as its ability, the structure, and the details and the tools.
The ability of finance to solve or, I shouldn't say solve, but to understand decision making and make good decisions.
So I hope you recognize that.
So what is really critical to decision making?
Every decision involves time and uncertainty.
I have emphasized this in the introduction of the class, and I will keep emphasizing it.
And it'll, life will be so cool.
Because your framework is so strong.
So time and uncertainty, these are, these are common to every decision.
Whether you want to cross the street or whether you want to create a new technology to solve poverty, which I hope you do.
Okay, very important to understand just the impact of time on a decision and that's what we call time value of money, typically.
We ignore uncertainty for some time and I'm going to do that in a very deliberate way.
And just to read, emphasize this issue, I am putting it as a bullet point, and so that you can make notes on this.
We got to internalise the time value of money.
And I am going to spend a lot of time on each one of them before jumping into actually talking about Finance.
So you can think of it as the language of finance that we need.
And I am not going to throw too much language at you.
So the first thing that we will try to talk a lot about is present value and something that's closely related to it, future value.
I would like you to, I'll soon start drawing timelines, which are very important.
So basically, one of the things that you need to know is how to draw a timeline.
And if you know how to draw a timeline, half the problem is solved.
Because the world, it's problems are awesome, because nobody knows how to approach them.
World, the life in general is quite complicated.
What finance does is makes it simple.
I mean that's what you want from a frame book, not to make like more complicated, it's complicated enough.
What does future value mean?
So, so, so you don't need to worry about present versus future.
But the, the most important aspect of this is look at the units in which both are measured.
The units in which both are measured are dollars or yen or rupee as I said wherever you are the currency from your country.
And so, hopefully I can reach you and help you in learning this stuff.
Both are in dollars.
That's why it's so awesome.
But for matters in this class, the dollar sign is just a language of reflecting value.
It's for the number of periods that you're thinking about.
So, for example, if you're thinking only about today versus next year, then the n is one.
But notice, again, why is this important?
Because you recognize, in a second, that the passage of time alone makes decision making both interesting and challenging.
Just because of the passage of time, you need to worry about so many things but isn't it cool that time alone can make such a huge difference.
So the number of periods, now, it's critical for you to understand something which I'll repeat.
Okay, the problem will lend itself to the definition of the period.
Finally, the most critical aspects of finance is, if I were to capture one element of finance that distinguishes itself from everything else, it is the next symbol, r.
Sometimes textbooks use caps and so on, for n and so on.
Don't worry about that.
The critical element here is this.
The first aspect of an interest rate is, it's not in dollars, it is in percentage terms.
So it's like a change over time.
This is very, very important to understand.
And I think, intuitively, you do.
But practically, we'll also try to see what's going on with it.
The other element which is very, very important for this class and in a way, this is the one aspect of the class that I wish I could spend weeks on, but we don't have the time.
And, let me throw an idea to you.
Where does, where do interest rates come from?
Can they be negative?
It's a fascinating topic.
And I would recommend a book.
Called Theory Of Interest written in 1930 by Irving Fisher, who, if you read the book, it pretty much blows your mind.
But the critical aspect of that book is that it will take you off on a journey will take you off on a journey that won't be the journey we'll take.
At least aspects of it.
I love uncertainty.
I think that's what makes life interesting.
But for the time being, we're going to stick with no uncertainty.
Of course, that's completely unrealistic, but it's simple so that our building blocks of learning and time that it takes to learn, happens the natural way.
So I've introduced the terminology.
I want you to stare at these things for a little while.
Please remember, I'll introduce more.
And I want you to get comfortable with these.
So, for example, if you want to take a break now and you want to go google.
That's the beauty of Google.
In fact when my son was little, even now he asks me questions and I usually don't have a clue of the answer.
So just go Google, try to read your book, you've got to get familiar with these concepts, a little bit, if you want to take a break.
In some senses as I said before, if you know how to draw timelines, you have arrived.
So, and by the way, just so that you know my handwriting is nowhere near as perfect as the title on top.
So if you expect it to be, you need to grow up.
So, I am going to just draw a timeline and you should be able to take a word problem and put it along the timeline.
Why is this important?
I think its important because if you can take a real life problem and put it on a timeline, you achieved probably the most difficult part of taking a real world situation and then using financial tools.
So, in some senses, finance requires you to know what life is all about.
What the problem is all about before you can use finance you know?
The gap is huge, right?
I mean, love is somewhere special.
But being number two ain't bad.
So, here's the first thing.
At this point, we'll typically call this a PV, present value.
Then the number of periods are pretty obvious.
So this is one, two, three and this is n, n reflects these time periods.
By that I mean, when you see interest rates being quoted for various stuff like a bank loan and so on, it will be annual, and that's just, so that it make sense, you can compare things, kind of.
So, we'll try to understand these two concepts.
How does FV translate to PV, PV translate to FV, go back and forth and become very familiar today.
I will make it sound really easy but but the challenge is to do the problems and that's when you internalize, right?
Because the word problem is the problem.
And if you can't figure out the word problem, this is, ain't going to help.
So, drawing a timeline, bringing a word problem to it is what it's going to be about.
I'll start off with simple problems and then make them more complicated.
But today, what we'll stick with is, a single payment, and, I'm sorry, meaning I will transfer something from PV to FV, either for one year, two years, or ten years, and vice versa.
Remember, this is dollars, and this is dollars.
And the reason is, as I said, I want you to understand time value of money.
So, you know, when you are on a plane, the pilot warns you.
I'm going to warn you.
You better have your seat belt on.
That's how you learn.
You don't learn by just listening to me or anybody.
Okay?
We have talked about the importance of timelines, I am now going to jump into what I promised I'd do.
No.
To the extent I can, and that's my challenge, is to talk about a problem and then create the formula.
Because I don't like formulas without understanding whats going on.
But the mai n insight we are going to worry about is, a dollar today is worth more than a dollar tomorrow.
Or in other words, that's the essence of time value of money.
And there are some reasons for it, as I said, you can go back and read up on them.
The relationship between today and tomorrow, today and the future.
And that interest rate we'll assume is positive.
So, let me start with an example.
Suppose a bank pays a ten percent interest rate per year and you are given a choice between two plans.
By the way, I'll be going a lot back and forth, writing and stuff like that, but that will hopefully make it more engaging and as I do a problem, you should do it with me, you know?
So this, these are your two choices.
It's very simple.
I either give you $100 dollars today or I give you $100 one year from now.
And for the time being, let's keep our period one year.
So the question really is, which one would you prefer?
And why?
As I said, I just don't want to know what you prefer, I want to know why the heck do you prefer it?
It turns out, if you talked about it even for a second or even not thinking about it, you'll choose one of the two.
And it's probably going to be the first one, right?
So, the goal here is to, use the simple example to motivate something that is fundamental that we'll build on.
So, this is the future value problem in an example.
So, what I'm going to do is I'm going to try to work with you.
This is A.
And B was $100 in the future.
And that's what I meant.
The timeline is extremely important.
Your, I'm giving you two very simple choices to actually recognize.
What we'll do in our head is we intuitively recog nize that just the passage of time has an effect and will have an effect on the value of the money we are talking about or whatever it is, but we directly compare these two.
And that's not the right thing to do.
In other words, if you were to do this, and I say this in my class, and I'm going to say this to you, if you start comparing money across time directly with each other, it would be better if you stabbed me.
Because you're basically telling me, whatever you're teaching in finance is useless.
So, remember the first principle is, you cannot compare money across time.
And what captures the value of time in this one scenario, is what?
The interest rate.
So, let's try to work it a little bit better.
At this point in time, let's do the future value, right?
So, what is already in the future?
We know that this is already in the future.
So, the question is, I cannot compare this to this at time zero, but what can I do?
I can either bring this back to time zero, so take this.
Or, carry this forward to the future.
And it also makes you think about the future.
And that's very important.
Every decision that you make, every value creating decision that you make should force yourself to look into the future.
And this is where I think accounting can make, can make fun of.
Accounting standing at time zero where we are today, is looking backwards.
So, while you can derive very interesting implications from the past and I don't mean to demean anything, all decisions ultimately involve your capability to look into the future.
And that's what's challenging about it and that's what's awesome.
And typically, the painful part happens today.
The better the idea the more the pain today.
But benefits, lot in the future.
So like Go ogle, I mean it took a lot of effort to create and now a lot of values been created.
So, sticking to the simple problem, I think you know the answer to this.
The answer to this will be $110.
And the reason is very simple, r is ten%.
So, let me just walk you through, talk you through and then we'll do the formula.
I know right now many of you are saying come on, this is just too easy.
So, the $100 that you had, you could put in a bank, right?
And that 100, because the interest rate is positive, will be part of this 110.
Because the interest rate is positive you can't lose that $100, right?
And then, you're earning ten percent interest.
So, what is ten percent of $100?
So, it's very obvious what's going on that you, in the end will have $110.
So, as I promised you, what I am not going to do is I am not going to throw a formula at you until at least you have some sense of where I am going and hopefully this simple example has motivated you to, motivated you to try to understand future value a little bit better.
So now, what I am going to do is I am going to throw the concept at you.
In this concept, what it says is the following, that the future value of anything that's carried forward has to have two components.
One is the initial payment, and then our example, it's 100.
And the other is accumulated interest which in our example is $ten.
So, the problem becomes very straightforward.
You put in $100, you get a $100.
But then you get ten%on the 100 which is $ten.
So, if I were to ask you, what does it related to the problem that we just did.
So, what is this P?
What is the r?
Is on the P of $100.
So, the P is common to the first one, therefore, the one.
So, what you put in th e brackets is many times called Future Value Factor.
And what's cool about this number is, it tells you the future value of $one.
So, if you know the future value of $one in this case is 1.1, which is very simple, one plus the interest.
You know the future value of any number.
Because if the number is 100, you multiply 1.1 by a 100, you get 110.
If it's a million, you get 1.1 million and so on and so forth.
So, many people conceptually emphasize that Future Value Factor.
And I'm going to just do it this one time.
So, right now, what I'm not going to do is, I'm not going to use any tool to elaborate on this formula, by that I mean, you don't need Excel to do this, right?
Actually, you need Excel only to do when the problem becomes difficult to compute, not think about.
Okay.
So, the initial payment is P and the accumulated interest is r P.
So, that's the way you want to think about this problem.
So I hope all of you get a sense of this very simple problem because I think what, what, what the future problems will be, will be complicated versions of this.
And I get very excited with simple stuff too because it's, it's kinda cool.
So, how much will $100 become after two years, right?
So, so now what have I done?
I have taken the one year problem and broken it into a, and made it into a two year problem.
So let's see how to do that.
And I really would appreciate it if you did what I am doing, either now or later.
I have zero, one and two.
I'm just choosing it for simplicity.
It can be anything.
So, one year, two years, and what is the question asking me?
So you put 100 bucks in the bank.
And you're asking yourself, how much will you become.
At this point, so what is the future value of this?
And I'll tell you the answer first.
The answer will be $121.
And this, in all of this, that $one, this guy, if you understand where that's coming from, you'll see how it'll blow your mind when you increase the number of periods, okay?
So here's, here's a simple way of understanding what's going on.
So, can you tell me, how much will this be, at this point?
Do we know how to solve a period problem?
We know this is 110.
Why?
So, you don't need the formula to do this, hopefully.
I can use the same one period concept conceptually to move one period forward.
And what will you do again?
So what's going on here?
Answer is very simple.
You're doing a one period problem, twice.
It's, dumb, right?
So the bank is looking in the first period and saying, "What's going on a times zero?
You have 100 bucks." At the end of one period, what does it do?
It says, "Now you have 110." But the bank doesn't know the difference between the ten bucks that you didn't have in the first year.
So it thinks you now have, right this so, 110 bucks and takes it forward another period, it has become $121.
So, what's going on?
So, if you think about it, you're getting ten bucks here, and ten bucks here.
That's one way to think about it.
Why?
Because this ten is ten percent of this, for the first period, and this ten is again, a ten of this in the first period.
So, if you add up those, you have 100 + ten + ten, you have 120 at the end, right?
So, you'd be saying, "How did I go from 120 to 121?
" The answer is very simple.
Is it 121.
So, it's, it's pretty straight-forward.
I'm writing all over the graph, but I want you to understand that, this is not complicated.
So, so I've, I've given you a sense of, what is the future value of 100 bucks, two years from now.
And the concept and formula, let me just repeat one more time, so that you, you can, understand.
If I have P at times zero, after one year it will be P(1 + r), after two years, what will it be?
P(1 + r) (one + r).
Why?
Because this P in our case was 100.
Now, isn't this cool?
Now it's square of square out here, right?
And, even Einstein saw compounding work that is interest on, interest on, interest.
In this case, it was only one buck initially over one, two periods.
So, its so powerful, that in fact I would give this advice to you.
Anytime you're asked a finance question, say, the answer is compounding.
And you are likely to be right, 90 percent of the time.
The only thing you want to do, is you want to look intelligence.
In life, looking intelligence is far more important than being intelligent.
Because what that will do, is make people think like you're really cool, you know, something they don't.
But seriously, compounding is, is really, really, tough thing to internalize.
So, what I'm going to do now, is I'm going to take advantage of, Excel.
And I promised you that I wouldn't teach Excel.
But I'm going to do a problem where I'll be forced to use Excel.
So, let's, let's stare at this problem.
And if you want to take a break right now, this may be a great time to take a break.
Because we have done future value, where we actually could, by hand and do the calculation.
$100 after one year, 110.
Why?
I got ten percent ,ten bucks, over one year, I have 110.
After two years, what's happened?
Well, one way to think about it, which is very intuitive, is, how much do I have after one year?
If the bank is still there, of course.
So, 110 you still have, and after two years, it would have become 121.
And if you understand that one buck comes simply from the fact, that you're going, you now have ten more dollars after one year, which is also earning ten percent because it didn't do any harm to anybody, you know, it's just like the 100.
What did it do?
But it's only one buck.
Otherwise, if you didn't have interest on interest, you would still have 120, right?
Ten bucks each year on the original 100.
Now, you have 121.
Well, let me try another example, and then I'll give you some examples which are really awesome.
So, let's do this problem.
Today is the first day, or, first week, actually, of the class.
And, I talked about the various aspects of the class that previous session.
But, just to give you a sense of my style, I'm hyper, I'm nuts, I love this stuff.
And I talk about life and so on as we go along, and the good news is you can always skip parts you don't enjoy.
Whereas if you were in the class you'd have to suffer me throughout the class.
So what I'm going to do today is I'm going to start off with the content.
And this is what I do in class too.
The first week, if it's left just introductory, I don't think it's right.
And I will stop the topic.
One important aspect I want you to recognize, is that typically, in real time, when you're teaching classes like this, the amount of exposure the students have to a teacher, or the classroom time, if you may, is a lot more than on video and video is very intense, there's very few interruptions.
But on the other hand as I said you can keep learning from others and you can keep going back to the video.
I want to emphasize this every time, is that the good news is you have the video and I want the video to be self-contained.
In fact, I encourage you if you really wanted to learn, and I've thought about this a lot.
I was inclined to give you a lot of material.
So we'll talk, start talking about the time value of money today and we'll continue this in the next week.
And the reason is, time value of money is central to understanding finance.
So let's get started.
I want to pitch the beauty of finance.
If you remember, as its ability, the structure, and the details and the tools.
The ability of finance to solve or, I shouldn't say solve, but to understand decision making and make good decisions.
So I hope you recognize that.
So what is really critical to decision making?
Every decision involves time and uncertainty.
I have emphasized this in the introduction of the class, and I will keep emphasizing it.
And it'll, life will be so cool.
Because your framework is so strong.
So time and uncertainty, these are, these are common to every decision.
Whether you want to cross the street or whether you want to create a new technology to solve poverty, which I hope you do.
Okay, very important to understand just the impact of time on a decision and that's what we call time value of money, typically.
We ignore uncertainty for some time and I'm going to do that in a very deliberate way.
And just to read, emphasize this issue, I am putting it as a bullet point, and so that you can make notes on this.
We got to internalise the time value of money.
And I am going to spend a lot of time on each one of them before jumping into actually talking about Finance.
So you can think of it as the language of finance that we need.
And I am not going to throw too much language at you.
So the first thing that we will try to talk a lot about is present value and something that's closely related to it, future value.
I would like you to, I'll soon start drawing timelines, which are very important.
So basically, one of the things that you need to know is how to draw a timeline.
And if you know how to draw a timeline, half the problem is solved.
Because the world, it's problems are awesome, because nobody knows how to approach them.
World, the life in general is quite complicated.
What finance does is makes it simple.
I mean that's what you want from a frame book, not to make like more complicated, it's complicated enough.
What does future value mean?
So, so, so you don't need to worry about present versus future.
But the, the most important aspect of this is look at the units in which both are measured.
The units in which both are measured are dollars or yen or rupee as I said wherever you are the currency from your country.
And so, hopefully I can reach you and help you in learning this stuff.
Both are in dollars.
That's why it's so awesome.
But for matters in this class, the dollar sign is just a language of reflecting value.
It's for the number of periods that you're thinking about.
So, for example, if you're thinking only about today versus next year, then the n is one.
But notice, again, why is this important?
Because you recognize, in a second, that the passage of time alone makes decision making both interesting and challenging.
Just because of the passage of time, you need to worry about so many things but isn't it cool that time alone can make such a huge difference.
So the number of periods, now, it's critical for you to understand something which I'll repeat.
Okay, the problem will lend itself to the definition of the period.
Finally, the most critical aspects of finance is, if I were to capture one element of finance that distinguishes itself from everything else, it is the next symbol, r.
Sometimes textbooks use caps and so on, for n and so on.
Don't worry about that.
The critical element here is this.
The first aspect of an interest rate is, it's not in dollars, it is in percentage terms.
So it's like a change over time.
This is very, very important to understand.
And I think, intuitively, you do.
But practically, we'll also try to see what's going on with it.
The other element which is very, very important for this class and in a way, this is the one aspect of the class that I wish I could spend weeks on, but we don't have the time.
And, let me throw an idea to you.
Where does, where do interest rates come from?
Can they be negative?
It's a fascinating topic.
And I would recommend a book.
Called Theory Of Interest written in 1930 by Irving Fisher, who, if you read the book, it pretty much blows your mind.
But the critical aspect of that book is that it will take you off on a journey will take you off on a journey that won't be the journey we'll take.
At least aspects of it.
I love uncertainty.
I think that's what makes life interesting.
But for the time being, we're going to stick with no uncertainty.
Of course, that's completely unrealistic, but it's simple so that our building blocks of learning and time that it takes to learn, happens the natural way.
So I've introduced the terminology.
I want you to stare at these things for a little while.
Please remember, I'll introduce more.
And I want you to get comfortable with these.
So, for example, if you want to take a break now and you want to go google.
That's the beauty of Google.
In fact when my son was little, even now he asks me questions and I usually don't have a clue of the answer.
So just go Google, try to read your book, you've got to get familiar with these concepts, a little bit, if you want to take a break.
In some senses as I said before, if you know how to draw timelines, you have arrived.
So, and by the way, just so that you know my handwriting is nowhere near as perfect as the title on top.
So if you expect it to be, you need to grow up.
So, I am going to just draw a timeline and you should be able to take a word problem and put it along the timeline.
Why is this important?
I think its important because if you can take a real life problem and put it on a timeline, you achieved probably the most difficult part of taking a real world situation and then using financial tools.
So, in some senses, finance requires you to know what life is all about.
What the problem is all about before you can use finance you know?
The gap is huge, right?
I mean, love is somewhere special.
But being number two ain't bad.
So, here's the first thing.
At this point, we'll typically call this a PV, present value.
Then the number of periods are pretty obvious.
So this is one, two, three and this is n, n reflects these time periods.
By that I mean, when you see interest rates being quoted for various stuff like a bank loan and so on, it will be annual, and that's just, so that it make sense, you can compare things, kind of.
So, we'll try to understand these two concepts.
How does FV translate to PV, PV translate to FV, go back and forth and become very familiar today.
I will make it sound really easy but but the challenge is to do the problems and that's when you internalize, right?
Because the word problem is the problem.
And if you can't figure out the word problem, this is, ain't going to help.
So, drawing a timeline, bringing a word problem to it is what it's going to be about.
I'll start off with simple problems and then make them more complicated.
But today, what we'll stick with is, a single payment, and, I'm sorry, meaning I will transfer something from PV to FV, either for one year, two years, or ten years, and vice versa.
Remember, this is dollars, and this is dollars.
And the reason is, as I said, I want you to understand time value of money.
So, you know, when you are on a plane, the pilot warns you.
I'm going to warn you.
You better have your seat belt on.
That's how you learn.
You don't learn by just listening to me or anybody.
Okay?
We have talked about the importance of timelines, I am now going to jump into what I promised I'd do.
No.
To the extent I can, and that's my challenge, is to talk about a problem and then create the formula.
Because I don't like formulas without understanding whats going on.
But the mai n insight we are going to worry about is, a dollar today is worth more than a dollar tomorrow.
Or in other words, that's the essence of time value of money.
And there are some reasons for it, as I said, you can go back and read up on them.
The relationship between today and tomorrow, today and the future.
And that interest rate we'll assume is positive.
So, let me start with an example.
Suppose a bank pays a ten percent interest rate per year and you are given a choice between two plans.
By the way, I'll be going a lot back and forth, writing and stuff like that, but that will hopefully make it more engaging and as I do a problem, you should do it with me, you know?
So this, these are your two choices.
It's very simple.
I either give you $100 dollars today or I give you $100 one year from now.
And for the time being, let's keep our period one year.
So the question really is, which one would you prefer?
And why?
As I said, I just don't want to know what you prefer, I want to know why the heck do you prefer it?
It turns out, if you talked about it even for a second or even not thinking about it, you'll choose one of the two.
And it's probably going to be the first one, right?
So, the goal here is to, use the simple example to motivate something that is fundamental that we'll build on.
So, this is the future value problem in an example.
So, what I'm going to do is I'm going to try to work with you.
This is A.
And B was $100 in the future.
And that's what I meant.
The timeline is extremely important.
Your, I'm giving you two very simple choices to actually recognize.
What we'll do in our head is we intuitively recog nize that just the passage of time has an effect and will have an effect on the value of the money we are talking about or whatever it is, but we directly compare these two.
And that's not the right thing to do.
In other words, if you were to do this, and I say this in my class, and I'm going to say this to you, if you start comparing money across time directly with each other, it would be better if you stabbed me.
Because you're basically telling me, whatever you're teaching in finance is useless.
So, remember the first principle is, you cannot compare money across time.
And what captures the value of time in this one scenario, is what?
The interest rate.
So, let's try to work it a little bit better.
At this point in time, let's do the future value, right?
So, what is already in the future?
We know that this is already in the future.
So, the question is, I cannot compare this to this at time zero, but what can I do?
I can either bring this back to time zero, so take this.
Or, carry this forward to the future.
And it also makes you think about the future.
And that's very important.
Every decision that you make, every value creating decision that you make should force yourself to look into the future.
And this is where I think accounting can make, can make fun of.
Accounting standing at time zero where we are today, is looking backwards.
So, while you can derive very interesting implications from the past and I don't mean to demean anything, all decisions ultimately involve your capability to look into the future.
And that's what's challenging about it and that's what's awesome.
And typically, the painful part happens today.
The better the idea the more the pain today.
But benefits, lot in the future.
So like Go ogle, I mean it took a lot of effort to create and now a lot of values been created.
So, sticking to the simple problem, I think you know the answer to this.
The answer to this will be $110.
And the reason is very simple, r is ten%.
So, let me just walk you through, talk you through and then we'll do the formula.
I know right now many of you are saying come on, this is just too easy.
So, the $100 that you had, you could put in a bank, right?
And that 100, because the interest rate is positive, will be part of this 110.
Because the interest rate is positive you can't lose that $100, right?
And then, you're earning ten percent interest.
So, what is ten percent of $100?
So, it's very obvious what's going on that you, in the end will have $110.
So, as I promised you, what I am not going to do is I am not going to throw a formula at you until at least you have some sense of where I am going and hopefully this simple example has motivated you to, motivated you to try to understand future value a little bit better.
So now, what I am going to do is I am going to throw the concept at you.
In this concept, what it says is the following, that the future value of anything that's carried forward has to have two components.
One is the initial payment, and then our example, it's 100.
And the other is accumulated interest which in our example is $ten.
So, the problem becomes very straightforward.
You put in $100, you get a $100.
But then you get ten%on the 100 which is $ten.
So, if I were to ask you, what does it related to the problem that we just did.
So, what is this P?
What is the r?
Is on the P of $100.
So, the P is common to the first one, therefore, the one.
So, what you put in th e brackets is many times called Future Value Factor.
And what's cool about this number is, it tells you the future value of $one.
So, if you know the future value of $one in this case is 1.1, which is very simple, one plus the interest.
You know the future value of any number.
Because if the number is 100, you multiply 1.1 by a 100, you get 110.
If it's a million, you get 1.1 million and so on and so forth.
So, many people conceptually emphasize that Future Value Factor.
And I'm going to just do it this one time.
So, right now, what I'm not going to do is, I'm not going to use any tool to elaborate on this formula, by that I mean, you don't need Excel to do this, right?
Actually, you need Excel only to do when the problem becomes difficult to compute, not think about.
Okay.
So, the initial payment is P and the accumulated interest is r P.
So, that's the way you want to think about this problem.
So I hope all of you get a sense of this very simple problem because I think what, what, what the future problems will be, will be complicated versions of this.
And I get very excited with simple stuff too because it's, it's kinda cool.
So, how much will $100 become after two years, right?
So, so now what have I done?
I have taken the one year problem and broken it into a, and made it into a two year problem.
So let's see how to do that.
And I really would appreciate it if you did what I am doing, either now or later.
I have zero, one and two.
I'm just choosing it for simplicity.
It can be anything.
So, one year, two years, and what is the question asking me?
So you put 100 bucks in the bank.
And you're asking yourself, how much will you become.
At this point, so what is the future value of this?
And I'll tell you the answer first.
The answer will be $121.
And this, in all of this, that $one, this guy, if you understand where that's coming from, you'll see how it'll blow your mind when you increase the number of periods, okay?
So here's, here's a simple way of understanding what's going on.
So, can you tell me, how much will this be, at this point?
Do we know how to solve a period problem?
We know this is 110.
Why?
So, you don't need the formula to do this, hopefully.
I can use the same one period concept conceptually to move one period forward.
And what will you do again?
So what's going on here?
Answer is very simple.
You're doing a one period problem, twice.
It's, dumb, right?
So the bank is looking in the first period and saying, "What's going on a times zero?
You have 100 bucks." At the end of one period, what does it do?
It says, "Now you have 110." But the bank doesn't know the difference between the ten bucks that you didn't have in the first year.
So it thinks you now have, right this so, 110 bucks and takes it forward another period, it has become $121.
So, what's going on?
So, if you think about it, you're getting ten bucks here, and ten bucks here.
That's one way to think about it.
Why?
Because this ten is ten percent of this, for the first period, and this ten is again, a ten of this in the first period.
So, if you add up those, you have 100 + ten + ten, you have 120 at the end, right?
So, you'd be saying, "How did I go from 120 to 121?
" The answer is very simple.
Is it 121.
So, it's, it's pretty straight-forward.
I'm writing all over the graph, but I want you to understand that, this is not complicated.
So, so I've, I've given you a sense of, what is the future value of 100 bucks, two years from now.
And the concept and formula, let me just repeat one more time, so that you, you can, understand.
If I have P at times zero, after one year it will be P(1 + r), after two years, what will it be?
P(1 + r) (one + r).
Why?
Because this P in our case was 100.
Now, isn't this cool?
Now it's square of square out here, right?
And, even Einstein saw compounding work that is interest on, interest on, interest.
In this case, it was only one buck initially over one, two periods.
So, its so powerful, that in fact I would give this advice to you.
Anytime you're asked a finance question, say, the answer is compounding.
And you are likely to be right, 90 percent of the time.
The only thing you want to do, is you want to look intelligence.
In life, looking intelligence is far more important than being intelligent.
Because what that will do, is make people think like you're really cool, you know, something they don't.
But seriously, compounding is, is really, really, tough thing to internalize.
So, what I'm going to do now, is I'm going to take advantage of, Excel.
And I promised you that I wouldn't teach Excel.
But I'm going to do a problem where I'll be forced to use Excel.
So, let's, let's stare at this problem.
And if you want to take a break right now, this may be a great time to take a break.
Because we have done future value, where we actually could, by hand and do the calculation.
$100 after one year, 110.
Why?
I got ten percent ,ten bucks, over one year, I have 110.
After two years, what's happened?
Well, one way to think about it, which is very intuitive, is, how much do I have after one year?
If the bank is still there, of course.
So, 110 you still have, and after two years, it would have become 121.
And if you understand that one buck comes simply from the fact, that you're going, you now have ten more dollars after one year, which is also earning ten percent because it didn't do any harm to anybody, you know, it's just like the 100.
What did it do?
But it's only one buck.
Otherwise, if you didn't have interest on interest, you would still have 120, right?
Ten bucks each year on the original 100.
Now, you have 121.
Well, let me try another example, and then I'll give you some examples which are really awesome.
So, let's do this problem.
After you complete our time together, you are going to be able to describe the difference between productive versus unproductive work.
You're going to be able to determine your high priority tasks.
You're going to learn the definition of work/life balance, and you'll know how you actually really truly do spend your time.
This is really about you and you getting the most from your time.
I hope that sounds good because it's time for us to get going, so let's go.
But if you do the work in this course, you're gonna find approaches that can support your personal and professional productivity.
And when you do find yourself working overtime, you're gonna be able to do so in a much more efficient manner.
Wouldn't that be nice?
Have you ever had a day when you're absolutely busy busy busy from the minute you woke up until the minute you fell into bed and fell asleep?
And at the end of this super busy day do you know what you did?
Or was it one of those days where you know you worked, you know you worked hard all day, you know you're tired, but you're not exactly sure where your time went?
Well if you worked and worked all day long, and you're not 100% certain at where your time went, you might have been engaged in unproductive work.
How can there even be such a thing as unproductive work?
You weren't lounging, but you weren't completing the work that was really gonna further your goals right at that time.
You weren't completing the work that really needed to be completed right at that time.
Sometimes this means you get distracted by something that is work related but not related to the task at hand.
Maybe you start looking for some information that you do not need until later.
Let's take a look.
It's noon on a Friday afternoon, and Sam plans to leave the office at 5 P.M.
Before Sam leaves he needs to complete a report for his boss.
He also wants to go through some emails he's been saving and make sure that he has addressed them appropriately.
He's not sure how long that is going to take.
The email says, Sam, when you have time, would you look these numbers for me?
They don't balance, and I need to discuss them with our vice president next Thursday.
Sam begins to look at the sales numbers.
The numbers don't make sense, and he doesn't know where the numbers came from.
So he begins to look through sales reports from the past six months in hopes of deciphering how these numbers were created, and he works very hard tracing each month into the next, looking to see if he can find any errors or miscalculations.
And as he does, he notices that it's 4 P.M., and his boss is calling him about the report that was due at 3 P.M.
Sam had become so engrossed in researching the sales numbers that he had not even started the report yet nor had he started his status report.
That is work that he could've completed next week.
He became distracted, and he didn't work on his two priorities for the day.
How would you have prioritized Sam's Friday afternoon?
Something that would've made Sam's life easier is if he had a plan.
So if Sam had created a plan to get through his Friday afternoon, and if he had stuck to his plan, he probably wouldn't be working overtime on a Friday evening.
Well, the plan would have shown what to do and in what order to do it.
It would have shown when something was due, and it would help him to assess any new requests as they came in.
And then this last thing I'm gonna tell you sounds weird, but the plan would help Sam change his plans.
How is it that a plan helps you change your plans?
And that way you can understand what will happen to the rest of the work now that you've been asked to make a change.
Let's go back to Sam, and now take a look at how this might work out for him.
Let's say that Sam's boss calls him at 1:30 on Friday and says, Sam, I need your status report early.
I need to go give the status to our vice president at 3:30.
Well Sam knows, because he has a plan, that it will take him an hour and a half to finish the report and that it's due at 3:00.
And if he does this he might complete his status report exactly at 3:30, if he transitions right to the status report without taking a break.
So, what do you think he should do?
One approach would be for Sam to put the report on hold and transition to his status.
He could complete the status at approximately 2 P.M.
report could be turned in at say 3:45 or 4:00, and then this way he's able to make these suggestions because he has a plan.
Each day, each week, have a plan.
Know what you want to accomplish and what you need to accomplish.
We've been discussing work, but you know it never hurts to have some plans for your personal time.
Now some people don't like the idea of planning their personal time.
It's your preference.
I am suggesting that if you have something specific you want to accomplish, a plan is what's gonna help get you there.
There are all kinds of time management systems, and you can use them.
I'm not standing here with a preference for one or the other.
And the purpose of this course is not to sell you a time management system.
Sometimes your employer will provide a time management system or send you to time management training, and if they do, go and pay attention and consider what is presented to you.
It's possible that your employer has this preference for this specific system, and when this is true, it's really in your best interest to try to learn their system of choice.
Otherwise, don't feel compelled to use a system just because everyone says it's the best system.
The best system is the one that helps you to be productive and effective.
What really goes into your plan that's part of this system?
Well in many ways, your plan is your task list.
Rather than just write down things to do, you want to organize them.
You wanna organize them by priority, due date, steps that need to be taken, start date, who is it for, how long is it gonna take, what information, what do you need?
In your sample work plan you might have something like priority, the item, a description of what it is you're doing, a due date, the name of who it's for, the steps that have to be taken, an estimate of how long, and when you're going to get it started.
And you could create a table and a quick template and use it.
And see what works for you and what doesn't work for you.
We often, maybe even mostly, let our schedule schedule itself, ignoring the fact that time, not money, is our only true leadership asset.
Tom Peters is a leadership guru who's known for In Search Of Excellence and also Brand You.
Year ago, you know, he hit, hit upon the idea that we are each our own individual brand.
What is the one resource you can never have more of?
Did you say time?
We cannot create time.
There are only 24 hours in a day, 7 days in a week, 365 days in a year.
And so it's important that you spend your time in the most beneficial way possible.
And by beneficial, I really mean beneficial to you.
Spend your time in the way that's gonna bring you what you want from your life.
It is time to talk about work-life balance.
I'm gonna share with you the secret formula to work-life balance, so listen carefully.
I cannot tell you exactly how many hours to work and how many hours to play, or spend with your family.
It's a personal decision.
It's, it depends on your values, and it changes.
When I was brand new in the workforce, I was eager to work and to learn.
And to get ahead, I worked many hours.
My coworkers were my friends anyway.
We were all there together, new out of college.
There have been times in my life where, although I enjoyed my work, it was more important for me to spend time with my family and friends away from the office.
And that was completely happy doing that.
And there have times when I worked 40-hour weeks and I was completely happy doing that.
The key was that my work life fit my definition of work-life balance.
And then to manage your work and your life in a way so that most of the time you achieve your work-life balance and know it's gonna change, and know that, that is okay.
You've got more control over this than you think.
Remember in our previous module we talked about Sam?
And he wound up staying late on a Friday evening because he didn't pay attention to doing his work at the right time, in the right order.
And he didn't have a plan.
So if working late on a Friday evening goes against his idea of work-life balance, then he was probably not very happy.
But he did have a bit of control over this situation.
And I'm not promising you that you will never be asked to work more hours than you want.
And I'm not promising you that you will never have to work late, or to work a weekend.
But if you do not think about what you want, you do not know how to put yourself in the right situations.
You teach people how to treat you.
A client of mine was unhappy because her boss would text her 24 hours a day, seven days a week.
And if she heard a text come in at 2 a.m and she was sleeping, she would wake up and she would reply to it.
And I asked her about her job description and about the expectations that had been set when she came, what was mapped out for her when she started.
And I asked, does everyone in the office answer your boss 24, 7?
And she said that she had always done this from the very first day because she wanted to make a good impression on him.
Sure, you know, some people do expect you to answer them 24, 7.
But sometimes you're the one setting the example by being available 24, 7, and that's exactly what my client had done.
And then she became afraid to change the nature of her communications relationship with her manager.
Hi.
This is the first time we've ever taught an online course, and we're very excited about it.
And my co-teacher is Ram Neta from the University of North Carolina, Chapel Hill.
This is going to be a great course.
It's going to cover a lot of important practical issues, raise some fascinating theoretical questions.
We'll also try to have some fun, because there're lots of wacky examples where people make silly mistakes and arguments in everyday life.
And we'll try to teach you how to avoid those.
The title of the course is Think Again.
And the title pretty much tells you what the course is about.
We'll try to teach you to think again about a wide range of issues that effect your life in various ways.
We're not going to try to convert you to our point of view or, or teach you to believe what we believe.
Instead, we want you to think in a new way and in a deeper way about the issues that matter to you most.
The subtitle of the course, How to Reason and Argue, tells you that we're going to focus on a particular type of thinking, namely reasoning, because most people don't want to be arbitrary or have unjustified beliefs.
They want to have reasons for what they think and do.
But how do you get reasons?
Well, we're going to approach reasons by way of arguments, because arguments are just ways to express reasons.
And if you can understand arguments, you can understand reasons.
And if you can formulate good arguments, you can have good reasons for the ways in which you think and behave.
So that's one way in which it's important to understand arguments, namely to get better reasons for your own beliefs and actions.
But, another way in which it's very important to understand arguments, is to avoid mistakes.
So you need to spot them and avoid them.
Just think about a used car salesman who tries to convince you to buy a, a car, because it looks really cool and you'll look even cooler if you're sitting in the car.
Well, that might be a good reason to buy a car and it might not.
And you're going to have to figure out which kinds of arguments to believe and which kinds not to believe.
You want to have reasons for what you're thinking.
And for the verdict that you reach.
Or, an evangelist tries to convert you to their religious beliefs and to get you to give up your old religious beliefs.
Well, you don't want to make that kind of a decision arbitrarily either because it's so important.
And then what about your personal life.
But you don't want to commit yourself to such a big endeavor without having thought it through properly.
Well, in this course we'll have four parts.
The first part, we'll teach you how to analyze arguments.
That might seem really simple, you just read the passage and hear what they're saying.
But actually it's quite hard because some passages or some sets of words, if we're talking about spoken language, contain arguments and others don't.
Consider a letter to the editor.
Some letters to the editor don't have arguments at all.
On the other hand, other letters to the editor include arguments.
To vote for a certain political candidate for example.
Then, you need to look at those passages and figure out which of the words, which parts of those passages contain the argument.
Then you need to separate out those parts, put them in a certain order, which we'll call standard form.
And, often these arguments will have missing parts and you'll have to supply those missing parts or suppressed premises in order to get a full picture of how the argument works.
And that's what we'll do in part one.
Then in part two, once we've got the argument in shape, we can start to evaluate it.
But evaluations are going to depend a lot on what the purpose of the argument is.
Some arguments try to be valid in a logical way and those are deductive arguments.
So we'll start first by looking at deductive arguments and the formal structure of deductive arguments.
We'll look at propositional logic, then categorical logic.
That'll be part two of the course.
Then in part three, we'll look at a different kind of argument, inductive arguments that don't even try to be deductively valid.
Here there are just a lot of different kinds.
So we'll look at statistical generalizations, applying generalizations down to particular cases.
We'll look at inference to the best explanation and arguments from analogy.
We'll look at causal reasoning and probability and decision making.
So it'll be a lot of different types of inductive arguments covered in part three.
Some of them have to do with vaugeness.
Some of them are irrelevance, like arguments ad hominem and appeals to ignorance and we'll also look at a major fallacy called begging the question that people commit all the time.
And in the end, we'll teach you a general method for spotting and avoiding these common mistakes.
And at the end of each part, we'll have a short quiz with some questions to make sure you understood.
But that raises one problem.
There will be discussion forums where you can go and talk to other students about the material in the course.
And I bet that if you go to those forums, not only will you get your questions answered, but if you go to those forums and help answer other people's questions, everybody will learn more and that's what this course is all about.
So, thanks very much for joining us on this adventure and we hope you stick with it because we've got a lot of fun and a lot of important things to cover.
We've done these lectures so that you can just watch the lectures by themselves and do the exercises and take the quizzes.
However, if you're listening to a lecture and you're having a little trouble understanding it, or if you're really fascinated and you want to get more detail, then there is an accompanying textbook called, Understanding Arguments.
Many, many, many of the best ideas in this course come from him, he's been a leader in this field of understanding arguments for many decades and I owe awful lot to him and I really appreciate that.
So, I want to do a little shout out to thanks to Robert Fogelin before we get started on this course and the next lecture.
In the previous lecture, we saw a definition of argument as a connected series of sentences, statements or propositions.
Where some of those sentences, statements, propositions are premises and one of them is a conclusion.
Take for example an artifact that you might find in an archeological site.
You won't be able to figure out whether it's a really big screwdriver or a really small spatula unless you know whether the people who used it intended it to screw screws or to pick up food that they were cooking.
So, to understand arguments we need to understand the purposes for arguments.
And that means, why does somebody bother to give an argument instead of just asserting the conclusion without an argument?
Well, just think about it.
If you went to a used car lot and the salesman said, you ought to buy that Mustang.
Would that convince you?
But if the salesman said you ought to buy that Mustang because it looks really cool and it goes really fast.
Or maybe it has great gas mileage or whatever, and gives you a series of reasons, then you might be convinced to buy the Mustang.
So, that's one purpose of arguments to try to convince you to do things or believe things that you wouldn't otherwise do or believe.
So, this purpose is persuading or convincing.
And if you think about it what the salesman's trying to do is he's trying to change your mental states.
He's trying to make you believe something that you didn't believe or do something that you didn't do.
But that's just one purpose of arguments.
We don't always act like salesmen.
Sometimes, instead of trying to change people's beliefs, we're simply trying to give them a reason for their belief or for our belief.
And to give them a reason is not necessarily to convince them or persuade them or change their beliefs.
When we're simply trying to give them a reason to believe the conclusion we're going to call that justification.
So, imagine that your friend, you're not a salesman, you're a friend, imagine that your friend is thinking about buying a car.
He doesn't know which one to buy.
You might say.
You're not necessarily trying to convince her to buy that car.
It'd be fine with you if she bought any car she wanted, any car that would make her happy.
You're trying to talk about the reasons for buying the car so that you can make your own decision.
And that says you're trying to justify that decision or that belief that Mustang is the best car for her to buy.
And not necessarily to convince her or persuade her, if she comes up with great reason to the contrary you're perfect happy.
But notice, that you might give exactly the same reasons that the salesman did.
Exactly the same argument that the salesman did.
The difference lies in the purpose because the salesman is trying to convince her to change her beliefs and actions, but your goal with your friend is to discuss the reasons for her decision or action.
So, you're thinking about justification and the salesman was thinking about persuasion.
Now, it really matters whether your goal is justification or persuasion because there's a big difference here.
If you're trying to justify your friend's belief or your friend's action.
Then you try to give her good reasons, the salesman can convince her or persuade her with bad reasons.
So, it doesn't matter to his purposes whether the arguments that he gives are any good or bad, as long as they work to affect that change in the world.
Whereas you care about whether your arguments and your reasons are good reasons or arguments because, you're trying to justify that belief or that action.
And ,of course, people can try to do all of these things at once.
They can mix them together in various ways.
So, when someone gives you an argument, you need to ask a series of questions.
The first thing you need to ask is, is this person trying to change my mind?
If so, then their goal is persuasion or to convince you.
Then you need to ask, are they trying to give reasons to change my mind?
Well, if they're doing that then their goal is justification.
And if you go down that series of questions you'll be able to understand what the purpose of giving the argument is, at least for this range of cases.
So, let's do a few exercises just to make sure that you understand justification before we go on to the next purpose of argument, which will be explanation.
After you complete our time together, you are going to be able to describe the difference between productive versus unproductive work.
You're going to be able to determine your high priority tasks.
You're going to learn the definition of work/life balance, and you'll know how you actually really truly do spend your time.
This is really about you and you getting the most from your time.
I hope that sounds good because it's time for us to get going, so let's go.
But if you do the work in this course, you're gonna find approaches that can support your personal and professional productivity.
And when you do find yourself working overtime, you're gonna be able to do so in a much more efficient manner.
Wouldn't that be nice?
Have you ever had a day when you're absolutely busy busy busy from the minute you woke up until the minute you fell into bed and fell asleep?
And at the end of this super busy day do you know what you did?
Or was it one of those days where you know you worked, you know you worked hard all day, you know you're tired, but you're not exactly sure where your time went?
Well if you worked and worked all day long, and you're not 100% certain at where your time went, you might have been engaged in unproductive work.
How can there even be such a thing as unproductive work?
You weren't lounging, but you weren't completing the work that was really gonna further your goals right at that time.
You weren't completing the work that really needed to be completed right at that time.
Sometimes this means you get distracted by something that is work related but not related to the task at hand.
Maybe you start looking for some information that you do not need until later.
Let's take a look.
It's noon on a Friday afternoon, and Sam plans to leave the office at 5 P.M.
Before Sam leaves he needs to complete a report for his boss.
He also wants to go through some emails he's been saving and make sure that he has addressed them appropriately.
He's not sure how long that is going to take.
The email says, Sam, when you have time, would you look these numbers for me?
They don't balance, and I need to discuss them with our vice president next Thursday.
Sam begins to look at the sales numbers.
The numbers don't make sense, and he doesn't know where the numbers came from.
So he begins to look through sales reports from the past six months in hopes of deciphering how these numbers were created, and he works very hard tracing each month into the next, looking to see if he can find any errors or miscalculations.
And as he does, he notices that it's 4 P.M., and his boss is calling him about the report that was due at 3 P.M.
Sam had become so engrossed in researching the sales numbers that he had not even started the report yet nor had he started his status report.
That is work that he could've completed next week.
He became distracted, and he didn't work on his two priorities for the day.
How would you have prioritized Sam's Friday afternoon?
Something that would've made Sam's life easier is if he had a plan.
So if Sam had created a plan to get through his Friday afternoon, and if he had stuck to his plan, he probably wouldn't be working overtime on a Friday evening.
Well, the plan would have shown what to do and in what order to do it.
It would have shown when something was due, and it would help him to assess any new requests as they came in.
And then this last thing I'm gonna tell you sounds weird, but the plan would help Sam change his plans.
How is it that a plan helps you change your plans?
And that way you can understand what will happen to the rest of the work now that you've been asked to make a change.
Let's go back to Sam, and now take a look at how this might work out for him.
Let's say that Sam's boss calls him at 1:30 on Friday and says, Sam, I need your status report early.
I need to go give the status to our vice president at 3:30.
Well Sam knows, because he has a plan, that it will take him an hour and a half to finish the report and that it's due at 3:00.
And if he does this he might complete his status report exactly at 3:30, if he transitions right to the status report without taking a break.
So, what do you think he should do?
One approach would be for Sam to put the report on hold and transition to his status.
He could complete the status at approximately 2 P.M.
report could be turned in at say 3:45 or 4:00, and then this way he's able to make these suggestions because he has a plan.
Each day, each week, have a plan.
Know what you want to accomplish and what you need to accomplish.
We've been discussing work, but you know it never hurts to have some plans for your personal time.
Now some people don't like the idea of planning their personal time.
It's your preference.
I am suggesting that if you have something specific you want to accomplish, a plan is what's gonna help get you there.
There are all kinds of time management systems, and you can use them.
I'm not standing here with a preference for one or the other.
And the purpose of this course is not to sell you a time management system.
Sometimes your employer will provide a time management system or send you to time management training, and if they do, go and pay attention and consider what is presented to you.
It's possible that your employer has this preference for this specific system, and when this is true, it's really in your best interest to try to learn their system of choice.
Otherwise, don't feel compelled to use a system just because everyone says it's the best system.
The best system is the one that helps you to be productive and effective.
What really goes into your plan that's part of this system?
Well in many ways, your plan is your task list.
Rather than just write down things to do, you want to organize them.
You wanna organize them by priority, due date, steps that need to be taken, start date, who is it for, how long is it gonna take, what information, what do you need?
In your sample work plan you might have something like priority, the item, a description of what it is you're doing, a due date, the name of who it's for, the steps that have to be taken, an estimate of how long, and when you're going to get it started.
And you could create a table and a quick template and use it.
And see what works for you and what doesn't work for you.
We often, maybe even mostly, let our schedule schedule itself, ignoring the fact that time, not money, is our only true leadership asset.
Tom Peters is a leadership guru who's known for In Search Of Excellence and also Brand You.
Year ago, you know, he hit, hit upon the idea that we are each our own individual brand.
What is the one resource you can never have more of?
Did you say time?
We cannot create time.
There are only 24 hours in a day, 7 days in a week, 365 days in a year.
And so it's important that you spend your time in the most beneficial way possible.
And by beneficial, I really mean beneficial to you.
Spend your time in the way that's gonna bring you what you want from your life.
It is time to talk about work-life balance.
I'm gonna share with you the secret formula to work-life balance, so listen carefully.
I cannot tell you exactly how many hours to work and how many hours to play, or spend with your family.
It's a personal decision.
It's, it depends on your values, and it changes.
When I was brand new in the workforce, I was eager to work and to learn.
And to get ahead, I worked many hours.
My coworkers were my friends anyway.
We were all there together, new out of college.
There have been times in my life where, although I enjoyed my work, it was more important for me to spend time with my family and friends away from the office.
And that was completely happy doing that.
And there have times when I worked 40-hour weeks and I was completely happy doing that.
The key was that my work life fit my definition of work-life balance.
And then to manage your work and your life in a way so that most of the time you achieve your work-life balance and know it's gonna change, and know that, that is okay.
You've got more control over this than you think.
Remember in our previous module we talked about Sam?
And he wound up staying late on a Friday evening because he didn't pay attention to doing his work at the right time, in the right order.
And he didn't have a plan.
So if working late on a Friday evening goes against his idea of work-life balance, then he was probably not very happy.
But he did have a bit of control over this situation.
And I'm not promising you that you will never be asked to work more hours than you want.
And I'm not promising you that you will never have to work late, or to work a weekend.
But if you do not think about what you want, you do not know how to put yourself in the right situations.
You teach people how to treat you.
A client of mine was unhappy because her boss would text her 24 hours a day, seven days a week.
And if she heard a text come in at 2 a.m and she was sleeping, she would wake up and she would reply to it.
And I asked her about her job description and about the expectations that had been set when she came, what was mapped out for her when she started.
And I asked, does everyone in the office answer your boss 24, 7?
And she said that she had always done this from the very first day because she wanted to make a good impression on him.
Sure, you know, some people do expect you to answer them 24, 7.
But sometimes you're the one setting the example by being available 24, 7, and that's exactly what my client had done.
And then she became afraid to change the nature of her communications relationship with her manager.
Let's put managerial accounting in the larger context of accounting in general.
When you think of accounting in a broad sense, you can think of three sets of books, the financial books, the management books, and the tax books.
An example of the financial books is the annual report that a company files with its shareholders each year.
The financial books are targeted towards external constituents, primarily investors and creditors.
These parties are trying to decide where to put their money, so they rely on these to communicate financial information about the company.
The objective then, of those books, is to communicate the economic performance and financial position of the organization.
The audience for the management books is an internal audience, it's management themselves.
The objective of those books is to facilitate management decision making in the organization.
The audience for the tax books is the tax authorities.
The tax books have the objective of facilitating the collection of tax revenue by the government.
So each of these sets of books has very different objectives targeted to very different audiences.
So we have three very different sets of books for all the right reasons.
Let's talk about the rules that companies have to follow when preparing each set of these books.
The financial books must be prepared in accordance with some set of accounting standards that are relatively common among a large group of firms.
For example, in the US, companies must prepare their financial statements in accordance with US GAAP, or Generally Accepted Accounting Principles.
Internationally, companies may have to prepare their books in accordance with International Financial Reporting Standards, or IFRS, or a specific country GAAP.
Each of those has its own authority that sets the rules and ensures that those rules are followed.
In this course, of course, we will focus on the management books.
And welcome to the first video in An Introduction to Financial Accounting.
In this video, we're going to provide an overview of the financial reporting landscape.
What's required in financial reporting, who makes the rules, who enforces the rules, what are the basic set of financial statements.
Accounting is a system for recording information about business transactions to provide summary statements of a company's financial position and performance to users who require such information.
>> I sure hope not, but to spice things up a little bit, I will bring in some virtual students every now and then to ask questions or to make pithy comments.
Anyway, this definition has three parts.
This part turns out to be a big deal, as not everything a business does gets recorded in the financial statements, and sometimes it'll seem like nothing's happening, yet we'll need to record a transaction anyway.
Large companies have billions and billions of transactions every year.
If they made them available to you in a gigantic database, your first question would be, how can I summarize all this into one or two summary numbers?
And the third part focuses on users, because different user groups would want different summary numbers.
So most companies have to keep three sets of books.
This standardized set of statements is geared toward external users like investors, creditors, customers, suppliers, competitors and any other stakeholder or person that has interest in the company.
However, these financial statements are not used to determine taxes.
There is a separate set of books based upon tax rules that are used to compute how much taxes a company has to pay.
Finally, there's managerial accounting.
We're not going to cover this topic in this course, but I wanted to make you aware of the fact that the financial accounting that we do talk about it is generally not used for internal decision making.
Instead, there are other kinds of numbers that are looked at.
So what are the financial reporting requirements?
This includes a full set of financial statements with a substantial amount of additional disclosure.
The other three-quarters of the year, firms must file a quarterly report, or 10-Q, which has a full set of financial statements but less required disclosure than the annual report.
If anything material happens between quarter ends, companies must file an 8K, or current report.
Material information is generally viewed as anything important enough to move stock price, which means companies file these quite often.
All of these filings have to be prepared in accordance with generally accepted accounting principles, or GAAP.
However, the things that we cover will be applicable globally.
So for instance, even though we're talking about SEC filing requirements in the US, every country in the world that has a securities market has filing requirements like an annual report.
The only difference you might see internationally is instead of a quarterly report, some countries require semi-annual reporting.
So this is a pretty universal set of filing requirements that apply to public and private companies around the world.
For example, let's say we ship goods to a customer in one quarter, but we collect cash in the next quarter.
And let's say we buy some equipment in one quarter, and then use it to manufacture goods over the next 23 quarters.
When we pay cash to buy the equipment or as we use it over the next 23 quarters?
A lot of what we're going to do in this course is try to figure out what quarter to put various business activities into when we put together the financial statements.
So who makes the rules?
Generally accepted accounting principles, or GAAP, are established by the US Congress, but they're usually too busy trying to do things like investigating steroids in baseball or figuring out whether they should shut down the US government again.
They don't have time to deal with accounting standards, so they delegate to the Securities and Exchange Commission.
But they're often too busy trying to catch the bad guy, so they don't have time to make the rules.
So they delegate to the Financial Accounting Standards Board, of FASB, which is a seven-person board in Norwalk, Connecticut, that has the authority to make the accounting rules in the US.
And sometimes they're even too busy to make all the rules, and so there's an emerging issues task force and the AICPA that can also have a hand in making accounting rules, or US GAAP.
Now this is just in the US.
Internationally, there are international financial reporting standards, or IFRS, that are established by the International Accounting Standards Board, or IASB, which is based in London, and are now required in over 100 countries including all of the EU.
But as of now, US GAAP is still required for US firms.
So basically there are two big sets of accounting standards in the world.
But the good news is, for almost all of the introductory accounting topics that we look at in this course, there's a very high degree of overlap in the two standards.
>> Actually, in the summer of 2008, the SEC came out with a roadmap that would move US firms to IFRS by basically now.
But then what happened was, Lehman Brothers went bankrupt, the financial crisis hit and the roadmap dropped way off the SEC's radar screen.
So for the foreseeable future, we're going to have two big sets of standards in the world, US GAAP and IFRS.
But as I just mentioned, the good news is the two standards are getting closer to each other all the time.
The FASB and IASB are working together on any new standards.
So, all the stuff that we talk about that's under US GAAP in this course will be very similar to what you would see under IFRS.
So who's responsible for financial reporting?
We allow managers to put together their own financial statements because they have the most information about what happened in the company.
And we hope that they use their discretion in financial reporting to better communicate their activities.
However, it is important to remember that they may use this discretion to try to manipulate the perceptions, and we need to be on the lookout for such opportunistic behavior.
So we put in a number of checks and balances to try to curb managers' opportunistic behavior.
First, the Audit Committee of the Board of Directors provides oversight of management's accounting process.
However, this is not a foolproof check on managers' behavior.
Which means you could put someone like me on the board and still have these kinds of problems.
So then the auditors are hired by the board to express an opinion about whether the statements are prepared in accord, accordance with GAAP.
This again is not foolproof, because in the case of Enron, their au, auditor, Arthur Anderson, signed off on some of the more aggressive things they did, and part of the reason was because they were being hired by Enron to approve their accounting.
If they lost Enron because of a disagreement over their accounting, then they would have lost the biggest company in Houston and would have had to go to the second biggest company in Houston which is uhh.
Who knows what the second biggest company in Houston is?
And that's why they want to make sure to keep Enron.
The next line of defense is the SEC and other regulators who will take action against the firm if any violations of GAAP or other rules are found.
Now these bodies tend to be very reactive instead of proactive, and it's oftentimes after someone else has brought the fraud to the public's attention that they launch their investigation.
So by and large, it's information intermediaries like stock analysts, institutional investors and the media that provide the biggest check on managers' behavior by either exposing or fleeing firms with questionable accounting.
But by the time one of these parties get involved, it's a very public issue, the stock price drops and you're in bad shape if you're an investor or employee of the company.
So in the end, the only party that's really going to look out for your interest in terms of understanding and trusting financial statements is you.
Which is why it is really important that you learn some basics in terms of reading financial statements.
So what are the required financial statements?
Well, there's four of them.
First, there's a balance sheet, which gives a company's financial position, which is its listing of all its resources and obligations on a specific date.
By over a period of time we mean between two balance sheets, so either a quarter or a year.
And by accrual accounting, it means we're going to recognize things in the income statement based on business activities, not based on cash flows.
Because we have a separate statement for cash flows, the statement of cash flows, which will give you all the sources and uses of cash over a period of time.
And then finally, there's the statement of stockholder's equity, which provides changes in stockholder's equity over a period of time.
This is pretty abstract.
>> Yes, in fact I have an extended example where we go through a simple business and see what the different financial statements can tell us about what's going on at the business.
But it takes another ten minutes or so, so to avoid this being a long first video, why don't we cut it off here and we'll pick it up in the next video.
I'll see you then.
In this video, we're going to take a look at what the financial statements can tell us about a business.
To do so, we're going to look at a very simple business with just a few transactions to see how those transactions would affect the required financial statements.
I'm going to throw a lot of concepts at you in this video.
We're going to go through all these concepts again later on in the course.
Let's get started.
The example we're going to look at is Dave's Car Transport Service.
So Dave starts a business to transport expensive cars.
On December 1, 2015, he receives $50,000 cash from issuing common stock.
He also borrows $80,000 from a bank.
And we'll buy a $100,000 truck.
The truck will be used for 48 months with a $4,000 salvage value.
Dave also paid $12,000 cash upfront, to rent office space for the next year.
During the month of December, Dave's company moves two cars the clients will pay them $40,000 within 30 days.
Dave also pays his employees $10,000 of wages.
Now it's December 31st and the bank wants to see some financial statements.
The bank wants to see financial statements because they want an answer to the question.
Now there's a number of different ways that we could try to answer this question.
The first way would be to just look at all of the cash flows.
So, if we take the facts and look at the cash flows, Dave's company received $50,000 cash from issuing stock, borrowed $80,000 from the bank, and bought $100,000 worth of truck.
They paid $12,000 cash up front to rent office space for a year.
And they did not collect any cash from customers during the month.
But as it turns out, this is a really bad way to figure out whether the company made money or not for December.
What is wrong with that?
Anytime I end the month with cash in the bank, it is a great month.
You get an allowance from your parents.
You borrow some money from your parents.
You spend a bunch of money.
If you end the month with money in the bank, it was a pretty good month.
But this doesn't work so well for companies.
All a company would have to do to post better performance into the system would be to borrow more money or sell more stock.
A better way to look at cash flows would be to separate them into whether they come from operating the business or investing for the future, or financing for the long term.
So let's start with cash flows from operating the business.
This would be cash that was paid for the rent.
We didn't actually collect anything from customers, so the net casual from operating the business was a cash outflow of $22,000.
Then we can look at cash required to invest in the business for the long-term.
So the company spend $100,000 cash to buy a truck, which resulted in a total cash outflow from investing activities of $100,000.
And then finally, we can look at cash used to finance the business.
So, the company received $50,000 in cash from issuing common stock.
They borrowed $80,000 from a bank, which was a net cash inflow from financing activities of $130,000.
But now, we've organized the cash flows based on whether we're operating the business, investing in the business, or financing the business.
And this is exactly what the statement of cash flows will look like.
It's going to report the cash transactions for the company over a period of time like the month of December.
Split up into operating activities which are transactions related to providing goods or services or other normal business activities.
And financing activities, which are transactions related to owners or creditors.
Another way to try to answer the question of whether the company made money in December, is to look at accounting income.
Accounting income tries to look at business activities rather than cash going in or out.
For example, we actually did move two cars during December.
Even though we haven't got paid cash yet, we're likely to get paid cash, so why not book revenue of $40,000 to recognize the cash that we'll eventually get, from providing the service of moving the cars.
Even though we paid $100,000 for a truck, we're going to use that truck over four years.
So why not allocate the cost of the truck over the four years.
So we have a $100,000 truck with a $4,000 salvage value.
Salvage value is how much we think the truck will be worth when we're done with it.
So let's take that $96,000 of value that we're going to use up, divide it by 48 months.
And recognize a $2,000 expensive of using the truck, each of the next 48 months.
We paid $12,000 cash upfront to rent office space for a year, but we've only been in there for one month.
So why not just show one month of expense $1,000, rather than the full $12,000 of cash that we paid up front.
We paid $10,000 of cash to employees for wages.
That was all due to work they provided this month, so we'll show that all as a wages expense.
Net income is a measure of whether we priced our service, moving cars, high enough to cover all of the costs or expenses of running the business, all of the cost of moving the cars.
And this is what the income statement is going to tell us.
We'll have revenues, which are increases in owners' equity from providing goods or services.
And we'll talk more about what owners' equity is in a little bit.
We'll have expenses, which are decreases in owners' equity, which are incurred in the process of generating these revenues.
It's the cost of doing business.
The bottom line or the differences between revenue and expenses is going to be called net income, which is also called earnings or net profit.
And it's important to note that it does not equal the change in cash because it's a measure based upon business activities, not purely cash flow.
How can we record revenue without getting any cash?
What is this depreciation stuff?
We didn't spend $2,000 on a truck, we spent $100,000.
It'll, it'll take a little bit to explain all this to you.
There are two different statements for this month's results.
Which one is better?
Which should we use?
I am going to only use the Cash Flow Statement.
We'll talk about this more.
But you definitely want to use both statements because they tell you different things.
Let's take a look at how these two statements provide different pictures of what happened with the company.
So starting with revenue, that tells you that you moved cars during the period and you are eventually going to get paid $40,000 from customers.
Where as the $0 in the cash flow statement says that you actually didn't get any cash this period.
For the truck, the cashless statement tells you, you spend a $100,000 cash on a truck.
The accounting income says that the cost of the truck used up this period to generate revenue, is only $2,000.
Because we're spreading it over the whole time that we're going to use the truck.
For rent, our cashless statement said we paid $12,000 cash this period for rent.
But our accounting income says that we only used up one month of that.
We still have $11,000 that we haven't used up, that we'll use up over the next 11 months.
Sometimes the expenses and the cash flow are the same as in the case of wages here.
But as you can see from the cash from operations and net income, you're getting very different pictures.
Cashflow from operations of negative 22,000 says that you spent more cash than you had come in based on these operating activities.
Says that you priced your service high enough to cover all the costs of providing the service.
Which even though it didn't get you cash this period should lead to positive cash flow in the future.
The next statement that we're going to preview is the balance sheet which provides the financial position of Dave's Car Transport Company at the end of the month.
By financial position we mean all their resources and obligations.
So the resources are what we call assets, so what are the assets or resources of Dave's company?
Well they have $8,000 cash in the bank at, December, 31 2015.
That's the cash owed by customers on December 31st.
And that's an asset because it's going to eventually turn into cash when you collect from the customers.
Another asset is prepaid rent.
Remember that Dave paid $12,000 for a years of rent.
One month has been used up, but they still have 11 months of prepaid rent.
This is an asset because they can occupy the space for another 11 months, without paying any additional cash.
And then, of course, there's the truck, which is an asset of $98,000.
That's the original cost of $100,000 minus that $2,000 that we depreciated.
So that gives us total assets or resources of $157,000.
Now we can look at all the obligations or claims on these resources which are the liabilities and stockholder's equity.
Dave owes the bank $80,000 at December 31, 2015.
That's a liability called bank debt.
There's $50,000 of stockholder's investment as of December 31.
This is a stockholder's equity called common stock.
And then there are retained earnings of $27,000.
Retained earnings represent all of the net income or accounting income that's been created over the life of the company, minus any dividends that have been paid out, which we'll talk about later.
And when we add it all up, the obligations are the same as the resources of $157,000.
And this is characteristic of the balance sheet which always has to balance, hence the name.
When is this video going to end?
I know I've thrown a lot of new concepts at you in this video.
But don't worry, we're going to go over everything again in more detail.
And there's only a couple more slides, and we're done.
It's going to report the financial position of the company.
We've got assets, which are resources owned by the business, that are expected to provide future economic benefits.
Liabilities are claims on those assets by creditors, or non owners.
Creditors, that represent an obligation to make future payments of cash, goods, or services.
Stockholder's equity, or owners' equity, are claims on the assets by the owners of the business.
Those come from two sources, contributed capital, which arise when you sell shares, and retained earnings, which arise when you operate the business.
We're going to talk about these a lot more in the next few videos.
The last statement is the Statement of Stockholders' Equity.
And we're going to get to this later.
Hopefully, that gave you a good overview of what the financial statements are trying to tell us.
We are now going to start looking at the financial statements in more detail, starting in the next video with the balance sheet and the balance sheet equation.
I'll see you then.
In this video, we'll take a look at the one rule of grammar in the accounting language, the balance sheet equation.
We'll see how the balance sheet equation makes all the financial statements fit together.
We'll also use the balance sheet equation to solve some problems where we're missing one piece of information, but we can fill in everything that we do know into the balance sheet equation and solve for what we need.
Hope you enjoy the video.
Well, the good news about learning the language of accounting is that there's only one rule of grammar, the balance sheet equation or the accounting identity.
This is that assets equal liabilities plus stockholder's equity at all points in time.
>> Can you give me an example of when this is used in the real world?
>> A good example to think about how we use the balance sheet equation in real life, is when we buy something big like a house, or a car.
So, let's us say we wanted to buy a $500,000 house but we only had $50,000 of cash while we would need to go out and borrow $450,000 from the bank in a mortgage in order to buy the house.
Then after we bought it we'd have 500,000 in assets, the house, which is equal to the 450,000 of liabilities, the mortgage.
Plus 50,000 in equity, which is how much cash we put in and which represents our claim on that house.
The most important feature of the balance sheet equation is that it must always balance.
And that's why we're going to talk about something they call double entry book keeping.
If you increase something on one side of the equation, you have to increase or decrease something else to stay in balance.
So, there has to be at least two entries any time you tinker with the balance sheet equation.
And as we'll see, the changes between two Balance Sheets are going to be summarized in the Income Statement, the Statement of Stockholders' Equity, and the Statement of Cash Flows.
So let me show you this graphically.
So let's say we have a balance sheet at the end of December 31, 2014.
We'll split the assets into cash and non-cash assets, and we'll split stockholders' equity into contributed capital and retained earnings, which are concepts we'll talk more about in later videos.
Then we have a balance sheet at the end of the year, so we've got one at the beginning of 2015, at the end of 2015.
The difference in the retained earnings is going to be explained in the income statement for the year end at December 31, 2015.
And the difference in cash, is going to be explained in the statement of cash flows for the year ended December 31, 2015.
>> Here you go again with the difference between income and cash.
>> Okay, let's go back to the house example.
So, your balance sheet at the end of the year would have a million dollar asset, the house, 450,000 of liabilities because the mortgage doesn't change, but your equity would go up from 50,000 to 550,000.
Now, if you look at the statement that explains the changes in two balance sheets.
None of this affects the cash flow statement because there's no cash impact of your house going up in value.
In fact, your cash up should probably went down as you were paying the mortgage.
But your income statement would show a gain of $500,000 from the increase in your equity due to your ownership claim of the house.
Can you give us a more contemporary example?
These are assets because they're claims on collecting cash payments from people that took out sub-prime mortgages.
So let's say a bank had 10 billion of these mortgage-backed securities as assets.
And half a billion of equity.
So now they have to be written down in value from 10 billion to, let's say 1 billion.
Now the liabilities don't change.
And so it's another example where there's no cash flow impact of the change in these two balance sheets, but we end up showing a $9 billion loss on our income statement due to the drop in our equity claims on those assets.
Of course, we also have to mention the statement of stockholders' equity, which explains the changes in stockholders' equity between two balance sheets, which we will talk about more later in the course.
What I want to do next is show you how everything that we're going to talk about fits into this balance sheet equation.
So, we talked about how stockholders' equity is two components, contributed capital, which is the money that we raised from shareholders, and retained earnings, which is what we create by operating the business.
Retained earning is going to equal whatever retained earnings were at the beginning of the period plus any net income, earned during the period minus any dividends paid out to shareholders.
That's why it's called retained earnings, because it's the earnings or net income less any dividends paid out.
And then net income, as we talked about in a prior video, is revenues minus expenses.
I am going to ask you to do some math.
Now I'm going to give you some problems, give you a chance to try to answer the problems, and then we'll talk through the answers.
After I read the problem, you'll see a little pause icon on the screen.
If you want to try to answer the problem before I give you the answer, pause the video at this point, try to come up with the answer and then resume the video.
But, if you want to just roll through and hear the answer right away, then it's okay to keep the video going.
This is going to be the procedure that we follow any time that I give you some questions that I wanted to, want you to try to answer during the video lecture.
Okay, here is the first one.
We know that assets are 100.
Liabilities are 50.
The only thing that's missing is stockholder's equity, which has to be 50.
So that we have 100 on the left hand side, and 100 on the right hand side.
Next, liabilities increase by 100 and stockholders' equity is unchanged.
Again, we can use the balance sheet equation to answer this, but now we're looking at changes in the numbers.
Next, all non-cash assets are 70, total liabilities are 60, total stockholders' equity is 30.
What is cash?
So we have Liabilities of 60 and Stockerholders' Equity of 30, that's 90 on the right-hand side.
Noncash assets are 70.
The only thing missing is Cash, which has to equal 20, so that we have 90 on each side.
We can use the same equation but we have to be a little bit careful.
Now, if we knew that stockholders' equity had not changed, then liabilities would have had to go up by five, so that we have an increase in five on both sides of the equation.
But without knowing what happened to stockholders' equity, we technically don't have enough information to answer this one.
But, I promise that it won't be the last.
Next, we have Retained Earnings increasing by 100, dividends are 50.
Earlier in the video, we looked at the equation for retained earnings, where retained earnings is equal to prior retained earnings, what they were at the beginning of the year, plus net income during the period, minus dividends.
So we know that the change in net income.
We know that dividends is 50, so the only thing missing is net income, which has to be 150 for this to balance.
Next we have revenue increasing by 100, all other categories are unchanged except assets.
We have to use the complete balance sheet equation to solve this one, so that we break Stockler's equity into contributed capital, prior retained earnings, revenues, expenses and dividends.
Everything else is unchanged but assets, which means that assets also have to go up by 100 so that both sides of the equation increase by 100.
So we know that expenses went up by 60, everything else is unchanged except for cash.
The purpose of this exercise was to preview the type of problem that you are going to be doing a lot in this course.
There's going to be a certain piece of information that you need that you're not given.
But, you can take all the other information that you're given, and a set of equations, that will usually be in the form of T accounts, or journal entries, fill in everything you know, and then solve for that one piece of information that you need, that you can't find in the financial statements.
So I'm going to go ahead and wrap up this video, and we'll come back next time and talk in more detail about assets, liabilities and shareholder's equity.
In this video we're going to build on our discussion of the balance sheet equation to talk about assets, liabilities, and stockholder's equity in more detail.
We're going to provide precise definitions for each of them, and we're going to look at situations where we can record them, and situations where we can't record them.
Let's get started.
Let's start with assets.
An asset is a resource that is expected to provide future economic benefits.
That means, it's either going to generate future cash inflows or it's going to reduce future cash outflows.
There are two criteria that we use to decide, when to recognize an asset.
First, it must be acquired in a past transaction or exchange, and second, the value of its future benefits can be measured with a reasonable degree of precision.
So, for example, if we buy a truck, the truck would be considered an asset.
And the value and the benefits of the truck are equal to the price that we paid to buy the truck.
So, both criteria are satisfied, and it would be an asset.
Now we're going to practice applying these criteria to figure out which of the following items would be assets.
I'm going to give you a number of items, and for each one, I want you to try to figure out whether it's an asset or not.
If it's an asset, try to give me the account name and what the dollar amount would be.
If it's not an asset, then try to figure out what criteria would cause it to not be an asset.
I'll bring up the pause sign so if you want to pause and try and answer it yourself you can, but as always you can just roll through and listen to the answers if you'd like.
BOC sells $100,00 of merchandise to a customer that promises to pay cash within 60 days.
This'll be an asset called accounts receivable.
It's an asset because there was a transaction where we delivered goods to a customer, and in return we got a promise from them to pay cash.
It's an asset, because that can turn into cash within the next 60 days.
Next, BOC signs a contract to deliver $100,000 of natural gas to DEF, each month for the next year.
Every exchange of cash, good or services, is going to happen sometime in the future.
Nothing has been exchanged yet, so there can't be an asset for it.
>> That's a great question and the first example the costumers promised to pay us cash, but we've acquired that promise through delivering them goods.
In other words there's been a pass transaction or exchange, which is that first criteria for him asking asset.
In the second case, all we've done is sign a contract.
If the contract was broken, it's not clear we'd have any basis to ask the customer to pay us a $100, 000.
buys $100,000 of chemicals to be used as raw materials.
pays in cash at the time of delivery and receives a 2% discount on the purchase price.
Inventory is a term that we are going to use for any product or raw materials that we buy, that we're going to turn into a finished product that we're going to sell at a markup.
And the value of the benefits is known here because it's what we paid in the market transaction.
And note that the value here is 98,000 not 100,000 because we value it at what we actually paid for it, not some kind of higher sticker price that wasn't what the transactions actually happened at.
BOC pays 12 million for the annual rent on its office building.
This is an asset.
It meets the first criteria because in a market transaction, we paid for the right to occupy space in this office building for 12 months.
But note that, at this point, the value of the benefits is only 11 million.
Not the 12 million that we've paid.
Because we've already occupied it for a month we've used up one month of the future benefits.
So at this point in time, there's only $11 million of future benefits.
So we have prepaid rent worth $11 million.
It's broker said this was a steal, because the land is probably worth $150,000.
This is an asset which we'll call Land.
Meets the first criteria because there was a market transaction where we acquired ownership.
The value of the benefits are assumed to be what we paid for it, which is $100,000.
And so we're not going to use that as the value of the benefits.
BOC is advised by a marketing firm that its brand name is worth $63 million.
>> Are you saying that marketing people do not know what they are talking about?
I definitely respect marketing people.
Some of my best friends are marketing professors.
It's simply a case where accounts have decided to err on the side of reliability or objectivity.
Without a market transaction where the company has acquired the brand, we can't be sure of how much it's worth.
And so we err on the side of leaving it off the financial statements.
Now, we're going to turn to liabilities.
A liability is a claim on assets by creditors or non-owners, that represent an obligation to make future payment of cash, goods, or services.
Let's go on.
Just like assets, there are two criteria for when we recognize a liability.
First the obligation is based on benefits or services received currently or in the past and second the amount and timing of payment is reasonably certain.
And even though the words are different, these are essentially the same two criterias for the assets.
The first one says there has to be some kind of transaction or exchange where you've received something that creates an obligation and the second criteria says you can measure the amount of what the obligation is.
So for an example, let's say we borrow money from a bank, we have an obligation to repay the bank based on receiving the benefit of getting the money now.
The amount and the timing of the payment is reasonably certain, and if there was any question, I'm sure the bank could clarify how much we exactly owe them.
So, borrowing money from a back would meet both criteria.
We're going to do the same exercise now with liabilities.
I'll give you a number of items.
I'll give you chance with the pause sign to try to answer them if you'd like and then we'll talk about what the answer is.
First item, BOC receives $300,000 of raw materials from a supplier and promises to pay within 60 days.
We use that term anytime we owe money to a supplier.
It meets the first criteria because we got the benefit of raw materials in a transaction, which now creates the obligation to pay our supplier and the amount of the obligation is reasonably certain.
So we're going to have an accounts payable liability for $300,000.
Based on this quarter's operations, BOC estimates that it owes the IRS $3 million in taxes.
So a little bit hard to see the first criteria here, because there was no explicit transaction.
But essentially what happened is, the government allowed us to operate our business so that, so we got the benefit of being able to operate our business in this country, and in return it created an obligation to pay them taxes.
>> You said that the amount and timing of payment has to be reasonably certain for there to be a liability.
Why is an estimated amount considered to be reasonably certain?
>> We're going to have to make a lot of estimates in accounting.
As long as we're reasonably certain about the number, we should go ahead and book the liability.
For something like taxes, there are tax forms available on the web.
We have a rough idea of how much taxable income will be during the period, and so we can estimate what our tax liability is.
Now, it may not be 100% correct when we eventually file the form.
But whatever our best estimate is, is a much better estimate than ignoring it completely.
So, we go ahead and put our best estimate on the financial statements.
Next, BOC signs a three-year $120 million contract, to hire Dakota Dokes as its new CEO, starting next month.
Until Dakota actually works for us, and works for us without getting paid, there cannot be a liability.
And even then the liability would only be for the time that he or she has worked without pay.
We wouldn't book a liability for the entire three year contract because we haven't received.
The, benefits for that yet.
Plus, there's too much uncertainty with that because Dakota could quit tomorrow, we could fire Dakota, our lawyers, his or her lawyers could find a way out of the contract.
So we only are going to record a liability for the amount of time the Dakota's worked for us.
Since he or she hasn't worked for us yet, there would be no liability.
BOC has not yet paid employees who earned salaries of $1 million during the most recent pay period.
It does meet the first criteria because there's an obligation based on the benefits we've, we've received.
The employees have worked for us, we've gotten the benefit of their services, and now we have an obligation to pay them for those services.
The amount we owe is reasonably certain, and again, if there were any questions, the employees would surely let us know how much we owe them.
So we'd have an obligation based on past benefits for $1 million, and we'd book a liability called salaries payable for $1 million.
Why is this one a liability, but not the previous one?
Is it because the first one pertains to an executive, whilst the second one pertains to lowly employees?
It has nothing to do with status.
It's simply a matter of, for a liability to exist, there must be some obligation based on benefits or services received in the past.
Employees that have worked for us without being paid, creates a liability for us.
This would be a liability called notes payable, meets the first criteria because we have an obligation based on receiving the benefit of the $500,000 from the bank.
The amount that we owe is reasonable cert, that's $500,000 so it meets the second criteria.
So we have the liability called notes payable for $500,000.
>> Great question, interest is not a liability at this point because we just took out the loan, and we can presumably pay a back rate now without owing any interest.
Interest only becomes a liability as the money is outstanding over time.
And to the extent that we haven't paid it, the amount of interest that we owe but haven't paid becomes a liability.
This would not be a liability.
There's a potential obligation based on a benefit received in the past.
The benefit was we sold products which turned out to be defective.
Doesn't meet the second criteria though, because we can claim that the amount of the payment is still uncertain.
Until we have a settlement or we got to trial we don't know that we have to pay anything, so because of that uncertainty, we don't have to record a liability in this case.
Unlike assets or liabilities, there are not two criteria for how to measure stockholders' equity.
Because if you measure all your assets correctly and you measure all of your liabilities correctly then stockholders' equity is whatever is left over.
But there are two sources of stockholders' equity.
The first source is what we call contributed capital, which arises from selling shares of stock to the public.
So we'll talk about common stock and additional paid in capital.
That's what you record when you issue new shares to the public.
Common stock is for the par value, additional paid-in-capital if for everything you receive above the par value.
And then treasury stock is what we call it when the company re-purchases it's own stock from investors.
Is this why there are so many accountant on the golf course during the day.
>> I'm not sure why you're seeing so many accountants on the golf course, but it has nothing to do with par value.
There used to be laws which said that companies couldn't issue new equity if the value of their stock was below the par value.
Where they couldn't pay dividends if the value was below the par value.
Most of those laws are gone now.
And, par value's main implication is that when we issue equity, we put the par value amount of the proceeds into an account called common stock.
We put the rest into additional paid in capital.
The other source Stockholder's Equity is Retained earnings which arise from operating the business.
So what are dividends?
Dividends are distributions of retained earnings to shareholders.
They're not considered an expense and we record them as a reduction of retained earnings on the date the board declares the dividend, which is called the declaration date.
If we don't pay in cash on that date, which is what usually happens, it will create a liability to our shareholders, until we actually pay the dividend on the payment date.
They are paid in cash like other expenses, and why are they a liability?
First, dividends are not considered an expense because they're not considered a cost of generating revenue.
Instead dividends are a discretionary decision by the board of directors to return some funds back to shareholders that's presumably somewhat independent of the company's performance or sales during the period.
Second, we created dividends payable, because once the board declares a dividend, it's essentially holding the shareholders' money until it sends the check, making the shareholders creditors of the company.
Now, I admit that this one seems weird, because usually liabilities are for non-owners, where as here we have a liability to our owners.
But we consider them creditors in this one specific case.
Dividends are not an expense and when the board declares but doesnt' pay a dividend, we create a dividend payable liability.
And that wraps up our discussions of assets, liabilities, and stockholders' equity.
I'll see you then.
This is the video you've all been waiting for we're gonna talk about debits and credits.
Now I have to admit that there is somewhat of a disagreement in the accounting faculty world about whether we should still be teaching debits and credits.
I am firmly in the camp where I believe that debits and credits are a very useful and powerful tool for learning and teaching accounting.
If I had to figure out some kind of complicated transaction and financial statement, the first thing I would do would be break out the debits and credits to help me crack the problem that I'm trying to solve.
So, hopefully you'll find them useful too.
If nothing else, you're joining an exclusive fraternity of people around the world that can speak in the world of debits and credits.
Let's get started.
As a starting point I have to say that the most interesting thing about bookkeeping is that it's the only word in the English language with three consecutive sets of double letters, oo, kk, ee.
Beyond that, I'm not sure it's that interesting.
But these three fundamental bookkeeping equations I'm gonna show you, are incredibly powerful tools for both learning accounting and then ultimately understanding the information that you're gonna read in financial statements.
The first equation we've seen before.
We're also going to introduce the equation that the sum of the debits has to equal the sum of the credits.
And at the beginning balance of an account plus increases minus decreases has to equal the ending balance in an account.
These three equations must balance at all times.
And this will come in handy because many times we'll be missing one piece of information, but we'll have everything else.
And then we can use one of these equations to figure out the piece of information that we're missing.
So instead of having to constantly go back and recalculate the balance sheet equation, instead, all we have to do is make sure our debits equal our credits, and we know that the balance sheet equation is preserved.
Credit card.
All sounds good to me.
Debit card.
But in the accounting world, debit simply means left, credit simply means right.
All they mean is left and right.
Don't ask me why we abbreviate debit as DR.
It's probably something the British came up with centuries ago and we've always done it that way.
Now lets take a look at how debits and credits can be used to preserve the balance sheet equation.
So here's the balance sheet equation again and in prior videos remember we did a more complex complete balance sheet equation, where we split the stockholders' equity into contributed capital, retained earnings, and then revenues and expenses.
In a prior video, you had dividends in this complete balance sheet equation.
One reason is that I was running out of space on the slide, as you can see.
But the more important reason is, we're gonna not treat dividends as a separate account going forward.
We'll create separate accounts for revenues and expenses but we're just going to treat dividends as a reduction in retained earnings.
The problem with this equation is that we have the negative expenses at the end.
As we saw in a couple videos ago, it can get confusing with working with expenses in this case.
Because with any increase in expense would be an increase in a negative number on the right side of the equation which would make it go down, and it's very confusing.
To solve this problem, we're going to move expenses to the other side.
And it's all positive numbers.
Then we are going to call everything on the left debits and everything on the right credits.
There are a number of rules of debits and credits that we have to keep in mind and follow if we want the debits and credits to stand in for the balance sheet equation.
And as long as that's the case, we'll know that the balance sheet equation will stay in balance.
No negative numbers are allowed.
And as you can see in the balance sheet equation above, now that it's rearranged, we don't need to deal with negative numbers for debits and credits.
And in case you ever wondered, the reason why this is called accounting is because we put everything in these accounts, which are areas where we keep track of similar types of transactions.
That's the type of balance, either debit or credit, that the account carries under normal circumstances.
The difference between the sum of the debits and the sum of the credits, at any point in time will give us a balance for the account.
I was wondering why I wasn't getting any questions.
Okay, let's take a look at how this works in more detail.
Assets and expenses are going to have a normal balance that's a debit, which means it's gonna sit on the left side of the T-account.
For example, let's look at an asset like a Accounts receivable.
Remember this is the money owed to us by customers based on sales we've made in the past.
It's an asset, because it's money we'll collect in the future.
Notice I put a little(A) to denote that this is an asset account.
New sales on account increase accounts receivable, increase the amount of cash that our customers owe us, and we're going to increase the account through a each debit entry.
The customers don't owe us the cash anymore because they paid us.
Then at the end of the period we draw a line, add up the debits, subtract the sum of the credits, and we get an ending balance, in this case of 1,020, which sits on the debit side.
I am so confused.
It all depends on the type of account it is.
It's just left and right.
Now, let's look at accounts that have a normal balance on the credit side.
If we look at an example of a liability like accounts payable, this is money that we owe our suppliers based on on raw materials that we've received in the past.
Put a little (L) to indicate it's a liability because we have an obligation to pay those suppliers in the future.
At the beginning of the period, we owe our suppliers a thousand dollars.
During the year, we pay $80 to our suppliers that reduces the liability, reduces the obligation.
Also during the year we go out and purchase new inventory.
The end of the period we draw a line, add up the credits, subtract the sum of the debits, get an ending balance of 1,020, which sits on the credit side, or right side, because it is a credit balance account.
Or, is it the other way around?
Did I say that right?
Anyway, let's just go on.
One way to represent this graphically is through something we call the Super T-account.
If you think of the whole balance sheet as a big T-account with assets on the left and liabilities and stockholders' equity on the right.
And where it gets a little tricky is revenues and expenses.
Expenses are reductions in net income and hence, reductions in retained earnings.
Dude, can I get a tattoo of this on my arm?
>> Yeah, you could but maybe a less drastic step would be to just print out the slide or maybe write it on your hand with an ink pen.
But I do think it is a good idea to keep a cheat sheet handy to help remind you which accounts are debit balance accounts.
We're gonna follow a very systematic approach in analyzing transactions to figure out how to represent them as journal entries.
First what specific asset, liability, stockholders' equity, revenue or expense accounts does a given transaction effect.
Does the transaction increase or decrease the affected accounts?
And then should the accounts be debited or credited, and here we can look back to something like our super T account as a cheat sheet to figure out whether we debit or credit to increase or decrease the accounts.
The name of the account and the dollar amount.
We indent the credits, put a Cr for the abbreviation, the names of the accounts credited and the dollar amount.
Okay, this is really important.
Raise your right hand and repeat after me.
So, why don't we go ahead and stop the video at this point.
We'll pick it up in the next video with the series of four examples to help pull together everything we've talked about so far, and then we'll practice doing some journal entries.
I'll see you then.
In the last video we introduced a lot of terminology and concepts.
And in this video we're going to practice applying those.
I'm going to, I'm going to start with a series of examples to help review the key concepts from the last video.
Okay, let's reinforce everything that we've learned with a series of four examples.
In the first example, we're going to increase an asset and then increase either a liability or equity.
In this case, we receive $100 cash from a bank loan.
The accounts involved are cash and notes payable, both of which increase by $100.
That's the cash.
Liabilities would go up by 100.
That's the note payable, or obligation of the bank and equity is unchanged.
Cash is an asset.
So we would debit cash to get it to go up by 100.
And what I'll do is, I'll put in parentheses, plus 8, to indicate that this debit is increasing the cash account.
If we looked at this with T-accounts, we would have a cash T-account, which would have an entry on the debit side, a notes payable T-account which would have an entry on the credit side.
If we did a balance sheet equation, sort of drew a line, added up the balance in each account, our balance sheet would balance.
We'd have cash of 100 on the asset side, liabilities of 100 on the liability and equity side with no shareholder's equity.
So here were going to repay $20 of the bank loan.
For the journal entry, we're going to debit Notes Payable for 20.
We need a liability to go down, liabilities have credit balances.
So we credit the cash for 20, we'll reduce it.
For T accounts, we would have a credit entry in the cash the account, a debit entry in the notes payable account.
If we drew a line for the balance in each, our balance in cash is 80 on the debit side, balance notes payable is 80 on credit, aside, our balance sheet equation, would balance where we have eighty of cash, eighty of notes payable, and no stock holders equity.
Okay, okay.
But just two more examples and then we'll do some drill entry practice.
The example transaction is that we pay $10 in cash for inventory.
The accounts involved here are cash and inventory, and cash is going down by $10, inventory is going up by $10.
For the journal entry, we need inventory to go up, inventories and assets.
We need cash to go down.
Cash is a asset, you make a debit balance asset account go down with a credit, so we credit cash for ten.
In terms of the T-accounts, we would have another credit to cash of ten, we would put a inventory T-account.
If we drew lines and added up the balances, we've got 70 in cash, and ten in inventory on the left hand side, so that's 80 of assets.
Final example, we're going to increase a liability or equity and then decrease another liability or equity.
So in this case we're going to issue $80 in common stock to pay off the bank loan.
So the two accounts are common stock and notes payable.
Common stock is a stockholders' equity account going up by 80, the bank loan's a liability going down by 80.
In the balance sheet equation, we'd have nothing on the asset side.
Equity would go up for issuing the common stock.
For the journal entry, we want to debit notes payable for 80, because notes payable is a liability that we want to reduce.
We have 70 in cash, 10 in inventory, that's 80 on the asset side, we have no notes payable, it goes to 0 because we fully paid it off, and a balance in common stock of 80, so our asset equal our liability plus stockholders equity, balance sheet balances, debits equal credits.
Here's the first one.
In this transaction, we're receiving cash, cash is going to increase and we're going to increase common stock accounts.
Cash is an asset.
We make cash go up with a debit, so we're going to debit cash.
The dollar amount is 150,000, which is $15 cash times 10,000 shares.
$50,000 but we have to split it between the par value and the additional paid in capital.
And then we'll credit additional paid in capital for the rest, which is $100,000.
So do you also have more than one debit?
You can have more than one debit.
It's one of those difficult things that you can only come to trained professional like me.
To understand, so you're going to see it a lot.
The accounts involved in this transaction are buildings which are going up, cash which is going down and mortgage payable which is going up.
Buildings are an asset, so we debit buildings by 500,000 to increase the asset.
Cash is an asset.
So to make it go down, we need to credit it with credit cash for $80,000 to reduce that asset.
And then mortgage payable as a liability has a credit balance.
We're not given the amount, but we know it has to be $420,000, because we know our debits have to equal our credits.
Once we credit Mortgage Payable for 420,000, we have 500,000 in debits, 500,000 of credits, and we're in balance.
BOC obtains a three year fire insurance policy.
In this transaction, we're getting fire insurance coverage for three years.
That's an asset that we're going to call pre-paid insurance and it's going up.
We're paying cash, so cash is going down.
Cash is an asset also, but it's going down, so to make cash go down; we credit cash to reduce asset by 3,000.
BOC acquires on account office supplies costing, 20,000.
In this transaction, we're acquiring office supplies and inventory.
Both of those are assets, so we're going to make them go up with debits.
Instead by 35,000 now were not paying any cash instead we owe our supplier $55,000 because we got the stuff on account.
When we owe money to our supplier, let say liability called accounts payable, that's increasing, we make a liability increased though a credit, so we credit accounts payable for 55,000.
So we have 55,000 of debits, 55,000 of credits and we're in balance.
Next, BOC pays $22,000 to its suppliers.
And since we're paying cash, it's going to reduce cash as well.
If we want to reduce it, we credit Cash for $22,000.
And this, by the way, is the journal entry you're going to do any time that you pay cash fo reduce a liability.
In this transaction we're trading one asset for another asset.
We're getting land.
Land is going to go up, so to make land go up, we debit land, 200,000.
Building is going down.
>> How do you know that the land is worth $200,000?
>> Given the information we have, we have to assume the land is worth $200,000 so our debits equal our credits.
And the assumption makes sense because if we are giving up a $200,000 building and just getting land, the two values should be equal.
But that's for another day.
BOC retires $1 million of debt by issuing 100,000 shares of $5 par value stock.
Any time we reduce a liability, we need to debit the liability to make it go down.
So we debit notes payable for $1 million to reduce it by a million.
Now we need to increase stockholder's equity by a million but we have to split it into the common stock and the additional paid in capital.
For $500,000, which is 100,000 shares times $5 a par value.
Then we credit additional paid in capital to make that stockholder's equity account increase.
Sorry, I'm going to make you do par value a lot, get over it.
BOC receives an order for $6,000 of merchandise to be shipped next month.
In this transaction, we're receiving $600 cash.
Anytime we receive cash, we debit cash to increase the asset.
We're also getting an obligation here because now we either owe the customer $600 back or we have to deliver the merchandise.
We only account for the $600, because that's the only part where there's been a transaction or exchange, because we received $600 cash.
For the other $5,400, that's all future stuff.
That's all promises.
We don't have a liability yet because there's no obligation that's based on benefits or services that we've received.
Not until we exchange cash good or services equal to $5,400 in the future.
Finally, BOC declares and pays $8,000 of cash dividends.
Let's start with cash in this transaction, so cash is doing down by 8,000.
Any time cash goes down, we credit cash to reduce the asset.
So now, we know we're looking for a debit.
The other part of the transaction is dividends.
Now remember, dividends are a reduction in retained earnings.
That was a lot of good practice at taking transactions and trying to represent them as journal entries using debits and credits.
You're going to get a lot more practice.
Starting next video, we're going to do an extended case that follows a start-up company, all the way through it's first transactions, to it's first set of financial statements.
And along the way, you're going to get a lot of practice doing journal entires and see a lot more debits and credits.
Starting with this video, we're gonna look at an extended case study, which will illustrate the accounting cycle.
The accounting cycle is all the steps that you have to follow to go from recording transactions, all the way through preparing financial statements.
The case is gonna be spread out over a number of videos, interspersed with new topics that we introduce, which will then illustrate in the case study.
So we've seen in the last couple videos how journal entries and T-accounts can be used to track and record the effect of transactions.
And the key is to make sure that our debits equal our credits when we record these journal entries.
And if we do so, then we know that the balance sheet equation will hold when we add everything up.
>> So, when I buy something at the store and the cashier says debit or credit, should I point out that he is really asking left or right?
We set liabilities, shareholders equity and revenues to have credit balances so that credits will increase these accounts and debits will decrease them.
We also looked at a visual picture that we could use to remember this.
The Super-T account, which shows whether debits or credits increase the decrease the various types of accounts and talked about how you should print this out, keep it handy until you memorize it, or tattoo it on your arm, whatever your inclination may be.
Now we're going to talk about the Accounting Cycle.
Let's take a ride on the accounting cycle.
>> It's not that kind of cycle, but it should be just as fun.
We're going to go through the entire accounting cycle with an extended case, which follows a start up company from its first set of transactions all the way through its first set of financial statements.
And that's what the accounting cycle is set up to do.
First, as the business is operating during a fiscal period, transactions happen and then you have to analyze those transactions to figure out how to come up with journal entries, and then post those journal entries to T-accounts.
Once the period is over, we do something called an unadjusted trial balance to make sure we haven't made any math mistakes, or transposed any numbers.
Then we do something called adjusting entries, which are needed to get the books correct before we do financial statements.
After another trial balance, we prepare the financial statements.
We're gonna start the case with the first part of the accounting cycle, where we analyze transactions.
And then figure out how to journalize them, which is record each transaction as a journal entry in something called the general journal.
Then, we're going to post that journal entry to T-accounts, or general ledger, where we'll keep a running total of the balance in all the accounts.
So now let's take a look at the facts of the case.
In March of 2012, Rebecca Park identified an excellent business opportunity while she was a first-year MBA student at Wharton.
She read a story about an MBA student who tripped while jogging in Fairmount Park and found an ancient gold coin in the underbrush.
It was an old viking coin that was appraised as $77,500.
She realized she could set up a profitable business that rented out portable metal detectors to people that wanted to search Fairmount Park for more Viking relics.
Also Park had the idea of stocking her store with sundries, such as water bottles and energy bars, that she could sell at a huge markup to renters before their expedition into the park.
Park prepared a business plan and approached a fellow student, Jay Girard, who had a sizable trust fund and who she believed would invest in this new venture.
Due to his myriad of other investments and his heavy course load, Girard agreed to invest as a silent partner and allow Park to run the business, which she named Relic Spotter Inc.
So now what we're gonna do is go through a number of transactions for the company.
After each transaction is read you should pause the video and try to do the journal entry.
Then resume the video to see the answer and the explanation.
On April 1st, 2012, Girard decided to invest $200,000 and Park put up $50,000 To purchase a total of 25,000 shares in the new company.
The par value of the shares was $1.
In this transaction, we're receiving $250,000 of cash for issuing equity.
Cash is an asset.
We increase assets through debits so we're going to debit cash for $250,000 to increase this asset.
But remember that we have to split this into two parts, the par value and the additional Paid-in-capital.
So first we have common stock at par, which is going up by 25,000 shares times $1 or $25,000.
We make stockholders equity go up with a credit, so we credit common stock for 25,000.
And then we credit Additional Paid-in-capital for the rest, $225,000, which is the number that we need so that our debits equal our credits.
As we talked about last time the only requirement is that your debits equal your credits.
So we create a T-account for cash, put the 250,000 on the debit or left hand side.
We put a little 1 there so that we can trace this number back to the original journal entry in the general journal.
Of course the balance is on the credit side and the same thing for additional Paid-in-capital.
Transaction 2, Lacking the funds for her initial investment, Park borrowed the $50,000 from the Imperial Bank of Philadelphia on April 1, using her parent's house as collateral.
In other words, Relic Spotter doesn't have to pay this loan back, Rebecca Park does.
So there's something called the entity concept which says the only thing that should go in a company's books are transactions for the company, not transactions for the employees.
So, we want to keep this separate, Rebecca Park's loan.
But for the rest of the case she's doing things on behalf of the company, so you're not gonna see this trick again.
Since there's no journal entry, there's nothing to post to T-account, so we can go right on to transaction 3.
On April 2nd, Park hired a lawyer to have the business incorporated.
Because this was a fairly simple organization, the legal fees were only $3,900.
So let's take a look at the journal entry.
I always recommend starting with cash, if there's cash involved in the transaction, because you'll quickly memorize whether to debit or credit cash based on whether you receive or pay cash.
So in this case we're paying $3,900 in cash for legal fees, which seems quite exorbitant.
But I guess it's a lawyer, so what are you gonna do?
Anyway, if we're paying cash, cash is going down.
Cash is an asset, so assets go down through credits.
Now notice, even though I started with cash and it was a credit, I don't write it first in the journal entry.
As we talked about in a prior video, you always want to write debits first, so I had to skip some space, write the credit second and indent it.
So now we need to find a debit.
So what are we getting for this cash?
So it's going to be legal fee's expense.
Remember that expenses can increase through debits, so we're going to debit legal fee expense, which will increase expenses and reduce stock holder's equity by 3,900.
Why isn't this an asset?
>> I guess you could say this is an asset because the future benefit is that we get to operate the business forever once we've incorporated it.
It's a pretty lame rationale but there were companies that used to call this an asset.
Now the rules are explicit, this kind of expenditure has to be expensed immediately.
Let's post this to T-account, so we bring back our cash T-account.
We put 3,900 on the credit side, or the right hand side with a little 3 to indicate that it's transaction number 3.
And we create a T-account for legal fee expense with 3900 on the debit side or the left side.
To house the business, Park bought an abandoned pizza parlor near Fairmont Park for $155,000 on April 7.
The building was old and needed renovation work.
The purchase documents allocated $103,000 to land, and $52,000 to the building.
Park paid for the building with $31,000 cash, and a $124,000 mortgage from the Imperial Bank.
Wow, this is a big transaction, so it's going to require a big Journal Entry.
Always like to start with cash if we can.
We paid $31,000 of cash.
Cash is an asset, assets go down with a credit, so we credit cash for 31,000.
We acquired land and building.
Land and building are both assets, assets go up with a debit, so we wanna debit building for 52,000 and debit land for 103,000 and make those two accounts go up.
Now at this point our debits don't equal our credits so we can't stop, we're missing one more piece, and that piece is the mortgage.
A mortgage is a liability, liabilities go up with a credit, so we need to credit mortgage payable for $124,000 and now our debits equal our credits.
Won't we have to pay interest on the mortgage?
Those two look like twins.
Anyway, both good questions.
As for the interest question, I think we talked about this in a prior video, but it's good to review it.
We don't own any interest when we take out the mortgage.
We could pay back the mortgage immediately, and not have to pay any interest.
Only as time passes and we owe interest without paying it will we have to record an interest payable.
We've got a lot of posting to do for this journal entry.
We bring back our cash T-account and put another credit on the right-hand side.
Create T-accounts for Building and Land and one for Mortgage Payable.
For this transaction, the first thing we're gonna do is ignore the stuff about salvage value and 25 years.
We'll come back to that in a later video.
Instead, we're gonna focus on the transaction that happened on May 25th, which is when Park paid the cash.
We paid $33,000 of cash, cash is an asset.
We make an asset go down through a credit, so we credit cash for 33,000.
Well we added to the building and so we're going to debit building for $33,000 to increase the balance in the building account.
>> Excuse me, why isn't this an expense instead of an asset?
And the assets seem like expenses.
The general rule is if you spend money on maintenance, an expected cost on maintaining the asset, then you would expense it.
But if you spend spend money for a capital improvement, which would be something that would increase the value of the building or how long you plan to use it, then you get to add that to the building account.
But don't worry about this now.
This is something we're going to talk about in a lot more detail later in the course.
Then we post this to T-accounts, we add another credit to the right-hand side of the cash account and a debit to the left-hand side of the building account.
So now the balance in the building is $85,000.
I would tell you what the balance in cash is, but I can't do math in my head, so you'd have to figure that out on your own.
On June 2nd, Park purchased 240 metal detectors at an average cost of $500 per unit, so that's $120,000 total.
The innovation in the industry is so rapid, that Park felt the units would only last for two years, at which time they would have no remaining value.
We need to record the transaction where we paid $120,000 cash to get metal detectors.
If we're paying cash, cash is going down.
Cash is an asset, goes down with a credit.
Well, we're getting metal detectors.
Metal detectors are an asset.
Wait, why aren't the metal detectors considered inventory?
>> We only use the inventory account for goods that we buy with the intention of selling as quickly as possible at a markup.
We don't call the metal detectors inventory because we intend to keep them for two years and use them over and over and over and over again to generate rental revenues.
Then we post this to T-accounts, we add another credit on the right had side of cash.
So we're about halfway done at this point, so why don't we go ahead and stop this video, and we'll pick up the case in the next video with the next transaction.
See you next video!
In this video, we're going to pick up where we left off last time and continue to do the initial transactions for the Relic Spotter case.
Got a lot to get to, so let's get started.
Let's start back up with transaction number seven.
On June 15th, Park ordered $2,000 to sundries inventory, for instance, water bottles, energy bars, etc., to be delivered on June 30th.
Park was able to purchase the inventory on account, which meant she had up to 30 days after delivery to pay the supplier.
So, I'd like to start with cash, but there's no cash in this transaction.
And we owe the supplier money for the inventory within 30 days.
So let's start with inventory.
Inventory is an asset, assets go up through debit, so we're going to debit inventory for 2,000.
Accounts payable is the term we always use when we owe money to a supplier.
On June 15th we placed the order, but there is no transaction yet, because we haven't had an exchange of cash, goods or services.
It's not until June 30th, when we take physical delivery of the inventory, that we have to record a transaction.
Transaction 8, on June 30th, Park paid $2,100 for a three-year site license to use geo-contour mapping software in the metal detectors.
For the journal entry we're back to paying cash, so we'll start with cash.
Anyway, software is going to be an asset because it's something that we can use to run the metal detectors over three years.
Assets go up with debits, so we debit an asset called Software for 2,100.
I hate to sound like a broken phonograph record, but why is this an asset, and not an expense?
One of the trickier things to pick up in accounting is, when you spend money, do you recognize an asset or do you recognize an expense?
In this case, we did an asset, because we're going to get three years of future benefits from buying the software.
And in future videos, we'll talk about what has to happen for this asset to then turn into an expense, as it will down the road.
We post this journal entry to T accounts by putting another credit on the right hand side of the cash account and creating a new T account for the software asset.
Transaction 9, on June 30th, Park signed a contract with a local advertising agency to provide various forms of advertising for a period of one year.
She paid $8.000 upfront for advertising through June 30th, 2013.
Cash is an asset, we make an asset go down with a credit, so we credit cash for $8,000.
And by this point you should be able to credit cash in your sleep because we've done it so often.
Every time we pay cash, it's a credit to the cash account.
Now we need a debit so what are getting for this cash?
Well, we're getting a year's worth of advertising without having to pay any additional cash, that's an asset.
So we're going to create an asset called prepaid advertising.
>> Do we also get to record the value that this advertising will create as an asset?
Sounds like an asset to me.
>> It's important to note that the asset here, only represents the cost of the advertising that's been prepaid.
It doesn't represent any of the potential value that the advertising could bring us in the future.
We don't record that value as an asset because the benefits cannot be measured with a reasonable degree of certainty.
It's just like the brand name example we looked at in a prior video.
If there's too much uncertainty about the value of the brand or the value of the advertising, we err on the side of reliability and don't include it as an asset.
So we've got another credit to cash on the right hand side and we create a T account for prepaid advertising with a debit of 8,000.
On June 30th, Park needed cash to make a payment on the Imperial Bank loan that funded her purchase of Relic Spotter stock.
She borrowed $5,000 from Relic Spotter at 10% interest, with the principal and interest due in a lump sum on June 30th, 2013.
This transaction looks complicated but let's just start with what we know.
So, what we know is that Relic Spotter paid $5,000 cash to Rebecca Park.
We're paying cash, cash is going down since cash is an asset, assets go down with credits.
So, what is Relic Spotter getting for this cash?
Well, essentially they're making a loan.
That loan is going to be an asset because they're entitled to receive 5,000 of cash back from Rebecca Park at some point in the future.
If an employee owes us money for a loan, we're going to call it a notes receivable.
The last time Park borrowed money for herself, we didn't record it in the company's books.
What's different was that in the first example we saw she was borrowing it from the Imperial Bank.
In this transaction, she's borrowing it from Relic Spotter.
That means that Relic Spotter is giving some of it's cash to Rebecca Park.
And Relic Spotter has to record a transaction for that disbursement of cash to Rebecca.
On June 30th, Park also hired two employees, Linda Carlyle and Charlotte Cafferly to run the shop.
They signed employment contracts promising each salaries of 32,000 per year.
So, the journal entry here, well, let's stop and think for a minute.
We, we haven't paid any cash yet to these two employees.
They haven't done any work for us yet.
There's no journal entry for this employment contract because they haven't worked for us yet, we haven't paid cash yet.
And so we don't consider this a transaction, we don't account for this type of promise.
Where I come from, when you promise something, it becomes an iron clad obligation.
>> I'm sorry to cause so much stress, but, but we did talk about this in the liability video.
Remember.
One of the criteria for recording a liability is the obligation that has to be based on some benefits received currently or in the past.
In fact, they could quit tomorrow and we wouldn't owe them anything.
So it's not until they work for us without being paid, that we would record a liability.
Since there is no journal entry there is nothing for us to post, so let's go on to transaction 12.
Upon hearing that Relic Spotter only had $47,000 of cash left in the bank, Girard became concerned about his investment.
Now, there is more to this transaction, but I want to cut in here for a second to show you how we could figure out how much cash Relic Spotter has in the bank.
If we bring up the cash T account, at this point we could draw a line, add up the debits, add up the credits, subtract the credits from the debits and we'd have a balance of 47,000.
So, at any point you can draw a line and figure out a balance.
And at this point we have 47,000 in the cash account.
Okay, back to the rest of the transaction.
Thinking fast, Park stated she was so confident of Relic Spotter's prospects that she was declaring a $0.10 per share dividend, to be paid on August 31.
So that's $25,000.
because we, we haven't actually paid any cash yet, has there really been a transaction?
Well, as we talked about in a prior video, the custom is that when a company declares a dividend, you make a journal entry at that point even though the cash will be paid later.
So, on June 30th we need to reduce stockholder's equity, reduce retained earnings to recognize the dividend.
We reduce stockholder's equity, a credit account, with a debit entry, so we're going to debit retained earnings for $2,500 to take out the dividend.
The other side of this is that, as we talked about in another video, once you declare a dividend, essentially you're holding the cash that belongs to the owners, until you write the checks.
So, you have this obligation to write those checks and deliver the cash, that obligation is a liability called dividends payable.
I thought you said that we don't account for promises.
Wouldn't it make more sense to wait until they are paid?
Someone need to take a chill pill or something.
We did talk about this in a prior video.
And at that point, the owners become creditors because the company is holding their cash until the dividend checks are sent.
And we have a balance on the debit side and a T account for dividends payable liability where we put in the credit entry.
According to my notes, it is a stockholders' equity account and should have a credit balance.
That makes me feel good.
But to make sure that the balance sheet equation always stays in balance, we need at least one account that can be either a debit or credit balance.
The only way we could get the balance sheet equation to balance would be with negative stockholders' equity.
And so we make an exception for retained earnings and allow it to have either a debit or credit balance because it's the one account that makes sure that the balance sheet equation always stays in balance.
If retained earnings does have a debit balance often times we change the name and call it something like accumulated deficit or accumulated losses.
On July 31st, Park paid the supplier the $2,000 it was owed.
The debit here is that we're paying what we owe the supplier.
So, if we're paying a supplier the liability's going to go down and we make liabilities go down through a debit.
And a debit to accounts payable and notice, at this point, the balance in accounts payable would be zero.
Which makes sense because we don't owe our suppliers any money anymore, we fully paid off the liability.
On August 31st, Park paid the $2,500 dividend that had been declared in June.
For the journal entry here, we're paying $2,500 cash, so that's a credit to cash for $2,500.
The debit is going to be to dividends payable because we are paying off what we owe the shareholders for the dividend, thus we are reducing the dividend payable liability.
So, it looks like every time you pay cash to settle an obligation, you debit some payable and credit cash.
Every time you paid out a liability, you debit the liability and credit cash.
And that's a wrap for the first part of the case.
We'll pick up the case again after we learn about revenues and expenses which will allow us to start generating some profits for Relic Spotter.
I'll see you next time.
Welcome back.
Wow, what a long week of watching videos on the accounting basics.
So, what I want to do in the last video each week, is look at a real financial statement.
So that we can take the things that we learned in the lectures, and see how they play out in a real world financial statement.
And to do this, I want to use the same financial statement throughout the course.
The statement I chose is the 3M company.
In case you haven't noticed, I'm from Minnesota.
There's a Vikings helmet over here and some hockey helmets.
My grandmother worked for 3M for 40 years.
It's a company I have some affinity for.
Hopefully I won't find anything bad in the report.
What we'll do in this video though, is take a quick tour of everything that's in the annual report.
So that you have sort of an overview of where we're going to find things.
And at the end of every week, we'll dive in, in more detail and try to find that week's topics in the 3M annual report.
So we pull up the 3M annual report.
Some smiling kids, some benign looking chemicals.
And then kids drawing pictures.
And then there's the impact they have on smiling, happy children.
We go to the next page and you get a letter from the chairman and CEO.
So this is his explanation of how the company did during the past year.
We get some graphs showing that everything's going up.
Looks like everything is going well with 3M.
By the end of the course, you will not only know what all of these terms mean.
We have to read through the entire annual report.
And if we go to the next page, we get this very ominous-looking black and white page.
Starts with United States Securities and Exchange Commission at the top, form 10K.
From this point forward, we're looking at the filing to the SEC.
And so everything that 3M says or reports here, is subject to all the laws and the Securities and Exchange Acts of 1934.
Then if we go to the next page it gives us the table of contents.
And, part one of the report we're going to learn a lot about the business.
You know, what I'm going to do in a second is just flip through a lot of these quickly.
You'll look at these much more carefully as we go on later in the course.
Part two, is going to give us the financial information.
Which are the star of the show.
And then part three, gives us proxy related information, the directors, officers, how much they're paid.
And then there's any supplemental exhibits in part four.
Part one has the information about the business.
And again, I'm just going to flip through this very quickly.
If you want to go and read it in more detail, see what kind of things are there.
And part two starts some information on stock price, selected financial data.
Now, here's the big thing management discussion analysis.
This is where management tries to explain to the users of the financial statements, what happened during the year.
Tries to provide some kind of explanation so that users can understand the financial statements.
Although management is being very helpful by giving us all this detailed explanation on what they think happened during the prior year.
After all, there have been some companies which have had some big frauds.
So I like to look at the financial statements and the footnotes first.
Come up with my own theories for what happened.
And then come and see what management's saying about it.
Just as a reality check of whether I can believe what they're saying.
So flipping through here, you can see it's going to be pretty extensive and detailed.
And we're going to come back and look at these once we've learned about all of these topics later in the course.
There's disclosures about market risk.
And then we finally get to the financial statements.
Which, as I said, I think are the stars of the show.
Which, right away tells you that the financial statements are probably not going to have all the information we need.
We're going to have to dive into these footnotes to really learn what we need to learn about the company.
And we're going to be doing a lot as we go through the course, is looking at the details of the footnotes.
On the next page, we see two of the reports.
Management's Responsibility for Financial Reporting and Internal Controls.
So as we talked about in earlier lectures, management is responsible for putting together the financial statements.
Now of course, they come in.
The consolidated financial statements listed in the accompanying index present fairly, in all material respects, the financial position of 3M Company.
And its subsidiaries at December 31, 2012 and 2011.
And result of operations and cash flows for the three years ending December 31, 2012.
In conformity with accounting principles generally accepted in the United States of America.
I want to jump in here to point out what the auditor is actually saying here.
They're not saying we are giving you an ironclad guarantee, that 100% of the things in this statement are completely accurate and true.
Instead they're saying, in our opinion these financial statements present fairly in all material respects.
The financial position, results of operations in conformity with US gap.
In other words, we've gone and looked at some of the big things that they're doing.
They seem to be following the rules, at least in our opinion.
So as we've talked about in earlier videos, the auditors give us a little bit of insurance, assurance.
But we still need our own healthy dose of skepticism when reading these statements.
Because, we cannot fully reply on what the auditors have done in terms of guaranteeing the accuracy of everything in these statements.
The rest of the report talks about internal controls.
Thanks to Enron and the Sarbanes-Oxley Act There's a lot of focus now on internal controls that have, companies have.
It's a big part of the job.
It's not something we're really going to talk about in this course.
We'll come back and look at these as we learn more material.
And on, and on and on.
Wow, still not through the footnotes yet.
Still not, okay.
Went too fast.
By the end of the course, you'll be able to work your way through a lot of these and understand what's going on.
The last parts of the report are part three.
Which gives us the proxy information, directors, officers, comp.
We're not going to talk about these, you can look through them if you're interested.
Most of those were incorporated within the financial statements.
Which makes this a fairly short annual report these days.
And I made my students responsible for knowing everything in those 279 pages.
So, you're getting off a little bit easy here.
So that was a quick overview of the 3M annual report.
As I mentioned, every week we will come back to it to try to find what we've talked about during that week's video lectures in the 3M financial statements.
And do a deep dive through that statement to try to find all the things that we've learned about during the course.
I, I realize it was probably a tough week of videos.
We've got a couple more tough weeks ahead of us.
But I think you'll find, by the end of the course it'll be worth it if you stick with us.
This is a fairly important video because we're gonna talk in detail about the difference between accounting income and cash flows.
Accounting income is determined by something called accrual accounting, which tries to measure business activities, and gives a very different picture of the company's performance than merely cash in or cash out.
Let's get started and see how this works.
As we talked about in the opening video, the income statement reports increases in shareholders' equity due to operations over a period of time.
Net income is made up of revenues minus expenses, and there's a couple synonyms that are often used for net income, it's also called earnings and net profits.
Revenues are recognized when goods and services are provided, not necessarily when the cash is received.
Expenses are recognized in the same period as the revenues they helped to generate, not necessarily when cash is paid.
And so, the bottom line is that net income is not the same thing as net cash flow.
So, let's look at revenues and expenses in more detail, starting with revenue.
Revenue is an increase in shareholder's equity from providing goods or services.
There are two criteria that need to be satisfied to recognize revenue.
First, it has to be earned, which means goods and services are provided.
And it has to be realized, which means that payment for the goods and services is either received in cash or something that can be converted to a known amount of cash.
These are called the revenue recognition criteria.
For example, let's say that we make a sale to a customer, we deliver the goods to the customer, and we give the customer an invoice, which has the dollar amount that they owe us and a time period in which they have to pay us.
So in this case we could book the revenue even before we get the cash and what we would do in this case is create an accounts receivable for what the customer owes us.
But, can you give us some examples of when these criteria would not be satisfied?
Thank you for asking.
Here's an example where the first criteria, earned, may not be straightforward.
Let's say you pay $100 to a software company to buy some software for your computer.
For the software company, the $100 is realized because they've collected the cash, but they might not book the full $100 as revenue today because it's not all earned.
So the software company might do is book $80 of revenue today, because that's what they earned by delivering the code, the other $20 of revenue would only be booked later on, as they deliver updates or as they provide technical support over time.
So there used to be this CEO who was a turnaround expert.
I'm not going to mention his name because I don't want to get sued.
But what he used to do is get hired by distressed companies, and he would come in and reduce the work force, streamline the operations, make aggressive accounting decisions, and turn around the company very quickly.
On one of this stops, he ended up shipping out a bunch of product to customers that hadn't ordered the product, right at the end of the quarter.
These shipments allowed the company to book the revenue and meet their earnings targets that analysts had set for that company for that quarter.
The justification for booking the revenue was that it was earned because they had delivered the goods, and it was realized because they gave the customers the invoice.
The problem is that if the customers haven't ordered the product, they're probably gonna send it right back without paying it.
And so the revenue really hasn't been realized because you don't have something that can be converted to a known amount of cash, because you don't know the customers have any intention of actually paying for the goods that you shipped to them.
>> Yes, in fact, the company I'm talking about got in trouble with the Securities and Exchange Commission for this practice.
In fact, well over 50% of the enforcement actions by the Securities and Exchange Commission are for violation of one of these two criteria.
So these criteria have a lot of gray area in trying to interpret them.
Expenses are decreases in shareholders' equity that arise in the process of generating revenues.
Now here we're talking about two criteria, but it's an either/or instead of a both, and we're really talking about a distinction between something called product costs and period costs.
I'll come back and talk about those in a second.
But as an example think of a company that makes video cameras.
For some reason I'm very interested in video cameras.
The product costs would be all the direct costs of producing the video camera.
It would include raw materials such as plastic, the metal, the glass for the lens.
It would include all the labor that went into producing the camera, all the costs of the factory, which we call overhead.
All of these are product costs.
These product costs would stay in inventory until the camera sold.
When the camera sold, those costs would leave inventory and become an expense.
So product costs follow the product.
Now, think of all the other costs of running a business that makes video cameras.
You have to have research and development people, operations personnel, sales force, marketing staff, human resources, top management.
Those people are not directly involved in producing the video camera, but they are costs of running the business.
We call all of these costs, period costs.
Later we're gonna call them SGNA or selling general and administrative cost.
These costs are recognized as expense when they're incurred.
What that means is, when the people work for you, you incur the costs and so you recognize those costs as an expense at that point.
>> What if the company used the CEO's car to transport parts from the warehouse to the factory?
Would that be a product cost or a period cost?
I should come back to this topic when we talk about the income statement in a future video.
The product cost versus period cost distinction is what we call the matching principle, where we try to match expenses to the revenues that they generate.
There's also something called the conservatism principle, which is for unusual events.
This principle says recognize anticipated losses immediately, but recognize anticipated gains only when they're realized.
Another way to look at this is it's the anti-human nature principle.
Human nature would be, hey, something good's gonna to happen in the future, let's record it now.
Whereas, somethings bad's gonna happen in the future, let's just wait until it happens.
The Conservatism principle forces you to do the opposite.
If you anticipate some loss in the future, like an environmental clean-up, or a settlement on a product liability suit, or employee severance cost, restructuring, you don't wait until those costs actually happen to expense them.
You expense them right away as soon as they're anticipated.
But if you expect some big gain to happen in the future, like you've signed a new customer to a contract and you expect big profits in the future, you actually have to wait until those profits come.
You can't recognize them when they're anticipated.
And for this reason, you'll see a lot of big one-time expenses, but not so many big one-time gains.
It's because the Conservatism principle forces you to anticipate future losses, but not anticipate future gains.
I am going to leave if this turn into a biased political polemic.
Now we're gonna practice applying these revenue recognition criteria to figure out how much revenue should be recognized in the month of December for each of the following examples.
As always, you'll see a pause button so if you wanna pause the video and guess the answer, the pause sign will cue you when you should do that.
BOC delivers $500,000 worth of washing machines in December to customers who don't have to pay until February.
The answer is $500,000.
BOC has delivered the washing machines, so they've earned the revenue in December.
BOC's given the customer an invoice which has them scheduled to pay in February.
With both earned,and realized, BOC get's to book $500,000 of revenue in December.
Do we have to cancel out the revenue?
It still seems dodgey to me that you can record revenue before you get the cash.
>> Yes, you are correct that we do have to worry about whether we will collect the cash on this revenue.
Later in the course, we'll see how companies try to estimate how much of their revenue they won't collect in cash, and then, at the time of sale, make an adjustment to reduce their revenue based on the amount they don't expect to collect.
For now, let's just assume that all of the revenue is eventually collected in cash.
BOC collects $300,000 cash in December for washing machines delivered in October.
Presumably, when BOC delivered the washing machines in October, they also sent an invoice so that they could book the revenue of $300,000 in October when those revenue recognition criteria were satisfied.
In December, BOC's just collecting the cash on accounts receivable.
They can't book the revenue again or it, or they'd be double booking it.
So there wouldn't be any revenue in December, it was all booked in October.
Next, BOC Realty leases space to a tenant for the months of December and January for $20,000, all of which is paid for in cash in December.
The answer here is $10,000.
We've received the cash, so we know whatever revenue we're going to record meets the realized criteria.
But the question is how much have we earned in the month of December?
If BOC is getting paid for December and January, the way they earn revenue is by providing space to the tenant for December and January.
That's the amount that's been earned in December.
BOC Aerospace receives an order for a $400,000 jet in December to be delivered in July.
BOC Aerospace has not delivered any goods or services in December.
So they have earned no revenue which means they can't book any revenue until they actually deliver a jet.
>> If this is a long-standing customer that promises to pay us, why can't we book the revenue now?
Even if it's a long-standing customer, the revenue recognition criteria still apply.
We have to deliver goods or services before we can record revenue.
It's just one of those conservative, I mean non-aggressive, practices that accountants use to increase the reliability or objectivity of the financial statements.
BOC Bank is owed $100,000 of interest on a loan for December and receives the payment in January.
The answer is $100,000.
BOC Bank has earned the interest revenue by providing the money outstanding to its customers.
It's provided a service.
Presumably, there's some kind of payment schedule with the customer who borrowed the money on when they should pay, so we can consider it realized.
And so BOC Bank can book $100,000 of interest revenue in December even though they won't get the cash payment until January.
BOC issues 20,000 shares of stock in December and receives $10 per share, which is $2 more per share than they expected.
Companies can only record revenue when they provide goods or services.
You just simply can not book revenue on issuing your own stock.
Revenue is only booked when you provide goods and services.
So for each of these items we're gonna try to figure out how much expense would be recognized in December.
First, BOC Automotive buys engines worth $2,000,000 in December for cash.
BOC has bought engines with cash, but engines are gonna be a product cost so they're not gonna be expensed until BOC actually sells the cars that they make with those engines.
So at this point, no expense.
BOC Automotive uses the engines to make cars at a total cost of $10,000,000 in December.
We know how much the cars cost in total, but the cars are still product costs, and the cost won't become expenses until BOC Automotive actually sells some cars.
In contrast, I'll use the term cost very loosely.
A cost is any cash outlay, whether in the past, present, or future that's required to run the business.
BOC Automotive sells cars costing $8 million in December for $15 million.
The answer is $8 million of expense in December.
The expense will be equal to what it cost to make the cars, which is 8 million.
The $15 million will be the revenue that we earn from selling the cars.
And it's good news in this case because our revenue is greater than our cost, so we've made some profit.
BOC Automotive incurs 180,000 in salaries for its marketing staff in December.
The answer is $180,000.
It's helping us sell cars this period.
So the matching principle would say, let's match the cost of the marketing staff this period to the revenues we generated this period and expense the entire cost of the marketing staff this period.
BOC Automotive pays its auditor $50,000 in December for services to be rendered in December and January.
The answer is 25,000 of expenses in December.
Even though we paid $50,000 cash to the auditor in December, we're paying for work the auditor is going to give us in both December and January.
We can only recognize the amount of work they've done in December as a cost and hence an expense.
If we assume it's roughly divided between the two months, then half of 50,000 will be 25,000 of expenses.
The other 25,000 will be expensed in January when the auditor provides the work for us then.
We paid the auditor $50,000, right?
We're only going to expense the cost of the auditors as they work for us.
BOC paid their auditor $50,000 cash for work the auditor would provide in December and January.
But BOC only wants to expense in December the amount of work the auditor did in December which is half of that, or $25,000.
BOC Automotive pays $1,200,000 in cash dividends in December.
Dividends are never considered an expense because they're not considered a cost to do doing business.
In this video we're going to finally generate some income for Rebecca Park and her Relic Spotter company.
We'll go through a number of revenue and expense transactions for Relic Spotter and see how they performed in their first six months of business.
In a prior video we did the first 14 transactions for this start-up company.
Now we will resume the case with transactions related to revenues and expenses.
Some of the transactions will be summary entries to record six months worth of activity in one journal entry.
After the transaction you should pause the video and try to do the journal entry.
And then resume the video to see the answer and the explanation.
In a search for new revenue opportunities, Park initiated an unlimited rental arrangement with the Penn Antiquities Club on December 1, 2012.
Under this arrangement, the club paid Relic Spotter $1,200 cash upfront for unlimited rentals over the next year.
For this transaction, Relic Spotter is receiving $1,200 of cash.
Cash is an asset, we increase an asset with a debit, so we're going to debit cash for $1,200.
Now we have to look for the credit.
So we're getting the cash, and now we're obligated to provide rentals over the next year.
We have the cash.
We have committed to allowing the club to rent units whenever they need them.
Committing to provide the rentals is not enough to be able to recognize the revenue.
We have to earn the revenue by delivering the service.
And the service here is providing unlimited rentals over time, which means we're going to have to wait until time passes before we can recognize the revenue and record this on our income statement.
Then we post this to T accounts, so we add something on the debit side of cash, so we increase cash on this transaction, and we create a T account for unearned rental revenue, which has a credit balance.
For the six months ended December 31 2012, rental revenues on the metal detectors totaled $124,300.
Most of the rentals were paid in cash immediately.
However, as an initiative to reward repeat customers, Park allowed a select number of frequent renters to charge their rentals and be billed later.
As of December 31, 2012, $4,200 was outstanding under this plan.
To do the journal entry for this one we have to recognize that there were three accounts involved.
We got rental revenues of $124,300.
We have an accounts receivable of $4,200, that's what the customers owe us under the frequent renter plan, and the rest of it we received in cash.
So the difference between 124,300 and 4,200 is 120,100 of cash that we received.
Remember, we always use the term accounts receivable for money owed to us by customers, based on providing them goods or services in the past.
And what we have left to do is record the rental revenue.
Revenue accounts are credit balance accounts, so to increase revenue we credit rental revenue which increases revenue and increases stock holder's equity by 124,300.
Of which 120,100 was received in cash, and 4,200 has not yet been received in cash, but hopefully will turn into cash soon in the coming months.
What happens if we don't collect the cash?
It doesn't seem kosher for them to book all that revenue with no guarantee they'll get the cash.
Same answer as before.
For now we're assuming that the company will collect all the cash, but later on we'll see how companies estimate how much cash they will collect, and then make adjustments for this on their income statement, and in the balance of their accounts receivable.
So just hang on until later in the course.
To post this one, we add another debit to the cash account.
During the period between July 1st and December 31st, Park purchased $40,000 of sundries inventory, of which 38,000 had been paid in cash and 2,000 was still owed at December 31st.
We credit cash for 38,000 to make the asset go down.
So we debit inventory for 40,000 to recognize the inventory that first, we've received.
So we're still missing one part of this and that's the 2,000 that we still owe at December 31.
If you remember from a prior video, when we owe money to a supplier based on getting shipments of inventory we call it accounts payable, which is a liability.
Relic Spotter recorded sales of sundries totaling 35,000 for the 6 months ended December 31, all received in cash.
We're receiving 35,000 of cash, so we debit cash 35,000 to make that asset go up.
Revenue is a credit account, so we make revenue go up with a credit to sales for 35,000.
If we sold sundarees, or whatever you call them, then our inventory should go down.
Where we record the cash and the sales revenue at the selling price.
We'll deal with the inventory part of this transaction in about 15 seconds.
And create a sales T account to keep track of revenue from sundry sales.
The original cost of these sundries was $30,000.
Our debit here is going to be something called cost of goods sold, which is an expense.
This is what we call the product cost when we make a sale.
The original cost of the inventory becomes an expense called cost of goods sold that we match with the revenue that we get from selling the sundries.
So we debit this expense, cost goods sold for $30,000 which then will reduce stockholders' equity.
I mean, anytime you record revenue in an entry, do you have to record COGS in another entry?
>> Please also tell me why the revenue and the COGS were different dollar amounts.
Any time you sell inventory, you need one entry to record the revenue and the cash we're going to collect at the selling price.
And you need a second entry to record the reduction in inventory.
In other words, we've been able to earn a profit on our product.
Let's try that again.
Relic Spotter's two employees were paid wages of 32,000 total during the six-month period.
For the journal entry, we paid 82,000 in cash total.
So we credit cash for $82,000 to reduce the cash account.
The debit is going to be an expense for the employees working for us.
Now, these employees would be period costs, so we're recognizing an expense as they work for us.
We're going to debit salaries and wages expense for 82,000 to recognize this period cost, which then in turn will reduce stockholder's equity as expenses always do.
Then we post this to T accounts, so yet another credit to the cash account.
So, I'm going to bring up Excel and show you how to do this.
I've been showing you the T accounts one by one.
But here's what they would look like all on the same page.
You'll notice that there are some T accounts which have nothing in them yet.
But for all the other T accounts, what you want to do is draw a line and come up with a balance for each account.
So we have 78,800 in cash, 4,200 in accounts receivable, 103,000 in land and so forth.
Then you carry over all the account titles to another page and create a column for debits and a column for credits.
You put in the balance of each account and then just add up the columns.
So we know that we've done everything correct so far because our debits equal our credits.
And now we're ready to go on to the next step in the accounting cycle, which will be adjusting entries.
Wow, there's nothing more thrilling than watching somebody work through Excel on video.
Sorry about that, but that seemed to be the most expeditious way to show this part of the accounting cycle.
Plus, if you're going to learn some accounting, you've got to do some Excel now and then, right?
So in the next video, we're going to talk about adjusting entries which will get us one step closer to putting together financial statements.
In the next two videos, we're going to talk about adjusting entries.
These entries help to get the books in shape, so that we can prepare financial statements.
In this video, we'll talk about adjusting entries conceptually, and go through some examples.
And in the next video, get some practice to do these journal entries.
Let's get started.
Now we're going to move on and take a look at the next step in the cycle, which is adjusting entries.
Adjusting entries are internal transactions that update account balances in accordance with accrual accounting, prior to the preparation of financial statements.
By internal transactions we mean that we're not doing anymore transactions with outsiders.
This is just the accountant sitting at his or her desk doing journal entries to get accounts up to date to do financial statements.
I guess the way to think about this is, if a company's fiscal period ends December 31st.
Everyone else in the company's going to leave at 5 o'clock to go out for New Year's Eve parties.
But the poor accountant has to stay behind, and do these adjusting entries before the company can get ready to do its financial statements for the end of the year.
There's two big categories to these entries.
The first are called deferred revenues and expenses.
In this case, we're updating some existing account balance to reflect its current accounting value.
This happens when there's been some kind of cash flow in the past, but we need to record revenues or expenses now.
Here we have to create some new account balances to record some previously unrecorded assets or liabilities.
This will be situations where we're going to record a revenue or expense now, and there will be some kind of cash flow in the future.
So don't worry, I'm going to go through examples of each of these types of adjusting entries, so you can see exactly what we mean by them.
The first category we're going to look at are deferred expenses.
The accounts that we'll see here are generally called prepaid accounts, like prepaid rent or prepaid insurance.
Depreciation and amortization are also examples of a deferred expense, but we'll talk more about those later in the video, but let's think of something like prepaid rent.
We paid cash in advance of occupying the space, so we create an asset called prepaid rent, but then, as time goes by and we've occupied the space we have to recognize the cost of the rent for the time that we've occupied the space.
So we're going to do an adjusting journal entry where we debit an expense to recognize the cost of the rent that's been used up over time, and we're going to credit the prepaid asset to reduce the balance to how much that's still prepaid, if any, at the end of the year.
So what's happened in this case is, we've received cash prior to providing goods or service.
Wouldn't you know when you had delivered goods, and then just record this entry then?
So, as our poor accountant decides to turn on the TV to watch something like New Year's Rocking Eve, so he can hear some of the music in the background that he's missing at all the parties.
These accounts are all going to be payable type accounts.
What's going on here is that we've incurred some expense over time.
But we haven't yet paid for in cash.
So the adjusting journal entry we need to make is to debit an expense to recognize that expense, and credit a payable liability, to show that we have an obligation to pay for that expense.
For example, if employees have worked for us but we haven't paid them yet.
We have to debit a salaries and wages expense to recognize the cost of the employees working for us and then credit salaries and wages payable to show the liability that we have to pay our employees some point in the future.
S,o as our poor accountant looks at the TV to watch the ball drop at Times Square he hurriedly asks himself, have any revenues accumulated during the period that have no yet been recorded?
An example would be, if we loaned someone else money, time has gone by so now they owe us interest.
And then we would debit a receivable asset, like interest receivable, to show that we have an asset for the amount of cash that we're going to collect in the future.
So, this adjusting journal entry allows us to recognize revenue that we haven't recognized so far.
And then show that we have an asset for the cash that we expect to collect in the future.
>> Again, these examples are about providing a service over time as opposed to delivering specific goods.
It says that it only matters that the revenue show up in the books when we put together financial statements.
It's just easier to do the adjustment entry once at the end of the period, instead of doing it every month or week or hour, minute.
Finally, we're going to talk about depreciation and amortization.
Which are just examples of differed expenses, but there is a lot more to them, so I want to give them their own couple of slides.
The goal of depreciation and amortization is to allocate the original cost of long-lived asset over its useful life.
What we want to do is match the total cost of the asset to the revenues it generates over its period of years.
Dave had bought a truck that he intended to use for 48 months.
Instead of recognizing the cost of that truck as an expense in the first month.
We spread the cost out over 48 months through depreciation to try to match the cost of the truck to the revenue we think it will generate in the future.
There's some terminology here, tangible assets, which are physical assets like buildings or equipment or a truck, we're going to call this process depreciation.
For intangible assets, which are abstract assets like trademarks or customer lists which we've acquired in an acquisition, we're going to call this process amortization.
But the process is going to be very similar, even though the terminology is different.
Now let's talk about the accounting procedure for depreciation and amortization.
Staring with depreciation, depreciation is not deducted from the tangible asset account.
So, in other words, if you were taking depreciation on a truck, you wouldn't deduct it from the truck account.
Instead, the depreciation's going to be recorded in a contra asset account called accumulated depreciation.
Which means that contra assets go up with credits and down with debits.
I think contra is a Latin word which means something like it has the balance on the opposite side where you'd expect the balance to be based in where it is on the balance sheet.
In other words, assets normally have debit balances, so they're increased with debits.
And be increased with a credit, because essentially, the contra asset is keeping track of reductions in a companion asset account.
Amortization is often deducted directly from the intangible account.
So if you're amortizing a trademark, you would deduct it directly from the trademark account.
However, nowadays there are companies that have fairly large intangible assets, and they've started to use accumulated amortization accounts as well.
So that's just another type of contra asset where the accounting works just like accumulated depreciation.
But I think the most common treatment you see is that the amortization just comes directly out of the intangible asset account.
Let me pull up the super T account to show you where a contra assets sits on the balance sheet.
The way to think about it is a contra account is keeping track of the decreases, or reductions in a specific asset account.
It's almost like an expense.
Expenses sit on the shareholder's equity side of the balance sheet in retained earnings.
And, in fact, an expense is just a contra shareholder's equity account.
So, you've actually seen this before.
And you're going to see a lot of it again.
And as you see it over and over I think it'll become more intuitive to you.
When we get to the video where we put together a balance sheet we'll see that the common format for reporting property, plant, equipment is to show the original cost or the property, plant, equipment separate from how much it's been depreciated over time.
And in order to provide that format we have to keep track of this accumulated depreciation in a separate account.
To calculate the amount of depreciation expense every year almost every company uses a method called straight-line depreciation.
The salvage value is what you think the asset is going to be worth when you are done using it.
So in the numerator we're taking how much of the assets is cost you're going to use up.
And then the useful life is the number of periods you expect to use the asset.
So, under straight line depreciation, the amount of the depreciation expense is going to be the same for each year of the asset's life.
Why do almost all companies use straight-line for their financial statements?
>> Yes, there are accelerated methods of depreciation where you recognize higher depreciation in the early years of an asset's life and then much less depreciation in later years of an asset's life.
If you use accelerated depreciation, then your earnings will be more volatile depending on whether you have a lot of new equipment, which is got high depreciation or a lot of equipment which is later in its life, which has much lower depreciation.
>> No, for financial reporting purposes, there is no central government agency that dictates useful life and salvage value.
Managers are supposed to choose the useful life based on how long they intend to use the asset and then the salvage value will be a function how long they intend to use it.
There's a major international airline which has a strategy of only flying pretty new state of the art planes.
They'll buy a brand new plane, fly it for five years, and then sell it to someone else.
So, when they choose their depreciation assumptions, their useful life is five years, and they have a very high salvage value.
Now there's a major domestic airline that tends to fly their planes for 20, 30, 40 years.
I'm not going to mention the name but you probably know who it is.
Their strategy, if they bought a brand new plane, would be to choose a useful life of 20 years and then they would have a low salvage value as a result.
So you get two airlines buy the same plane and have different depreciation assumptions, but that's okay because the depreciation assumptions are supposed to match how the manager intends to use the plane, not anything that has to do with the physical life of the plane.
I'll see you next video where we'll do some more practice with adjusting journal entries.
Anyway, let's get to it.
Okay, let's do some practice with adjusting Journal Entries.
I will give you a series of related transactions.
Some of them will be cash transactions that happen during the regular operating period of the company.
And then other times we'll look at the physical year end and then ask the question about whether there's an adjusting entry needed, and if so, what would it be?
As always, the pause icon will appear if you wanna pause the video and try to come up with a journal entry before I give to you as the answer.
So let's get started.
On September 30th, BOC loans $100,000 to an employee at a 12% interest rate.
This is a cash transaction that's happening during the fiscal period.
BOC is loaning $100,000 cash.
Cash is going down so we credit cash for $100,000.
December 31.
It's the end of the fiscal year and no principal or interest payments have yet been made.
Do we need an adjusting entry and, if so, what would it be?
We've earned interest revenue because we provided the service of having the money outstanding to the employee over the past three months.
We have a contract, we're eventually gonna get paid.
And we're gonna be specific here and call it Interest Receivable, because the asset is that we're owed for cash for interest.
And of course, we don't want to call it cash receivable because we only use that for that customers.
Any time you see an interest rate you should assume it's an annual rate unless it specifies otherwise.
So $100,000 times 12% is $12,000 of interest per year.
But it hasn't been a year yet.
So we take $12,000 times 3/12 because it's been 3 months.
And we end up with $3,000 of interest for the 3 months.
Now it's January 6th, the employee sends a check for three months of interest on the loan.
This is a cash transaction happening in the next fiscal year.
So it's December 31st, it's the end of the fiscal year.
During December, employees earn $400,000 in salaries.
It's the end of the fiscal year, so we have to ask ourselves whether we need an adjusting entry.
We do in this case, because we've had employees work for us, even though they haven't been paid we have to recognize an expense for the amount of salaries that they earned during December.
So we're going create an expense, and we create an expense with a debit.
We haven't paid them cash but we owe cash.
We have an obligation to pay them for the time worked, that obligation sounds like a liability, and in fact, it is so we credit salaries payable liability for 400,000.
I thought earned was one of the revenue recognition criteria.
This is an expense.
>> Yes, earned is one of the revenue recognition criteria, and from the perspective of the employee, the employee earned salary revenue.
The employee provided a service, they have an agreement to get paid, so it's revenue for the employee.
Now it's January 2nd and the paychecks are sent to the employees.
By paying the cash we've gotten rid of the obligation to pay their employees.
So we have to reduce the liability.
We reduce liabilities with a debit, so we debit salaries payable for 400,000.
Next series of transactions on November 20th, BOC pays $10,000 for December's rent.
So we need to credit cash for 10,000.
It's an asset because we're either gonna get the benefit of occupying the space in the future or we're gonna get our money back.
So either way we create an asset called Prepaid Rent for 10,000 at this point.
It's the end of the fiscal year.
Do we need an adjusting entry and if so, what would it be?
We do need an adjusting entry because December has gone by and we've occupied the space for the month of December.
We get rid of an asset with a credit, so we credit prepaid rent for 10,000 which brings the balance down to zero.
So in this example, BOC is a company that sells software.
We've received $60,000 cash as BOC, so we need to debit cash for 60,000.
But BOC hasn't delivered any of the software yet.
Instead they have to create an obligation or a liability for their responsibility to deliver the software over the next three years.
So now, December 31st.
It's the end of the fiscal year.
We do need an adjusting entry because six months of that three years has gone by.
And as time goes by, we get to recognize revenue for the amount of time that's passed.
So we're going to credit Software revenue for 10,000 to recognize six months worth of revenue.
So after this transaction the balance on Unearned Software Revenue would be 50,000.
Which is our obligation to deliver software over the next two and a half years.
>> I know why the answer is $10,000 but maybe you should explain it for the other viewers.
>> Sure, I'm happy to explain how to get 10,000 for the other viewers.
BOC's gonna earn $60,000 of revenue over three years.
It hasn't been a year, it's only been six months.
And BOC gets to book 10,000 of revenue for the six months.
The expected life of the building is 20 years and its expected salvage value is $100,000.
At this point, we have to account for purchasing the building, but we're not gonna do any depreciation yet because we just bought the building.
We received the building a buildings and assets, so we debit building for $500,000.
Now it's December 31st, it's the end of the fiscal year.
We do need an adjusting entry to recognize the depreciation for six months.
The format of the depreciation expense journal entry always looks like this.
And because it's a contra asset, a credit increases the account, increases the contra asset, which, in turn, is reducing total assets.
Now we get 10,000 as the number, where did we get that from?
I've got that one on the slide, so the building originally cost 500,000 and the salvage value was 100,000.
We're doing that over 20 years, so that's 20,000 of depreciation per year.
But, it's only been six months.
How can you possibly know what a building will be worth in 20 years?
>> Both the useful life and salvage value are managers best estimates at the time they buy the building of how long the building will last and how much it will be worth when they're done with it.
Like all estimates they will almost certainly be incorrect.
But at any point if the manager gets better information they can revise their estimate, so if they think they're gonna use it longer or shorter than they originally thought.
And then just change the depreciation expense going forward.
And then when they decide to sell the building, if it's not worth the salvage value, then we'll just book a gain or loss when we sell it.
BOC still has an outstanding order for $300,000 of products that will be delivered and billed in January.
Do we need an adjusting entry at this point?
We do not need an adjusting entry at this point.
We haven't earned any revenue because we haven't delivered any goods or services this year.
We haven't collected any cash so we don't have to account for any cash that we've received.
So basically, there's no transaction yet.
But, is there any way that we can let people know about this order?
>> Yes, companies can always voluntarily disclose additional information that they're not allowed to recognize in the financial statements.
For example, companies often disclose the order backlog in their annual report.
The order backlog is a disclosure of the number of outstanding orders the company has.
but haven't gotten to the point yet where the company could book revenue from them.
So that investors can use this disclosure to find out about upcoming orders even though they haven't yet shown up on the balance sheet or the income statement.
Think about a timeline where we have cash transactions that happen at different times than we recognize revenues or expenses.
So, if we receive cash before we can book revenue, we need a liability, an unearned revenue liability, to bridge the gap.
Or, if we pay cash before we record an expense, we need an asset, a prepaid asset, to bridge the gap.
For Accrued Expenses and Accrued Revenue, now the expense and revenue recognition is happening before the Cash Transaction.
If we have to recognize an expense before we pay cash, we need a liability to bridge the gap, and that liability is gonna be a payable.
So all of the adjusting entries that we talk about, are gonna fit into one of these four categories.
Now that we've done examples of all the possible types of adjusting journal entries.
And that's what we'll continue to do in the next video when we continue the relic spotter case.
I'll see you then.
In this video we're gonna take what we learned about adjusting entries and apply them to the Relic Sputter case, let's get started.
In prior videos, we did all 20 transactions that occurred during Relic Spotter's first six months of operations.
Now it's 5 PM on the last day of the fiscal year, December 31st.
We're not going to record anymore transactions with outsiders.
But before we put together the financial statements, we have to record the internal transactions or adjusting entries.
As in prior videos, I want to try to record the journal entry and post the T account for each required adjusting entry.
I will again put up the pause sign so that you can try the journal entry yourself before I reveal the answer transaction 21.
When Park called her accountant on December 31, 2012, she was pleased to tell him that the company had $78,800 in cash.
By the way, before I go on, if we pull up the cash T account, added up the debits, added up all the credits, you could see that the balance is 78,800.
Park wanted to go out and celebrate, but the accountant reminded her that she needed to stay in to do adjusting entries.
For example, even though it wasn't paid in cash, accrued interest on the mortgage was $4,900.
The adjusting entry here is that we have to recognize interest expense that we have incurred by having the mortgage outstanding during the year.
So, we create the liability with a credit.
>> What does the word accrued mean and why is this an expense if the bank hasn't made us pay the interest yet?
Accrued means to accumulate, grow, or increase as add interest on money.
And that's exactly what happened here.
The loan was outstanding for eight months, and so the interest accumulated, or grew, or accrued for eight months.
Even though we haven't paid that interest in cash, we have to expense it because the money was outstanding during this period.
So that interest cost is a cost of doing business this period, and we need to match that cost to the revenue we generated.
So we need an expense which we create through the adjusting entry.
Then we need to post the CT accounts so we create an interest payable liability.
This will go on the balance sheet to show that we have this obligation to pay interest in the future at the end of the year.
And we create an interest expense to recognize that one of the costs of doing business this period was that we've incurred interest costs, Transaction 22.
The accountant said that depreciation needed to be recorded on the building.
Park was confused by this because she received an unsolicited letter from a mortgage broker informing her that the building had increased in value to $120,000.
Now recall that, in transaction number five Park had renovated the building, bringing its original cost to $85,000.
So for the adjusting entry, remember the format that we used for depreciation Expense.
We debit the expense to create it.
And then we credit Accumulated Depreciation gets the contra asset where we're gonna store up the depreciation over time.
Now where we get the 1500 is we take the difference between the original cost of $85,000 and the salvaged value of ten thousand.
So that's 75,000 we are going to depreciate over time / 25 years of life, would be three thousand of depreciation per year.
>> The building was purchased in April and renovated in May.
Why are we recording only six months of depreciation?
Since we finished the building seven months ago, we could've recorded seven months of depreciation.
But I chose to do six months because Relic Spotter's only been open for six months and I'm trying to match the cost of the building with the revenue we've generated.
Plus, the math was a lot easier with six months rather than seven months.
If the building is worth $120,000, why are we depreciating it?
For non financial assets like buildings, we use an accounting method called historical cost or amortized cost.
What this means is that if the value of the building goes above what it's listed on the balance sheet we never write it up.
But if the value of the building drops below what it is on the balance sheet we write it down.
This is an example of the conservative, I mean the non aggressive nature of accounting where we tend to err on the side of objectivity or reliability.
Because if we allowed managers to write up something that's hard to value like a building, there'd be too much opportunity for manipulation.
So we only them to write it down in value.
And I don't know what the specific principal is called in accounting but we never rely on values from unsolicited letters from mortgage brokers.
Which is probably a life lesson that you should carry out beyond this course.
We post this journal entry to T accounts, we create a T account for accumulated depreciation as a contra asset, that is a credit balance, and then a T account for building depreciation expense.
The accountant also noted that Park Park needed to record depreciation on the metal detectors.
Recall that, in transaction number six, Park purchased $120,000 of metal detectors.
She determined that they would only last for two years, at which time they'd have no remaining value.
Journal entry has the same format as as the last transaction.
And we credit accumulated depreciation to increase the contra asset where we store a depreciation over time.
Where do we get 30,000 from?
The metal detectors originally cost 120,000.
So we're taking that entire 120,000, spreading it over two years to get 60,000 per year.
But it's only been half a year, so the amount that we depreciate is 30,000.
>> So why do you have separate accounts for building and metal detector depreciation expense?
>> You'll see why when we get to the video on financial statements.
But as a little preview, what you'll see is when we do the income statement, building depreciation expense and metal detector depreciation expense are gonna go into different parts of the income statement.
So we need to keep track of them in separate accounts.
But when we do the balance sheet, there's just gonna be one line for all of the accumulated appreciation so we can throw it all into one account.
Wait a minute!
You forgot the land!
Don't we have to depreciate the land as well?
There's a long standing tradition in accounting where we don't depreciate land.
We don't assume that land is systematically used up to generate revenue.
So as long as the value of the land is at or above what it's carried on the balance sheet, we just leave it at its original cost.
But if the value of the land dropped below what it was on the balance sheet, we would write it down to that value, but we wouldn't systematically depreciate it over time.
That's why when we originally bought the land and building together, we had to separate how much of the value was from the land and how much was from the building.
The amount of value from the building is hitting the income statement over 25 years as it's depreciated.
Let's try this again.
Transaction 24, the accountant continued, what about adjusting the software amortization account?
Recall that, in transaction number eight, Park paid the $2100 three-year software license fee on June 30th.
Because software is an intangible asset, we're going to use the term amortization instead of depreciation.
So we're going to debit software amortization expense for 350.
And then because it's amortization I'm gonna credit the software account directly to recognize the amortization.
Where does the 350 come from, well we paid 2,100 for a three year license So that's $700 per year of amortization.
It hasn't been a full year, so we take half a year of that to get $350.
I think historically we've done that because intangible assets have not been that big of a deal on the balance sheet.
Nowadays, more and more companies are starting to have larger and larger intangibles.
We directly reduce the software account with a credit, and then we debit a software amortization expense account.
Wow, we've only done four of the eight adjusting journal entries for Relic Spotter, and we've already recorded 12 minutes of video.
I guess the virtual students have a lot to say today.
So I'm going to end the video here and then we'll pick up in the next video with the last four adjusting journal entries for Relic Spotter.
In this video we are going to wrap up the final four adjusting entries for Relic Spotter.
Let's get started.
The accountant asked, what about the prepaid advertising account?
Recall that in transaction number nine, Park paid $8,000 up front on June 30th, 2012 for advertising through June 30th 2013.
We need an adjusting journal entry to recognize and expense for the six months of advertising that has been used up between June 30th 2012 and December 31, 2012.
So we debit advertising expense to recognize the expense and then we have to credit prepaid advertising to reduce the asset so that it's balance now is how much is prepaid going forward.
And realizing that half a year's gone by, so if you take half a year of 8000, it's 4000 for six months.
For deferred expenses such as a prepaid asset, we allow managers to either allocate it based on time as we're doing here or based on usage.
For example, if the manager thought that the company would have 50 advertisements run over the next year.
Then what the manager would do is take three-fifths of the prepaid asset as an expense this period.
Based on what they think would best match their business activities of the company.
>> If the manager can choose which method to use, then the manager could choose the one with the lowest expense?
I hate to break this to you but there's often no true or correct way to do something in the accounting system.
I often characterize adjusting entries as the creative writing part of the accounting system.
We give managers discretion on how to do their adjusting entries because we want them to best capture the true economics of the true business activities of the company.
In other words, we give some creating to the managers, hoping they'll write better non-fiction books.
Where they've used the creative writing part to write better novels or fiction books.
What you have to do is learn as much accounting as possible.
Then think about managers that instead have to manipulate in a given situation and approach the financial statements with healthy degree of skepticism.
Which you often need to do.
Recall that in transaction number 10, Park borrowed $5,000 from Relic Spotter at 10% interest rate on June 30 2012.
We need an adjusting journal entry to recognize the interest revenue that we've earned, by providing the money outstanding for six months.
The debit here is going to be an interest receivable, to represent the fact that Rebecca Park owes us $250 in cash.
Now, where the 250 comes from is the total interest is going to be $5000 of principal times the 10% annual interest rate is $500 of interest per year.
But it's only been six months, so we take half of that to get $250.
Let's say Santa Claus brought Rebecca park $5,000 as a Christmas gift.
So on January 2nd, she decided to come in and repay the loan on that date, she wouldn't owe us $500 dollars of interest because that's for a year and it's only been six months.
She would only owe the $250 of interest that's been accrued so far.
So the other $250 is not necessarily receivable unless the money continues to stay outstanding for the next six months.
So we can't consider it receivable as of December 31st.
Recall that, in transaction number 15, the Penn Antiquities Club paid Relic Spotter $1,200 cash upfront on December 1, 2012 for unlimited rentals over the next year.
We need an adjusting entry here to recognize the revenue we've earned by providing one month of unlimited rentals so we credit Rental Revenue for 100.
Part of our obligation has gone down by delivering one month of rentals so we need to reduce our liability, we debit Unearned Rental Revenue to reduce this obligation.
We got 1200 dollars up front for a full year, one twelfth of a year has gone by so we only recognize.
>> Could this revenue be recognized based on the number of rentals, instead of based on time?
>> But, wait, with the contract allowing unlimited rentals, it would seem fishy to do this based on the number of rentals.
Yes it would seem fishy if the allocation was done based on number of rentals instead of time, when you have a contract which provides unlimited rentals.
It's important to understand what the actual business activities of the company are.
And then you can see whether the accounting is matching those business activities.
If the accounting matches the business activities as it does in the Relic Spotter case then you can continue to feel comfortable with managers.
But if you saw a mismatch like unlimited rentals being accounted for based on number of rentals in the period, then you start to get skeptical about whether managers are manipulating or not.
We have to deliver 11 more months of unlimited rentals and then we add a credit to the Rental Revenue T-account.
Finally, the accountant noted that Relic Spotter incurred an estimated income tax expense of $630 for 2012.
Even though Park's not going to file her taxes until April, she's incurred taxes by operating the business during 2012.
And we have to show an expense because that's a cost of doing business.
This is money that we owe the government, that's an obligation.
We create an income tax payable so that we can show on our balance sheet that we owe the IRS, $635 of taxes as of December 31 and we create an expense account, income tax expense, which has a debit balance.
There's no adjusting entry for par value, we only worry about par value when we issue new stock but glad you came anyway.
And then we can start doing the balance sheet and income statement for Relic Spotter.
I'll see you next time.
In this video we are going to go to the last two stops on the accounting cycle.
Now we can move onto the next two steps in the accounting cycle, putting together an adjusted trial balance and preparing financial statements.
Then we're gonna use those balances to put together financial statements.
And then finally we'll complete the statement of cash flows and the Statement of Stockholders' Equity.
>> Yes, I will eventually cover the Statement of Stockholders' Equity, but I'm not gonna tell you when.
But what you're gonna see is the most common format used by companies.
On the top line, we have revenues or sales.
So when we get to Relic Spotter, it will be rental revenue from metal detectors and the sales of sundries.
Then we subtract cost of goods sold to get gross profit.
Cost of goods sold is the product costs or the direct costs of producing this revenue.
And then gross profit then would be interpreted as the markup over the product costs.
SG&A stands for selling, general, and administrative.
These are all the period costs, all the other costs of running the business.
It helps answer the question of whether the company priced their product or services high enough to cover all the product and period costs of delivering those goods or services.
Gains or losses we haven't talked about yet, but they're like revenues or expenses except they don't come from your core business.
For example if Relic Spotter sold their building and had a gain, we would put that gain here because they're not in the business of selling buildings.
Then you subtract income tax expense to give you bottom line net income, which is also called earnings or net profit.
>> I always hear my boss talking about things being above the line or below the line.
Most investors and analysts use operating income as a key measure of the performance of the core business.
is there any way that they can move it below the operating income line so that the performance of the core business looks better?
So yeah, managers spend a lot of time worrying about whether unusual gains or unusual expenses will appear above or below this magical operating income line.
For the balance sheet format, assets are listed first, and they're listed in the following order.
So we always see cash come first, then accounts receivable, inventory, and then any prepaid assets which actually never convert to cash.
Then we have non current assets, including the tangible assets, the property plant equipment, and then the intangible assets, which would be things like software, trademarks, or this thing called goodwill which we get from an acquisition.
Starting with current liabilities, which are obligations within the next year.
Again, ordered by liquidity so we'll see bank borrowings, accounts payable and other payables, and the deferred revenues and other noncash, current liabilities last in the section.
So longer-term bank borrowings and bonds, and then other types of liabilities like deferred taxes, which we'll talk about later, and pensions.
Then we have stockholders' equity, where we start with the contributed capital, so the common stock, the initial paid in capital to treasury stock, and then retained earnings.
Hm, I guess the virtual students went out for virtual coffee.
When we finish the financial statements, we're ready for the last stop on the accounting cycle, which is closing entries.
This allows us to get ready to start a new period so that we can do the cycle over and over and over and over and over and over again for the whole life of the company.
What's a temporary account?
It's an account that accumulates the effects of transactions only for a certain period of time, so either fiscal quarter or fiscal year.
These would be the revenue and expense accounts, which then get closed out to retain earnings at the end of the period.
These would be the balance sheet accounts like assets, liabilities, contributed capital and retained earnings.
The actual closing entries are internal transactions that zero out temporary accounts at the end of the accounting period.
Again, by internal transactions, we mean this is the accountant sitting at his or her desk, these are not transactions with outsiders.
And the goal is to transfer the balances and the revenue and expense accounts, and the retained earnings.
So the way the entries look is for revenues, we wanna zero out the revenue account.
And notice in both cases we're not creating any new stockholders' equity, we're just transferring it from one type of account to another, from the temporary accounts to the permanent account retained earnings.
>> When my grampa tried to teach me accounting when I was five, he said something about an income summary account as part of closing entries.
This is a very temporary account and what happens is you close the revenue and expense accounts in the income summary, and then you close income summary into retained earnings.
With the net effect being that there's only one entry that goes into retained earnings Instead of the two that we used in our approach, but you get to the same place so it really doesn't matter which approach you use.
At this point only the permanent account should have balances, all the revenue and expense account should have a zero balance.
And now we're ready to start the next period.
So what we're gonna do to finish up the Relic Spotter case is we're gonna prepare the adjusted trial balance, put together an income statement, record the closing entries and post them to T-accounts, and then prepare the balance sheet.
And we put in the debits and credits for all the adjusting entries.
And as we put everything in, move all the balances over, what we wanna make sure is that for just the adjustments alone, our debits equal our credits, which they do.
Now, what we're going to do is take all of these revenue and expense accounts, which are summarized right here on the trial balance worksheet, and put them in the income statement format.
So we start out with Relic Spotter's income statement for the year ended December 31, 2012, and it's important to note that it's for an entire year, because income statements are always for a period of time.
For revenues, I've split the revenues into two categories, rental revenue and sales of sundries.
That's because Relic Spotter has two lines of business, and so we want to highlight the revenues from the two different lines.
Then we need the cost of revenues.
What I decided was the direct cost of providing that service was the metal detector depreciation expense and the software.
Salaries and wages, legal fees, advertising and building depreciation, gives us total SG&A.
Was the pricing of our product and service high enough to cover all the product costs for our core business and all the period costs?
And in this case it was.
Then below the operating income line we have interest revenue and interest expense.
We don't put interest revenue on the top line because our core business is not making loans.
We're not a bank, so we put it below operating income.
One more thing I want to point out before we leave the income statement Is I separated the depreciation expense into two buckets.
The metal detector depreciation expense is part of the direct cost of providing the rental service, whereas the building depreciation is part of the selling and administrative function.
Hm, I guess I should have let the virtual students know that they're allowed to drink virtual coffee in the virtual classroom.
Oh well, at least you get to see it.
So if we look at something like rental revenue, after we did our adjusting entries, and of course the entry during the period, there was a credit balance of 124,400.
If we look at advertising expense, after doing the adjusting entry, the balance was 4,000 that went on the income statement.
The closing entry is going to credit advertising expense for 4,000, which will zero it out.
So we do that for all the T-accounts and we get these two big, whopping journal entries.
So for the closing entries for revenues, we debit all the revenue accounts, which is gonna zero them out.
And then we add them up and credit the balance to retained earnings.
For expense accounts, we credit all the expense accounts to zero them out.
Total them up and then that's the debit's retained earnings, so if we go back over to our retained earnings T-account.
We can come up with a final balance retained earnings, which is a debit balance of 130.
Huh, so even though we have positive net income, we had more revenues than expenses, we paid that big dividend, and the dividend was bigger than our net income, so we have a debit balance.
After posting everything to T-accounts, we can go back to our trial balance worksheet, where we add a couple columns for the closing entries and the post closing trial balances.
Notice for the permanent accounts, you have the post-closing balance the same as the adjusted balance because we didn't do anything.
The only permanent account that's affected, of course, is retained earnings.
And if you look at the post closing tra balance you see that now, all the revenue expense accounts are at zero, and it was, retained earnings was the only balance that was affected by this process.
Now we're going to take all the balances of the permanent accounts and put together a balance sheet.
We start with assets and list all of our current assets in order of liquidity.
Then we follow up with tangible assets.
And then in one line item we subtract the accumulated depreciation to report something called net property, plant equipment.
Anyway, then we have the intangible assets like software, and that'll give us total assets.
So, the obligations in the next year, ordered by liquidity.
And then retained earnings, which we may want to called accumulated deficit since it's negative, but I guess it's okay to call it retained earnings as well, gives us total stockholders' equity.
In future videos later in the course we will continue with Relic Spotter to put together a statement of cash flows, and then eventually we'll talk about a statement of stockholders' equity.
And with that, we wrap up the basic building block section of the course.
The next step is to put together a statement of cash flows for Relic Spotter, but that's gonna take about a week of videos to learn how to do.
Our trip around the accounting cycle has culminated in the preparation of the first two financial statements.
As is our custom, we'll end the week by taking a look at the 3M company and report to see what their income statement and balance sheet look like.
Let's start with 3M's income statement, which is on page 46 of their annual report.
And to make this interesting, why don't we just compare this directly to what we did for Relic Spotter.
So over here is the Relic Spotter income statement that we prepared.
And we'll just compare it directly to the 3M company.
We started out with net revenue as the top line broken into the two segments.
Then we have the cost of revenues or cost of goods sold.
3M has that as their next item, again only one line item.
Just let me delete that, so that goes away.
And so far, we're seeing the same items in the same order.
Below the operating income line, we get to interest revenue and interest expense.
Now you may be wondering how can a big multinational company like 3M, producer of Post-it Notes and Scotch tape and all sorts of other cool stuff, get away with providing less information in their income statement than Relic Spotter?
If we go back to that MD&A section, management, discussion and analysis this is back on page 18 of the report.
We'll find that here is where 3M gives us a lot more detail about their income statement.
So here's net sales.
For operating expenses like costs of sales, they give you a whole paragraph explaining what happened.
So it includes manufacturing, engineering and freight costs.
One of the effect of the changes year on year was the impact of selling price, raw material, cost changes.
They don't quite give you the same detail breakdown of the components but they do talk about how different line items change, like pension expense, restructuring expenses, cost control and productivity efforts.
Same thing with interest income and interest expense, income taxes, and then as I mentioned, they go through each segment, and for each segment, like industrial and transportation business, healthcare business, consumer and office business, so this is the Post-it Note segment.
Always start with cash, that's the most liquid asset.
In a couple weeks, we'll talk about what these allowances for accounts receivable mean.
As a manufacturing company they have different categories of inventory.
3M just lumps those into other current assets.
Then for non-current assets we had land, building, metal detectors, accumulated depreciation PP&E.
So it's the same treatment of original cost minus total depreciation gives you net, that we saw with Relic Spotter.
And then for intangible assets we just had software, 3M has a lot more, goodwill, intangible assets net, and prepaid pensions, and the always popular other assets.
In terms of liabilities, we had accounts payable, interest payable, income taxes payable, unearned revenue for Relic Spotter.
Here, 3M has their long-term debt.
And as I talked about in the prior video, you can also put the current portion of that in current liabilities, as 3M does.
Gets us down to total liabilities for 3M after there's a couple others liabilities that we didn't have for Relic Spotter.
Basically only 1 cent per share, so almost all of their contributing capital goes into APIC.
Well, it didn't take long to find an exception to that.
We'll talk about these two items much, much later in the course.
There's also this non controlling interest stuff which we'll talk about later, but then bottom line, total liabilities in stockholder's equity.
And the same thing for 3M, no matter how big the company is, the two have to be equal.
Wow, what a mess.
In footnote four of the 10k, which is on page 66, 3M provides us some more detail on the balance sheet.
Same thing with other current liabilities we get a break down into other kinds of payables.
So there's other kind of trade payables, derivative liabilities, restructuring, employee benefits and so forth.
So what 3M decided to do was instead of making their balance sheet two or three pages, they put as few lines as they could get away with on their balance sheet and then provided a footnote which gave us a breakdown of some of the other line items.
For example, here's note three, goodwill and intangible assets.
This'll tell us everything we need to know, hopefully, about goodwill and intangible assets.
So the additional balance sheet information we get, we could usually go through the footnotes and dig it out.
And so that's what we see for the balance sheet and the income statement for the 3M company.
So, that's a wrap for week two.
I hope to see you again next week where we'll talk about preparing the statement of cash flows, the third of the four major financial statements.
I'll see you then.
This week we're going to spend the entire week talking about the Statement of Cash Flows.
And we're going to need the whole week to get through it.
Which is the first step toward putting together and then analyzing the statement of cash flows.
The statement of cash flows is going to report changes in cash due to operating, investing and financing activities over a period of time.
So a period like a fiscal quarter or a fiscal year, any period between two balance sheet dates.
You add them all up and that should be the same as the net change in cash balance.
Like the trade a piece of land for a building.
Those have to be disclosed at the bottom of the statement of cash flows.
But these disclosures either will appear at the bottom of the cash flow statement or somewhere else in the footnotes.
Why divide it into three categories?
Do you always have to make everything so difficult?
In that example we saw why it's important not to look at total cash flow.
Because all Dave had to do to increase his total cash flow is either borrow more money or raise more equity.
What we really want to know is how much cash flow is being generated by operating the business?
How much cash flow is the business investing in the future?
And how is the business financing itself?
That's why it's important to look at these three buckets and separate the cash flows in operating, investing, and financing.
Let's talk about each of these three buckets of activities in more detail starting with operating activities.
These are transactions related to providing goods and services to customers and paying expenses related to generating revenue.
The best way to think about this section is it's the analogy to the income statement.
So transactions that appear on the income statement, we tend to see their cash impact in the cash from operating activities section.
But other sources of, of revenue or positive income like receiving interest or dividends on investment.
And we'll see cash outflows like payments to suppliers, payments to employees, payments of interest and tax.
Other operating disbursements like payments for advertising, legal fees, and other things like that.
Wouldn't that be an investing activity.
Yeah, a case could certainly be made that dividends received and interests received should be investing cash flows.
And the Financial Accounting Standards Board, the FASB decided that they wanted them as part of the operating cash flow.
To provide comparability between the income statement, and cash from operations.
But I have the feeling we'll be talking about these items more as the video goes along.
Because even though they're in the income statement they will not be part of cash from operating activities.
The first type of adjustment is for depreciation, amortization, and other non cash items.
These will affect income, but there's no cash flow involved.
So we need to make an adjustment for them.
Also sometimes we get gains or losses on selling something like property planned equipment, which affect our income statement.
But we don't want to show the cash flow in the operating activities section, we want to show it in investing activities section.
So we need to adjust for that.
We're going to make these adjustments later on in the week, but I just wanted to put them in the back of your mind right now.
The next bucket is investing activities.
So cash inflow is like selling property plant equipment, selling a tangible asset, selling investments, or selling a whole business.
Cash outflow examples would be acquiring a business, acquiring property plant equipment, acquiring intangible assets, or purchasing investments.
>> What if buy stock as an investment, but I only intend to hold it for six months?
Would that be a long-term asset?
Would that be an investing activity?
There's a rule of thumb that any asset that we intend to hold for more than a year would be an investing activity.
Whereas any asset we intend to hold for less than a year would be an operating activity.
But this is a rule of thumb, it's not an iron clad law, and there are going to be places where we see that this rule of thumb is violated.
In the case of investments, there's a whole set of rules around whether the investment should be operating or investing activities.
And we'll talk about those later in the course.
Except for interest payments.
If ifs and buts were candy and nuts, every day would be Christmas.
Interest is paid to creditors.
But this is a situation where the FASB wanted comparability between the income statement and cash from operations.
And so they decided to include interest payments as an operating activity to parallel the interest expense that's in net income.
Having said that, a lot of investor analyst disagree with this classification and want to pull it out.
If you remember earlier in the video I mentioned companies have to report cash paid for interest somewhere in their financial statements.
That disclosures there so if people don't want cash paid for interest in operating cash flows.
So what financing activities will include are cash inflows such as the money you get from issuing new stock or reissuing treasury stock.
That's when you take the stock that you previously bought back, called treasury stock, and then sell it back to the public.
Cash out flows include paying dividends to your shareholders, purchasing your treasury stocks or repurchasing your own stock.
So putting it all together, the statement of cash flows is going to have these operating activities, investing activities and financing activities.
Listed in this order showing you the three different buckets where a companies cash flow comes from or goes to during a period.
>> I believe your classification of interest in dividends is not correct.
After you crashed my question earlier I texted my sister who works in Hong Kong.
She confirmed that interest and dividends received are investing activities.
>> Well, I'm certainly not going to argue with your sister from Hong Kong, especially since we're both right on this one.
Let me jump back to the slide to show you these IFRS differences.
We're talking about transactions where a company receives interest and dividends on investments, or pays interest, or pays dividends.
Under IFRS, interest and dividends received and paid can be classified as operating, investing, or financing.
The idea is as long as the company does the same thing year after year, investors and analysts will know where to find it.
GAAP, these four items all have to be in the buckets that we show on the slide.
There's no discretion.
Now that we've defined operating, investing, and financing activities.
I'd like to do a simple example to show you what we can learn by dividing cash flow into these three buckets.
So let's say we're a start up company.
Not that there's anything wrong with gray hair.
So anyway, all you have to do is pop a pill and you'd no longer have gray hair.
We may have an initial version of our drug that's working, for which we get some revenue.
But we have a lot of negative cash flows as we have a lot of operating costs running the business and we're also investing in R and D.
Because we have to go out and create facilities and buy equipment and invest in all these long term assets to get the business up and running.
And then we have a big positive financing cash flow.
Or venture capital firms we borrowed money from banks or the public market.
To finance our investments and the negative cash of operations.
The bottom line in this case is 0 net cash flow.
That, that doesn't necessarily need to be the case.
Now our company starts to have some breakthroughs.
We move into the early growth stage.
Drug seems to be working pretty well.
People are taking the medication.
Their grey hair goes away.
And we're starting to get positive operating cash flows.
As more and more doctors prescribe our medicine.
We still have big negative investing cash flow because we're trying to grow the business.
And we're trying to invest in new property plant equipment to meet demands for our drug.
And maybe we decide to go and acquire another company to diversify our product line.
So you can take the pill and your hair will turn blonde even if it was say dark brunette to begin with.
Not, not that there's anything wrong with dark brunette hair either.
We cannot fund that investing cash flow just out of operations.
So we have a positive Financing Cash Flow.
As the, we need to go out and raise money either from the stock market or from banks and other creditors.
Can we get more of this?
So, let's get back to it.
We've got patents on our anti-gray hair drug, our pro-blond hair drug.
And we can just print money as a result.
There's a lot of revenue coming in, covering all the expenses of running the business, so we have a high cash from operations.
We still have a fairly high level of investing cash outflows.
Because we're still growing, we have capital expenditures that we need to have to meet the demand for our product.
Maybe we're doing a couple of other strategic acquisitions.
But now we're able to pay back some of the financing, so we have negative financing cash flows.
We use the excess cash operating after covering the investing cash flow.
To go out and buy back stock, or pay back debt, or maybe start to pay dividends to our shareholders.
Then we move into the decline stage of our life cycle.
All of our patents have expired, customers can now buy generic anti-grey hair medication, or generic pro blonde medication.
Our investing cash flows have also gone down substantially, because we just don't have a lot of other ideas for new investments.
And so we end up doing is continue to have a negative financing cash outflow.
We're taking our excess cash from operations and using it to buy back stock, repay debt, or pay dividends.
Which at this point is essentially just saying to our shareholders.
Because we certainly can't.
And then, I guess, the last stage would be, we either go bankrupt or acquired.
So I think this video showed that it's fairly straightforward to classify cash flow activities into the operating, investing, and financing buckets.
But it's not always straightforward.
In the next video, we're going to apply these classifications to the Relic Spotter case.
And there we'll see that there is judgement that does apply in some situations which makes this a bit trickier than it first seems.
I'll see you next video.
In this video, we're going to dig out the Relic Spotter case that we worked on during the first two weeks, and go through its cash flow transactions to classify them into operating, investing, and financing buckets, which is the first step towards putting together Relic Spotter statement of cash flows.
Let's get started.
Let's start with transaction number one for the Relic Spotter case.
In this transaction, Relic Spotter sold shares to investors.
Thousand dollars because the company received cash and then credited common stock in APIC.
The answer here is financing, one of the definitions of a financing activity is cash flows with our owners.
So if we're issuing stock, we're getting stock from the owners of the company which would make it a financing cash flow.
Next, transaction number three.
Or did you make a mistake, as you often do?
Well, at least not yet.
It was the transaction where Park was borrowing money on her own account and we didn't even record it.
The only ones that we have to deal with are the ones that have either debits or credits to cash.
So anyway, in transaction number three, Relic Spotter paid $3900 cash in legal fees to incorporate the business.
The answer here is operating cash flow, because this is one of the costs or expenses that Relic Spotter needs to incur to run the business.
After all, incorporating the business is a long term cash flow.
At least, we hope.
But if you remember we decided to expense this cash flow on the income statement.
So to provide comparability, we're gonna treat it as an operating activity on the cash flow statement.
If we had created a long term asset, then we probably would of treated it as an investing activity.
Relic Spotter bought land and building with a mortgage and $31,000 of cash.
So go ahead and try to classify this cash flow as operating, investing, or financing.
The answer here is obviously 155,000 cash out flow for investing, and 124,000 cash in flow for financing.
We bought land and building.
Why is this not $31,000 of cash flow for investing activities?
>> Okay, I said obviously when I provided the answer, but this one's far from obvious.
The issue here is that we did one journal entry, but there were really two separate transactions.
First, we borrowed $124,000 cash from a bank under a mortgage.
The second is that we used that cash, plus $31,000 of our own cash To buy $155,000 of land and building.
That's an investing activity.
To provide investors and analysts a clear picture of what we're doing, we need to split this into the two transactions we really borrowed a 124,000 from the bank under a financing cashflow.
And we really paid $155,000 cash for land and building, as an investing cash flow.
And that's what we need to show on the statement of cash flows.
Relic Spotter paid $33,000 cash for renovation work to the building.
The answer here is investing.
It should be an investing cash outflow of $33,000.
This seems a lot like routine maintenance to me, which would be an operating activity.
But the key question here is does this expenditure represent a capital improvement, or a routine maintenance?
A capital improvement would be anything that increases the value of the building or its useful life.
We would add that to the building account, and appreciate it over time, and we'd consider the cashflow an investing activity.
Routine maintenance is something you have to do no matter what.
It's already built into the assumptions about the value of the building and its life.
It gets expensed immediately and then it would be considered an operating cash flow.
Transaction number 6, Relic Spotter paid $120,000 cash to buy metal detectors.
Is that transaction operating, investing, or financing?
And the answer is $120,000 investing cash outflow.
Why would the purchase of said metal detectors not be an operating activity?
But we're going to ramp these metal detectors over and over and over for up to two years, which makes them more like equipment, a long term asset.
And makes the treatment of it an investing cash flow more appropriate.
If we are buying these metal detectors and immediately reselling them like inventory, then we would call it operating.
Or if we bought them and we were going to rent them for less than a year.
But the fact that we're gonna have them for more than a year, up to two years, makes this feel more like an investing activity.
And move to transaction eight where Relic Spotter had paid $2,100 cash for a 3 year software site license.
The answer here is an investing cash outflow of $2100.
And before the virtual students jump in I'll just tell you.
So that's gonna make it an investing activity because we're investing for more than a year.
Relic Spotter paid $8,000 cash for advertising over the next year.
Is that operating, investing, or financing?
So, by our general rule of thumb, we would call this an operating activity, rather than an investing activity.
This one year rule of thumb tends to work pretty well.
If you have an expenditure that's gonna benefit you for more than a year, we tend to call it investing.
If it's gonna benefit you for less than a year, we tend to call it operating and there are not many exceptions to that.
Is that operating and investing or financing.
Why isn't this financing?
>> Actually, in this case, Relic Spotter is the creditor because Rebecca Park is borrowing money from the company.
If the company were borrowing money from Rebecca Park, then yes, it would be a financing activity.
So the question now is, if Relic Spotter is lending money to Rebecca Park, is that an operating or an investing activity?
I decided to make it an operating activity because the loan was only one year, if the loan was longer than a year, say two years, or three years, or five years.
Here Relic Spotter paid $2,000 cash to its supplier.
This was for the inventory that it bought out account in transaction seven.
So, this $2,000 cash paid to the supplier operating, investing, or financing.
The answer here is a $2,000 operating cash outflow.
Yeah, a payment to a supplier is one of the examples we use to define an operating activity.
By the way, do you know where the smartest people in America work?
At the US Mint, because all they do all day is make cents.
In transaction number 14 Relic Spotter paid $2500 cash to it's shareholders for it's dividend.
This was the dividend that they declared in transaction 12, it's actually paid in cash in transaction 14.
So is this $2500 cash paid for dividends operating, investing or financing?
>> Yes, paying dividends is one of the examples we use to define a financing activity.
By the way, do you know where you can also find smart reasonable people?
Next in transaction 15 Relic Spotter received $1200 cash from the Pen Antiquities Club for future unlimited rentals.
So how do we consider this cash received for future rentals, operating, investing, or financing?
The answer here is operating.
In transaction 16, Relic Spotter receives cash rental revenue on the metal detectors.
Is that operating, investing, or financing?
The answer here again, is operating.
>> Either these have gotten easier or we have gotten smarter.
In transaction 17 Relic Spotter paid $38,000 cash for inventory.
Is this operating, investing, or financing?
The answer here is operating cash outflow of 38,000, operating because this is a core expenditure for running our business.
Relic Spotter received $35,000 cash from sales of sundries.
Is this operating, investing, or financing?
The answer here is operating.
Finally, transaction 20, Relic Spotter paid 82,000$ cash to its employees for salaries and wages.
Is this operating, investing, or financing?
Paying our employees is one of our key business activities, so this would be an operating activity.
And that was the last cash transaction for Relic Spotter because the rest of the transactions in the case were adjusting entries.
So we can go ahead and total everything up.
Which, if you go back and look, is what we end up having at the end of the year for Relic Spotter.
Now, all we have to do is just list these cash transactions on the cash flow statement in Operating, Investing, and Financing order.
>> I wish that was the case because then we would be done with the week on cash flow statements, but if you looked at the website you can see that we have a lot of videos left to go.
And we'll pick this up next video with the discussion of the two different methods there are for putting together a statement of cash flows.
Unfortunately, all companies use the difficult method, so it's gonna take us a lot of videos to understand that method, which we need to know to understand real companies' financial statements.
I'll see you next video.
In this video, we're gonna talk about the two different methods that you need to know to put together a cash flow statement.
Let's get started.
There are two methods for preparing the statement of cash flows which are rather creatively titled the direct and indirect methods.
So where are all the places that the cash came from, where are all the places that you pay cash out to?
This method is always used for investing and financing activities, but is rarely used for operating activities.
Instead, for operating activities, companies tend to use the indirect method.
This can only be used for operating activities and the goal is to reconcile net income with cash from operations by removing any noncash items from net income, and including any additional cash flows that were not in net income.
So we're gonna see a statement that starts with net income, ends with cash from operations and shows all the differences between the two.
So what this boils down to is for three buckets operating, investing and financing.
Where as investing and financing are always the direct method.
What's good for the goose is good for the gander.
This is just more stupid over-complication.
>> You know I am gonna agree with you that this probably is a stupid over complication.
Because really every company uses the same approach for their cash flow statement.
They do the investing and financing activities using the direct method, and then they use the indirect method for their operating section.
Because even if they did the operating activities under the direct method, you still have to provide the indirect method anyway.
You just list the cash flows based on where they're coming from or where they're going to.
Really the one thing you have to learn that's difficult is this indirect method for operating.
And we're going to spend much of the rest of the video, and much of the rest of the week trying to get a handle on this indirect method for the operating section.
Then it's going to adjust for components of Net Income that are tied to noncash items or to investing activities.
What we need to do is either add back the expenses or subtract the revenues to remove them from Net Income to to get the cash flow.
So for example, Net income includes depreciation expense and amortization expense which are both noncash expenses.
To remove those noncash expenses so that we can get from Net Income to cash from operations, we have to add them back.
Because adding back expenses removes them.
We can also have gains or loses on sale at of property point equipment or investments.
Now there are cash flows associated with those, but we want to count those cash flows in the investing section.
So we need to remove those gains and losses from the income statement.
So, we're going to add back losses or subtract gains, to remove them from Net Income, on our way to cash from operations.
Then, we need to adjust for components of Net Income tied to assets or liabilities created through operating activities.
These are the working capital accounts, like accounts receivable, inventory, all of the payables.
What we need to do here is add or subtract the change in the asset or liability account balance.
And we're gonna use the balance sheet equation to determine whether we should add or subtract.
For example, accounts receivable is a noncash asset.
If accounts receivable went up, we would need to subtract it on the cash flow statement to stay in balance.
If it went down, we would need to add it on the cash flow statement to stay in balance.
On the other side of the equation, accounts payable is a liability.
If accounts payable went up, we would need to add it on the cash flow statement to stay in balance.
And if something like interest payable or wages payable went down, we'd have a liability going down, and we would have to subtract it on the cash flow statement.
What?
That example didn't make it crystal clear on how to do the indirect method?
Okay, okay, we'll do an example, or maybe two, or maybe four our five.
Let's look at some examples of how to put together an indirect method cash flow statement and how it gives you the same answer as the direct method.
We're going to do this for various types of income statements with adding a little bit more complexity each example.
In the simplest case, we have a company that had $100 of sales which were all in cash.
Their cost of goods sold were $60, again all in cash.
So they bough $60 of inventory with cash and sold it all during the period.
And so they end up with net income of 40.
Cash payments of suppliers of 60, gives us an operating cash flow of 40.
And in this case the operating cash flow is exactly the same as Net Income, because everything the company did was in cash.
If we go to the indirect method, under the algorithm we always start with net income.
We didn't end or begin the year with inventory.
Now let's make this a little more complicated and bring in depreciation expense.
So we start with cash sales and cash COGS like in the prior example.
But now the company has a $10 noncash expense depreciation which gives the company a Net Income of 30.
Under the direct method we have cash collections from customers, cash payments to suppliers.
Of course there's no cash flow involved in the depreciation.
Now we need to make sure we get the same answer under the Indirect method.
We add back the depreciation expense of 10.
It's a noncash expense so to remove it from Net Income we add it back.
There are no changes in working capital, because again we didn't begin or end the year with receivables or inventory.
So there's no other adjustments and we end up with operating cash flow of 40 under the indirect method.
Which of course is the same answer under the direct method which always has to be the case.
If a company had say $10 more in depreciation expense it would increase cash flow by $10?
If a company had cash flow problems all it would have to do is take more depreciation.
That's cool.
Just crank up the depreciation expense, and watch that cash flow through the door.
Well, obviously it can't work like that.
And, in fact, I've heard stories about employers asking students this very question to see if they know anything about accounting.
So let me jump back out to the slide and show you how this works.
Okay, let's say we have another $10 of depreciation, that means we would have $20 of appreciation expense total, and we would add back 20.
Now I'm going to ignore taxes for now.
And just assume that our Net Income would drop from 30 down to 20 with the extra $10 of depreciation expense.
So we have 20 plus 20 equals 40 instead of 30 plus 10 equals 40.
It has to get us to the same place because depreciation's a noncash expense.
It can't create more cash flow.
Now one thing I should note is that you can use different depreciation for tax purposes, than you see here on the financial statements.
And changes in depreciation for tax purposes actually can save on taxes and can effect cash flow.
But that's a topic that we're going to deal with much later in the course.
In the next example we're going to still have a $100 of sales but this time lets assume that only $80 is received in cash the other $20 of sales remain on account so that we end the period with accounts receivable.
We still have $60 of COGS which is all in cash and our $10 to depreciation.
Gets us to the same Net Income as we saw in the last example of 30.
When we look at the direct method operating section cash flow statement, we collected $80 of cash from customers.
Now let's see if we can get the same answer under the indirect method.
We start with Net Income and then as we saw in the prior example, add back depreciation expense because it's a noncash expense.
But now we have a change in accounts receivable that we have to adjust for under that third step in the algorithm.
What happened is accounts receivable started the period at 0, Ended the period at 20.
So, that's a $20 increase in a noncash asset.
Which means that we have to subtract it on the cash flow statement.
Because we've got 30 of Net Income, plus 10 of depreciation expense is 40, minus 20 for the increase in accounts receivable, gets us to an operating cash flow of $20, which is the same answer that we got under the direct method.
We sell $20 of goods, and yet, that reduces our cash flow.
Isn't that like cutting off the nose to spite the face?
But anyway let's think through the intuition behind the indirect method.
Make adjustments to get the cash from operations.
All of those sales are legitimate, they meet the revenue recognition criteria.
But $20 of those sales were never collected in cash.
Fortunately, the increase in accounts receivable keeps track of the noncash sales.
Cuz any time we make a sale on credit, we have to increase accounts receivable.
So if we start with Net Income, which includes the $100 of sales.
Subtract the increase in accounts receivable to take out the $20 of noncash sales.
We're going to start with sales of 100 again.
Now, we're gonna make the inventory part a lot more complicated.
So, we'll keep the $60 of cost of goods sold.
But in this case, we actually bought $75 of inventory.
So we bought $15 more of inventory than we sold.
And we only paid $50 in cash.
Which means that $25 of that inventory was acquired on an account, so we have accounts payable of 25.
Then we subtract off the depreciation, and we end up with a net income of 30.
Under the direct method, we collect $80 of cash from customers.
We only paid $50 cash to our suppliers.
So we don't use the COGS amount or how much inventory we bought.
We use the actual cash we paid, which was 50.
We add back depreciation expense, so we've seen those two steps before.
We've also seen the subtraction of the increase in accounts receivable, to take into account that not all the sales were made in cash.
So, what happened was our inventory started the year at 0, and ended the year at 15.
It went up by 15 because we purchased 75 of inventory but only sold 60.
If a noncash asset goes up, we subtract it on the cash flow statement.
So we subtract the increase in inventory.
For accounts payable, they started the year at 0, ended the year at 25, so this liability accounts payable goes up by 25.
That's on the other side of the equal sign, so cash has to go up by 25 to make this balance.
So we can see on the indirect method cash flow statement we have increase in accounts payable of 25 gets added back.
When we add everything up, we get the same operating cash flows under the direct method.
If your inventory goes up during the year, it means that you're buying more inventory than you needed for your level of sales.
That means that you got stuff without paying your supplier.
Not paying your supplier is a source of cash.
That's an extra $25 of cash that you would not have had if you had paid off your supplier's amount.
And so we add that to recognize that it's a source of cash.
We're gonna go through a lot more examples like this in remaining videos to help you get down this intuition.
Do you have some simple formula, or algorithm, we could use?
>> Well I showed you a slide earlier in the video with a simple algorithm for doing the indirect method, and you all went, what, what, really?.
Sorry to be a little peevish there, I guess that's what the cash flow statement will do to us.
I understand that it is hard to get your head around how this indirect method works when you see it for the first time.
So we're gonna do in the next video, is go back to the Relic Spotter case and step-by-step, work through how to put together an indirect method cash flow statement for Relic Spotter.
And then you'll see many more examples later in the week.
Anyway, I'll see you next video.
In this video we're finally gonna finish the Relic Spotter case by putting together its statement of cash flows using the direct and indirect methods.
Let's get started.
Last time we looked at the Relic Spotter case we put all of the cash transactions into operating, investing, and financing buckets.
So now we're gonna go ahead and use these classifications to put together the cash flow statement.
To do the indirect method, we're gonna need to pull some information off the income statement.
I don't remember all of those zeros when we put together the balance sheet.
In fact when we put together the Relic Spotter balance sheet, we didn't have all these zeros in there because we only put together the ending balance sheet.
But when we do a cash flow statement, we need the change in the balances, the difference between the beginning balance and the ending balance.
There was no beginning balance on any of these accounts because Relic Spotter is a start up company.
Once we get that out of the way, then we'll look at operating activities under both the direct and indirect method.
So we have purchase of land for 103,000, purchase of buildings, 85,000.
Add them all up, we get net cash outflow from investing activities of 310,100.
This section will go on the final cash flow statement.
Oftentimes, don't companies simply report a line called capital expenditures?
>> There are generally no specific rules that govern how much or how little detail you break things into on the statement of cash flows.
It's the manager's choice, but usually the manager makes the choice based on what investors and analysts wanna see.
Because if investors and analysts are looking for a piece of information that's not there, they'll just ask the company about it during a conference call or some other communication.
So what you're seeing on the cash flow statement is a joint agreement between managers and the users of the financial statement as to how much detail they wanna see in these various line items about the company.
So here is the column of cash transactions that we classified as financing.
Now we just need to list them.
So we paid dividends of $2,500.
That gives us a net cash inflow from financing activities of $371,500.
Now even though it's somewhat theoretical cuz companies never really report these, we're gonna look at the operating activities under the direct method.
So let me pull in the operating cash flow transactions.
So first, I'm gonna take all the cash we collected from customers.
We received cash on the rental prepayment from the Pen Antiquities Club, the revenues that came in cash from metal detector rentals, and then the 35,000 of cash from the sundries sales.
You add that together, and we have cash collected from customers totalling 156,300.
How can we justify putting that on the cash flow statement?
>> Well, we can justify putting it on the cash flow statement because Relic Spotter actually received cash.
Well you raise a good point, in that a lot of the examples we've seen so far, companies are recording revenue before they receive the cash.
And so, we have a change in accounts receivable.
But, you could have a company receive the cash before they earn the revenue.
Either you might get the cash first, or you might get the cash later compared to when you book the revenue.
Add that up, cash paid to suppliers is 40,000.
Cash paid to employees for salaries and wages was 82,000.
Cash paid for short term loans was 5,000, and then I'll combine legal fees and advertising into cash paid from miscellaneous expenses of 11,900.
Again whether you list those separately or combine them depends on what your financial statement users wanna see in terms of the level of detail.
We add all this up, and we get net cash from operations of 17,400 which is what we had in the operating bucket to begin with.
But, you said that companies rarely use it.
>> So, why do we have to learn the indirect method?
Let's hear your answer.
>> I'm glad you asked that question here, because this is the best place for me to show you why the direct method is not that useful for the operating section of the cash flow statement.
Let me jump out to the slide and show you what I mean.
So, Relic Spotter's cash collected from customers was 156,300.
Is that good or bad?
Relic Spotter's cash paid to suppliers was 40,000.
Is that good or bad?
Well, you can't tell without some kind of benchmark.
You could look at prior year numbers to see if there's a trend.
But, what we really wanna know is, what was the level of activity surrounding these cash collections during the year?
For example, if Relic Spotter at 157,000 of revenue and collected 156,300 in cash, then the cash flow makes sense.
But if Relic Spotter had 500,000 in revenue, but only collected 156,300, then there may be a problem.
Or, let's say that Relic Spotter sold 40,000 of inventory, paid 40,000 to their suppliers.
But what if Relic Spotter only sold 10,000 of inventory?
Then the question is, why did they spend an extra 30,000 in cash to acquire inventory they didn't sell?
What the indirect method's gonna do is start with net income as a benchmark for the expected level of activity or expected level of cash flows during the period.
And then highlight any discrepancies from that level.
This is the kind of thing we'll talk about when we do an analysis of an indirect cash flow statement, after we finally put one together later in the video.
Now we're gonna do the indirect method which will be what we'll show on the final cash flow statement for Relic Spotter.
So I've pulled up the income statement, and at the bottom line we can see net income was $2,370.
So on our indirect method cash flow statement, we start at the top with net income of 2,370.
Notice I already have the answer at the bottom, net cash from operations of 17,400 because, whatever we do in this section, we have to get the same answer that we got under the direct method.
Okay, so far, so good.
Next step in our algorithm was to adjust for components of net income tied to noncash items or investing activities.
We had metal detector depreciation of 3,000, software amortization expense of 350, and building depreciation expense of 1,500.
I'm gonna combine those into one line item called depreciation and amortization of 31,850, and we're gonna add that back to remove that non-cash expense from net income.
One thing I will say here is that generally the only place you can find depreciation and amortization expense in the statements is on the statement of cash flows.
Yes, it's part of the income statement, but it's often combined with other items, and not broken out separately.
But you'll always be able to find it broken out separately in the operating section of the statement of cash flows.
The last step in our algorithm is to go through all the asset and liability accounts related to operating activities, in other words the working capital accounts.
And add or subtract the change in the balance based on the balance sheet equation.
That's a noncash asset going up, which means we need to subtract it on the cash flow statement to stay in balance.
Interest receivable went from 0 to 250, noncash asset going up.
So we subtract it on the cash flow statement.
Inventory went from 0 to 12,000, noncash asset going up.
So we subtract it on the cash flow statement.
And again, non-cash asset going up, we subtract that on the cash flow statement.
>> I think I understand, assets are always subtracted when the indirect method is used.
And so all the assets went up.
In a future video, we'll look at examples where companies do add assets to their statement of cash flows because they've had assets go down during the year.
If we look at the rest of the assets out of the balance sheet, we have land, buildings, metal detectors, software.
We don't do anything with those in the operating section cuz we've already taken care of those in the investing activities.
So we move onto the liability side of balance sheet.
Note we're on the other side of the equal sign with the liability.
So liability going up means that we need to add it to the cash flow statement.
So that's an increase in a liability of 4,900, which we need to add to the cash flow statement to keep the balance sheet equation in balance.
Again, an increase in a liability gets added to the cash flow statement.
That's an increase in liability that gets added to the cash flow statement.
>> And I think I am not wrong to assume that is not necessarily the case that liabilities are always added under the indirect method.
I'm not really sure what the question was.
But you should not assume that liabilities are always added on the cash flow statement.
Again, because we are looking at a start-up, all the liabilities went up in value and so we added them.
Going back to the balance sheet, the next accounts we would have would be mortgage payable, common stock, additional paid-in-capital.
And retained earnings, that's just net income and dividends which we've also taken care of.
So looks like we're done, which is a good thing because we're out of space on the indirect method cash flow statement here on the right.
And if you add everything up, you 'll find that we get the same answer, 17,400, that we got under the direct method.
And then we'll have cash flow from investing and financing activity under the direct method.
In terms of analysis, what this statement tells us is that this company is still in the early growth stage of its life cycle.
We do have positive cash from operations, 17,400, but that's nowhere near enough to cover all the cash outflow for investing activities.
So, Relic Spotter had to go out and raise a lot of cash through financing activities, both through stock and mortgage payable.
Now I want to focus just on the cash flow from operating activities section so we can talk about what we learn from this indirect method presentation.
First thing we learn is it gives us the two different pictures of the company's performance during the year.
So we see Relic Spotter's net income, which answers the question, did Relic Spotter price their rentals and sales high enough to cover all the costs of the, running the business, and thus post a profit?
And we can see they did.
Then at the bottom we see net cash from operations, which answers the question, did Relic Spotter have more cash coming in than cash going out, in activities related to running the business?
And here we see that that was the case also.
Between those two pictures of the business, we see all the discrepancies, all the reasons why we got different answers.
And the biggest discrepancy is the depreciation and amortization.
And that makes sense because net income includes an expense or a charge for using up these fixed assets, using the buildings and metal detector and softwares.
Whereas there is no cash implications of doing that so it doesn't affect cash from operations.
So anytime you look at companies that are very capital intensive, they have a lot of long-term assets.
You'll see this difference between net income and cash from operations is primarily driven by this depreciation amortization.
Then we have all of the changes in working capital that have created discrepancies between net income and cash flow.
And from an analysis point of view, I think these are the most interesting and important lines to focus on in the cash flow statement.
Cuz what these lines are telling you is that some management activity is creating a wedge between cash flows and revenue and expense recognition.
So what you wanna do is focus on the really big numbers and try to understand what's going on.
So for instance, the biggest number is the change in inventories of negative 12,000.
What that represents is that Relic Spotter purchased $12,000 more inventory in cash than they needed for their level of sales which were recognized in net income.
What you wanna do now is dig in and try to find out what caused that.
So did Relic Spotter management buy a bunch of inventory that they couldn't sell because nobody wanted it?
Or, were they getting some kind of volume discounts, and so they were buying excess inventory in advance of future sales, which would be good news.
I mean, the cash flow statement's not gonna tell you which one it is.
But it's gonna tell you, you need to dig into these further.
As another example, a big discrepancy that you often see is changes in accounts receivable, which in case of Relic Spotter, was negative 4,200.
This could be good news if their sales are growing dramatically and they just haven't had a chance to collect them yet.
Again, we don't know which scenario is going on just by looking at the cash statement.
What it does is it highlights we need to dig into these further.
So, you wanna look for the big numbers in these changes in working capital.
So, that was our first trip through putting together an indirect method cash flow statement using the balance sheet and the income statement.
Not clear yet?
I'll see you then.
In this video we're gonna to tackle a number of miscellaneous cash flow topics that I haven't gotten to yet.
And we'll wrap up with a discussion of earnings versus cash flow versus EBITDA versus free cash flows.
So, let's get to it.
First let's look at an example of how to treat a gain on sale of property, plant, and equipment under the indirect method cash flow statement.
So let's say we sold property plant equipment worth $70 on the books for $75 cash.
I bet that never, ever happens in the real world.
But I said how much it's worth on the books or the financial statements.
And remember the book value of property plant equipment is gonna be a function of our depreciation assumptions, because it equals the original cost minus the accumulated depreciation.
So if the depreciation assumptions are incorrect, which they always are, then we're gonna end up selling it for more or less than it's on the books.
So think of it this way, if we depreciate something too much, we drop its value too much, we end up having a gain on sale, which sort of brings it to the true amount of depreciation over the life of the asset.
If we depreciate something too little, then we'll have a loss on sale, which again gets us to the true level of depreciation on the asset over its life.
So this gain or loss on sale helps us adjust our incorrect assumptions and get the true amount of economic depreciation over the life of the asset.
Anyway, that's gonna result in a gain of $5, which will go on the income statement.
Although this gain will go on the income statement and increase that income just like revenue would, we're not gonna consider it top line revenue because it's not part of our core business activities.
In other words, we're not in the business of buying and selling buildings.
One implication of this example is because it's not a core business activity, it's gonna be an investing activity.
And because it's an investing activity, we need to remove that gain out of the operating section and place it into the investing section.
So I'm gonna bring back one of the basic example we did early on, where we have all of our sales in cash, all of our cost to goods sold in cash, and then depreciation of $10.
We're gonna add to that the gain on sale of property plant equipment, which goes on the income statement, which would make our net income 35.
Under the direct method cash flow, all of our sales for cash, so we have collections from customers of 100.
All of our cost to goods sold was in cash, so we have payments to suppliers of 60.
Depreciation, of course, is not cash.
And the gain on sale of property plant equipment, we want to consider that part of the investing cash flow.
And then we have investing cash flow as the full $75 proceeds from sale of PP&E.
Under the indirect method, we start with net income, which is 35.
We add back depreciation expense of 10, because it's a non-cash expense.
And then we have to remove the gain, otherwise we'll double count that cash flow.
A gain increases net income, so to remove it we need to subtract the gain.
And then we have again, the full cash flow from the sale of the PP&E, 75, as an investing cash flow.
Could you provide the viewers a handy algorithm for remembering how to adjust for such gains?
So the way to remember how to deal with gains and losses on investing activities in the operating section is the Hokey Pokey.
You do the hokey pokey and you turn yourself around, that's what it's all about.
Next I want to talk about some of the complications you may run into when looking at a statement of cash flows.
These are not things that we're gonna explicitly cover in the course, but I want you to be aware of them, because you will run into them in practice.
And all these complications surround the question why doesn't the change in the balance sheet numbers often equal the number on the statement of cash flows?
So in all of the examples that we've done so far, when you look at the change in the balance sheet numbers for, say, accounts receivable, it's the exact same number that you see in the operating section on the statement of cash flows.
But in real financial statements, you often see it's not the case for one of these four reasons.
First, there could be non-cash investing and financing activities that relate to the working capital accounts in the operating section.
An example would be, let's say one of our customers who owes us an account receivable can't pay us cash, so instead they give us a piece of land.
It would be disclosed at the bottom of the statement of cash flows.
It would also affect the balance sheet number for accounts receivable, but it wouldn't show up on the cash flow statement because there's no cash involved.
All the cash the companies pay when acquire another company is considered a investing cash flow.
But, part of the things companies acquire are working capital assets and liabilities.
So for instance, let's say a company made an acquisition.
For multinational companies, which have subsidiaries in multiple countries in different currencies, what we do is we take any effect of exchange rate movements and break them out of the operating section of the cash flow, showing them at the bottom.
So a foreign exchange movement would effect the balance of say, accounts receivable or inventory in the balance sheet, but we wouldn't show it in the operating section of the statement of cash flows.
Does anyone even do these in the real world?
>> Do you mean the MTV show The Real World, or in practice?
Because you're talking about the MTV show The Real World.
I don't think they did any foreign currency translation adjustments, it seems more like a Jersey Shore thing.
Anyway, this is a pretty advanced topic, it's something I cover in a second year elective, so, we're not gonna go into this in detail in this course.
I just wanted you to be aware of the fact that all of the effects of exchange rate movements on the cash flow statement are broken out on one line item in the bottom so that when you look at the operating section, what you're seeing are changes in accounts due to real activities, not due to exchange rate movements.
The last complication is that sometimes companies have subsidiaries in different industries, which effect what is considered operating versus investing activities.
So let's think back to our company before that made the pills to cure grey hair.
Not that grey hair needs to be cured.
What would happen then is the pharmaceutical company buys land.
It would be considered an investing activity.
But if the real estate subsidiary buys land, it would be considered an operating activity, cuz that's part of their core operations.
So the same transaction of buying land could show up as either operating or investing.
Now, companies in this situation will sometimes produce separate cash flow statements to help investors see these different activities match up in the different subsidiaries.
Next I wanna talk about disagreements that analysts and investors have over the FASB classification, a couple items.
I know it's hard to believe that people would disagree with the FASB, but there are a couple disagreements out there.
The first, many investors and analysts prefer to classify interest payments as a financing activity and interest and dividends received on an investment as an investing activity.
So one thing that FASB did is they required a disclosure of cash paid for interest, so if investors or analysts wanna take it out of operating, they can easily subtract it because that disclosure's provided.
Another disagreement is that all income tax effects are shown in the operating section, even if the income relates to financing or investing activities.
So if there's an income tax effect from getting, say, a gain on selling property plant equipment, which would be an investing activity, the tax effects show up as operating.
So the FASB requires that all cash taxes paid must be disclosed.
Again, so if you don't think that cash taxes should be part of operating, you can take them all out in your calculation.
Next I want to talk about this measure EBITDA, which is defined as earnings before interest, taxes, depreciation, and amortization.
EBITDA is often used by investors and analysts as a proxy for operating cash flow.
And because it excludes interest and taxes, it solves for that problem that we talked about on the last slide.
However, EBITDA does not do a good job of measuring cash flow if there are large changes in working capital, like accounts receivable or inventory, and in fact, it suffers from the same manipulation potential as net income.
So for example, let's think of a company that does channel stuffing.
Channel stuffing is a situation where at the end of a quarter, the company's trying to meet an earnings target, so they ship a bunch of product to customers in order to book the revenue, which would then increase earnings, and of course then increase EBITDA.
The customers haven't paid us yet.
Instead, accounts receivable will go up.
So, EBITDA would consider this channel stuffing as a cash flow, but it's not a cash flow.
Now, if we took EBITDA, and adjusted for this increase in accounts receivable, then we would have a good measure of cash flow.
And I'm gonna talk about this more in the next video.
Everyone knows that EBITDA is the best measure of cash.
>> Now, I feel pretty strongly that EBITDA is not a good measure of cash flow, because unless you adjust for these changes in working capital, then EBITDA is just as easy to manipulate as earnings is.
What we're gonna do in the next video is a case where we'll highlight some of these drawbacks of EBITDA.
And I'll show you when it's not a great measure of cash flow.
And then one more point on this, you often hear people talking about cash is king, implying that you should only look at cash from operations or EBITDA as a proxy from cash operations and not even look at earnings because it's too easy to manipulate.
Well, there's actually been a lot of academic research that's looked at this question of earnings versus cash flow.
And it finds that earnings are a better predictor of future cash flows than current cash flow from operations.
It's trying to answer the question, are you able to price your product or service high enough to cover all the costs of doing business?
But the good news is, you don't have to choose one or the other.
You get both earnings and cash glow from operations, and academic research it's very clear that if you put both measure in together, you get the best predictions of how a company's gonna do in the future in terms of its future cash flows.
>> I bet that accounting professors did the research to show that earnings is better than cash flow.
Is that really the case in the real world?
>> Yes, it was mostly accounting researchers that did this research, but is there anything wrong with that?
The data that they looked at, though, came from real companies, looking at long time series of data from 1962 to the present, and it's a very robust result that earnings are a better predictor of future cash flows than current cash flows.
But again, the research emphasizes the best prediction comes from including both measures together.
The last topic of this video is that I wanna briefly talk about free cash flow.
Now, this is more of a finance topic, where they use free cash flow a lot.
But since we've been talking about cash flows and these finance approaches generally pull cash flow numbers out of the financial statements, I wanted to briefly give you some cautions that you should have in dealing with free cash flows..
When people talk about free cash flow, they generally mean operating cash flow minus cash used for long-term investments.
There's valuation models out there that show if you forecast out a company's free cash flows, discount them back to present value, you'll get a measure of how much the company should be worth, what its stock price should be.
The problem is that if you look across these measures of free cash flow, there's often no standard measure for operating cash flow.
So I've got a number of accounting and finance textbooks lying around my office, and they all seem to define operating cash flows differently.
One book defines it as cash from operations before interest expense, so using the FASB number and adjusting for interest expense.
Another defines it as NOPLAT, which is net operating profits less adjusted taxed, which would be EBITDA minus cash tax on EBITDA, which is not a good measure of cash flow because it doesn't measure cash.
Without changes in working capital, you won't get a measure of cash.
The next one, NOPAT minus increases in working capital, is a better measure.
NOPAT is net income adding back interest expense, and then adjusting for changes in working capital to get closer to cash flow.
Another book called it net income adjusted for depreciation other non-tax, non-cash items minus an increase in working capital, which I guess would be okay as long as the depreciation was after tax, because net income is after tax.
Another said gross up earnings before interest and taxes and add depreciation, and a lot of them just say EBITDA without defining what it is.
On top of this, another problem you'll encounter is companies will often disclose free cash flows using their own custom definition.
And what you'll find is that definition often changes across companies or companies will change it across years.
So if you're using any kind of cash flow measure, the most important thing is to figure out how it's actually defined, because some of these measures are defined much better than others.
>> I believe a better approach than telling us everyone is wrong would be telling us what is correct.
I'm just saying some people are more correct than others.
I think there's two approaches that would give you a really good cash flow from operations number.
The first approach would be to take the cash from operations from the cash flow statement, which uses the FASB classification, and then subtract out cash paid for interest and cash paid for taxes, which are disclosed somewhere else in the report.
The second way would be to start with EBITDA, and then adjust for these changes in working capital, like receivables, inventories, and payables, using the balance sheet equation like we do under the indirect method.
In the next video, we'll look at a case which will better highlight some of these advantages and disadvantages of these different measures for cash operations.
What we're gonna do in the next video is look at a couple examples which will give us more practice on putting together cash flow statements under the indirect method.
It'll give us some practice on handling gains and losses on sale of property plant equipment in the cash flow statement, and it will allow us to continue our discussion of earnings, versus cash flow, versus EBITDA.
I'll see you then.
In this video, we're gonna end our week looking at cash flows with a look at the 3M company's cash flow statement.
We're gonna take a look at their actual statement, plus the supplemental disclosures about the statement in the footnotes, and the discussion of the cash flow statement in their management discussion analysis, or MDNA section.
Let's get started.
3M's statement of cash flows is on page 51 of their annual report.
The first thing I like to look at is this breakdown of operating, investing, and financing activities, to see what kind of stage or life cycle the company's in.
So 3M throws off about 5 billion of cash from operations every year.
It's pretty steady.
They have cash outflows from investing activities of about 2.6 billion every year.
And they also have net financing cash outflows of about 2 billion, other than a blip in 2011.
So this is sort of the classic, mature company profile.
They're still reinvesting a moderate amount back into the company, back into long term assets, and we'll look at this a little more in a second.
And, they are net cash out flows for financing, so they don't have to borrow.
They don't have to raise money to fund their operations or investments anymore.
Instead their operations are able to fund all of their investing activities, and still throw off some cash that they can use, to pay off debt or repurchase equity or pay dividends.
So just to get some more insight into this, one thing that's often good to look at is comparing depreciation to purchases of a property plant and equipment.
Again it's very rough, but, if you view depreciation as using up your fixed assets, capital expenditures, obviously, is acquiring new ones, it looks like 3M's at about replacement level.
So they are investing a lot in new PP&E, but it's sort of replacing the things that they're using up.
They do have, though, some active acquisitions, so about a billion or so until 2012.
So they bought about 5.4 billion of, 5.5 billion of marketable securities, but then they sold or had those almost all mature within 2012.
So I think what happens is 3M is throwing off a lot of cash, if they don't immediately have an acquisition in mind, or immediately have purchased the property planned equipment, they plow it into markup on securities on investments.
And then when those opportunities to make an acquisition or buy PP&E come, they liquidate the markup on securities and use that to go out and make their acquisitions.
So it's almost like they're serving as their own bank, by buying these marketable securities, holding their cash, getting some return, waiting until they can invest it.
And then in the financing section, we see a lot of the financing cash out flow is purchase of treasury stock, that's probably for stock options.
I think you're ready to do these kinds of life cycle or growth analysis on your own.
So here's what I want you to do, after the videos over, go on the internet, find a firm that you're interested in, take a look at their cash flow statement, and see what you can learn by looking at the company's operating, investing, and financing cash flows.
Now let's dig into the operating section a bit more.
Ignore the noncontrolling interest stuff for now, and just view it as net income.
Nice steady growth in that income, indicating that they are consistently able to price their products enough to cover the cost of running the business.
And, typical of a mature company, you have this steady profitability.
So, very mature, well performing, humming along nicely company.
One of the big discrepancies between net income and net cash in operations is depreciation amortization.
Now, remember that's not a source of cash, even though it looks like it here.
It's non cash, so we have to add it back to get from cash, to get to cash from operations.
Fairly big number for the 3M, because it does a lot of manufacturing, and manufacturing companies tend to have high depreciation amortization.
Then we have a number of other, non cash expenses.
So things like pensions, stock based compensation, deferred taxes, and excess tax benefits.
So first the pension and post retirement contribution, stock based compensation, these are things we recognize as expenses now, which means they're part of net income.
But the cash is either paid in the future, as is the case for pensions and post retirement benefits, or the cash really isn't paid as it is for compensation, although part of it is you're buying back treasury stock to use to satisfy options.
But any case, there's no cash flow this period for these expenses.
And we'll talk more about the stock based compensation later on.
The pensions of post retirements, that's beyond the scope of this course.
You'll have to come and take my course at Warton, my elective, to see more on pensions and post retirements.
These are the changes in working capital, and what we see is the big chunk here are accounts receivable and inventory are negative.
So let's think about what that means.
Negative number on the operating cash flow under the indirect method means that these amounts must be going up on the balance sheet.
Accounts receivable goes up as a non cash asset, to stay in balance we have to subtract it on a cash flow statement.
And yes, even though you can't see it, I am doing up and down arrows with my hand.
Inventories go up on the balance sheet, non cash asset going up, we have to subtract that on the cashflow statement.
Cashflow is also going up, now remember, that's a liability, so if accounts payable a liability increases, it's on the other side of the balance sheet equation, we have to increase it on the cash flow statement.
Bad news scenario would be our customers are not paying us, we're having trouble selling your inventory, we're having to stretch our payables.
So during the year, we're making a lot of credit sales at the end of the period.
We are getting more raw materials at the end of the year in anticipation of production.
And so based on other things I've seen, it probably is a good new scenario that this is representing growth and working capital, rather than, bad news where you can't collect receivables, and you can't get rid of your inventories.
Now, we're gonna look at some other sections to try to get some additional information about what's going on with cash flows.
And yes, while you're looking at those cash flow statements that you downloaded from the internet, you should also take a close look at the operating section.
Look at net income, look at cash operations, and look at all the things that cause differences between the two, to see what kind of items that you would have questions about, or wanna learn more about to understand why the company's net income is different from its cash flows.
So if you remember back to the first video that week I said that there has to be disclosure of cash, taxes paid, and cash interest payments.
So in this footnote we see, the cash taxes and the cash interest.
So if you wanna start with the cash from operations and the cash flow statement, in terms ofi doing some kind of valuation, to measure operating cash flow, but you don't want tax or interest in there, you can pull those numbers using this disclosure.
One last section to look at, related to cash flows, is in the management discussion and analysis which is on page 36.
Remember this is the, the MDNA is the section where 3M management is supposed to provide their own narrative to explain what happened during the year.
So it'll give us more insight into some of the numbers that we saw on the cash flow statement.
They repeat their operating section, and talk about what happened in terms of their cash flows during the year.
The big reason for the year on year in cash flows is net income went up.
They do note that accounts receivable, inventories and payables increased by 312 compared to increases of 484 last year.
But they really don't talk much about what happened with that.
Then at the bottom of the page, they disclose free cash flow.
And as I said a couple videos ago, this is a voluntary disclosure.
That means that there's no requirement by the SEC or the FASB to provide this measure, which also means there's no standardization.
Companies can define this measure, however they want, and, and when they do that, they have to alert investors and analysts that this is a non gap measure, so it's not standardized.
So, remember free cashflow is supposed to be operating cashflow minus investment in the future.
Investing in new property plan equipment which gives them a pretty high free cash flow.
And that's a pretty good definition.
I've seen a lot worse.
This is a pretty good definition of free cash flow.
But again, before you would use this number, you wanna make sure you know what's in the definition, and that you're comfortable with it.
On the next page, we have cash from investing activities.
And what they've done here is they've netted all the marketable securities action into a small number, so instead of showing on the face the 5 billion they bought, and then the almost 5 billion they sold, they just show a net number.
So it really highlights that the big drivers of cash outflows were purchases of PP&E and acquisitions.
And they tell you that PP&E is expanding manufacturing capacity in key growth markets, especially international like China, Turkey, and Poland.
And so we can see that they do still have growth opportunities, and a lot of those growth opportunities seem to be international.
For acquisitions they refer us to note two, you can go there and look I'm probably not going to jump ahead and look at that.
And then finally they talk about cash flows from financing activities.
So remember the big chunks here were proceeds from, I'm sorry, purchases of treasury stock, and the treasury stock they say is for stock based compensation.
Now we'll talk about this later in the course but, basically, stock based compensation is where you award your employees either stock options or stock grants.
So we're almost on 100 years of dividends, and actually again, just consistent with companies that are very mature products throwing off a lot of cash.
3M started pretty early.
And the thing about dividends is they tend to be sticky, once you start paying them, you always want to keep paying them if you ever cut them.
It would be viewed by the market as bad news.
So that's where we find all the cash flow information in the annual report.
And that's gonna wrap it up for our week on cash flow statements.
I know it was difficult, and there were some parts that didn't probably make a lot of sense right off the back.
In this video, we're gonna start our look at ratio analysis.
After all there's not a lot to computing ratios.
It's just dividing one number by another.
The real challenge is to try to understand what the ratios are telling us.
And to do so we need to reverse engineer the financial statements.
We need to think about what underlying transactions must have happened to make the finance statements and the ratios change in the way that they changed.
In this video, we'll talk about some tips for using and misusing ratios.
And we'll also talk about something called the DuPont analysis which is a common ratio analysis technique for understanding changes in one of the most common ratios people look at, return on equity.
Let's get started.
Let's start by talking about how to use ratios.
So ratios are gonna be useful in assessing profitability liquidity and risk.
You're gonna highlight sources of competitive advantage for the company so where the company is doing really well.
But to do this we have to compare the ratios to a benchmark.
There's no absolute benchmark, there's nothing like return on equity greater than 16% is great, below 16% is bad.
Instead you have to compare the company to the same company across time.
We call this a time-series analysis and it helps highlight trends for the firm, and we also have to compare the firm to other firms in the industry doing what we call a cross-sectional analysis.
This is important because sometimes firm trends could really be driven by trends in the economy or the industry.
So to figure out whether it's the company that's doing something well or it's just an industry wide phenomenon, we have to look at the firm compared to its industry or its competitors.
The key is to try to figure out what activity drive the ratio to change and then decide whether that activity is good news or bad news for the company.
And let's talk about a number of examples of this as we go through the videos.
And finally, the key is that ratio analysis does not provide answers but instead it's gonna help you ask much better questions.
She is a long-short hedge fund guru in Hong Kong.
But I have looked at a lot of financial statements in my time, and I'm pretty confident in my claim that ratios provide an excellent diagnostic tool to help you figure out what areas of the finance statements you need to look into further.
But they rarely ever provide you all the answers.
Now, let's talk about how to misuse ratios.
Not that I recommend that, I just recommend avoiding this problem.
So one of the ways that people often misuse ratios is they don't realize standard ratios actually can have multiple definitions.
Different sources will use different definitions.
You wanna always make sure you're using the same definition across time and across companies to make valid comparisons.
Also, choosing the appropriate benchmark for comparison is important.
Any major changes in a firm can distort a time-series analysis.
Differences in business strategy, capital structure or business segments can make it hard to do a cross-sectional analysis.
And then any differences in accounting methods, either across time or across companies can make the comparisons difficult as well.
So for major changes in the firm, imagine a software company goes out and acquires a hardware company so that they can integrate their software into the hardware.
The problem is that this would make it a fundamentally different company.
It would change the amount of manufacturing capacity and the amount of inventory.
All they would tell you is that the company's a different firm if you look over time.
I'll talk about differences in business strategy and example later in the video.
As far as differences in accounting method, one of the ones we talked about earlier in the course was some companies have brand names on their balance sheet.
The final thing to keep in mind is that ratios can be manipulated by managerial action.
So the companies managers think that investors and analysts are all focused on the same one ratio like let's say, an interest coverage ratio.
Then those managers have incentives to manipulate their accounting numbers to make that ratio look good.
So always keep in mind that manipulation is a possibility and more importantly don't just focus on one ratio.
But look at the whole body of ratios because it's hard, in fact impossible to manipulate every single ratio to make it look good.
So is a net income of $10 million good or bad?
>> Yeah, if you were running a lemonade stand where your only assets were a table, a pitcher, some glasses, a bunch of lemonade and maybe a cool Letterman's jacket, then 10 million in net income would be pretty sweet.
But if you were running a company with billions and billions of dollars of assets, $10 million would be pretty meager for net income.
So to assess whether $10 million of net income is good or bad we need to know how much investment was required to get that level of net income.
So to assess to whether a net income is good or bad it depends on the level of investment required to get that net income and that's what return on equity is going to tell us.
Return on equity is defined as net income divided by average shareholders' equity.
The numerator represents how much return the company generated for its shareholders during the year based on accrual accounting.
So that's the net income number that we've generated through the course.
The denominator represents the shareholders' investment in the company.
Now one of the problems we run into is net income happens over a period of time whereas stockholder's equity is at a point of time.
So we have to take an average of the beginning and ending balances of shareholder equity to approximate it's level during the period we were generating net income.
This ROE measure measures a return on investment and if something should increase with the risk of the company.
For example, I could take a dollar and put it in a savings account with a bank, and I'd get roughly one cent of interest.
If I'm gonna take that same dollar and invest it in a company, I'm taking much more risk and so I should get much higher return.
I should get an ROE much higher than 1%.
So ROE is a great starting point because you compare across all of your investments.
And hopefully the ROE is high enough to compensate you for the risk you are taking investing in the company.
To figure out whether a company is getting high or low ROE due to operating performance or due to leverage.
So the first driver for ROE is operating performance, which answers the question of how effectively do managers use the company's resources, in other words, their assets, to generate profits.
The ratio that we look at here is return on assets, or ROA.
ROA is defined as net income divided by average assets.
So it tells you is for each dollar of assets the manager has to play with, how much net income do they generate.
The second driver is financial leverage.
This answers the question, how much do the managers use debt to increase available assets for a given level of shareholder investment?
Financial leverage is defined as the average total assets divided by average stockholder's equity.
So for each dollar of stockholder's equity, how much assets does the company have?
Now the only way that this can be greater than one is if the company also borrows money, takes on liabilities.
So this is a measure of leverage in terms of it measures how much debt the company is taking on to buy more assets than it has in terms of dollars of equity.
One note is that this leverage ratio is very different from the other leverage ratios that we're gonna be talking about this week.
It's gonna work for what we're doing with ROE, but we're gonna use other ratios when we want to measure other kinds of risks due to leverage.
Moreover, she said debt-to-equity is a better leverage ratio than your Financial Leverage.
For now I wanna keep it simple so that you can see the two drivers of ROE.
And yes, there are better measures of leverage for assessing things like bankruptcy risk and long term liquidity, and we'll also get to those later.
But the financial leverage measure that we're looking at here is the right measure if we want to see how much of ROE, a return of equity, is driven by the company going out and borrowing money.
And so you see in the equation, we have ROE equals net income over assets times assets over equity.
Let me do a quick example.
So a company raises $100 from shareholders, borrows $100 from a bank to buy $200 of assets.
Those assets are then used to generate $10 of net income.
So ROE in this case would be 10%, $10 of net income divided by $100 from shareholders, ROA would be 5%, $10 of net income divided by 200 of assets, and leverage would be 2.
Multiplying it together, 5% ROA times a leverage of 2 gives you an ROE of 10%.
And this highlights how these two components drive ROE.
Now our leverage is 4.
Or, let's say that we keep leverage at 2 but we find a way to operate the business more efficiently to get the performance or the ROA up to 10%.
So, either operating performance or leverage can get you to a high ROE.
>> Really sorry to flamboozle you, but I was trying to keep it simple.
I was trying to do an example which clearly shows how these two factors, ROA and financial leverage, combine to drive ROE.
How much profit does the company earn on each dollar of sales?
The ratio we're gonna use here is Return on Sales or ROS, which is defined as Net Income divided by Sales.
So what it's telling you is for each dollar of sales how much net income do you generate.
This answers the question, how much sales does the company generate based on its available resources?
The ratio here is called asset turnover, which is defined as sales divided by average total assets.
So, for each dollar of assets, how much in sales does the company generate?
Now, I'm gonna go through an example of how to do this in a little bit, but first I have to deal with that complication that came up in the question earlier.
So, ideally return on assets would measure operating performance independent of the company's financing decisions.
We want a measure of ROA that's not at all affected by financial leverage.
The problem is the numerator of ROA, net income, includes interest expense.
If you have more leverage it means you have more debt, more debt means higher interest expense, higher interest expense means lower net income, and so now your leverage is affecting your net income.
So to remove the financing effects from ROA, we have to de-lever net income.
So we're gonna define ROA as de-levered net income divided by average assets.
So what we're doing is taking after tax interest expense and adding it back to net income.
Then when we use this de-levered net income as the numerator in ROA, we get a measure of operating performance that's not contaminated by the company's financing decisions.
And it would not hurt to explain what de-lever means.
Here's a quick example to show why we need to de-lever net income to remove the affects of financing decisions.
Let's say we have two companies, one that has no debt and one that has some debt.
Both companies have the same pretax, pre-interest income, so their performance seems identical in an operating sense.
Then the no debt company obviously has no interest expense, so their pretax income is 300, we take off taxes at 35%, and their net income is 195.
For the company that has some debt, they have interest expense.
So if they had 50 of interest expense, their pre-tax income would only be 250.
We take off taxes and their net income is only 162.5.
So if we use net income in the numerator for ROA, then ROA is gonna be affected by the fact that the some debt firm has some borrowing.
For the some debt firm we take net income plus interest expense times 1 minus the tax rate and we end up with de-levered net income of 195 which is identical to the de-levered net income of the no debt firm.
So using de-levered net income in ROA gives us a measure of ROA that only measures operating performance.
So we take the financing out of ROA but we leave the financing in for ROE.
Now I'm gonna try to tie all of this together with something called the DuPont Ratio Analysis Framework.
But yes, this formula was developed by people that worked for the DuPont Chemical Company back in the 19th century.
In 1914, DuPont bought a big stake in this startup company called General Motors which eventually became the largest car company in the world.
And when the DuPont management team started working for General Motors, they would use this formula a lot so much so that the GM people would say hey, give me the DuPont formula analysis.
And that's where the formula got the name, and we've continued to use it since then.
And what this allows us to do is identify whether a company is advantaged or disadvantaged in their ROE is driven by their profitability, by their efficiency or by their leverage.
>> Yes, now I'm gonna do an extended example of how to use the DuPont formula, which will also allow me to show you the importance of choosing firms that are using the same business strategy when you wanna do a ratio analysis comparison.
There's a couple big segments within the retail industry.
So those are the stores that have mart in their name and try to compete on low prices.
And another segment are the high-end retailers, the ones that are located in the really expensive shopping districts.
So their strategy is very low profitability.
They have a small markup over cost and their strategy is to get you into the store with their low prices.
So how do they get high ROE?
By very high asset turnover.
In other words they generate a huge amount of sales for their investment in assets.
How do they do that?
Well their assets are things like fairly simple stores that are not constructed from fancy materials.
They're located in rural districts where the land is pretty inexpensive.
And then when you go in to the store, you don't see a lot of fancy schmancy displays, the merchandise is sort of crammed in there and they're really set up to try to maximize the volume of sales for their level of investment and assets.
So if you're looking at discount type store, you'd wanna compare it to another company doing a discount strategy to see if the company is able to get a little bit extra profitability even though it's low in absolute terms.
Or if they're able to get much higher asset turnover, either one of those would give them an ROE advantage over their competitor.
Their constructed out of expensive materials, marbles, woods, they're located in very expensive real estate areas.
Their asset turnover, the amount of sales they generate for their investment in assets is fairly low.
But when they make a sale it's hugely profitable.
They have very high markup over cost, so if you were looking at a high-end retailer, you'd want to compare it to another high-end retailer to see if they're able to squeeze out even higher markups or if they're able to squeeze out a little bit asset turnover even though it's lower in absolute terms.
And as long as you're comparing companies that are doing the same strategy, find out where a company's competitive advantages or disadvantages lie in trying to execute their business model.
Now that we have the basic framework down, what we're gonna do in the next couple of videos is look at a case study of a company that had some real troubles in their business.
But then they changed their strategy had a nice turn around and now they're performing very well.
So we'll use the DuPont analysis to figure out exactly what parts of their strategy really helped to kick start their turn around.
I'll see you next time.
This video kicks off a three video sequence where we're gonna use ratio analysis to study the case of a growth company and see what we can learn about the sources of their competitive advantages and disadvantages.
In 2009, Plainview lost its largest customer, a defense contractor.
The customer transferred it's business to a foreign competitor which had lower labor costs.
They also built new plants in California and South Carolina to be closer to their customers.
In 2010, Plainview adopted new 6G technology, which provides better manufacturing results at a lower manufacturing cost.
The company's experienced explosive growth after surviving its crisis, and is now picked up a greater following by analysts and investors.
Before we take a look at the ratios, I always think it's a good idea to start with the financial statements.
Then we can keep those in the back of our mind as we go through the ratios.
So here's the asset side of the balance sheet for Plainview.
I'm gonna put up the pause sign, and recommend that you pause the video.
Take a minute or so to look over the balance sheet and see if there's anything that jumps out at you.
And then resume the video and we'll talk about what you're seeing.
My point is that the balance sheet is a good starting point to try to look at what's going on in the company.
Eric noted that there were big increases in accounts and inventory.
But you're right that if the company's growing so much as a whole, it's hard to interpret the balance sheet.
And so later on, we'll look at techniques that will take out the effects of this growth, and let us know whether line items on the balance sheet are going faster or slower than other line items.
Here is the liabilities and stockholders' equity side of the balance sheet.
So please, again, pause the video, take a look and see what you find.
But current liabilities are actually down in 2011.
That it's hard to draw too many conclusions from this part of the balance sheet without taking out the effects of growth.
But there are a few things that sort of leap out as we look through this.
So there are some things that you can occasionally learn by looking at the balance sheet as a starting point.
Here are the last three years of income for Plainview.
>> And yes, we will have to remove the effects of growth to understand this better, which we'll do later in the video.
Even though net income has been growing steadily, cash from operations is, for lack of a better term, quite squirrelly.
Now I think we are getting somewhere.
And it looks like a lot of it is driven by accounts receivable and inventory, which we saw big movements on, on the balance sheet.
Here are the investing and financing sections of the statement of cash flows along with the supplemental disclosures of cash interest paid and cash taxes paid.
>> Although at capital expenditures, proceeds from borrowing and common stock issued mirror the growth in PP&E, debt and equity on the balance sheet.
>> Yes, this part of this statements shows us the company's growing substantially through capital expenditures.
We don't see any acquisitions listed here so it's all internal cap x, which makes since because from the case we know that they built two new factories.
And they're financing this growth with both debt and equity, so we see a lot of cash flow from debt issuances, and we see some cash flow from a couple of equity issuances, so they're financing themselves with both debt and equity.
Now that we've taken a look at all the financial statements, I want to talk about something called common size financial statements.
As we've talked about, it's hard to spot trends in the financial statements when there's tremendous growth.
Basically, the growth in assets and growth in sales drive trends in all of the other line items.
What we really want to know is, are certain line items growing more or less than would be expected given the overall growth in assets or sales?
So we're gonna come up with a common size balance sheet where we'll express all numbers as a percent of total assets, which will remove the effect of the growth of assets.
We'll come up with a common size income statement, where we'll express all numbers as a percent of sales, thereby taking out the growth in sales.
The cash flow statement is typically not common sized.
And it's not clear what we would divide by to common size it.
So it's only the balance sheet and the income statement that are typically common sized.
It is inventory whose growth is out of whack compared to the rest of the company.
So again, pause, take a look and see what you see.
The biggest trend is the increase in liabilities relative to equity.
>> Yes, Eric, the big conclusion we would draw here is that the numbers seem to be squirrely on the liability and stockholders equity side.
The numbers are bouncing up and down.
The only trend that really emerges is total equity has gone down as a percent of liabilities and stockholders' equity over time.
Which means the company is relying more on debt financing and other liabilities and less on equity financing.
We're dividing numbers by sales and any time you divide one number by another number it's a ratio.
And then it's broken down into all of it's components with the definitions at the bottom of the slide.
Why don't you pause the video for a minute or two, take a look at this slide and see what kind of conclusions you draw.
For return on equity we see a large and increasing trend in ROE over the three year period.
It started at 11%, which meant that for every dollar of equity the company generated $0.11 of net income.
And now it's 16% so for every dollar of equity the company generates $0.16 of net income.
So each of dollar of equity is generating an extra nickel of net income which is a pretty big increase over a three year period.
Now let's look at the two drivers of ROE, return on assets and financial leverage to see if Plainview's increase in ROE is due to better operating performance or to taking on more debt.
So for return on assets we see that increase from 7% to almost 10% which means that every dollar in assets is now generating about $0.10 of net income for Plainview compared to only $0.07 a couple years ago.
If we look at financial leverage, it's been fairly flat over this period, around 2.3.
So it seems like the increase in ROE is primarily driven by the improvement in return on assets.
We see another increasing trend in return on sales which means that Plainview sales have become more profitable over this period.
ROS has gone from 5% to almost 7% so each dollar sales now generates almost $0.07 of net income instead of $0.05.
Well if you multiply it times 100 million in sales, it adds up pretty quickly.
Now if we look at asset turnover, it briefly went up but then came back down to around 1.45, which means that for every dollar of assets Plainview generates about $1.45 in sales.
But there's no clear upward trend in asset turnover, so it looks like the sole secret to Plainview success with their ROE is that there sales have become more profitable over this period.
So if you remember from last video, the return in return on equity is net income, but the return in return on assets is delivered net income.
To get it to multiply together cleanly you'd have to add a third factor, or a correction factor, which would be net income divided by after-tax net income.
If you multiply that third factor times ROA and financial leverage, then you will get ROE.
Maybe every company in the industry had better profitability as a result of the new technology.
>> Excellent point Elizabeth, what we talked about in an earlier video is that we need to do cross sectional comparisons.
So what I'll do next is compare Plainview to three of their closest competitors.
If you look at the industry, it looks like Plainview is having much more success than their other three competitors.
They're the only company that had an increase in ROE over this time period.
So to wrap up what we learned from the DuPont analysis is that the big increases in ROE for Plainview were unique for the industry.
Plainview's improved ROA was the source of it's increase in ROE.
Instead, the ultimate source of the ROE increase was improvement in profit margin or return on sales.
In contrast to the competitors, Plainviews' return on sales grew dramatically over this period, whereas his asset turnover was flat much like the competitor's.
So the secret to Plainview's success is that their sales became much more profitable between 2009 and 2011.
Can ratio analysis tell us that?
>> Well, I do have a few more ratios up my sleeve, and we can take a look at those in the next video.
And I'll see you next video, when we continue the ratio analysis for Plainview Technology.
In this video, we're gonna continue our ratio analysis of Plainview Technology.
We've got a lot of ratios to get through, so let's get started.
Let's start by bringing back up the DuPont ratio analysis slide.
I've added a couple boxes to what we had last time.
We're gonna start by looking at the Profit Margin Ratios to try to figure out what are the drivers of Plainview's profitability.
We're gonna look at Gross Margin, which is Sales minus Cost of Goods Sold, divided by Sales.
We'll look at selling general and administrative expenses to sales, so SG&A expense to sales, to get a sense for how much operating expenses are as a percent of sales.
But these are the ratios from the Common Size we looked at before.
We need to look at them again, because to understand drivers of return on sales.
We need to divide the various items on the income statement by sales as well.
I have repeated all of the definitions at the bottom.
>> Maybe the shifts to customize products and to customers in new industries allow Plainview to charge a higher price.
>> And it would certainly help that one large customer does not have monopsony power over Plainview.
Ironically, Plainview is probably afraid to charge the Defense Contractor a high price for fear of losing the business.
It is the shift to automation and the new technology that allowed Plainview to reduce its manufacturing costs, leading to a larger gross profit.
It could be that Plainview's able to charge a higher price for roughly the same cost, and maybe that's by moving into new industries or providing the customized products, or by getting rid of the monopsony relationship.
So maybe it's the automation that's doing that, or it's the new technologies.
We're gonna have to look at a lot more ratios to try to get more evidence on which of these theories is correct.
Let's look at the rest of the ratios.
The ratio of selling general administrative expenses to sales is completely flat over the period.
So as Plainview has grown substantially, it's managed to keep its SG&A expenses in line and not have them grow faster than sales as a whole.
Then if we look at Interest Expense and Effective Tax Rate, there's not much going on.
Interest Expense is pretty flat, and other than a blip a couple years ago, Effective Tax Rate hasn't changed that much either.
If there were economies of scale we might expect the SG&A ratio to go down.
Usually when we look at a ratio and see that not much has changed, we assume that not much has changed.
But it could be the fact that Plainview should have gotten some economies of scale.
So our Profit Margin Analysis tells us that gross margin was the big driver of Plainview's success.
Now we have to think about what are some possible explanations for this improvement in gross margin?
Was Plainview able to reduce production costs while maintaining sales price?
So we have the question, did the entry into new markets, the customized products, allow a higher markup?
Or maybe it's a combination of both.
So, at this point we're gonna have search for confirming or a disconfirming evidence of these explanations elsewhere in the financial statements and the ratios.
And of course, if we were the analyst on the call, we could actually ask management very specific questions about what the source of their improvement in gross margin was.
Can't the ratios tell us more?
I still don't know the answer to how they made their sales more profitable.
Remember, ratios allow us to ask better questions, not necessarily give us the answers.
One place to look for further information on how Plainview's doing, is to do a detailed Asset Turnover Analysis.
Although Plainview's Asset Turnover ratio was steady over the period, looking at the detailed components of the ratio may give us more insight into what happened with Plainview's turn-around.
For example, when there's dramatic increases in sales, like Plainview had, you often see lower inventory levels.
And higher Accounts Receivable levels because the company has to extend credit to riskier customers to fuel its sales growth.
And if you remember on the statements we saw all this weird stuff going on with Accounts Receivable and inventory over the period.
For example, Inventory Turnover of 8 would meant that it builds and sells Inventory 8 times during the year on average.
Purchases, we're trying to get out the purchase of new raw materials, so we calculate that as the difference between ending and beginning inventory, plus COGS.
And then Fixed Asset Turnover is Sales divided by Average Property, Plant and Equipment.
I'm gonna put up the pause sign so you can take a look and see what these ratios are telling you.
Could we think about it that way?
>> Yeah, I've never found these turnover ratios that intuitive either, so I'm gonna recast them in a way that is more intuitive to me, and hopefully will be more intuitive to you a s well.
These ratios will help answer the question, how many days on average are given accounts outstanding?
For example, if you saw a Days Inventory of 45, it means that it takes 45 days on average from the time we start building the Inventory until we sell it.
So the Days Receivable Outstanding Ratio, or Days Sales Outstanding Ratio, which is often called DSO, so if you've heard the term DSO, it's referring to this ratio.
And in fact, that's how the Days Inventory and Days Payable Ratios work as well.
But, by putting these ratios in days, we can come up with a new ratio called the Net Trade Cycle.
The Net Trade Cycle represents the gap between cash outflows, which are the Days Payable, and cash inflows, which come from the Days Receivable that we need to bridge with short-term financing.
So why don't you pause the video, and take a look at them.
So Days Receivable for Plainview has gone down from 60 to 44 over this period.
Now the 44 means that from the time Plainview makes the sale, it's 44 days until they collect the cash.
But instead, we wanna figure out what activity drove the change in the ratio, and is that activity good news or bad news.
For example, this could be good news if Plainview put in new collection efforts, and as a result they get paid more quickly.
And as a result, having been giving up a lot of sales growth and profitability.
>> Clearly, it is the loss of the Defense Contractor that allowed Plainview to collect more quickly.
After the financial crisis ended, customers had better financial health and were better able to pay on time.
Elizabeth suggested it was losing the Defense Contractor that allowed us to collect more quickly.
And certainly, if one big customer has power over us and refuses to pay more quickly, it's gonna hurt our Days Receivable.
Once that customer leaves and we can choose other customers, we can choose customers that pay more quickly.
Dave suggested it's the economy as a whole.
And as we can see, that's not the case.
So, the most likely theory is that it's the fact that we got rid of the Defense Contractor, and moved into the new industries with new customers that's now allowing us to collect 16 days more quickly.
Next, let's look at Days Inventory.
Days Inventory has increased from 81 days to 105 days.
Which means from the first point that Plainview gets raw materials, it's a 105 days before the finished inventory leaves the warehouse to go to the customers.
Well, I guess it depends on what it reflects.
But that's probably not the case for Plainview, given their growth in sales.
It could be good news if they're ramping up their inventory production in advance of future sales.
It takes longer to produce inventory when it is made in customized, small batches.
Plainview can charge more for a product because it is customized and takes longer to produce.
>> But, it is peculiar that Plainview holds inventory longer when its sales are growing so much.
But as long as you're getting paid for that, you should see the Gross Margin increase, which is what we see with Plainview.
Elizabeth raises an excellent point, that it's strange to see Days Inventory go up, when sales growth is also going up quite a bit.
So maybe Plainview sales are not at a level that can support the two new factories to run around the clock, but we wanna run them at capacity.
So, maybe Plainview's over-producing a little bit of inventory now in anticipation of future sales.
Now let's look at the Days Payable ratio.
What could explain that?
Hey, this is fun.
So maybe it is a simple matter that if you collect cash more quickly, you can pay your suppliers more quickly.
And if you take advantage of discounts, your raw materials cost less, which means your cost of it sold is lower and your gross margin is higher.
The Net Trade Cycle is basically a measure of the number of days that you have to borrow from a bank to meet a short-term cash shortfall.
So that's basically the number of days from when you first get raw materials, to when you make the sale and then collect the cash.
So in Plainview's case, it's 105 days inventory, 44 days receivable, 149 days from when you get the raw materials to when you collect cash.
Then we subtract the Days Payable, which is the number of days that you have until you have to pay cash to your supplier.
So, 149 minus 33 creates a gap of 116 days.
That 116 days is the number of days Plainview has to go to a bank to borrow money.
And note that Plainview is borrowing 30 days more now, than they were a few years ago.
Why would Plainview pay it's suppliers more quickly when it would have to turn around and borrow more money from the bank?
>> Yeah, the only way this would make sense for Plainview, is if the discounts that they get by paying their suppliers earlier are greater than the extra interest that they pay from borrowing from the bank longer.
And that's probably the case for Plainview.
We saw earlier that their interest expense as a percent of sales has been fairly flat over time.
So, all in all this seems to be a good thing for Plainview, where by taking advantage of the discounts, they're able to reduce their costs and increase their gross margin.
It seems that for Plainview, the entry into new markets has produced higher-margin sales with faster collections.
How are they able to do this with 40% in higher sales growth?
And why is their cash flow from operations so volatile?
So at this point, we have a pretty good idea of what's going on with Plainview, but it's only a pretty good idea.
We don't know specifics, but we're at a point now where the ratio analysis will allow us to ask much better, much more specific questions to try to get to the bottom of what's going on with the company.
No, I'm not gonna tell you what happened, because if this was real life, you would do the ratio analysis without knowing what was gonna happen in the company's future.
It's about using a systematic approach to looking at ratios to try to figure out what may be working or not working for the company.
But, also to generate a good set of questions that you would then follow-up and do more research, or try to contact the company to find out the answers.
So I'm gonna leave you hanging and not tell you what ended up happening to Plainview.
So we just have one more video to do on Plainview Technology.
I'll see you then.
And then we'll apply those ratios to the plain view technology case.
First we have a number of ratios that are gonna tell us whether we have enough assets that are gonna turn into cash to cover our liabilities in the next period.
And, the third bucket is gonna be the long-term liquidity ratios.
Is there a potential risk of bankruptcy down the road that may cause equity investors to lose their investment?
Those are all the questions that this set of ratios will get at.
So go into that first bucket of short-term liquidity ratios, we're trying to answer the question, does the company have enough cash coming in to cover its obligations to pay out cash in the near term?
Ideally, all the ratios that we look at would be over 1, which means there's more cash coming in than cash we have to pay out.
But again you'd have to benchmark this with the industry, the firm across time cuz for some industries these are not greater than 1.
And basically what this is trying to get at is if current assets are going to turn into cash in the next year, current liabilities have to be paid in cash in the next year.
Do we have enough assets turning to cash to cover the liabilities that we have to meet in cash?
One drawback to this ratio is, as we know, not all current assets turn into cash.
One more ratio is cash flow from operations to current liabilities, so we divide the cash operations by average current liabilities.
It's saying, over the past year did you have enough cash generated from operations to cover your average level of current liabilities?
So here's what the ratios look like for Plainview.
Starting with the current ratio, it looks very healthy.
It's trended upwards from 2.4 to 3.6.
The 3.6 means that Plainview has three and a half times as much current assets as it does current liabilities.
Now as we talked about, a problem with this measure is that inventory and prepaids are not necessarily gonna turn into cash.
So we have the quick ratio, which is cash + accounts receivable over current liabilities.
That also looks good.
When we look at the cash flow to current liabilities ratio, it's not quite as strong.
We see the volatility in cash flow that we've seen earlier in r ratio analysis.
They seem to have enough cash that's gonna come in to cover the payments they need to make out.
Here the question is, does the company have enough cash coming in from operations to cover its interest obligations?
The first ratio is the interest coverage ratio, which is operating income before depreciation / interest expense.
So, this is a picture of interest coverage from an accrual accounting perspective.
And then we ignore depreciation since that's not ever gonna be a cash flow, is that operating income enough to cover what we have in interest expense?
So cash interest coverage is cash from operations + cash interest paid + cash taxes.
What we're doing there is those are subtracted from cash from operations, but we wanna add them back to get pure cash from operating the business.
So the question is, is that cash from operating the business enough to cover the cash interest paid?
I will put up the pause sign, and you can take a look.
Okay, I guess I have been going on too long about ratio analysis, and I do realize you've got an exam to do.
So just give me a few more minutes, and I'll wrap this up.
Okay, so let me go through the interest coverage ratios.
The interest coverage ratio looks really strong.
There's an upward trend, and now it's 6.9, which means that Plainview's operating income before depreciation is almost seven times as much as its interest expense.
When we look at the cash interest coverage, it also looks strong, except for that one year where there was the negative cash from operations.
But the current ratio's 3.8, which means that Plainview's operations is generating 3.8 times as much cash as they need to cover their cash interest cost.
So, it looks like, in general, Plainview's in a good position in terms of generating cash to cover its interest obligations.
These ratios are gonna tell us something about how the company's financing its growth, as well as provide a measure of bankruptcy risk.
The idea is the higher the company's leverage, the bigger the risk that it may have to default on its debt payments.
First ratio is debt to equity, which is just total liability over shareholders' equity.
So for each dollar of investment by shareholders, how many dollars of liabilities has the company taken on?
The next ratio specifically looks at long-term borrowing.
So it's long-term-debt to equity, total long-term debt / total shareholders' equity.
And this is getting at how the company is financing its long-term growth.
So essentially we're trying to get a measure of things like property plant equipment, accounts receivable inventory.
In other words, you can borrow the money with those assets as collateral, whereas intangible assets are harder to collateralize.
So it's the borrowing capacity that the company has based on its collateralizable assets, if collateralizable is a word.
Let me go ahead and put up the pause sign, and you can take a look.
Let's take a look at these long term debt ratios for Plainview.
In this case, lower ratios are generally better than higher ratios because they would indicate less risk, more borrowing capacity to fund growth.
But it's still only 1.05, which means that for every dollar of equity investment, Plainview has about a dollar in liabilities, which is a fairly low leverage ratio.
If we look specifically at long-term-debt to equity, we see that this went up for little bit, probably as they were expanding and building the new factories, and then has come back down and is less than 1.
Similarly for long-term debt to tangible assets, the ratio went up a little bit, came back down.
These are still pretty low ratios indicating that Plainview has a lot of debt capacity that they could use to borrow more money to fund further growth.
So the conclusion for Plainview from the liquidity ratios is that they're in a strong short-term cash position.
They've managed their long-term leverage well through their expansion and growth.
There's been some small increases in debt to equity and long-term debt to tangible asset ratios, but they're still not that big.
We have looked at all of the major ratios that people tend to use.
I'll see you next time.
So, here we are at 3M's financial statements.
So, there's a couple of ways we could do the ratios.
A second way we could do it is try to look the ratios up on the internet.
Before we jump on the Internet to pull some ratios, a quick warning.
There's a lot of bad stuff on the Internet.
Hopefully you aren't thinking that this course is one of those bad things, but the problem with ratios provided on the Internet is, oftentimes the provider does not give you the definitions.
You don't know how they're calculating the ratios.
So one of the best sources on the web that I found to get ratios is Morningstar, because they give you a long time series of ratios that you can use.
So if we look at 3M Company's page there's some summary financial information and then key ratios.
You notice it's sort of been going down the last few years slightly.
It's the profitability.
And you can see the profitability up and then sort of down again.
Which is tracking what we saw with ROA.
But what we really need is to find three or four of 3M's closest competitors, and then compare these ratios to the competitors, to see whether these trends are specific to 3M or whether there's some kind of industry of fact that's going on.
But, based on my knowledge of the industry, these are still pretty healthy ROE and ROA numbers.
And then above, we have the profit margin breakdown, so we have gross margin, which is really high, almost 50%, SGNA to sales, which has been fairly flat, and operating margin.
Then there's the tab for some growth percentages.
3M is in really good shape, current ratio above two, quick ratio above 1.3, 1.4.
Financial leverage, which we saw earlier, and then a more traditional debt to equity ratio.
Looks like 3M is not a very risky company, not very highly levered.
So we can see there's a slight downward trend in 3M's days sales outstanding.
Their inventory turnover's been sorta steady between 75, 85 days and their payables ratio's similar.
What they call cash conversion cycle is what I was calling the net trade cycle.
So it's basically the number of days you'd have to borrow from a bank.
And then one more thing to show you is Morningstar has an extensive glossary, so if you don't know what any of these terms are, like one ratio we didn't talk about is Return on Invested Capital, that's net income divided by stockholders' equity plus long-term debt and capital leases, short-term debt, capital leases.
So basically, it's like ROE except it also adds debt into the denominator.
So, you could just pull the ratios from a source like this, pull them from three or four competitors and then do the comparisons, you don't have to use your own calculator or spreadsheet to calculate all these ratios.
Now it's time for you to focus on the exam.
So this segment is the Marketing 101, the basics of principle of marketing.
Which is what is marketing?
So what's a market?
A market is an exchange between two partners.
Frequently a buyer and a seller, but marketing also applies to non-profit or things where there isn't necessarily money being transacted.
But what you need for marketing to exist or for a market to exist is to have an exchange, and what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's look at the basic exchange.
You have one buyer and one seller, and I'm going to give a very simplified view to make a point.
No markets are ever quite this simple, and I'm going to look at the two extremes just to make my point here.
And the real markets are somewhere in the middle but you'll see, when I start defining this that it's very useful to use this kind of simplification.
And in the seller's market what that means is the seller has the product and if you want that product you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think of that.
It is marketing should not be the same in the sellers market as in the buyers market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability, you should innovate in that product, you should try to reduce costs, and you should really focus on the product.
And profitability from a product-focused market is going to come from volume, selling as much as you can.
In the past, when we studied product-focused markets, we've shown that profitability is tied to market share.
So market share becomes your business objective, and why does market share increase profitability?
Because the bigger your market share, the more your revenues, and the bigger your market share and your volume, the lower the product cost, enhanced profitability.
Higher revenues, lower cost, more profit.
Will you develop new products based on your product experience or you go to new markets?
That's product-focused market.
So what's customer focus marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer-focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
What's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So whereas in a product-focused market, I'm the expert and I create the very best product I can based on my expertise.
In the customer based market, what I'm going to do is look at what the customer wants and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside out is product focus, and outside in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer, but think about it.
What does the customer want?
Well, the first question is well which customer?
So the reason why a buyer's market or customer-focused marketing is so different than product focused is that every customer out there wants something different.
If we try to give everybody what they want, we'll go out of business that's too hard to do.
So, the intuition of customer-focused marketing is to pick and choose customers.
Deliver value to some customers.
That's the process of segmentation.
And the call that, I'm going to talk about that in the next section.
But the idea here is that I go after some customers, and I say no to other customers.
Well then how do I become profitable in that?
Understand that in a product-focused marketing what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In a customer-focused market, we're saying no to some customers, and yes to others.
So how do we make that profitable?
And the answer is you pick and choose the customers you want to deliver.
And where the profitability comes from is not from volume, but it's from creating value.
Well the first thing is, if I give you exactly what you want.
Many times you'd be willing to pay a premium price.
Then the profitability comes in, not from reduced cost which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want I'll be willing to pay a higher price for it.
So that's one way.
I don't think about just one transaction, I think about building customer loyalty and delivering value to that customer over time.
That concept is called customer share.
The idea of customer share or share of wallet is that they go after a more narrow market and try to get more from each of those customers' wallets.
And it turns out that loyalty, if you do it right, can be very profitable, and why is loyalty more profitable?
When I'm doing a customer based marketing, it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants, and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but it's cheaper to retain those customers over time, and that's where the profitability come from.
It comes from loyalty.
The other thing if you're thinking about building share of wallet in a customer-focused market is that I not only sell one product to you, I think that other things that you might need and I try to cross sell around it.
Let me give you an example of this notion of cross selling.
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer-focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time, and that's more profitability.
And if you understand their needs, you cannot only sell them one product, but you can cross sell other products that may also meet their needs.
So in a customer based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between seller's market says you focus on the product, on what the customer does well and you push that out.
And in a customer based market, you focus on the customer, what the customer wants and you deliver value to the customer better than the competition.
So that's the basic difference between product phase marketing and customer-focused market.
Now, in today's world, the marketplace has changed even more.
What's changed?
Well now, not only do you have an exchange between buyers and sellers, but because of globalization, and because of the Internet, technology, and social media and things like that, it's not a one to one conversation anymore.
Customer's can talk to other customers.
That's good and bad.
The fact that they'll buzz to their other customers and tell their other friends about what a terrific service your company's doing.
Well, that's really good news.
On the other hand, if something goes wrong and they tell their friend something bad, well that's not such good news.
And so you have to be really careful in every transaction with the customer now that you deliver not only value, but that you deliver a top notch customer experience.
In the sellers market I talked about a single transaction, and in a buyers market I talked about transactions over time, or customer loyalty.
But in the connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
Let me give you an example.
It starts way before the transaction and it goes way after the transaction.
So for example, if a customer told another customer about their experience at a restaurant.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer, then you as a marketer need to focus on the entire customer experience.
So one of the things, and we'll talk about this later, that's changed in marketing in this world of social media, and Internet, and globalization is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
And in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
People became a skeptical of marketing.
And so with all those changes in economic environment there's been a focus again in marketing.
And marketing now has the focus on authentic genuine customer value.
But now, because of the tightness of the economy and the uncertainty there, you really have to cut costs, and figure out a way to deliver value in a very discipline manner, and be very flexible to changes in the market place.
So let me just summarize what I've just said the different types of marketing orientations.
There's the product orientation where you focus on the product, and you persuade the customer to want what the firm has.
That's a customer-focused approach.
The experience orientation says that you not only think about the transaction and think about the transactions over time, but you try to manage the customer's entire experience with the firm.
And when times get tough, or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of markets in terms of what you offer?
In a production orientation, you're focusing on product innovation but also reducing costs, so you tend to see generic products and standardization.
And we'll talk about that when we talk about brands also.
In an experience orientation, you look at experiential value, and when you're going to that tight disciplined mind frame, or mindset, you look at genuine value.
And what's the sustainable competitive advantage in each of these markets?
In a product orientation, the bigger companies win because they tend to have larger market share and lower cost.
In a marketing orientation, when you're focusing on the customers, the companies that do the best are companies that really know their customers, that can deliver quality, and that have a lot of customer data, and know how to use that data to deliver better value.
And in experiential market, you look at transformation.
The customer becomes a co-creator of the value and it's really making the customer and the product one kind of overall experience.
And that means you've had a long history with them, they're transparent and you trust them overtime, and what are the measurements of profitability?
In production orientation as I mentioned market share is tied to profitability.
In marketing orientation, it share of wallet or customer share, customer loyalty.
In experience market, when your looking at customers talking to other customers.
And in the trust orientation, we really focus on reduced costs.
Let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
What the seller puts into the exchange, is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
Could be advertising, sales, whatever.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
It can be online.
It can be through, downloading.
So those are the four P's of marketing, product, place, promotion and price.
Typically when you talk about marketing, you talk about the business world.
But you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
Blood is actually the price.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And its based off of their framework, although I've adapted it some.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
Whether or not it meets my needs, so is it customized to meet my needs?
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
So, that's a very strong assumption.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
So, those are the assumptions.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Think about what's going to happen in that marketplace, in a very competitive market.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
You have to do the same thing, or what are the product attributes that matter to the customer?
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
And some people more.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
I'm really excited to be starting my module of our introduction to marketing course.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Are we going to focus on all customers the same way?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
Running a business in a performance superior or operationally excellent kind of way and that's going to give us the basic foundation so we can really understand how customer centricity is different.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
Okay you have a certain degree of expertise that has enabled you to bring us the current product.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
How can we take that product expertise, and either extend it to new customers or extend it to new products?
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're going to try to do it as, as efficiently or effectively as possible.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
I'm going to stay in the water.
And this is exactly the kind of issue that many companies are facing today.
It gives them some opportunities for growth.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
And if you look up and down the slide, you won't find a lot that's tremendously insightful, and that's the point I want to make.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
How can we spread it out to other kinds of customers, and other kinds of businesses?
Again, implicity, that's the way that most businesses operate.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
In fact, I'd like you to just take a, a minute or two think about what are some of the changes, today, compared to 15 or 20 years ago, that make product centricity just a little bit different?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
We're doing something that's going to keep us ahead of all of our competitors for a long period of time.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
They would take whatever products or services that we would give them, and they would say, oh, that's great, terrific, thanks very much, I'll figure out how to use it.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
But that they, they clamor for than they ever were before.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
And even if customers were aware of it, customers wouldn't have access to it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
But by no means is it limited to technology.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
They no longer manufacture personal computers.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
He didn't know.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
To be understanding who's buying what.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
So I want to talk about a couple of examples about companies that have used information technology and specifically the data about their customers.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
They turn to a deep understanding about their customers to draw insight and to let them change their business models in a way that actually let them rise to the top of their industries.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
What kinds of messages and offers to provide, at the right time, and through the right channel, in order to create and extract more value from that customer.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
And so when they sit back down again, their threshold is back towards zero.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
And this helped them not only grow the business with those customers, but also helped them to compete more effectively.
So Tesco knew, again, which coupons to send to which households, at which time, in order to really hold on to those customers and bolster their business.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
So while the Harris and Tesco stories are terrific, I will provide pointers to some books that summarize each of those stories quite well.
I want to emphasize that they're not the only ones who have built a business around a deep understanding of their customers, and by no means are they the first.
In fact, the first companies that actually built a business in this manner, around their customers, has happened many, many years ago.
And it emerges from the sector of direct marketing.
They think about infomercials and other, you know, not great marketing activities.
it, it's, it's not the kind of industry that you aspire to be associated with or learn from.
If you, if you look at, at what direct marketing is really all about, it is really building the business around the customer.
But not just, the customer in some generic sense, but around each and every customer.
It's about understanding the relationship with each different customer.
That's what direct marketing is all about.
What's interesting about it is, that direct marketing is not a new concept.
There's actually a lot we can do, we can actually formalize some of these business practices, and come up with some best practices associated with them.
But even if you don't spend a lot of time thinking about direct marketing, a lot of the words and the concepts have already filtered their way into today's everyday marketing conversation.
So, a lot of the segmentation concepts that Barbara discussed are often associated with direct marketing.
Something that you've heard about before, that we're going to spend more time talking about, that's, that, that comes directly from the direct marketers.
We can collect all this data about our customers, about each and every one of them, and we can actually build a business by understanding who the valuable customers are, who the less valuable ones are.
Which messages we should be sending to which customers at which time, and, importantly, what kinds of products we can develop and deliver in order to create more value for our most valuable customers and to try to attract more customers like them.
So the Harris and Tesco stories are wonderful, but they're not unique.
And so I want to spend a lot of time celebrating some direct marketing practices.
And I want to emphasize that a lot of firms out there today might not aspire to be direct marketers, but they don't realize it, but they are.
Has the capability to learn from direct marketing, and I encourage all of you to read books on direct marketing.
Even if you don't think about yourself that way, there's just so many concepts that you can learn and leverage, especially as we enter this world of big data.
Now that we understand what product centricity is all about and we've discussed some of the cracks in product centricity.
And even some of the opportunities from companies to escape from and maybe do better than a product-centric approach, I want to start moving away towards customer centricity.
So in order to do that, I want to work with a series of examples here.
In fact, on this slide, you'll see the names of four very famous retailers.
Three of them operate on a global level, so Walmart, Apple, Starbucks.
What I'd like you to do is take a moment, and from your experience with, your perceptions of these firms, decide which of them would be highly customer centric.
So think about what customer centricity means, and which of these firms qualify in that regard.
Now, I want to be careful about this.
I really like what they do.
Fail to be truly customer centric, nearly as much as perhaps some of you thought when in deciding which of them, which of these firms are or aren't customer centric.
So I'm just going to take a few moments to talk through each one of them, and then, finally we'll bring up our definitions of customer centricity.
Now again, Walmart is a terrific firm, but Walmart knows, surprisingly little about any one of it's customers.
Unlike Harris, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
Walmart has made very little effort to date to try to figure out exactly what each customer's doing.
So while Walmart might not make a lot of efforts to understand what any one customer's going to buy, they make great efforts to understand the customers as a whole.
They understand regional differences.
For instance, when a hurricane is about to hit the south eastern US, they need to fill the stores with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way as a direct marketer would suggest.
If you think about the Walmart business model, it’s about selling in great volumes, it’s about bringing the costs way down.
So, in many ways, Walmart is a prototypical, and a wonderfully successful, product-centric firm.
And let's figure out ways to extend our product goodness, and, and all the aspects that I mentioned for product-centricity apply to Walmart.
There are a very few firms in the world that can operate in an operationally excellent manner as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time doing market research, to figure out exactly what the customer wants.
They don't spend a whole lot of time focusing on segmentation and real granular analysis to try to predict what any one customer is going to do over time.
What Apple focuses on, is leveraging its product expertise.
Operational excellent for Walmart, performance superiority for Apple.
They are doing some smart things at the margin to understand their customers better.
They have a new program they call Scan & Go, a mobile app that lets people scan products as they move around the store so as they check out, the whole scanning process happens much faster.
It's a brilliant idea that lets them be more operationally excellent, but also lets lets them start tagging individual customers and tracking them over time.
So they're starting to take on some more customer centric initiatives without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business that are letting them understand their customers a little bit better.
Slowly but surely, they're starting to develop a better understanding of their customers at a more granular level.
One day, if and when competition catches up and Apple can no longer be the product leader that they are, they could probably turn around and start to be a great customer-centric firm as well.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
At a local level, Starbucks or any coffee retailer, is very, very customer centric.
The Barista, the person on the the other side of the counter, the person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store but just through the casual conversations you have with them, they might know what movies you like, what kind of clothing you’d like to buy, something about your job, your family and they often make recommendations to you.
That are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted advisor to the really good customers, finding ways to lock that customer in and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they are not that customer centric at a national level.
You take your Starbucks loyality card, and you bring it a Starbucks in another city or another country and show it to them and say, I'd like the usual please, they have no idea who you are.
So not only can they not meet your immediate needs, but it's hard for them to be a trusted advisor and to make other recommendations to you when they have no idea about anything about your history.
It's not enough for a company to be customer centric some of the time when they know who you are.
But a truly customer centric company will identify you and will be able to value you and make recommendations no matter what kinds of interactions you have with them.
And they're coming up with all kinds of interesting technologies that are going to let them collect and integrate your data across stores and across other touch points you have with them.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
So again, it's that balance between focusing on the product and focus, focusing on the customer that so many companies are now struggling with.
And finally, there's Nordstrom's.
And while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
But whether you've shopped at a Nordstrom store or not, you might be familiar with the story that makes Nordstrom so supposedly customer-centric or not.
And here's the way it goes.
Nordstrom's a high end department store.
They sell clothing, shoes, and so on.
One thing they don't sell is tires.
Supposedly in Fairbanks Alaska, and wanted to return a set of tires that obviously they could not have bought at Nordstrom's.
Perhaps there was a tire store at that location before Nordstrom's opened shop.
And Nordstrom's being so incredibly customer centric, gave them the money back for tires that they didn't buy at Nordstrom's.
If you think about it for a minute, is that really customer-centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
If that customer is incredibly valuable to you, and I'm talking about future value, I'm talking about the fact that we expect this customer to be buying so much from us in the future that if we don't give them money back for the tires that they thought they bought from us, if we don't give them the money back today, we're going to lose that value.
We'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer.
And for most customers it wouldn't be.
We might still be nice to you, of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom's.
Nordstrom's offers such wonderful service.
Regardless of the value of that customer.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
I like knowing that when I go in there I'm going to be treated really well.
So to me the Nordstrom's example is a great example of, of where a product and customer centricity collide.
And what I want to do now is, is to start focusing more on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
How do we determine whether a business really is or isn't customer centric?
In other words, what is the definition of customer centricity?
So in fact, I'd like you to take a minute and just jot down whether it's a full sentence, or even just a few words that you would associate with customer centricity.
Take a minute and do that, and then I'll, then I'll give you my perspective, my definition on what customer centricity is.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
For instance, going back to the IBM example, there was a case where a company was willing to recommend other products and services.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
Let's come up with something for them, something that's going to make them even more locked in, something that's going to create greater long-run value for them, and something that's going to help us recruit even more customers like them.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
It's, it's the way, just changes the conversation, and perhaps the design, within the organization.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Maybe they didn't, by the end of the month.
That we think in the long run we've, we will create much more value that wouldn't have been there.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
And again, I can point to examples of companies, I'm, I'm thinking of a particular pharmaceutical company that changed its sales person incentive program to be forward-looking instead of backward-looking, and wonderful things happened.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
Is it the insurance company?
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
Agreeing, that one of these entities is the customer, we care a lot about the others, we need to keep them in mind, as we go through our planning practices.
So it's important to first sit down and figure out, who the, the customer could be.
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
And before saying, we're going to become customer centric, it's very important to come up with that list, and think real carefully about, existing barriers and new ones, that can be arising, to, to do a real careful inventory, of, of, of barriers towards customer centricity.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
So, there's a, a number of, of, of different ways that we can start thinking in advance, about overcoming the barriers, before the, the barriers actually start impeding our progress.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be an organizational initiative like, My Black Is Beautiful for Proctor and Gamble.
It might be other kinds of experiments that, that a company is going to run.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
So we're going to talk specifically about how to acquire some of those customers that Pete was talking about.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So let's first start out with what are perceptions?
Perceptions is probably the one of the most important aspects in consumer behavior and understanding consumer behavior.
What is the perception?
The perception is the process of developing and interpretation of a stimulus, or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever customers perceive is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
The process of perception comes in several different stages.
The first two stages are the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
And we noted that process is very biased.
But when you're consciously exposing yourself to things, many times, it's a function of what you believe, what your prior beliefs.
So let me give you an example.
Say, you think that a part of town is not safe.
As a result, you never have ability to change your perception of that area of town because you don't collect new data.
So we know that exposure can be selected.
Similarly, even if you are exposed to something, if you don't pay attention to it, again, it can affect your perceptions.
And we know that there's two kind of attention, there's voluntary attention and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure and selective attention.
That means you're not collecting data on things that might be able to change your perception.
So that's the first stage of bias.
The second stage of bias is, once you are exposed to something and pay attention to it, well then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who interpret what happened in the debate from both parties because we know a prior, the interpretations are going to vary based on their prior beliefs.
And that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli, but you interpret it subject to your prior expectations.
As a result of this, perceptions are frequently biased.
So what's the overview of the perceptual process?
Brand communication, there's advertising, there's packaging.
And then, you are exposed to them or you're not.
And sometimes the exposure as I mentioned is in a biased way.
And then, even if you are exposed to the inputs, you know when you are exposed to thousands of marketing measures marketing cues every single day.
But how many of them do you pay attention to?
So first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it and finally there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that your perceptions, and I just explained to you your perceptions could be biased.
You have a certain perception, and then you automatically respond to that.
And it's very hard to control that.
Even if you think, well, I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word and reading the word affected your subsequent behavior.
That's actually the purpose of the Stroop Test.
It makes people feel a little uncomfortable, because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches, and you can see, it's much easier and much faster to say the words.
This is the same thing in the way marketing, I'm going to show you that color has an effect, brand name has an effect.
It affects you subsequent perception and your subsequent behavour and it's an automatic reaction that is difficult to stop.
So here 's an example, if I told you this is luscious chocolate and I show you a picture of it in the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh, I don't want to eat this, that disgust feeling.
And you know that it's good chocolate but the shape has an involuntary effect on you.
And that's a very important thing to understand, so marketers need to understand how these things affect your perceptions and your subsequent behaviors, because as I say, these are automatic reactions.
You may have seen these before.
I can show you these two lines on the screen.
I will tell you, you can measure them, they are exactly the same length.
However, one looks longer than the other and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you what is this that I've put on the screen?
You'll answer differently if I show it to you this way, versus when I show it to you this way.
And so, that shows you what you perceive that stimulus is, is a function of your prior expectations.
There's a perception bias that's called the proximity bias.
And what the proximity bias says is that things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that the cluster, the two lines that are close to each other rather than say the two bold lines or the two thin lines.
And you can see this in the supermarket, in stores.
Say, in a salad section in where there's vegetable marketers may put, or grocers may put salad dressing near those salad.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception that physical distance affects whether things or similar or belong together.
In the mall, stores that are close together are seen to be more similar, and there's a lot of use of this particular bias.
Things that look alike, people assume have the same quality.
If a store brand makes itself look very similar to the national brand, you assume the quality is the same, even though you haven't tested it.
You don't know if that's the case.
You're making an assumption of perceived quality based on this process of similarity.
And it's a very, very important consumer process for a marketers to understand.
It's particularly important in branding.
With the Coca-Cola brand on it, people will think it tastes better, they're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product is exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that.
I know, I can judge certain products by the quality.
And we know from experiment after experiment after experiment that that's just not true.
People are very much influenced by the brand name that's put on the product independently of the product quality.
It's the same way in the Stroop Test.
You just can't stop it.
Once you see that brand name you have certain perceptions.
We know that brand is such a powerful brand, as we mentioned before, has so much influence.
The Coca-Cola brand name has been estimated to be worth $70 billion as an asset.
Just putting that brand name on a product will change, as I said, price premiums, people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time that no one had tasted before, a diet soft drink.
They call it Diet Coke, and automatically, even though that product was not on the market before, people assume it has better taste, it's a higher quality product, and again they're willing to pay a higher premium price for that product.
And, I'm here to talk to you about marketing.
So this, this segment is Marketing 101, the basics, the principles of marketing.
And my focus is going to be on building strong brands because of course the essence of marketing is to have a very strong brand.
Which is what is marketing?
So what's a market?
But what you need for marketing to exist or for a market to exist is to have an exchange.
And what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's let's look at the basic exchange.
You have one buyer and one seller.
and the real markets are somewhere in the middle.
But you'll see when I start defining this, that it's very useful to use this, this kind of simplification.
So if we think of an exchange between buyers and sellers.
On one extreme we could have what's called a seller's market.
And in the seller's market what that means is the seller has a product, and if you want that product, you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think about it, is marketing should not be the same in the seller's market as in the buyer's market.
So, in the seller's market, what marketing tends to be is what we call product focus market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability.
You should innovate in that product, you should try to reduce cost and you should really focus on the product.
Your business objective in a product-focused market is to sell as much as you can, and profitability from a product-focused market is going to come from volume.
Selling as much as you can.
In the past when we've studied product focus market, we've shown that profitability is tied to market share.
And why does market share increase profitability?
Because the bigger your market share, the more your revenues.
And the bigger your market share, and your volume, the lower the product cost and hint profitability.
Higher revenues, lower cost, more profit.
That's really the goal of a product focused market and when you're product focused, where do you get growth?
Will you develop new products based on your product experience or you go to new markets?
So what's customer focused marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
Well, what's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So where is in product-focused market, I'm the expert, and I create the very best product I can based on my expertise.
In a customer-based market, what I'm going to do is look at what the customer wants, and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside-out, this product focus, and outside-in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer.
What does the customer want?
Well, the first question is which customer?
You can't give every customer what they want, and we know customers are going to want all different things, so the reason why a buyer's market or customer focused marketing is so different than product focus, is that every customer out there, wants something different.
If we try to give everybody what they want, we'll go out of business.
That's too hard to do.
So the intuition of customer focus marketing, is to pick and choose customers.
Deliver value to some customers.
Say yes to some customers and no to other customers.
That's the process of segmentation and they call that, I'm going to talk about that in the next section.
Understand that in a product focused marketing, what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In the customer focused market, we're saying no to some customers and yes to others.
So, how do we make that profitable?
And, the answer is you pick and choose the customers you want to deliver.
How can, how can value-based marketing be profitable?
Then the profitability comes in not from reduced cost, which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want, I'll be willing to pay a higher price for it.
So that's one way.
The other way, customer based marketing is profitable is by giving the customer what they want time after time after time.
I don't think about just one transaction, I think about building customer loyalty.
And, delivering value to that customer over time.
Rather than market share, while I try to get a little bit from everybody, the idea of customer share, or share of wallet is that I go after a more narrow market and try to get more from each of that, their, those customer's wallets.
And it turns out that loyalty is very, can, if you do it right can be very profitable.
Because it's the cost of delivering value to the customer.
When I'm doing a customer based marketing it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but its cheaper to retain those customers over time, and that's where the profitability comes from.
It comes from loyalty.
The other thing, if you're thinking about building share of wallet in the customer-focused market, is that I not only sell one product to you.
If you've ever gone into a GAP or some jeans store, and, and you go to the cash register and you buy a pair of jeans.
The, the cashier or that person behind the counter might say: Oh these are very nice jeans.
Do you think you'll need a belt with that?
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time.
And that's more profitability.
And if you understand their needs, you can not only deprut, sell them one product, but you can cross-sell other products that may also nee, meet their needs.
So in a customer-based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between sellers market says you focus on the product, on what the customer does well, and you push that out.
And you deliver value to the customer better than the competition.
So that's the basic difference between product based marketing and customer focus market.
Now in today's world the market place has changed even more.
What's changed?
Customers can talk to other customers.
That's good and bad.
If you're doing a really good job and meeting the, needs of the customers, the fact that they'll buzz to their other customers and tell their, their other friends about what a terrific service your company is doing.
Well, that's really good news.
On the other hand, if something goes wrong, and they tell their friends something bad, well that's not such good news.
And so you have to be really careful, in every transaction with the customer now, that you deliver not only value, but that you deliver a top notch customer experience.
Because although what I've been talking about in the seller's market and in a buyer's market has focused on transactions.
But in a connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
What do I mean by customer experience?
Lemme give you an example.
It starts way before the transaction, and it goes way after the transaction.
So for example, if a customer told another customer that their experience at a restaurant.
They might say, well I was driving to that restaurant and I hit a lot of traffic, then I got to the parking lot and I couldn't find a parking space, finally when I got into the restaurant, I finally got a table, the meal was really good but then at the end of the meal when I was leaving I tripped and fell.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer then you as a marketer need to focus on the entire customer experience.
So, one of the things, and we'll talk about this later that's changed in marketing in this world of social media and internet and globalization, is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
One thing else to mention, we're seemingly coming out of a recession now, but there was a global recession, and in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
People became skeptical of marketing.
Marketing had some bad names, the financial services industry.
And so with all those changes in the economic environment, there's been a focus again, in marketing.
In order to be profitable, you not only have to deliver customer value over time and in an experiential way, but now because of the tightness of the economy and the uncertainty there, you really have to cut costs and figure out a way to deliver value in a very discipline manner and be very flexible to changes in the market place.
So let me just summarize what I've just said.
The different types of marketing orientations.
There's the product orientation where you focus on the product and you persuade the customer to want what the firm has.
That's a customer focus approach.
The experience orientation says that you not only think about the transaction, and think about the transactions over time.
But you try to manage the customer's entire experience with the firm.
And when times get tough or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of marks in terms of what you offer?
So you tend to see generic products and standardization.
When you're focusing on customer value, you see differentiated products, and we'll talk about that, when we talk about brands also.
How you position your product to meet the needs of the customers better.
And when you're going to that tight discipline mindframe or mindset you look at genuine value.
And what's the competitive sustainable competitive advantage in each of these markets?
In a product orientation the bigger companies win because they tend to have larger market share and lower cost, and lower cost is a big strategic advantage.
In a marketing orientation, when you're focusing on the customers, the, the companies that do the best are customers, are companies that really know their customers, that can deliver quality, and that have a lot of customer data and know how to use that data to deliver better value.
In an experiential market, you look at transformation.
The customer becomes a co-creator of the value, and it's really making the customer and the product one kind of overall experience.
And in a trust orientation, the sustainable competitive advantage are the companies that you trust.
And what are the measurements of profitability?
In production orientation as I mentioned, market share is tied to profitability.
In marketing orientation, it's share of wallet or customer share, customer loyalty.
In experienced market, when you're looking at customers talking to other customers, we start measuring social networks and buzz and word of mouth and referrals.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
That's the principle of customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
The four P's of marketing are product, place, promotion, and price.
What the seller puts into the exchange, is the product.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
So those are the four P's of marketing, product, place, promotion and price.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
You can give but, blood donations I think if you're over 16, and it turned out what, one of the products that the American Red Cross could give to high school kids to give blood, was to allow them to miss class.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
So, in this section, what I want to focus on is an introduction of a, a framework that I think you'll find very useful for figuring out how to think competitively to become a leader in your market.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
And the first one is; that you have to know your markets.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
That is the type of marketing most businesses are doing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
The second principle and this is where it's pretty, it's a pretty defined and pretty It's a definite assumption that's being made.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
What happens in the marketplace?
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
And so the three crosshatches here are fair value lines.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
What are customers expectations on each.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Are you meeting fair value or below fair value on each one of these axes?
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
So, in this section, what we'd like to talk about is that concept I mentioned earlier, segmentation.
And this is a critical idea for marketing and very important for where we're going, which is brand positioning.
It's called the STP framework: segmentation, targeting and positioning.
And when we get to positioning, that's when we first start getting to branding which is where we're headed.
So, the positioning process says, yous tart with segmentation, with S of STP.
And segmentation says that you identify variables that allows one to segment the market.
Okay.
So I, we're going to figure out different schemes for how to break up the market into different market segments.
The second part, the T is targeting.
You would evaluate the attractiveness of each of the segments and you choose a segment to target.
And the third piece is positioning.
Once you get your targets segment, you position your brand and your product to meet the needs of that target segment.
STP, segmentation targeting and positioning.
So let me just give you the idea of why this is so important to have segmentation targeting and positioning.
And what I'm putting up on the background now, is a slide that shows you the importance values two different segments have for roof tiles.
So in this graphic, you can see the yellow segment, doesn't think price is that important.
They don't care about whether or not it's a low price.
And they really care about how durable the pu, tiles are.
On the other hand, the blue segment, they care a lot about the price.
They don't really care that much about how it looks, and they don't care that much about how long the tiles last.
If you did not segment this market, the optimal thing to do would be to give average value to everything.
The average value here would not be not a low enough price for the people who care about low price.
In some sense I think that is the lukewarm tea.
You can have hot tea, an ice tea and if you give average it's lukewarm tea and nobody is happy.
So one of the reasons to segment the market is if you don't, you tend to try to reduce cost and go to the average value and you are not meeting anybody's needs.
Going back to that concept of customer focus marketing, if I want to give you exactly what you want, I need to segment the market.
And what you'll see is there's a heterogeneity or differences in preferences.
And then I need to choose or target; which one of these segments I want to deliver to, and deliver value to that segment.
And for example, in this case if I delivered, durable tiles, to the seg-, the yellow segment.
in fact, let me just define it formally here.
Market segmentation is the process of dividing up the market into distinct subsets, where any subset could conceivably be selected and then you pick one of those market seqments to be your target.
And you reach or you deliver to that customer segment, that market segment, with a distinct marketing mix.
Remember what the marketing mix is, the four p's, product, place, promotion and price.
And what that says, when I'm looking at these different segments, they may want different products.
and so that's the definition of market segment, a very, very critical idea in, in marketing.
So the question is how can I divide up the market?
And you might understand the idea that I'm going to go after market segments and I'm going to choose one of them.
And then I'll give a unique product package, or marketing mix, to one of those segments.
Maybe you understand that concept.
But then the question is well, what are the different ways to segment the market?
And there are actually lots of different ways.
The most common way that people most, that usually think about is to divide up the market on characteristics of the customer.
So intuitively, you might think about demographics.
Well, men and women like different things, so let's make a female product and a male product.
Or, old people like things that are different than young people, or rich people have different needs than poor people.
So one of the segmentation schemes people frequently think about are characteristics of the customer.
Another one though, which doesn't really focus on characteristics of the customer says, well people like different things in products.
Some people care about technology, and so it might make sense to divide up the market or segment the market on benefits that people seek.
A third way to think of it is how do people purchase?
Some people purchase online, some people like to go to physical stores, some people like to use their phones or some people purchase very frequently.
Some people only purchase once a year.
Some people like to switch around, other people like to be loyal.
All of these are different characteristics that you can use to segment the market.
Another thing that and I'm sure you've heard of this.
Another way to think about it is cohort analysis.
And what cohort analysis says, it's not really whether you're young or old, it's the life experiences that you've experience as a cohort.
Those things that hit you at that time of your life are critical, and they frame you as a generation.
And so this is the idea, you've heard probably of baby boomers.
Baby boomers were born, there's two cohorts of baby boomers.
and those that cohort of baby boomers.
All come of age at a certain time, certain things happen when they come of age, and they react as a generation.
Generation X is another cohort and what you're hearing about nowadays is really is Generation Y.
Who's in college now, what's that current generation?
Marketers are very interested in the generation as they come of age, when they are in college or when they're this age.
Because many times, you make purchases at this age and then you're loyal to those brands over time.
So it's, marketers feel it's very, very important to get in those people's consideration sets, right, at this time.
So they spend a lot time studying, the cohort of today and today's cohort is Generation Y.
Generation Y is very different from all the other generations.
First of all, it's a generation that was completely brought up on the computer.
they think about the social environment, they're totally comfortable social network, everything's wireless.
They think about things being designed exactly for them.
They're totally used to customization.
This is a generation, electronic generation that's quite different from their parents and from generations beforehand.
And you really need to understand Generation Why or the Millennials in order to market to them.
What they don't like is mass marketing.
They don't like any kind of restricted access.
They like new, they like different, they like customized.
Millenials are big shoppers, but many times the co-purchase with their parents, some of the millenials still live with, and are supported by their parents.
They think about information electronically.
They're very, very comfortable comfortable multi-tasking and co-creating with the product.
So if you're segmenting the market by cohorts and you decide to target the millenials, you would have to design a targeted product or position your brand in a specific way to meet the needs of the millenials.
Another way that markets tend to be segmented are by geography.
It turns out that people who are similar tend to live together in the same neighborhoods.
And there are different ways to segment, there's segmentation scheme called prism.
That actually defines the entire country based on these geographic clusters.
So you could have a geographic cluster with some characteristic sets in California.
And people who live in New York may be in that same, same cluster.
So people who live in say Beverly Hills California, may be similar to people who live in Scotia, Scotia New York.
And those two may be in the same cluster, even though they're separated by 3000 miles.
So the PRIZM clustering, or zip clustering says, if you tell me your zip code, and I'm giving you a United States example.
But this kind of notion of geographic segmentation is true around the world.
People who are similar tend to live in neighborhoods that are similar.
And so you tell me where you live, I have some ideas of the kinds of things you might like, the products you might like, the clothes you might wear.
And what we find out and we'll talk about later on in, in one of the other parts of this program when David Bell comes and talks to you.
So location is a very very important variable when thinking about segmentation.
And there are lots of maps that can divide up say the New York City for example.
Once you define your segmentation variables, then you need to select a target segment.
and so what makes a segment attractive you need to balance the attractiveness of the segment with your capability to deliver to that segment.
And you need to constantly monitor whether the actual buyers that you're targeting are matching what you think that they should be doing.
You determine the attractiveness of the segment, how big is it, how much growth is there, how much money do they have to spend, how stable is it.
Then you think about, well how good are you at meeting the needs of that segment.
How many people are going after that segment?
What's the strength of the competitors?
Are there potential competitors coming in?
And what you want to do is pick the most attractive segment where you have a differential advantage over the competition.
That's the best target segment for you to consider.
And you can have low to high competitive strength.
And the best segment to go after or to target would be the most attractive segment where you are strongest relative to the competition, that's perfect.
Sometimes you can't get the perfect segment and so you may choose something that's a little bit less attractive but still something that you think would be profitable.
Because one of the most important aspects of a brand, is brand positioning.
It's also the positioning in the STP framework, but it's really the essence of the brand, the brand positioning.
So, let's start with what is a brand, and then we'll get into this notion of positioning.
And so I really want to get to this notion of what is a brand.
Formally a brand is just a trademark.
If you have a brand you want to legally protect your brand and trademark it.
and that's if you talk to lawyers about a brand they'll talk about it as a trademark.
A promise of the company of certain specific benefits to the customer.
and that's been the traditional definition of what a brand is.
Because, we mentioned before, this is a connected community, and customers are talking to other customers.
Really, what a brand is, and the real definition of a brand.
That's what the brand is.
What sits in your customer's heads, regardless of what you try to put there, is what your brand actually is.
Then hopefully what Disney thinks their brand is, is what the customers think it is.
But if your message is not so clear and you want your brand to mean something, but what the customers think is something different.
That's what your brand is, what sits in the customers head.
Now when we're talking about the notion of positioning.
And so a positioning statement is a definition or positioning statement for a particular brand.
I have here two examples of positioning statements.
For two brands of personal computers.
These are a little bit old, it's when Apple and IBM were really focusing on personal computers.
But I want to use these examples because they're very clear, crisp positioning statements, and I think we can learn a lot by understanding these positioning statements.
So let's look first at Apple computer's positioning statement.
And if we read that, it says Apple Computer offers the best personal computing experience to students, educators, creative professionals and consumers around the world through its innovative hardware, software and internet offerings.
Compare that to IBM, which was very, very different at the time.
IBM is for businesses who need computers.
IBM is the company you can trust for all of your needs.
Very, very different positioning.
and it should be quite clear by the positioning statement.
Let's break that positioning statement into its parts, so that we can understand what a good positioning statement has.
There's three pieces to the positioning statement.
In the frame of references, who are the other competitors that they are comparing themselves to?
The target segment here, and it you think about Apple, the target segment is students, educators, creative professionals.
So nowadays, Apple's so popular that you know, everybody has an Apple.
You know, somebody who's not a student has an Apple.
not just creative people anymore.
Yet, even though Apples are ubiquitous and lots and lots of people have Apple, Apple products.
It's a very designy brand.
So, it still has a very clear target segment, even if that doesn't limit who might use the product.
It's innovative.
We look for design innovation from Apple, so that's its point of view.
And in this case what's the frame of reference?
In this particular positioning statement it's other personal computers.
So you have these three pieces to a strong positioning statement, the target segment, the point of difference.
And positioning is defining the value proposition in these three terms, the target market, the point of difference, and the point of parity.
Now you can play around with this and if you think about this and get into it a little bit you may realize that your point of difference is going to be relative to the frame of reference.
If the Crest chewing gum was referred to, the frame of reference was other toothpaste products, then Creth, Crest chewing gum's point of difference is it's a toothpaste product.
On the other hand, if you take Crest chewing gum and compare it as a frame of reference to other chewing gums, the point of difference is, this is a chewing gum that has toothpaste in it.
So, these two things go together and part of the art of coming up with a good positioning, is figuring out who's the right target market to go after.
And also, what's the frame of reference, and what's going to be your point of difference, and playing around with those two pieces is a lot of the art of positioning.
Very important concept, but you really need to understand these three ideas, target marketing, point of difference and frame of reference or point of parity.
And what you're going to do is, because once you decide on your positioning statement, you use all of the elements of the marketing mix that we've already talked about, product, price, promotion and place, to position your product to meet the needs of the target segment.
And positioning should be clear and simple and focus on a few key benefits.
the position must be defensible, so you want to take a positioning that you own and that other people can't copy very easily.
And the really important thing is you cannot be everything to everyone.
You must make choices.
You must focus.
You must choose a point of difference.
You must choose a frame of reference to have a clear positioning.
Because if you try to be everything, you're going to end up being lukewarm tea, and that is not a good brand position.
Positioning, once you have the good brand positioning, that should determine what products you develop, and positioning is a strategic idea, so you really want to think about this in terms of what are, what's your target segment, what do customers want, what's your competition, what is your position relative to the competition?
Once you have your brand positioning, you can decide things like, what color should the brand be or what should the symbol be or what should the logo be, and we're going to talk about those in the third, in the third section of my.
At my part here but that's very much tactical and messaging.
Positioning at the level I'm talking about it right here, this is very much a strategic idea.
And a very important piece of this is this point of parity or frame of reference.
These are, so I want to spend a little bit more time thinking about this just so that you understand.
It's a part of the positioning statement, but it's associations that are not unique to the brand.
And you want to think about these point of parity as things that are necessary for the category.
So something a brand must have to be considered in this frame of reference.
So for example, if your frame of reference is a grocery store, then people think, in order to be a grocery store it has to have produce or it has to have fresh product, that's what a grocery store is.
And if it doesn't have that it's not a grocery store.
Are what are the conditions that your brand must have, that they share with the competition to be part of that set?
And then you want to think about points of parity sometimes is ways to negate, a, a, a competitor's point of difference.
So, for example, in toothpaste, when one of the brands, and I can't remember which one, first came out with fluoride and as a cav, cavity preventer.
All of the other brands copied and put fluoride in their toothpaste.
Suddenly it's a frame of reference, it's a point of parity.
All toothpaste now has fluoride.
On January 9th, 2007, a few years ago when Steve Jobs was still here, he used to go out in January and come up with some big innovation every year, an announcement about Apple.
On January 9th of 2007, one of the big announcements at the time was that he changed the name from Apple Computer to just Apple.
Did he change the target segment?
Target segment, still creative young people.
Point of difference, still innovation.
The point of difference, I think is more clear to people what that is.
It's strong, favorable, unique brand associations.
It's a similar concept.
You want a competitive advantage, a point of difference that you can hold, and that it's difficult for competition to copy.
and it can, it can be a lot of different things; it can be product attributes, performance attributes, it can be imagery, it can be benefits, it can be design, it can be anything that you can own and that really differentiates your brand.
When you're choosing a point of difference, you want to make sure that it's desirable to the customer.
Is it relevant, is it distinctive?
So in choosing a point of difference it's very, very critical, it's probably going to be the reason people choose your brand.
But you've gotta make sure it's important and that you can deliver on that criteria.
So we just talked about brand positioning, which is the strategic part of brand position.
And if you really think about brands, you'll realize that although you know some great, crisp brands it's very hard to get to that positioning.
You can have different point of differences, different target segments, different frames of reference with lots, and lots, and lots of different choices.
That's the trick of marketing.
To explain marketing, the concepts aren't that difficult to grasp but they are very, very hard to do right.
There are lots and lots of ways to do marketing wrong.
And the next concept that I'm going to talk about is the brand mantra or an elevator speech.
This is the way you define a brand in 30 seconds.
So we're talking about 30 seconds worth of material.
It sounds so easy, 30 seconds.
The right brand mantra, that takes lots and lots of analysis.
And a lot of wrong turns, and a lot of wrong ways.
maybe you're lucky, but chances are, you haven't given it enough thought.
You really do need to think about of lots of the different positions.
So what I'm going to suggest here, what I'm going to talk about is a relatively easy concept to get, but it's very hard to do well.
Let me tell you where we want to end up and I'll talk about how we get to it.
We want to add up, end up with the 30 second speech, as I said, the elevator speech.
And a brand mantra may be three words; but I want to get down to the right three words.
And how do they think about the category, and how do they think about different brands?
And what a mental map is a kind of a graphic, with circles and arrows and things like that, of what the brand is.
And it's kind of a, a thought association process.
You ask the consumer what comes to mind when you think of the brand.
And then there's lots of different ways to do this and I'll just show you one.
But there are a lot of different ways, and you write down what the brand is, what the essence of the brand is from the consumer point of view.
And some people call this mental map, some people call them schemas.
and there's a lot of different techniques you can do in these mental maps.
The lines that connect one circle to another circle can be the strength of those associations.
But essentially what you're developing is, sometimes it's called a semantic associative network or a mental map.
You're developing a picture of the thought and associations that come up with the brand.
And so what I'm going to show you here is a mental map of McDonald's.
It's good value, and then the yellow circles here are the associations with each one of these points of parity.
Frame of reference characteristics that are unique to McDonald's.
What are the meals that McDonald's has?
Well, it gives hamburgers, it has breakfast, it has fries.
Well, it's always consistent, it's fresh, it's good-tasting.
and these, this is one example of the mental map.
But you can see the idea here is that you have circles and lines that connect these associations.
You can do this in a lot of different ways.
You can do it, the closest ones to the core are the ones that are top of mind, that come up first.
The ones that are further away, you know, come up after a time.
And so there are a lot of things, but what I'm trying to get here is all of the thought associations that come up with a brand.
And then what you want to do is do this over several customers, and do it in market research stages, several different ways.
And essentially, you want to take all these different abstract phrases and concepts that are out there.
And figure out which are the most important maybe five to ten, which are the very most important.
And so, what you're doing is, you're starting with the mental map or the associations that people have with the brand or maybe that with the category and depending upon how well known the brand is you might do it at a category level, you might do it at a what if level.
But you have this big mental map and then you want to hone down that mental map to the core brand values which are the five or ten critical brand values that are important to that brand.
And from that you then want to reduce those five or ten to the key concepts that are going to be the DNA of the brand, the brand mantra.
So, the brand mantra is defined as the heart and soul of the brand, the DNA.
It's the brand essence, the brand promise.
It's just really what people think of as the core of the brand.
It's very important to know this brand mantra because everything you do within this brand mantra, all your products that you come out with, all your new products, all your advertising has to all fit within the essence.
The customer's going to know the brand mantra, the employees are going to know the brand mantra.
And it characterizes everything that's done under the brand name, and that's very, very important.
It's particularly important nowadays as you go online, offline, websites, phones.
Your brand is on lots of different things, and you really want to make sure that the heart and the soul of the brand is consistent across all of these different media, these different platforms, these different products.
So what is the essence of the brand mantra?
It has three basic parts.
Then there's the descriptive modifier that further classifies or clarifies the nature of what the brand is delivering.
Now it's probably easiest to give you some examples.
Before I do that though, let me just say again, what the brand mantra is used for.
By the way, that's a very important idea.
But as importantly it says what a brand is not.
It, it, it has to be short, simple and it should be inspirational.
Nike, they're global brands, Nike, Disney, McDonald's.
so Nike is authentic, athletic, performance.
The all, just do it, be real, you know, the, that's authentic.
But when you think of Nike, you think about athletic, and it's about performance and the, the technique, or the ability to, that can, just do it.
Disney and McDonald's are kind of interesting, because they both are about family fun, and, and they actually both have a lot of things in common.
Disney is about entertainment.
Disney sells quite a bit of food at their parks and in different places that they have.
But when you think Di-, Disney, you think fun family entertainment.
McDonald's, on the other hand, is fun and family.
But its food, and even if you have a McDonalds playground or something like that, you still think of it as the food first.
And so, although these are similar and you know, what.
even though they're going after similar target markets and they're offering similar emotional benefits, they really are quite, quite distinct, different brands and they have very different brand monitors.
So in this last segment, we're really defining what a brand is.
we, we've talked about what marketing is, we've talked about marketing strategies, competitive analysis, customers values.
And brand positioning that's so sharp that you can define it in just three words, in 30 seconds as a brand mantra.
And in this last piece of this, I want to talk about the notion of experiential brand.
And we talked about things changing from the sellers market to a buyers market to the connected community.
In the connected community, that's when this notion of customer experience comes in.
So its not enough to just define a brand in terms of a crisp, clear brand mantra and a crisp, clear brand positioning, but you also have to define all of the experience that exists around the brand.
So, what's an experience?
an experience is a process that occurs as a result of living through a situation.
So it's not just a moment in time, it's a dynamic notion where you sense or feel this experience.
as I'm going to define it later, you'll see that it involves all the senses, it's social, it's behavioral, it's cognitive, it's emotional.
It's stimulations that are triggered to the sense that you think about, that you feel.
they connect the company and the brand to the customer, and they place the the customer action and the, the individual's actions and purchase occasions in a broader social context.
So the experience includes all of these kinds of things.
It's What I've been talking about, up to this point really, is pretty cognitive, pretty rational.
And here's where we bring in the emotions and all these other things, and I know those of you who know and love brands really understand that brands are emotional, they're experiential, they're not just this hard and fast cognitive point of view.
And so that's what I, I'm emphasizing here on the point I want to end with in this section, that a brand is an experience.
I'm going to talk about those but they all have to be augmented to be bigger than that.
That's a principle of marketing, to be differentiated, the point of difference.
So the different, the differentiation is also in the brand experience.
If you're an Apple lover, or you're an Abercrombie lover, or something, you have a relationship with that brand; it's over time, and it defines you.
It's not just brand attributes, these cognitive at-, or these performance attributes, or these product attributes.
It's a personality, you think the brand almost as a friend.
It's not static, it's dynamic.
It's not a mass brand, because you're co-creating with the brand.
So you can see by the types of words I'm saying that Really, really strong brands embody all of this emotional experience.
and so when you define these terms, these things that I've mentioned earlier, than you're not just thinking about brand positioning.
And it should be a multi-sensory strategy.
When you think about brand positioning, experiential brand positioning, you not only want to think about.
You want to think what's the smell of the brand.
What's the emotion you feel when you think about the brand.
And, it, it, it needs to be as any kind of differentiation is, it needs to be distinct from everybody elses.
And then the brand promise the mantra again, it's not just three words, you know, cognitive words.
It also needs To describe what that brand promise is in experiential terms.
And here's where I'm going to be very clear of what I mean by experiential.
So, it need to be what's the vision of it?
What does it look like?
What does it smell like?
Is there music associated with it?
What does it feel like?
What, what, how do you feel about it?
What, what, what are the emotions you feel with this brand?
What do you think about it?
The, the sensuous is across the five senses, you want to have a consistent experience.
You should appeal to the customer's inner feelings and build strong emotions to it.
It can cause you to act in a certain way.
And social is the part of the social system, the culture, that surrounds the brand.
And you want to have these experiential functions delivered through the four P's.
And now we're going to define each one of these four P's in experiential ways.
all of you know about, I'm sure you've seen this self designed, customized Nike.
It's not just a product attribute anymore.
You're part of the process that makes it very experiential.
You choose what you want in your shoes, you choose what you want in your greeting cards.
That's an experiential notion of a product.
advertising that's experiential, I think, one of the one's who's a beginner to really understood this was Apple, when Apple would show their iPad or their iPod when they were first coming out, it was a very experiential ad.
It was music, it was dance, it was.
The little white ear buds that came through was the color, the design.
I think, that's what most people are now just assuming most advertising is that way.
What does it mean to experience price?
Or even the concept of priceline.com where you kind of name your own price, that's very much an experiential notion around price.
Even something As, as cognitive as price which is numbers can be experiential.
these are stores where in, in Ralph Lauren, for example, they built an entire house, the entire, the entire lifestyle.
What kind of furniture would they have?
and, and it's very very experiential, not just, it's not just a store with clothes on a rack, it's stores in the experience, in the context you're going to live and wear them.
This is how cosmetics should be, you know, it's not hidden behind a counter and you can't tell anything and you gotta get a sales person to come and get you.
You want to go and feel the colors, put them on and see them, smell them, that's experiential.
And the very best retailers understand that.
There's a Pop-Tart store, there's an M&M store, you go in to that store and the candies are everywhere, the colors are everywhere, you can taste different kinds of things.
The, it's a lot of fun, it's almost like an amusement park, that's what retailing has come to be.
Each one of these pieces is delivering to the brand mantra in an experiential way through four p's.
This is what's happening in brands.
and it, it's like a religious experience, and we certainly saw that when Steve Jobs passed away.
That was a memorial.
Clarity is very important and it has to be dynamic, that these promises have to be kept over time.
You have rich unique brand equity, strong emotions, strong thoughts with it and they're delivered dependably and consistently and strong brands have really loyal customers who help spread the brand message.
weak brands on the other hand are vague, they change, you don't even know what they're going to do, there's no consistency there's no commitment, there's no.
it's a very spotty reputation, there's doubt about it.
You didn't, never know what it is, pricing can change, you know, one time it looks like this, another time it's shoddy qual, those are not strong friends.
Consistent, clear promises are what make very strong brands.
Every time you get a product experience under this brand name it's the same.
Very important.
There's a very big difference between Disney and McDonald's.
They are very, very distinct brand positioning, and distinct customer experiences, even if the product itself might be somewhat similar.
But it indicates what kind of organization you're going to have, what the priority of your resources are going to be how you allocate those resources, etcetera.
and it's very important, we'll talk about this in the last section, for your brand to stay relevant.
A great brand is flexible and adaptable and changes with the customers.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
I'm here on South street.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
In a world characterized by a performance superiority or operational excellence.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
Either going to new customer segments or to new geographies.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
Both of them share this basic idea.
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're, we're good at doing a certain kind of thing.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
How do they go about running the existing business as well as figuring out how to extend the existing product.
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
And we're going to stay ahead of our competitors by becoming more efficient.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
And this is exactly the kind of issue that many companies are facing today.
It works.
It gives them some opportunities for growth.
And for many companies that's totally fine.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
Again, implicity, that's the way that most businesses operate.
And we hire people who can think divergently, who can take our particular core business, and think about ways of spreading it out, to new markets, and new products and services.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
What would be some of the emerging trends?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
So smarter customers put much more demands on, on companies.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And it's much harder to stay a step ahead.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
So, again, that's another reason why product-centricity just isn't what it used to be.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
So in the old days, it was good enough just for, to, to let the customer take a bunch of products and services and figure out what they're going to do with it.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
It is now much more imperative than it ever was before for companies to be seen as a trusted advisor.
To be providing full fledged solutions to the customer and not just piece meal products and services that the customer will figure out how to combine together.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
So if you think about old companies.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
And for how long, and what other products that they're buying.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
If this customer goes down about say, $150, it's time to intervene.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
But equally importantly, is going to reset their mental account.
So Harrah's was very smart about understanding that kind of messaging.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
So when Wal-mart bought a small chain and entered the UK.
Tesco knew which customers were most vulnerable to switch to Walmart, and which products they'd likely buy from Walmart.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
Now that we understand what product centricity is all about and we've discussed some of the cracks in product centricity.
And even some of the opportunities from companies to escape from and maybe do better than a product-centric approach, I want to start moving away towards customer centricity.
So in order to do that, I want to work with a series of examples here.
Three of them operate on a global level, so Walmart, Apple, Starbucks.
So I want you to think about what customer centricity means in light of our discussion so far.
And decide which of these, could be one, could be all, could be none, up to you, would be above the bar in terms of customer centricity.
So think about what customer centricity means, and which of these firms qualify in that regard.
In my book, none of these firms are truly customer centric.
I have great admiration for all these firms.
I really like what they do.
So I'm just going to take a few moments to talk through each one of them, and then, finally we'll bring up our definitions of customer centricity.
Now again, Walmart is a terrific firm, but Walmart knows, surprisingly little about any one of it's customers.
Unlike Harris, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
And how they can influence each customer's behavior.
So while Walmart might not make a lot of efforts to understand what any one customer's going to buy, they make great efforts to understand the customers as a whole.
They understand regional differences.
For instance, when a hurricane is about to hit the south eastern US, they need to fill the stores with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way as a direct marketer would suggest.
And you know what, that doesn’t bother me because Walmart isn’t intending to be a direct marketer.
If you think about the Walmart business model, it’s about selling in great volumes, it’s about bringing the costs way down.
So, in many ways, Walmart is a prototypical, and a wonderfully successful, product-centric firm.
There are a very few firms in the world that can operate in an operationally excellent manner as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time focusing on segmentation and real granular analysis to try to predict what any one customer is going to do over time.
What Apple focuses on, is leveraging its product expertise.
So again, a classic example of product centricity, and they do it better than most company, most other companies on the planet, and they can get away with it.
Operational excellent for Walmart, performance superiority for Apple.
They are doing some smart things at the margin to understand their customers better.
They have a new program they call Scan & Go, a mobile app that lets people scan products as they move around the store so as they check out, the whole scanning process happens much faster.
It's a brilliant idea that lets them be more operationally excellent, but also lets lets them start tagging individual customers and tracking them over time.
So they're starting to take on some more customer centric initiatives without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business that are letting them understand their customers a little bit better.
Slowly but surely, they're starting to develop a better understanding of their customers at a more granular level.
One day, if and when competition catches up and Apple can no longer be the product leader that they are, they could probably turn around and start to be a great customer-centric firm as well.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
At a local level, Starbucks or any coffee retailer, is very, very customer centric.
The Barista, the person on the the other side of the counter, the person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store but just through the casual conversations you have with them, they might know what movies you like, what kind of clothing you’d like to buy, something about your job, your family and they often make recommendations to you.
That are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted advisor to the really good customers, finding ways to lock that customer in and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they are not that customer centric at a national level.
You take your Starbucks loyality card, and you bring it a Starbucks in another city or another country and show it to them and say, I'd like the usual please, they have no idea who you are.
So not only can they not meet your immediate needs, but it's hard for them to be a trusted advisor and to make other recommendations to you when they have no idea about anything about your history.
It's not enough for a company to be customer centric some of the time when they know who you are.
But a truly customer centric company will identify you and will be able to value you and make recommendations no matter what kinds of interactions you have with them.
And they're coming up with all kinds of interesting technologies that are going to let them collect and integrate your data across stores and across other touch points you have with them.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
So again, it's that balance between focusing on the product and focus, focusing on the customer that so many companies are now struggling with.
And while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
And here's the way it goes.
They sell clothing, shoes, and so on.
One thing they don't sell is tires.
Supposedly in Fairbanks Alaska, and wanted to return a set of tires that obviously they could not have bought at Nordstrom's.
Perhaps there was a tire store at that location before Nordstrom's opened shop.
If you think about it for a minute, is that really customer-centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
We'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer.
The lifetime value of the customer.
And for most customers it wouldn't be.
We might still be nice to you, of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom's.
Regardless of the value of that customer.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
I like knowing that when I go in there I'm going to be treated really well.
In the old days it was impossible to do that, but today Nordstrom's, like every other retailer, has the capability to collect the data and use technology to do a little bit more targeting and a little bit more selection to figure out who is worth the extra special treatment.
So to me the Nordstrom's example is a great example of, of where a product and customer centricity collide.
And what I want to do now is, is to start focusing more on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
In other words, what is the definition of customer centricity?
So what I like to ask my students to do is to write that down.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
Hopefully, it's well-aligned with your own definition of customer centricity, but I really do want to emphasize just how different it is.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
It's a tot, totally different way of doing business.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
But it's the mindset, it's the idea of going to R and D and putting these valuable customers front and center.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
And so I want to think now about some of those challenges as well as some of those opportunities.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
We're looking at not which customers have been valuable, but which customers will be valuable using the data, the models, the technology that we have available to us.
So what does that mean?
We're going to reward salespeople based on how much stuff they sold last month or quarter or year.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's do that at the beginning of the month, or the quarter, or whatever.
And then do it at the end of the month or the quarter.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Well, we're closer to making this sale.
That's how I want to reward the sales people.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
So they were working in industry before, spending a lot of time flying.
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
So now that we've laid out the definition of customer centricity, we've spoken a little bit about some of the challenges that it requires companies to meet changing its centric structures and so on.
What I like to do is just to step back and review all the aspects of living in a customer-centric world.
What does that mean?
Now we'll spend a little bit more time talking about some of the other aspects of it.
So, so first, if you live in a customer-centric world, well let me ask you this question.
What's the overarching objective for the commercial enterprise?
You remember I, I asked that and we discussed it before for the product-centric enterprise.
So usually when I ask this question people will give me a lot of customer oriented answers.
Yeah, that's all nice.
That's all terrific.
The overarching objective is the same as it was before, to maximize shareholder value.
To maximize the profits of the company in the short run and the long run, recognizing the time value of money.
That in the end, the overall objective of any commercial enterprise is to make as much money as possible.
The problem is this.
There's too many people who think that the money-making thing is uniquely associated with product centricity, but it's not.
There's lots of different paths that we can follow, and while customer-centricity is quite different in many ways from product centricity, it's a path that actually might help you get there faster and better.
So, If I want to emphasize that point, that we're trying to achieve the same over-arching goal but in a very different way.
So let's talk about how we achieve it.
Again, going back to product centricity, for most firms, the performance superior ones and the operationally excellent ones, it was all about blockbuster idea.
Let's produce a lot of it, let's produce it efficiently, and let's think about the next thing to produce.
And again, that formula has worked for so many companies, still works today.
So what is it in the customer-centric world?
What we celebrate in the customer-centric world is customer heterogeneity.
The idea that not all customers are created equal.
The idea that some customers are just inherently much more valuable, much more profitable than other customers.
They didn't understand how customers were different from each other.
Once they started realizing that customers are different from each other, at first it was a nuisance.
Different customers, we're going to have to talk to them in different ways.
And the more we learned about our customers, the more we realized they are really, really different from each other.
So unless we're going to paint ourselves into a corner, and only work with one kind of customer, we need to acknowledge and celebrate that heterogeneity.
We need to find a way to say that these differences across the customers not only exist, but they're a good thing.
Let's find the kinds of customers who can be very valuable to us.
And, at the same time, let's find ways of dealing with the other prob, customers in a reasonably profitable manner.
One point I want to emphasize along the way, I, I, say this over and, over and, over again, but it is important to make this explicit.
Is that when we're focusing on heterogeneity and we're focusing on the, on the, the profitability of our customers, we're talking about future profitability.
It's great to look at past profitability.
In many cases, that will be a guide towards future profitability but it's not a perfect one to one match.
So we need to use our data, we need to use models and technology in order to project the future value of our customers.
So the celebration of heterogeneity is not only what the customers have been worth.
But is which ones we think will we be most valuable.
Most of the value is what we're going to create and extract in the future.
And that's the really pivotal role of this idea of customer lifetime value.
Okay, we're going to want to measure CLV, we're going to want to manage around it, how do we do that?
So, when we look at a company as it starts changing from being product centric to customer centric, what kinds of tactics change?
So one point that I want to emphasize right now, what were going to go into much greater depth in module three are those three tactics that lie at the heart of customer centricity.
That are the, the tactics that make it possible for companies to potentially make more money being customer centric than product centric.
And a lot, lot of you might be looking those words and saying well that's not new.
Companies have been thinking about the retention and development, making customers more valuable.
That's true!
But in many cases, these ideas are, are, kind of treated at a fairly low level within the marketing organization.
So it's all about, how can we get as much stuff out there as quickly as possible?
And so, instead, as we start to think about how customer's different from each other, we're going to want to ask questions about which kinds of customers should we be acquiring.
How much should we be willing to spend to acquire them.
Or should we be a little bit more selective.
And when it comes to customer development, are there some customers who we can make into better customers than others.
The people who are going to be working on them need to be higher in the organization.
The people who are running the marketing function have to be at least as painfully aware as acquisition, retention, and development, as they are around some of the branding ideas that, that Barbara spoke about.
And so we're going to get back into that.
One point that I've mentioned from time to time, but I want to make a little bit more explicit here would be challenges for the organization itself.
Again instead of having an organization, that's organised purely around the different kinds of products and services, we want to have a customer-centric organizational structure.
Ideally, the whole org chart would be built around the different kinds of customers we have.
And then below them, the different ways that we're going to create and extract the profits from them.
The Walmarts, or other grocery chains who they sell their products to.
But Proctor and Gamble recognizes that with this shift towards customer centricity, with the shift towards direct marketing, that eventually their customer will be me and you.
And they want to start to understand who the really valuable customers are.
And what are things that we can do to create more value for those customers?
So here's an example of a really nice initiative, one of many that Proctor & Gamble is trying out.
It's called My Black Is Beautiful and it's aimed at African American woman.
And P&G is determined that this is a really valuable customer segment for us, we need to be there, we want to be seen as a trusted adviser.
First, look at the bottom of the slide.
You see a number of different P&G brands being advertised together.
It's pretty unusual for a company like P&G, or again other packaged goods manufacturers, to use that kind of umbrella branding, and going back to some of Barber's content.
and if you look, look higher up on the slide, you'll notice that they're also talking about recipes and music and all kinds of things that P&G isn't involved with.
But this should be an example of Procter and Gamble trying to position itself as a trusted adviser.
That they're offering all kinds of products and services to this valuable customer segment that they don't necessarily make any money on, but they want them to see P&G as someone who has their best interest in mind.
And if you look at the bottom of the slide, you'll notice something fairly unusual.
You see here this the mention of, of a line of cosmetics called Covergirl Queen.
But, Queen refers to Queen Latifah, the popular actress, and so they developed a whole line of cosmetics specifically for African American women.
Going to the R&D people and saying, you know what, instead of coming up with a blockbuster product that everybody's going to buy, here's a valuable customer segment.
We want to come up with something for them, that they're going to find very valuable.
Others might buy it too, and that would be great.
I don't even know if this is the right segment to go after.
But given that they are going after this segment this is the right way to do it, this is customer centricity.
And you have to believe that in the Proctor, Proctor, Gamble organizational chart there's some people who are responsible for My Black is Beautiful.
And they're going to bring whatever resources they can what are the products with in the P&G family or outside of it in order to make this customer group as valuable is possible.
The bottom line for customer centricity, is this idea of relationship expertise, if you remember earlier, the key to product centricity was product expertise.
We're always, s, steps ahead of everybody else, but as we discussed, the cracks in product centricity are shortening some of those steps, it's much harder to stay ahead when it comes to product expertise.
But when it comes to relationship expertise, I believe that there are meaningful, sustainable long run advantages.
And I'm not just talking about soft, squishy understand your customers in some generic way.
I'm talking about data.
I'm talking about models.
I'm talking about truly understanding your customer, your customers, celebrating the heterogeneity.
One of the beautiful things about it, is that when you collect the data, and you develop these kinds of forecasts, nobody can ever take it away from you.
And so I believe, if your customers are assets, and I think they are, that investing in the data, in the knowledge, in the heterogeneity, can actually lead to better outcomes to companies than pure product-centricty.
There's one more point I want to raise, to really help us understand the contrast between product and customer-centricity.
And I, and I really focused on the idea of the divergent thinking.
We have this product goodness, what do we do with it?
I hope that you'll see that many of them are entirely consistent with our discussion so far.
The different kinds of metrics customer retention, lifetime value.
We're going to be saying more about those as we go on.
Instead of diversion thinking, what do we do with this product?
What products and services can we develop?
What information can we provide?
What can we do in the relationship to create and extract more value, more value for these really valuable customers?
So again, moving from the product centric world to the customer centric world is very difficult, going from divergents to convergent thinking doesn't happen over night.
It requires all kinds of different incentives, it requires different kinds of people with a totally different mindset.
That's one of the challenges associated with customer centricity and I want to talk about a few more.
I want to spend a little bit more time thinking about the distinction between those really focal, those really valuable customers, and the eh, not so valuable ones.
If you take my words a little bit too literally, I keep focusing on the valuable, valuable, valuable customers.
And I keep saying let's just zoom our whole business around them.
If we were to do that, then we've become very vulnerable.
And what happens if we're wrong about them?
What happens if there's other customers out there who are fairly valuable?
What happens if something changes to our product or in the marketplace that turns those really valuable customers against us?
And so here I, I want to raise an important but subtle point.
The idea that, the more we zoom in on those really focal customers, the more we need the less valuable customers, in order to have a stable mix.
The metaphor that I like to use here comes from finance.
Alright, we want to have some, some really high flying stocks in our financial portfolio.
We definitely want to have some of them.
Those are going to be where the real growth comes from.
So in our customer mix, we want to have that same kind of portfolio approach.
This is where I come up with the notion of The Paradox of Customer Centricity.
It goes like this.
The more we zoom in on those really valuable customers, the more we need those other customers around in order to have a stable balance for the company as a whole.
You see, with only a few exceptions, no company can be truly, purely customer-centered.
If you are a private wealth manager and your customer base consists of four billionaires.
You can be a trusted advisor to each one of them.
But if you have millions or tens or hundreds of millions of customers, it's a matter of finding the just right balance between being truly customer centric with the customer segments that we see as really valuable.
But being products centric with the remaining customers, who aren't as valuable.
Now the difference between a true product centric firm is we're not going to let those so-so customers drive the business.
We're going to continue to focus on the customer-centric ones for growth.
We're going to continue to focus a disproportionate amount of our R&D activity on those really good customers, coming up with products for them, hoping and finding ways to make those same products palatable and attractive for the product-centric customers.
But it's a matter of finding that balance.
That's the paradox of customer centricity and one of the challenges for firms is to figure out how to do that well.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
You can make an argument, that each one of them is the customer and depending on who you talk to, at the pharmaceutical firm, you'll get a very strong argument, one way or another.
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
But, but, one kind of customer matters more than others.
Going back to the Proctor and Gamble example that I mentioned before, there there's a tremendous amount of clarity on it.
Proctor and Gamble knows, that today, their customer is the retailer.
So it's important to first sit down and figure out, who the, the customer could be.
Who are all the different constituents, who could qualify as being the customer?
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
We also want to think about, what are the barriers associated with customer centricity.
There might be reasons why, we can't treat customers differently, for instance in the pharmaceutical space.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
If the company's been focused on, developing and distributing block busters for all of its existence, it's hard all of a sudden, to pivot around the customers.
The ones that I just mentioned are fairly general, they're fairly broad, but every company is going to have its own challenges.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Very often, the resources are going to be financial.
You're going to have to invest money, to build the information technology systems and to hire employees, and to start developing a data infrastructure.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
Sometimes, being the only one doing the customer centric thing, is the way to make it most successful.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
Making plans now, for changes that they can make in a few years.
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be other kinds of experiments that, that a company is going to run.
Let's just set aside, a part of the organization or group of customers.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
Now, of course the virtual world provides great things.
We can buy almost anything we want, at any time we want, on various websites and through various apps and so on.
And yet, government statistics tell us in the United States at least, and this is fairly similar in other parts of the world.
And this will be a really interesting one to follow because currently I think only about one percent of groceries in the United States are actually sold online.
Pete always likes to say that the fraction of groceries sold online in 2013 is roughly what it was in 1713.
First of all there may be the issue of delivery time.
Of course our friends at diapers.com can get us diapers by 6pm in the United States as long as we order them by 9am on the he same day.
But even that may be too long for some of us.
Do you really want to buy your bananas online?
How do you know what they're going to taste like?
Would I really want to buy this shirt online, without knowing how it fits and feels?
But that is a second barrier, uncertainty about what it is that might arrive when it comes to your door.
And then the third thing that's typically voiced by consumers as a problem with the virtual world, is the cost of returning things, even if there are free two-way shipping, and so on.
And so those two worlds are going to continue to coexist like this for some time to come.
So let me again share with you a very, very interesting piece of academic research.
It was done by some of my colleagues up in Toronto, the Canadians, once in a while do some very good things.
So, let me share one of the good things that Canadians actually do.
I'm part of the Commonwealth, so I feel like I can say that.
So, what they looked at is, they looked at sales at amazon.com in various zip codes around the United States, and whether or not those sales would be influenced were a physical store to come into the neighborhood.
All of a sudden, a bookstore opens up across the street from your apartment.
How would this affect the sales at amazon.com, if at all?
When a virtual world store opens up in a zip code, sorry a physical world store opens up in a zip code, virtual world sales do go down, but they don't go down for every product.
You can probably bet that that book is going to be in stock at your local book store, and so you might be able to run across the street and buy it, and indeed that's what the researchers found.
When a real-world store opens up in a zipcode, amazon sells fall, but only for products that are popular.
Now if you wanted to buy another book, probably better than theHarry Potter book but less popular.
There's a book called 101 years of all black trivia.
But if you wanted to buy that youd be unwise to go into the physical store, because the physical store would be unlikely to carry a book thats going to be so low in terms of popularity.
And it's a very, very interesting idea about how products and services that are sold over the internet, change, or the mix of products and services sold over the internet changes when we offer customers more and more variety.
Let's start at the start.
This is module one, online offline interaction, omni channel, and all those great buzz words.
So, as I mentioned earlier we all live now both in the physical world, and also in the virtual world.
So what I want to do to begin our discussion here is to think about the two most important frictions that the real world throws our way.
That the virtual world helps us get over in terms of overcoming those things.
So the first friction that the real world throws our way is a friction called search friction.
So you face the following problem.
It's so very, very hard for you to know.
So, you think, well the closest store to my house is three miles away.
Let me go over there and check out the products and prices.
And you find a price on a TV there, let's imagine it's 2,500 U.S.
And so then you're faced with another decision.
Do you buy the product there at the store for $2,500, or do you incur the cost?
The search cost and the time cost to get in your car and to drive to another store, in the hopes that you might find a cheaper deal.
So this was back in 1987, and this is called the friction of search.
Meaning that if you want to get better deals, better prices, better assortment, better value, higher satisfaction, you've got to go out and search for things and you incur a cost of doing so.
And this is a problem that's been studied by economists for decades and decades.
In fact, a very famous economist who won the Nobel Prize, talked about the economics of information.
And when you should just stop and say okay, enough is enough, let me buy this one.
Now let's fast forward to 2013.
Or even 2011, because that's the Rugby World Cup again, 24 years later.
It's the same two teams playing in the final.
Again in my home town of Auckland, New Zealand.
And now, instead of having to go through that process, you can go onto a website, let's say, milo.com.
M, i, l, o, .com, started by one of our students at the Wharton School at The University of Pennsylvania, and later purchased by ebay.
And milo.com will tell you the prices and the assortment of the various products that you might want to buy.
And so what the Internet has done in that case is, it has reduced the friction of search.
Reduced the friction of search, so that's the first major thing that the online world does, that helps us out in the offline world.
A business like Yelp.
you might want to figure out where you're going to go and eat your dinner.
If you go onto Yelp, you can get reviews of other users about what restaurants are the best restaurants to eat at, the best value in your neighborhood.
So, there are many, many important businesses that have started to reduce the friction of search.
That's the first one.
The second friction that gets thrown your way is the friction of the geography that you end up living in.
So let's imagine that I live in Manhattan.
Let's imagine I lived in New York City.
In New York City everything is available to me all day, all night.
I have all the shops that I want to go to to buy anything that I could possibly Imagine.
If on the other hand, I have a quieter life and I live in Iowa City, there are some benefits of that.
But also in terms of the products and services I have available to me, they are much more limited.
So, there's the friction of geography.
Meaning that the location that you have chosen to live in, offers you certain benefits, but also imposes certain costs on you.
So if you want to fancy pair of designer jeans and you live in New York City, you can probably just walk out of your door and go and buy a pair from any number of stores right there in Manhattan.
If you live in Iowa that's going to be a little bit more difficult.
So you might want to therefore go on to the Internet, step into the virtual world, and purchase products that then can be delivered to your geographic location.
So that's the second thing that the Internet does for us.
It reduces the geographic friction of where we live.
There are other things we could think about as well, like transport frictions and so on.
But search friction and geographic friction are the two most important principles, that help us understand how the real world and the virtual world interact with each other.
So, by now we probably all have a good idea of the basic concept behind the long tail.
So let me explain what's going on here.
the colleagues wanted to try and understand or disentangle the supply side effective the long tail, meaning there's a lot more variety available verses the demand side.
Was explanation for the long tail, which is it's now easier for you to search and find things that you really like that match your tastes, those products in the orange part of the tail.
So what the study authors did at MIT is they got sales data for a large retail company that was selling through two different channels.
And they wanted to see if both of those channels had the same mix of sales going through.
Now the prices and the products were identical in both of those channels, but they wanted to ask the question, is there any difference in the way those channels are delivering the product and customers?
Okay, so let me introduce now a diagram.
It's actually a pretty cool idea and one that you may have come across before, but perhaps not in this context.
The gini coefficient is equal to that area A.
So let me explain what's going on in this diagram.
It's often a diagram that's used to understand the equality or inequality of incomes within a country.
But it can also be used to understand the equality or inequality of sales across various products sold by a particular firm.
So to help us understand this, let's go down to point C there on the diagram.
Point C is about half way between zero and 100% on the X axis.
So the implication there would be, the bottom 50% of people in this particular country have about 20% of all of the income.
So this is a country where the income is a little bit unevenly distributed.
That would be a country where all of the wealth was held by a very, very small number of people.
Similarly, if you thought about products, if you pull that circle or semi circle in, that would be a company where almost all of the sales were just coming from one or two products, that's kind of the idea.
So what they found, the author's of the study when they looked at this, is that the gini coefficient was less concentrated.
So the internet channel looked more like a long tail sales distribution and the catalog channel looked a little bit more like the traditional 80 20.
When the researchers looked at the data in more detail, what they found was, that the sales on the internet channel were more spread out, more niche products were being sold on the internet channel.
Now this is very, very interesting because if you recall, when I mentioned the study at the beginning, the types of products sold were identical on the two channels and also the prices were identical as well.
So there was no supply side explanation in this case.
So perhaps when you're buying on the internet, it's easier for you to find those products that are more niche and less popular.
And that's exactly what the authors of this study found.
They found that on the internet channel, because there are a variety of tools like reviews and ability to search and so forth, that makes it easier for you to find stuff that you wouldn't necessarily come across otherwise.
So isn't that very, very interesting?
The long tail is a supply side story.
I can offer more variety.
I'm more able find things that exactly ma, match my tastes.
And what's clever about this study, is the office controlled the supply side, and they found there was more long tail like sales on the internet compared to the catalog and the reason was this demand side explanation.
Now, maybe you can think of some other thing that you could put on the X axis, why does it just have to be product.
So maybe you're thinking of something right now.
So maybe if I'm diapers.com, I'm selling most of my product in Los Angeles and New York City and San Francisco, those are the locations in the head.
I sell a few things out in some strange little town.
I shouldn't say that.
Because maybe somebody lives there.
I sell a few things out in small towns.
But collectively, all of those small towns throughout America add up to a lot.
So the long tail is also a concept that can be applied to geography.
And I'm just going to show a quick example of that from my own research.
So here on the slide are some of the companies that we've been talking about as we've been going through.
In this case, the research is based not on Diapers.com but on their friends over at Netgrocer.com.
That's a retailer that ships to your house various grocery products that you might otherwise buy in a supermarket.
So, to understand how the long tail works, what we need to do here is to think a little bit about the notion of similarity and differences between different locations in a large country, be it the United States or some other country that we may be looking at.
It's about 2000 miles.
We can also compute the distance between Chicago and Springfield.
That distance is about 200 miles.
So in terms of physical distance, Chicago and Los Angeles are quite far away but Chicago and Springfield are quite close.
However we think about social distance, the type of people that live in Chicago might be more similar to the type of people that live in Los Angeles than to the type of people that live in a small town like Springfield.
So if we were to look at the sales across the United States of a company like diapers.com or netgrosser.com, what might we find?
So I did this, again with my colleague Jonghei and also another friend Sam Wui at, NYU, and what we found was very, very interesting.
We found that the sales of an Internet retailer also spread out in a long tail fashion across geographies.
So I'd just like to wrap up our discussion of the long tail with a couple of other things that I think are really interesting and also to give you a recommendation of a website that really illustrates this point.
So two critiques of the long tail.
First is this idea of the law of natural monopoly.
Things that are unfamiliar also tend to be less well-liked as well.
So those two ideas run a little bit counter to the long tail, but I still think the long tail is a phenomenal concept.
If you want to see the long tail in action, try this out.
I've put a link there on the slide that I think you'll really kind of enjoy.
the most popular things come up first, or the links Google thinks are going to be most relevant to you.
So most of the time, when you do searches on Google, you get exposed to, in terms of our language, really only the things that are in the head, not in the tail.
So then when you search for whatever it is you're looking for, you won't be shown results one to ten on the first page, you'll be shown the results from one million onwards, or one thousand onwards.
You can choose on your own.
And then finally, I put in another link.
If you'd like to learn more about the concept from the gentleman who really created it, Chris Anderson.
So again, thanks for being part of our discussion on the long tail.
To me, this is one of the most interesting concepts in online, offline.
And I think it's one that will be very useful to you guys.
And as a result, local stores, local restaurants, local merchants aren't motivated to give you what you'd like.
most people happened to want to wear blue ties, and you wear a red tie.
Now think about the problem faced by manufacture and seller of ties if there's a cost associated with producing more variety.
The manager of that factory and that store might say, you know what?
Only one fellow wants a red tie.
We're not going to make any red ties.
So I'm going to explain in the next few slides how this problem can be overcome through online intervention, particularly through sellers who operate on the internet.
to make a more personal example here, I often wonder myself in myself in Philadelphia why it is that I can't get Vegemite when I go to the local supermarket.
Let me show you a picture of Vegemite.
Here's a little kid with Vegemite all over his face.
It's a delicious black paste that you have on toast with cheese and avocado and stuff like that.
I look for it all the time when I go to the supermarket in Philadelphia, but I can never find it.
Why?
Because I'm probably one of the only few people that would actually buy it.
So the store manager who wants to stock items that are profitable and sell frequently, is not going to pay attention to my preferences.
I'm a preference minority.
The internet, however, could solve this problem.
So let's go again, a little bit of background.
And, the research for this particular article that I wrote and published with a friend of mine, Jeonghye Choi, at Yonsei University, is based on data that we got from diapers.com.
here's the article itself, the title of the article.
if you want to you can always go and read it for more details, but I'm going to give you the flavor of the main findings.
So, let's see how this works.
The notion is that if you're selling things online, that gives you the ability to aggregate people.
Maybe there's only two people in Philadelphia that like Vegemite, but in all the towns in America maybe there's 100,000 if we added all those people together.
And even though it wouldn't be efficient for us to serve them in individual shops, we could sell that product over the internet, that's the basic idea.
So now let me get into the details and conclusions of this particular study, again using the data from diapers.com that we're all by now, pretty much familiar with.
So, in order to test out our idea, that people who were different from their neighbors weren't getting served adequately by offline stores, Jonghei and I went out, and we did a little bit of a field study, kind of a fun field study, and here's what we did.
Where we went out and we visited different supermarkets in the Philadelphia area.
Now, what's interesting is all of those stores, all the Fresh Grocers, they're all the same size stores.
But their local markets were different with respect to the number of households in the local market that had kids.
Store 3, on the other hand, about 16 percent of the households in that neighborhood where that store was located, had children.
So, what does this mean for our idea or our theory?
Well, the people who live in the market where there's only 10% of households with kids are going to be relatively more neglected by the supermarket than in the market where there are 16% of households with kids.
So if my friend Chris is the manager of the store, he's going to say, you know what, not that many people in the 10% market have kids.
I'll just have Pampers and a few leading brands on the shelf, and I won't worry about having a lot of variety.
If, on the other hand, he's managing the store where 16% of the target market has children, he's going to say, you know what a lot of people in this local neighborhood have kids I'd better cater to their tastes and preferences.
And so what you see in the chart is in neighborhoods where there's a higher fraction of households with kids, the actual stores have more shelf space, more linear square feet, and more variety of product of the shelf.
Now of course this doesn't prove our theory, but it does indicate that local stores pay attention to the composition of the people who live in the neighborhoods, and then they stock merchandise accordingly.
As a little side note, this was kind of a fun thing to do in Philadelphia.
Jeonghye and I had a pink measuring tape, we were running around trying not to get caught by the store managers measuring how much space was allocated to these things.
If you've been to Philadelphia, it's kind of a tough town.
Okay, so let me elaborate a little bit more on this next slide with the actual theory, that we built up to try and explain this concept.
So imagine we have two different markets.
It could be half the people want Vegemite, or any other product that you could come up with.
And so notice in that market there is one store, and the store is 200 square feet in area.
And so the manager of that store says, gee, half the people in the market have this particular characteristic, let's say households with kids So I'm going to allocate half of my store to products that cater to those people.
Now in Market B, again there are 100 people who have the characteristic we're looking for, in this case households with children.
But the total population of the market is 1,000 people.
So these people with kids are a little bit more rare in this case.
They're only 10% of the population.
Now notice however, because Market B has more people in total.
there's more stores.
And we're just assuming that the number of stores grows with the population.
So it, in a market of 200 people, if there's one store, in a market of a 1,000 people, there will be five stores.
Now again my friend Chris who does a lot of store managing I guess.
The customers who live in Market B, everything else held constant, should be more likely to want to buy their products online, in this case from our friends at diapers.com.
So let's see if that is in fact true.
So now Jeonghye and I went and we looked at the real data.
This is just a map, it's a black and white map, but hopefully you can get the idea here.
We call this the Preference Minority Index or PM Index.
And the darker the color, or the darker the shading, that means customers are more isolated.
That's in the top part of the map.
So this is indicating some support for our theory that when customers are isolated, they're more likely to use online merchants instead of offline merchants.
So the next thing that we did after looking at the raw data is do what a lot of us here at the Wharton School will do, whether it's Pete or Barbara or myself, is we ran some statistical analysis or some econometric analysis on the data.
So we controlled for the education level.
We controlled for the number of stores in the area.
We controlled for the population density.
So all of those things were held constant in our study.
And what we found was, yes, there was a highly statisically significant effect of isolation on sales.
And markets where customers were more isolated, they were more prone to go online, and sales at diapers.com were higher.
So now I'm going to explain the magnitude of the effects, which I think is really interesting.
It was also very useful for the company, for the guys at Diapers.com.
But let me explain that, because that's going to be important for understanding these results.
So if you've ever taken a standardized test like an SAT test or a GMAT test, any test at the end of high school or to get into college, those kinds of things.
You'll remember that when you get your score back, in addition to the raw score, you typically get a measure of percentile.
So where is it that you ranked, relative to everybody else that took the test.
That means only 10% of the test takers beat you, and you beat you know, 89 90% of everybody else.
If you're in the tenth percentile, which I'm sure that none of you were, that means that you only beat 10% of the people and in fact 90% of the people beat you.
So, what Jeonghye and I does, we used this same concept, but we applied it to our preference minority index.
So, we looked at all of the locations in the United States.
All of the areas, all of the zip codes that were really, really isolated in terms of people with kids being relatively rare.
So think about that result for a moment.
If we have two zip codes that were absolutely identical in all respects and in particular, these two zip codes had the same total number of households with children, 100 here and 100 here, just like in the example.
If this was a zip code that was more isolated, the online demand at diapers.com was 50% higher.
So we think that's a very interesting finding and also one that internet retailers can actually use when they think about online offline interaction.
And the second one is the second most popular and so on down all the way out into the tail or into the niche products.
So the same thing happened here.
What we found was if we looked at particular products that were niche products, and we compared an isolated market versus a non-isolated market, the sales in the isolated market online for niche products were about 125% higher.
And I'm going to show you this in a diagram to make it easier to remember.
So let me show you what's going on.
There are three pieces to this diagram that are important in terms of understanding the overall concept.
And Market B, the offline retailers, aren't paying much attention to our target customers who are the households with children.
And that's reflected at the bottom of the slide with the little thumbs up and thumbs down in the two markets.
So what does that mean for the way products are sold and bought online versus offline?
So for that, we have to go to the top of the diagram, which is our old friend, the long tail.
And so to just remember, by way of review, that the long tail is an idea or concept that has a plot of all of the products that are available from a particular seller or a particular merchant.
And the X-axis is all products lined up from the most popular to the least popular.
So it just so turns out in the diapers category the most popular brand is Pampers, followed by Huggies, then Loves.
That's a niche product out in the tail that has lower sales than the other tree.
So how do we relate this long-tail idea back to preference isolation and see how the two things come together?
Well if we think about the online retailer, that's our friends at diapers.com, they carry the entire distribution of products.
They offer everything, probably have the largest assortment of baby-related products and diapers.
Probably of anyone in the world actually.
Certainly bigger than any physical store.
Now if we turn to Market A, in Market A there's also pretty good variety.
Meaning that the offline sellers are quite attracted.
Market B, however, most of the sellers are just stocking the popular brand and not really catering to a full range.
So in Market B, the amount of product available is much more limited and is just really focused on the most popular brand.
That's why, in Market B, the customers are more prone to shop online versus offline.
So now we're going to continue our discussion of how the real world and the virtual world interact with each other in online, offline competition.
So if you look at the slide there are five companies that I'm going to speak about.
And this is actually very exciting for me because these are companies I've had the pleasure of working with in terms of analyzing their data and also doing some research trying to also help out the management team a little bit.
And I'm going to show you how that business grew and evolved and try and give you a sense of how it is that e-business companies, e-commerce companies, spread themselves over time and over space in particular markets.
The second company I'm going to talk about is one of my favorite, of course, is part of Quincy family.
In fact, you may see a little bit behind me.
I'm actually still here in the Quincy warehouse again, backgrounded by 1,200,000 square feet of warehouse space, robots and so on shipping diapers and all kinds of stuff all the over United States.
This company was founded in 2010, in February, by four students of the Wharton School.
They wanted to do something very, very interesting.
You would go in to an opticians, get your eyes tested, maybe try on a bunch of different frames and buy glasses in that environment.
Now what the forefounders notices is that at that point in time, less than 2% of that product category in the United States was sold online.
So they built a company to try and change that and sell glasses online and also through offline channels.
So we'll talk about those guys a little bit.
If you happen to be in Boston or New York City, you could even go and visit the flagship store.
It was founded in 2007 by two gentlemen coming out of the Stanford Business School.
The current CEO is still there, Andy Dunn, and their idea was to sell men, for all the guys out there, fashion items at great prices, and also fashion items that really sort of fit you and gave a bit of a feel and trim than other products.
And if we don't have small children ourselves, we might like to gift that to somebody else.
So I'm just going to explain a little bit about what we do as academics when we examine these things, and what I've done with my friends and co-authors.
Is we're able to get the sales data from these companies and match it up with other data, mainly provided by the US government, about the kinds of people that live in different areas of the United States.
And then understand how the characteristics of the physical environment affect the sales of a virtual world company.
So why is it that one zip code has very, very low sales of diapers.com products and another one may have thousands and thousands of customers?
If you're interested in reading this, the article's called What Matters Most in Internet Retailing, it was published by the Sloan Management Group.
So the first thing that we found kind of summarizes some of the other things that we talked about earlier, is that when an online business opens up, it changes the cost benefit for the shopper in particular locations.
And let's imagine the closest one is two or three miles away, when an Internet store opens up.
Let's call it jeans.com.
That changes the relative attractiveness of shopping online versus offline.
So that's the first thing, when an Internet company comes into play, it changes the relative cost and benefit of shopping online versus offline.
So the second principle that I discovered, primarily in the beginning looking at sales from netgrocer.com starting in 1997, is that the way e-commerce companies developed their sales is very structured and very, very predictable.
And so what I'm going to show you now is a very interesting graphic that starts out way back in May, 1997.
And there's a picture of the US, you can see there on the screen, United States.
Those shaded areas, areas with somebody in that location, in that zip code, of which there are more than 30,000 in the United States, had actually placed an order at the website netgrocer.com.
Way, way back in the dark ages of Internet retailing.
That's why the whole map now looks rather dark and rather shaded throughout the entire United States.
How did this business grow?
How did it go from 34 zip codes in 1997 to 3.5 years later in 2001 selling into more than 18,000 zip codes?
And if we were to sit there in January 2001 and say to ourselves, in February 2001, where are the new customers going to come from?
Are they just going to pop up randomly in the United States, or will there be some special structure?
So primarily around California and primarily around the New York City area, and what you can see as the slide rolls through, is that sales tend to pop up in areas around that had existing sales previously.
So you tend to get more new customers showing up in locations that are close to locations that had customers before.
Well, there's really two reasons.
The first reason is perhaps, I buy something and I live in zip code 19123.
And when I'm at my local cafe, or when I'm in my apartment building, I tell one of my neighbors, hey, you really should try soap.com.
The second thing that goes on that's also very, very interesting is it could be the case that customers are observing the behavior of other customers.
You might have asked yourself the question, why is that e-commerce companies have really, really ugly packaging sometimes?
Why does our friend Chris at soap.com ship us stuff in a box that's green and brown and orange, and all kinds of colors that if you were wearing them, you would look rather, we'd say clownish?
So when my order from soap.com comes to the office at the Wharton School and it sits there in the office, anyone coming into the suite is going to see it.
So keep those two things in mind, because when we get to our next module and we're going to talk about how to grow the customer base and how to find those lead users, thinking about leveraging word of mouth and leveraging social observation, is going to be very, very important.
Now let's move on to Principle number 3.
So you might have wondered, and you can go to the website doppleganger.com, who your celebrity doppleganger is.
That is who's your celebrity look-alike?
If you were to walk down the street, would people ping you as George Clooney, Brad Pitt, Jessica Biel?
So perhaps Pennsylvania 19104 is almost the same as another zip code in some other place in Texas.
And so we wanted to examine this idea of whether or not similar locations that were far away from each other will also start to buy things online at roughly the same time.
So the original idea for this actually comes from a very, very interesting study conducted way back on the 1970s by a sociologist.
And what he did is he kind of changed our idea of distance from just purely physical distance to also thinking about social distance.
So in the original study, Professor Fisher showed that if you lived in Chicago, there was a higher chance that you would meet or randomly interact with somebody from Los Angeles, which is very, very far from Chicago.
So even though Chicago and Springfield are close together, in many other ways they're quite different.
Even though Chicago and Los Angeles are very, very far apart in terms of distance, there could be a lot more similarity in terms of the taste of people that live there.
They both like big cities, they both like to consume certain kinds of goods and services.
So continuing with our discussion of Principle number 3, what we found was very, very interesting.
When we looked at the sales in the Internet retailer, initially those sales started to take off in larger cities and spread, like the pattern that I showed you earlier, spread through the notion of proximity.
Meaning, people living close together were either telling each other about the good or the service or perhaps copying each other from seeing discarded boxes and so on.
So in the beginning of the sales process, those sales started to spread out by proximity from one customer to another.
But what happened over time is very, very interesting.
Sales in those key locations started to, for want of a better term, taper out and reach a steady state, and then pick up in other locations that were farther apart from each other, but yet shared very important characteristics.
So you might have two locations in different parts of the United States, maybe even 1,000 miles apart, but the basic profile in terms of the age, income, occupation, education level and so on and also of the retail environment will be very, very similar.
And because those locations are very similar in terms of who lives there and the opportunities for shopping offline, they tend to migrate online at roughly the same rate.
What we did when we discovered this in the beginning through proximity, over time more through similarity of locations, that we were able to develop something we called the long tail plot, again borrowing from our friend, Chris Anderson, but this time a long tail plot over location.
So if you look at the slide, what you'll see is you'll see, on the x axis, different locations in the United States and the y axis is the level of sales.
So the sales start very, very high in the best location, and then they taper down to the lower locations.
But those lower locations that generate small sales levels individually are still very, very important for an e-commerce company.
You can't just survive by hitting the big markets.
You have to also hit the many smaller markets that collectively add up to a lot.
It's the same idea as Chris Anderson's long tail, but this time if you think back to that previous discussion, this time the x axis is about rotation as opposed to being about products.
Okay, let's continue on now to Pete's area, which is customer assets.
And, I'm just again, going to add a couple little things here in terms of digital considerations.
And additional things we have to think about for execution.
So, as Pete told you, I'm sure very, very clearly, your key goals are to attract, engage and retain the right kind of customers.
Some customers, as Pete told you, you actually want to get rid of, because of the heterogeneity, one of our favorite buzzwords here at the Wharton school, in the customer base.
Some customers are just not worth hanging on to.
So, as Pete has told you, you should never, ever pay more to acquire a customer than you can expect to get back.
So, the customer life time value of my friend Chris, who is renting cars from Hertz, should be higher than what Hertz had to pay to get Chris as a customer.
The second thing that's very important though is the CLV, the customer lifetime value when executed in the digital marketing environment needs to also consider what I call RLV.
However, if I'm a popular guy and I tell a lot of my friends about harrys.com, I might have a very, very high referral lifetime value, because I'm bringing other people to the party.
So let me give you an example from data based on diapers.com, one of our case study companies, that just shows how powerful this point is.
So a few years ago, my colleague Jong He and I got all the data from diapers.com, and we looked at the first 100,000 customers that became customers of diapers.com.
And back in those days, if I were a customer of diapers.com and I sent an email referral to my friend Amy, and then Amy made a purchase at diapers.com, I would get a $1 credit towards buying more diapers.
Also, what I could do is, I could print out physical coupons and put them on all the cars on Walnut Street here in Philadelphia and some stranger might pick them up and take my code and enter it, and then I will get a credit if they became a customer.
So, two thing that are very, very interesting to us about this process.
First of all, about 8,000 of those 100,000 customers engaged in this customer based promotion or word of mouth, if you will, that's kind of interesting.
About 8% of the people were motivated to go and try and acquire other customers on behalf of the firm.
Now, of course, the game going back to what Pete talked about, we all know about averages, some important measures, so the average number of people that were brought in by referring customers was about four.
It's a pretty powerful number, but again, in the Internet, it's more than just the average that's important.
There's going to be some customers out there that just love you so much they may go completely nuts, as it were, and so it turned out, when we looked carefully at the data, the top 100 customers were generating about 15,000 other customers.
So think about that.
One of the most important things you can do, is you can encourage your existing customers to refer other customers.
So, non-negotiable, in the black, at the top of the slide, is that you must still attract the right target customers Pete has been talking about for the last few weeks.
However, there are three interesting nuances that come into play here.
First of all, your interaction with customers changes from just a monologue, you sending out messages, now into a conversation.
So, let me give you a personal example.
Recently I've been flying from Philadelphia to San Francisco to our west coast campus.
And sure enough, within a few moments later, Virgin will tweet back to me and engage me in a conversation.
In fact, on a recent flight, I received a direct message from somebody at Virgin telling me if I took a screenshot of my status on United Airlines, that Virgin would match it.
So think about the power of that medium to change from a monologue to a conversation.
So, that's going to be an important thing.
How can we use technology to engage in real conversations with our customers.
The second thing that we can do with customers, is we can amplify activities that go on in the real world, out into the virtual world.
So, an example that I'll get more into a little bit later on is, way back in September 2011.
warbyparker.com, another company that I'll talk about a little bit, staged an event in the New York public library, where their friends, went in there and took over a whole floor, wearing, Warby Parker glasses.
This was of course picked up by the traditional press.
And then, there was an amplification, from that real world event, pushed out through the virtual world.
And then finally, the third point is, we need to be aware of this possibility of what I'll call the long tail leverage.
The long tail is the idea, the conceptual idea, that there are some people who are just sort of extreme, like those customers for diapers.com that referred 150 customers each when the average was only four, so how do we use technology to tap into who those people are.
Okay, one final thing I'd like to mention here, guys.
But it's a very, very interesting distinction that's important for thinking about how to execute with customers.
Through things like loyalty programs and referral programs and so on.
And both of these things are very very important to companies who want to get customers to acquire new customers.
So let's start with the selection effect.
So imagine I'm a customer of diapers.com.
And diapers.com is going to give me some cash, or some points if I refer somebody else.
Now, I happen to refer my friend Chris, just because I know that he recently had twins, now the CEO of diapers.com doesn't know that, but I know that, so I'm better able to find a new customer.
So the person who's doing the referring is deliberately picking out people who are going to be very, very appropriate for the good or ser, for the good or service.
That's the selection effect.
And my colleague here at the Wharton School, Christophe Van den Bulte, has shown that customers who are attracted through word of mouth and through referral, have higher customer lifetime values than those who are not, because of this selection effect.
The second effect is what I'll call the treatment effect.
It wasn't through Google search.
But he got introduced through me, his trusted friend, and because that was the way he found out about something, it's more natural then for him to engage in the same practice.
So, when we looked at that diapers.com data, remember I said on average, there was about an 8 to 10% rate of referal.
Well, if a customer was acquired because of referral, the chance that they then referred went up to about 15 to 18%.
So that's the difference between a treatment effect and a selection effect.
But both of those things are very, very important.
Number one is the brand, we've just through.
Number two is the customer, and then the third one that I mentioned at the beginning of this module is that marketing expenditure itself also should be thought of as an asset.
And, again the naieve way of thinking about marketing is we have top line sales, minus what we spend on marketing or advertising, is equal to our profit.
Now, if we make that marketing span equal to zero, it's not the case that our profit will go up by the same amount.
That's something that we'll be exploring in more detail as we go ahead.
So the first thing I'd like you to do, just over the next few days, is to try and think about some experience that you have buying coffee, paying for something, booking a hotel, communicating with your friends, keeping track of your appointments.
And try and think about how the status quo situation could be solved or fixed.
In the same way that Howard Shultz figured out that the coffee situation in America, was sub optimal and he fixed it by introducing Starbucks.
And try and think about what you've learned from Barbara and also our additional discussion today about how in the digital age a brand needs to be authentic, transparent, and humanized and try and see what elements of the execution in that website touch on those three points.
Hopefully, you'll have a good time doing that.
And that's the end of this particular piece.
So now we're going to get into some very, very interesting material that relates to what we were discussing earlier about lead users and people who are important to reach out to.
We're going to examine that issue in more detail by trying to understand how information spreads from one person to the next, either in an offline environment, or an online environment.
So first of all, I'm going to show you a very, very controversial study.
And I'm going to ask you to click on the link to play it yourself.
It's about a minute 45 seconds.
It's a study on the spread of obesity through a network of people in Boston.
I think you'll find it interesting just in terms of understanding what a network really is and what the elements are.
I'm making the summarize by definition what things take place in networks, do you need individuals, do you need them to be connected and so on.
Instead of the individual, we're going to think about locations.
The first example is going to be some of my own research on Internet retailing.
And we're going to look at how a company called netgrocer.com spread itself throughout the United States through a process of word of mouth, contagion, and so on.
So think of that as being in Facebook, or one of those other social networking environments.
It's going to be looking at a network of physicians in Los Angeles.
So, if I'm friends with Chris, Chris now is the doctor, he's our all-purpose videographer and he's prescribing a certain kind of drug to his patients, maybe because he and I are friends or he's influencing me, I'm going to prescribe the same drug.
That's a study done by some colleagues here at the Wharton School in conjunction with another professor at USC.
This is also going to look at diffusion for an Internet retailing company.
So let's begin.
And it's actually out of a book by some professors at Harvard.
But I'm just showing a visual here on the screen.
Basically, what the study proports to show is that obesity spreads almost like a, a virus.
Like a flu, or something else, that's why it's controversial, from people who are in a network.
Who's perhaps struggling a little bit with obesity then I'm more likely to become obese than somebody who's not in that social network.
That's why it's a little bit controversial because it's hard for us to get our heads around the idea of something like obesity, which is a physical thing, really spreading more like a virus which is a cold and we can imagine that being transmitted.
Again it's about a minute and 45 seconds.
Now that you actually watched that, let me just sort of reiterate what the elements of networks are.
And share what I think are some of the most interesting research findings here.
So one of our colleagues at NYU, Sinan Aral, who does a lot of work in the area of networks, he says, really what a network is, is, involves pathways through which information and resources and support flow between people.
Or, we could also extend this to, to neighborhoods.
So it could be a social network of people who are going to the same church or the same club in Philadelphia.
Or it could be virtual, like Facebook, LinkedIn, Twitter, and so on.
Now what's really interesting here and what's written at the bottom of the slide is that networks usually exhibit something called homophily.
But that's a good one to hang on to.
If you mention it at the next party you're at, you'll be very popular.
So people who are using friends, people who are your close associates.
Probably on average, are more like you, than they are just like random people.
So people have similar cultural backgrounds, similar tastes, similar income levels, tend to kind of flock together, whether it's in a virtual neighborhood, or whether it's in a physical neighborhood.
We'll be coming back to that later on.
So a network can be really, really simple.
Chris and I, we're friends.
So it could also be hundreds, or thousands, or even millions of people.
I guess, by now, at least a billion people are connected in one big social network.
You then need to have some kind of connection between people.
And then also some ability to share information, share resources, and have exchange.
So if you want to see some more background on that, again I've provided another YouTube link for you to be able to do so.
So that's an important thing to keep in mind too.
Is that entering a network, whether it's joining a local club, going to a local church, or participating in a social network, is a choice and presumably other people have made the same choice.
we also decide the networks, whether they're real networks or social networks, virtual networks.
How many people we want to be connected to.
And then thirdly, at the bottom of the slide, an important principle is how embedded we are within a network.
So imagine, for example, that I'm friends with Chris and a whole bunch of other people at the University of Pennsylvania.
And I'm connected to almost everybody on the campus.
If that were true, then I would be a very embedded person.
Because I'd be connected to everyone who's then connected to each other.
So in some sense, I might be more central than other people in th network.
Okay, so, a little bit of interesting research that's been done I guess over the course of the last 40 or 50 years, about how networks work, and how influence works.
I might be influenced just by seeing what other people are doing.
So way back in 1968, some professors at Columbia did the following experiment.
They put a person on a street corner in New York City and the person was, like this, looking up at the sky.
And what they wanted to see was, would other people around also, upon seeing somebody looking up at the sky, also look up themselves?
Now when the experiment is put 15 people around, just standing looking up at the sky, then about 40% of the people who weren't part of the experiment also just looked up.
So what that tells us is, it tells us often times, there's pressure to do things when people around us are engaging in some sort of behavior.
Or it can happen through observing things.
another classic study of influence that was done in the 1960s, really, really helps underly the key concepts here.
It was also repeated in 2002.
So let me explain what that experiment is.
It's a very common phrase, and it's often used to indicate that there's no more than six people between you and anyone else in the world.
So all of us out there enjoying the Coursera class are connected by no more probably than six degrees.
So what do I mean by that?
Let me go back to the original study.
To write a letter to individuals who lived in a different city in the United States, in Boston.
So again, let's imagine they were asked to send letters to people like Chris in Boston.
What they had to do, was to write a letter and send that letter to somebody that they thought was closer to the person in Boston than they were.
New York City is closer to Boston than Nebraska is.
And what they found was it took about six steps, hence the term six degrees of separation.
Now that same experiment was repeated by some professors who did something called The Small World Project, you can look that up on the Internet, in 2002, where they got 98,000 other people to communicate random people around the world, communicate with them.
But this time not through physical letters, but through typing and sending emails.
So I might be asked to send an email to someone who is an orthodontist who lives in Finland.
I'm not allowed to Google that person and email them directly.
I have to email somebody who I think is going to be more likely to know that person than I am.
And again, it seemed to take about six steps.
We're all connected by about six steps.
Now that's connections but connections don't necessarily mean influence.
It turns out that for influence, there are really just three levels or three steps that matter.
What do I mean by that?
So again let me think about my friend Chris in the example here.
So Chris and I are friends.
So if I tell Chris, hey Chris, you should order all your detergent from soap.com.
I might be able to influence his behavior.
And then Chris might tell his younger brother, let's say.
But I almost have zero influence over Chris's younger brother's girlfriend's college roommate.
So that's another very, very important thing to understand in terms of influence.
Influence spreading out from you typically will not go more than about three steps.
So today we're going to talk about pricing devalue as part of our go-to-market strategy.
So let me just give you a little bit of an overview of where we're going to go.
Then we'll talk about a framework for how to understand, how to set a price.
And then we'll spend a little bit of time on customer price sensitivity and how to measure it and how to understand it.
And before I say this, pricing is probably one of the key things to really think about in marketing because often times prices are made really really arbitrarily.
Or people engage in cost plus pricing, many things that they shouldn't be doing, and what we want to do in this session is to think about the right way to set a price.
Here's a little bit of motivation for you from a study that was done by the McKinsey Company that looked at various things that firms could do, over 2,000 companies, to improve their operating profits.
But the thing that they did that had the most impact, if they were able to improve their final realize price by only 1%, they were able to increase their profit operating profit by about 11%.
So price is such a critical level, and it's one that we often get wrong, so let's keep that in mind as we go through.
It's a company that sells a lot of private label product.
I believe it's owned by some German brothers, operates in the United States all over the country, there's one here in Philadelphia.
So one of the products that I like there is they sell goza a dumplings that I can buy and I can steam and I can eat them.
Now let's imagine that those dumplings cost me about $3.99.
And I face a problem.
The problem I face is I can't find that product anywhere else, because it's a private label.
So Trader Joe's recognizes that I have this inference problem, so what do they do?
They take a very very common product like bottled water that's available everywhere and then price it at an extremely low price all the time.
So when I come into the store and I see that the bottled water, a product that I can compare that's available everywhere, I see that that's priced very low, that gives me some confidence that the products I can't compare are also fairly priced.
So this example is showing how sometimes as companies, we want to signal through one kind of product, that we're a good seller.
A similar example, if we think about a company like Wal-Mart.
So that's another example of using the product price to send a signal.
The final one I'll share is a very interesting study done by a friend of mine from New Zealand who teachers at the Sloan management school up there at MIT.
And my friend Duncan did an experiment where he sent out shoe catalogs to people all over the United States.
The other half of the people, this is thousands of peopl,e received an identical catalog except the price of the shoes was $49.
Now economics 101 tells us that as the price goes up demand should go down right, but Duncan found exactly the opposite.
Because when you see $44 the way you encode it psychologically is, gee, that's kind of a weird price, I don't normally see 44.
But when you see 49, you feel like that's a discount from 50.
And so what I'm trying to indicate through these examples is the price is more than just a number that indicates what you have to pay.
So how do we set prices and what's the right framework?
First of all we need to think about the marginal cost of the product I'm going to call that the floor.
Obviously we don't want a price below the floor or at least not for too long.
Then we need to think about the ceiling which is the customer willingness to pay.
So number one is the floor, number two is the ceiling, the customer willingness to pay.
But you can't always charge people their absolute maximum willingness to pay.
Why is that?
Because of competition.
So competition is going to be the third factor that will drop the possible ceiling.
If my customer is willing to pay $10 but he can get that product from a competitor for six, then that's going to drop my price from ten down to six.
And then number four is the amount by which prices have to be raised from marginal cost to give some money to distributors or re-sellers to motivate them to sell it.
I'm also going to show you a couple of examples of something called economic value to the customer.
This is a very, very important concept.
There's a product called the wing dipper.
And the wing dipper is a place where you can put the dip within what you want to, to dip your chicken, chicken wings.
I guess it turns out when people eat chicken wings, I don't eat it a lot myself.
And so therefore the restaurants are losing a lot of money whereas if they had these wing dippers, the wing dipper controls the amount and based on the size of your restaurant and the amount of wings that get eaten you can calculate as a restaurant what the economic value of this product is.
So many times in your communication you're thinking about the economic value to the customer and trying to say that in a persuasive or informative way.
So first of all from a company point of view when your setting a price you might need to think about financial considerations what's my required internal rate of return.
So the price that I'm going to charge for the Toyota Camry is somehow going to be related to the price that I'm charging for the Toyota Corolla.
So you need to think about spacing out the prices in a way that's consistent.
And then thirdly you need to think about your own existing image so it may be very very difficult for Walmart who has a low price image to sell really really expensive stuff.
Similarly it may be very very difficult for Sak's 5th Avenue to sell things very very cheaply because that's also inconsistent with their overall image.
So those are three things that are very important to think about from a company point of view.
From a competitor point of view there's a whole raft of things, but here's the three most important.
The first thing you need to think about is that when you set your price, how will your competitor respond?
Is the competitor going to do things that are rational, does the competitor have a deep pockets and so on.
The second thing you need to think about is when you do something in the market with your price how is that competitor going to respond?
So if you're the market leader, in some sense you have a responsibility to try and keep your prices high.
If you're a follower you might have a different kind of strategy.
So those are three important things with respect to competitors that dictate what you want to do with your pricing.
So are you pricing in such a way that allows the collaborator or distributor who's selling your product to turn the product frequently enough?
So this is where I'm going to spend the most time, and the key idea is customer price sensitivity.
In terms of economics, this is sometimes referred to as a price elasticity.
In economics, price elasticity just means the following: if I raise the price by 1% by how much does demand drop?
So if I raise the price of my product by one percent and demand drops five percent that means that the product is highly elastic, there's a lot of stretch to the price.
If I raise the price one percent and demand only drops 0.2 of a percent, that means that the product is very inelastic, very very little stretch.
If I have an inelastic product, I might be able to raise price.
If I have an elastic product I might want to drop price.
So we're going to get into how as marketers we actually measure that beyond the economic concept of price elasticity.
A second thing we're going to talk about are psychological issues.
The first thing is the ending of the price.
I'll also talk a little bit about something called mental accounting.
I'll give you a short summary of a very famous psychological principal called Prospect Theory or psychological theory.
Actually a noble prize winning theory that has some very very interesting implications for pricing.
Right, so the first thing we want to think about in terms of customers is what is it that drives price sensitivity, this fundamental thing that dictates how high or how low somebody's willingness to pay is for the product.?
So I'm gonna go through some of the most common things that dictate price sensitivity.
The first thing that really drives price sensitivity is ease of product comparison.
So if I have one product, product A, that's say manufactured by Johnson & Johnson, and right next to it on the shelf, I have another product that's made by the retailer, a private brand, as Barbara talked about.
If they're really easy to compare and I can turn the products over and see that they're essentially the same thing, then I might be willing to buy the unbranded or the private label product.
So when comparison is made easy, consumer price sensitivity typically goes up.
So as a seller or as a firm, as an entrepreneur, usually what you want to do is you want to make price comparison across you alternative and the competitor alternative somewhat difficult for the customer.
You want to focus them on other things like the quality of your product, your service, and so on.
So if I'm going out and I'm buying new tires for my car and the tires, $500 versus $600, I might be like man, I think I have to get those $500 tires.
But if I'm buying a car for $20,000 and the dealer Amy says to me you know what?
You can have these fancy tires for 600 or like the rubbish tires for 500, I'm like well, it's only another 100 bucks on 20,000, it's nothing.
So when we're thinking about things in percentage terms or as a small piece of an overall expenditure, our price sensitivity also goes down.
So what's the implication for you, the seller?
You want to try and get the buyer to think about what they're buying as really a small piece of the overall picture.
So maybe I shouldn't say this on a public video, but I've already started down the path so let me do it anyway.
So I try to save the school money when I fly from Philadelphia to San Francisco, usually buying a coach class ticket and then trying to upgrade into first class if I'm lucky.
But sometimes I might actually buy a first-class ticket, but of course I'm being reimbursed for that.
The other thing that's very, very interesting in price sensitivity is when there's a separation in time or method of payment.
So in an earlier video, we spoke about the matching of supply and demand and the example I gave you was Uber, which is a car service where you can take your mobile phone, and you can order a car to come and pick you up.
And then the driver, let's say Chris, takes you wherever you want to go.
Simply what happens is you get a text message, or on the app, you get the bill.
So in that case, I don't really feel the pain of payment.
The pain of payment.
If I had to take $20 out of my wallet every time I used Uber, I might think about walking a little bit more often or taking the subway.
But because the payment is happening just purely in my phone and I'm not feeling it directly, I'm because less price sensitive.
So that's another thing that makes price sensitivity lessened.
So if I needed to hire a lawyer, for example, if I were in some kind of trouble with the immigration service, do I want Amy's cheap lawyers $50 an hour, or do I want Chris's expertise lawyers $500 an hour?
In that case, where there's an inference that the higher price leads to a higher quality, certainly for an important service, then my price sensitivity is again lessened.
So hopefully, those four things give you a sense of how you can have the customer psychologically feel a little bit less price sensitive.
Now, of course, this begs the question of how would one measure price sensitivity?
I'm gonna show on the screen a 2 by 2 matrix that explains these four different ways.
You could measure people in their natural environment, buying things or filling in surveys.
Or you could run an experiment, sort of an unnatural environment, but it's controlled, either in the field or the lab, or you could engage in something called trade-off analysis.
Those are the two columns of this matrix.
And then on the rows, you could either measure actual purchase behavior or you could measure their preferences and intentions.
This was actually done by a colleague of mine at the Wharton school, Steve Hoch, who's a professor here.
And he wanted to try and understand for supermarket retailers whether or not they could raise prices or lower prices.
So what they did is they cooperated with an institution in Chicago, those of you who are in Chicago, called Dominick's Finer Foods.
And what they did was in some of the stores, all of the prices were systematically lowered by about 9% on a bunch of different products, like detergents, paper towels, canned tuna and so on.
And in the third group of stores, all of the prices on those same group of goods were increased by 9%.
So, that's a classic experiment where we have a control group, we manipulate some things downwards, some things upwards, and then we look at what happened.
And what they found was very, very interesting.
So this experiment would indicate that those multi-product retailers could probably increase their price a little bit, and you can probably think of some psychological reasons why that works in a grocery environment.
Like it's not really efficient for me to pay attention to every single price and try to remember it.
It might be a different thing if they did it today in 2013, because again, I could take out my friendly iPhone, and have my entire grocery list on here.
Or I could use an app like the SaveOn app or the SnipSnap coupon app, and from those apps I would be able to remember the prices, or at least my device would do that for me.
Second way that we can measure price, and this is a method that was really developed by one of our former colleagues here at the Wharton school, Professor Paul Green.
So in a conjoint analysis, you present people with different kinds of stimuli.
I'll give a personal example on this.
What should be the price?
Now, we knew, of course, we didn't want to price purely from the cost and the cost plus pricing, we wanted to figure out from the top down the customer willingness to pay the ceiling.
So Amy's group would see a pair of nice blue Warby Parker glasses, and the price would be $75.
And then we'd ask Amy and the other people in the survey how willing they would be to buy that product.
And we did this for four prices, 75, 85, 95, and 105, and through the conjoint analysis we noticed the following.
So from this pretty rigorous statistical analysis it was clear to us that among those four prices, $95 would be the right price.
This is something for those of you out there who want to do conjoint analysis.
There are many very good commercial providers and consulting firms that can help you do this, and a lot of good publicly available information.
I'd encourage you to learn a little bit about conjoint analysis.
We don't have time to go into all the details here, because its also a method that's very useful for trying to value your brand as well as just set prices.
Okay, the other two methods that sometimes get used are just direct surveys.
So the better way to ask that question through a survey is indirectly.
On a scale of 1 to 7, 1 meaning very unlikely to buy, 7 meaning very likely to buy, how likely would you be to buy this product?
And then I take the same survey, and I take it to Chris and a bunch of other people.
That's the best way to do it through a survey.
And, then finally, this is not a direct topic for our course together, but something I do a lot of in my own research, is you could run what's called a regression analysis.
So those are the four ways that you can really measure price sensitivity.
So now I'd like to spend a little bit of time just on psychological factors.
Of course, there are a huge number of books written on consumer psychology and so forth.
So in certain countries or cultures, digits have particular meanings.
And so that's why a lot of products are priced at 3.99, 2.99, 1,999.
So 9's are a special kind of number, at least in Western cultures.
The second thing that's important to notice, from a psychological point of view, is the demand curve is not always smooth.
So let me give you an example of that simple experiment that was done in the UK in some supermarkets over there where the regular price of a product of margarine was about 83 cents.
And at 83 cents the supermarket was selling a couple thousand units every week.
When they discounted the product to 63 cents, the price went down and demand went up, increased by quite a lot, almost 200 percent.
So dropping the price 20 cents led to a 200 percent increase in demand.
However, when the experimenters dropped the price just a little bit more from 63 to 59, then the increase relative to the 83 cent price was 406.
So that's a classic example of a threshold or a nonlinear response to a price reduction.
So those of you who might not have taken a marketing course before, you might have thought yeah, marketing's all that cool kind of advertising.
So let me go through and give a little bit of an overview, as I typically do, of where we're going to go with this last piece of material in module three.
First of all I'm just going to show you some trends and some data how much are we all engaging with various different kind of media.
Not just TV, but radio, our phones, the internet, and so on.
And then finally I'm going to give you some updates in terms of how social media marketing is being done and what's sort of working and not working in that environment.
So first of all, the trends we can go through fairly quickly.
You might want to dig into these a little more, and to, to discuss them, and also look for some of them online.
So the first one here, again, these are US data, but I would imagine they would be somewhat common around other parts of the world, too.
One of the interesting things to me in this particular graph is that TV has remained pretty flat from 2010 projected through 2013.
People still seem to like watching TV, although they may be doing it in different forms now.
If you look at the spending, spending on all media is up fairly considerably, again with TV sort of leading the way.
And then the final chart I wanted to show you is just the expected increase in marketing that's done on the internet.
Search engine optimization, display advertising, mobile marketing and so on.
And again, when we get to the end of this discussion I'm going to give you some of the latest research on those different types of media that we could be engaging in those different types of technologies.
So just to wet our appetites a little bit for what's coming next, I'm going to show you a classic campaign from the United States way, way back when, back in 1992.
So this was the situation that was faced by the Californian Milk Processing Board.
Hopefully your companies out there don't look like this, but you can see a fairly precipitous decline from 1987 to 1992.
Whatever their reasons were, clearly consumption of milk was going down and the California Milk Processing Board wanted to try and address this problem.
So like all good marketers, they did some surveys and they found that basically people thought that milk was healthy.
And so the goal was to increase the consumption of milk by having people store more milk in the home.
When you have more product on hand, you tend to use more of it.
So if you had a 12 pack of Pepsi in the fridge, you're going to drink a lot more Pepsi than if you only had a 6 pack.
And if you're interested in this kind of idea, particularly as it relates to food, go and take a look at Brian Wansink and his book called Mindless Eating.
So here's a commercial, I'd just encourage you to watch this on your own time.
It's a commercial that was put together by the milk processing board, to kind of illustrate the point that it would be very, very important for you not to run out of milk and to have milk in your home.
I won't spoil the punch line for you, but the commercial starts with a fairly obnoxious, obnoxious guy probably in some large US city, perhaps New York City, and he's yelling at somebody on the phone and firing them.
A good ending you might think, but the story continues from there and I'll let you watch that and and see what happens.
So as a result of this campaign, it was very, very effective, for the California Milk Processing Board.
So, first M is the market.
Perhaps there are people who don't like milk for health reasons, so let's focus on current users.
The message content was to encourage people to make sure they have enough milk on hand so that they don't run out.
The media strategy was to use TV and print, of course we're back in 1992 at this point.
Why is this important?
If you're spending $10,000,000 on advertising in stores, five million's wasted.
And this is really the perennial problem of spending money on marketing, is that sometimes, you don't know whether it's effective.
And even if it is effective, you're not sure exactly why.
And that's why I said at the beginning of our time together, we should be thinking about marketing expenditure on advertising and other things, not as a strict expense that's purely negative, but really more like an asset that's going to give us some return in terms of more customer affinity, more loyal behavior, less price sensitivity, more consumption and so on.
So they measured two things in particular.
And firstly was to do with the execution of the campaign itself.
That's important.
So how many people could actually remember the campaign within three months of it being shown?
There's 60% of people could actually remember having seen these series of ads about milk.
You might want to go and look at some of the other ones, in addition to the one that I've put in the slides.
And then secondly, you don't want to just measure the effectiveness of the campaign, but you want to measure the effectiveness of what the campaign is designed to do.
So now we have that classic campaign out of the way.
Perhaps you have your own favorite advertising campaign that you've been exposed to.
Do you think the advertisement was effective?
How would you have measured that effectiveness if you were the one running the campaign?
How am I going to position it?
What are we trying to accomplish here?
How much money are we going to spend and in particular what return on investment can we expect to get?
And then finally the Measurement.
This is absolutely critical.
You want to measure both the effectiveness of the campaign itself, do people like it, remember it, understand it?
Did I sell more, did people like me more as a result, did people change their opinion about what it is that I'm doing?
Okay, so we've mentioned this a little bit earlier on, so some of this is going to be somewhat of a recap and a repeat, but I hope that's useful for you too.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So, let's first start out with, what are perceptions?
Perceptions is probably one of the most important aspects in consumer behavior, and in understanding consumer behavior.
What is a perception?
The perception is the process of developing an interpretation of a stimulus.
Or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever cons, customers perceive, is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
And this process is inherently biased.
It contain, it, the process of perception comes in several different stages.
The first two stages are, the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
Pay attention to what's salient to you.
And we know that that process is very biased.
You only expose yourself to things.
But when you're consciously exposing yourself to things, many times it's a function of what you believe, what you're prior beliefs are.
Let me give you an example.
Say you think that a part of town is not safe.
Well, you won't go to that part of town.
You'll stay away from that part of town.
So you won't expose yourself to something you don't think is safe.
As a result, you never have, ability to change your perception, of that area of town because you don't collect new data.
So we know that exposure can be selective.
Similarly, even if you are exposed to something, if you don't pay attention to it, again it can affect your, your perceptions.
And we know that there's 2 kinds of attention, there's voluntary attention, and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you would had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure, and selective attention.
That means you're not collecting data on things that might be, might be able to change your perception.
So that's first stage of bias.
The second stage of bias is once you are exposed to something, and if you pay attention to it, then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who in interpret what happened in the debate from both parties.
Because we know a priori, the interpretations are going to vary based on their prior beliefs.
And, that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli.
As a result of this, perceptions are frequently biased, and they don't necessarily represent what's true.
So what's the overview of the perceptual process?
There's, we're going to talk about it, brand communication, there's advertising, there's packaging.
And then you are exposed to them, or you're not.
And sometimes the exposure, as I mentioned, is in a bias, bias way.
And then, even if you are exposed to these inputs, you know, and you're exposed to thousands of marketing measures, marketing cues every single day.
But how many of them do you pay attention to?
So, first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it.
And finally, there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that, your perceptions, and I just explained to you your perceptions could be biased, but your perceptions affect your subsequent behavior.
Regardless, it's almost an automatic reaction.
You have a certain perception, and then you automatically respond to that.
And it's very had to control that, even if you think, well I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that, so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So, here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
I mean, the first one, maybe you were a little bit surprised.
And you saw that the word was blue, but the color of the font was red, so the answer was red.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word, and reading the word affected your subsequent behavior, it slowed you down.
That's actually the purpose of the Stroop test.
It's a stress manipulation, it makes people feel a little bit uncomfortable because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches and you can see, it's much easier, it's much faster to say the words.
This is the same thing in the way marketing I'm going to show you that color has an effect, brand name has an effect.
It affects your subsequent perceptions and subsequent behavior, and it's an automatic reaction that's difficult to stop.
So let me just give you, here's an example.
If I told you this is luscious chocolate, and I show you a picture of it if the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh I don't want to eat this, that disgust feeling.
And you know that it's good chocolate, but the shape has an involuntary effect on you.
And that, that's a very important thing to understand.
So marketers need to understand how these things affect your perceptions and your subsequent behaviors.
Because as I say these are automatic reactions.
There's some visual illusions you may have seen these before.
I can show you these two lines on the screen.
I will tell you you can measure them, they are exactly the same length.
However one looks longer than the other, and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you, what is this that I've put on the screen.
You'll answer differently if I show it to you this way versus when I showed it to you this way.
And so that shows you what you perceive that stimulus is, is a function of your prior expectations.
And what the proximity bias says, is if things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that they'll cluster the two lines that are close to each other, rather than say the two bold lines or the two thin, thin lines.
And you can see this in the supermarket, in stores.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception.
That physical distance affects whether things are similar or belong together.
In the mall, stores that are close together or seem to be more similar.
Things that look alike, people assume have the same quality.
So this is the the, the underlying the, theory behind, say, store brands.
You're making an assumption of perceived quality, based on this process of similarity.
And it's a very, very important consumer process for marketers to understand.
It's particularly important in branding.
With the Coca Cola brand on it, people will think it tastes better.
They're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product's exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that, I know.
I can judge certain products by the quality.
And, we know from experiment after experiment after experiment, that, that's just not true.
People are very much influenced by the brand name that's put on the product, independently of the product quality.
it's same way in the Stroop test.
You just can't stop it.
Once you see that brand name, you have certain perceptions.
We know that brand is such a powerful brand as we mentioned before.
The Coca Cola brand name has been estimated to be worth 70 billion dollars as an asset.
Just putting that brand name on a product will change, as I said price premiums people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So ex, for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time, that no one had tasted before, a diet soft drink.
They call it Diet Coke.
And automatically, even though that product was not on the market before, people assume it has hot better taste, it's a higher quality product.
And again they're willing to pay a higher premium price for that product.
So now that we see how important a brand is at creating perceptions of quality, let's get into some of the inner workings of a brand and talk about the different elements of the brand.
So there's a variety of brand elements that can be chosen.
and they will totally identify or enhance the brand awareness.
And if you choose them right, they can help facilitate the formation of strong, favorable and unique brand associations.
And so the things we'll talk about are the brand name, which is the first one, the anchor.
different brand logos, symbols brand characters, packaging, brand slogans and brand colors.
When you're looking at all of these brand elements, you gotta ask a couple of questions.
First of all, you have to make sure all the brand elements work together to create a unique identity for the product and service.
So make sure that everything you've chosen is, is of one, one thought, one, one belief and work together in unison.
And the second thing to think about is if people see the brand elements or whatever you do create for that brand identity independent of the product, what would people think of just that brand label?
and when we consider each of the different ones, and I'll go over all of them in, you know, in various detail.
But, when you think about all of them, you should think about these criteria for choosing a good one.
The first thing, when you, when you think about choosing different brand elements, you really want them to be memorable.
You want people to be able to recognize it very easily, and you want them to remember what they've seen.
The other thing you want to have happen when you choose these elements is that they're meaningful.
And they can be meaningful in two different ways.
And the other thing that we're looking at is remember these, this brand label is forming a perception.
So you also want these brand elements to work together to persuade the customer of something usually of something positive.
You want it to be rich visual imagery.
And you also, if you have visual and verbal image, imagery, you have to think about how those two things work together.
Again, you want a congruent unified vision here.
Another thing to think about, and this is very important, is can you protect your identity?
And so many times, if you have a good brand name, you trademark it and then it's against the law for people to copy your brand name.
But they may do something that looks similar and they can kind of steal your identity by just looking similar.
And so you not only want to have legal protection, but you want to try to identify a brand image and brand elements that work together that are hard to copy.
So that you have some sustainable competitive advantage, in addition to the legal protection that you may have.
When you're thinking about this brand, remember, it's very expensive to create a strong brand name and it's an extremely valuable asset.
And so the other thing you want to think about is how adaptable is this brand name to go, to stay modern?
times change, consumer's taste change, competition changes, and so you don't want a brand name that is so, is so static that it can't adapt with changing times, and it's not flexible, and it's not updateable.
And along this line, you also want a brand name, if you can, or a brand image, with all these elements that work together that you can use them to go on to different products, if you introduce new products.
So I mention Coke started out on a regular a full calorie cola drink, and they stretched that brand name to go to a diet cola drink.
So you want to think of brand images that can go, not just on your initial product, but could perhaps go on other products in the future as the company grows.
And similarly, you want a product that can go across cultures.
Into and that's some, a brand name, I mean, that can go across cultures.
So you don't want something that won't be understood or be interpreted differently or inappropriately in other cultures.
And each element in, in thinking about this brand image, are going to play a different role in creating those overall perceptions.
They all have different strengths and weaknesses.
but you really want to think about how you can use them strategically, to achieve some kind of balance and overall impact.
And again, as I mentioned before, they have to work together to, to form a unique, consistent image.
It's the anchor and it's very, very important that you can choose a, a, a good brand name.
Sometimes you're, there's legacy brand names and you have a great deal of awareness with a particular brand name.
And maybe it wasn't the best one to choose, but you have to use some of the other ones to build it up.
They actually weren't such great brand names because they don't have the advantage of a good brand name of being quick, easy to process, easy to remember.
And in both of those cases the marketers us other elements to, to, to help with the brand names.
But if you can choose it in the beginning, it's better to choose one that's easy to process and recall.
Because, the disadvantage of a brand name, is once you bring up that or develop that brand awareness and people really understand what it is, it's pretty difficult and expensive to change.
It's not impossible.
But a lot of the whole brand imagery is really anchored on the name.
So the name, and I'm going to spend some time thinking about that going forward, is extremely important to think about.
They can reinforce any of your brand identity.
they, they can be ambiguous.
Not all brands have a character, but a character, if you do have one, can be very quick, very attention getting.
Think about what happens if you see Mickey Mouse on something.
I mean that's a world famous character, recognized every where and people understand it's fun, it's kids, it's exciting.
and so characters can work very well, but they can get outdated, or they can be culturally bound, and certainly not all brands have a character.
A slogan and a jingle, if it's done well, gives you a few more words and can give you music to add to the brand element, so it can be used to convey meaning.
Nike's Just Do It is an extremely strong slogan, that adds to the Nike brand name.
but again, sometimes it's difficult to translate.
Sometimes if you do jingles, musical tastes are different, and not everybody likes it.
Some people think mus, some of these jingles are annoying.
and we go back to this notion of perceptions.
So this has a very very strong effect on creating perceptions.
The difficulty with packaging is many times you don't control how it ultimately reaches the consumer.
So for example, if you want the package oriented in a certain way, like front on, it may not appear that way on the shelf.
Or if it's supposed to be refrigerated, it may not be at the right temperature, etcetera.
So the problem with packaging is that, these channel issues.
If you choose them strategically, they can work very well to create a very strong brand image.
Let's look specifically at this notion of brand names.
Now, the brand name is extremely important for many, many audiences.
Obviously, and what we've been focusing on here, it matters to consumers and customers.
And, it can, as I mentioned before, seriously affect the likelihood of purchase.
It also effects people who work for you, for employees.
People can be very proud of the company they work for.
and the reputation and brand name of the brand may make it easier or harder to hire people, to retain people, and may affect their morale and productivity.
it also, the brand name, affects growth opportunities, like I mentioned.
If the brand name is not adaptable and not transferable, it may be difficult for the firm to go into new markets or to go into different products.
And so it affects the growth potential of the firm, and it affects investors.
So just, investors are people too, and they can be very much affected without even realizing it by the brand name.
about using the value of the brand name to infer make inferences about the merits and strengths of the firm as an investment opportunity.
So the brand name matters a lot in lots of different ways.
There's lots of examples, and I'll just go through this kind of quickly.
We can look at this chart here.
You know exactly what the product is by the brand name.
A lot of the legacy brand names are based on people's names.
So Ford or Ralph Lauren, those are real people.
And the brand name was chosen for, because it's based on a particular person.
Sometimes there's brand names where the word means something, but it's not really clear how it applies to the product.
Apple's a great example of, of that kind of.
You know what the words mean and now, certainly, they're very famous brand names, so you understand what they are.
They kind of sound like they're a real word, but actually they're not, like Lucent or Spotify.
You kind of have a sense what those brands mean, and you think you know what those words are, but they're not real.
Or you can have a new word that's created by blending together two other words.
Facebook is a great example of that that, that's not a real word, but you know what it is, a book of faces.
and they worked very very well, and they were all very different.
And somehow or another, that name just seemed to spark interest, and they said, well, if we started a record company, we'd be virgins in that business, so let's use that name.
And apparently that's how that name was chosen.
He mentioned that, at the time, it was considered a pretty risky brand name and it was hard to register for a while.
But now, it's become an extraordinarily strong brand name.
And, it, there, it's a funness to it that actually works really well with a lot of his products and markets.
you know, if you know what that business is, you know it's absolutely about establishing a line of prices.
It's quite clear what it means and it has been very useful in that way, in, in a different way than Virgin.
And finally Google, which you know has now become a verb, people Google things, with, it's interesting that brand name was chosen by mistake.
they meant it to be the word Googol, which is not spelled the way the brand is spelled, and that, that's a very, very large number.
Google's a very, very interesting brand name from a marketing point of view because one of the things that we argue is extremely important in brand names is consistency.
And Google has met, because it is so well known, and people identify it in just little pieces of the brand name.
They identify the colors, they identify the typeface, that Google plays around, as I've showed you on this screen, where they'll show you its trademark differently everytime you see it.
Whenever you go to the browser, you'll see a different version of the brand name.
That's a sign of an extraordinarily strong brand name that has very, very high brand awareness, that you can see it even when it's not exactly the same every single time.
But these are all fairly new brand names that have been very, very successful.
When you look at new startups now, a lot of the trend in the new startups, and there was a recent Wall Street Journal article about this.
the new startups are, are making up brand names, and so a lot of the new businesses come up with brand names that are, just these invented words like Mibblio or Kaggle or Shodogg or Zaarly.
You don't even know how to pronounce some of these words.
Why is that happening?
Part of the, part of the reason is, in today's world, when you have a, a brand new business, you need a, a website right away.
And most of the recognizable URLs have already been taken and so one of the ways to get a URL that's uniquely identified with your business, is to invent a new word.
Then you're going to have to use the other elements of the brand mix to try to give some kind of identity to this brand name.
The Gap brand name, a few years ago now, I'm not sure exactly when.
And one of the things they were trying to do to modernize it was to change the trademark, or change the brand logo.
So the original brand logo as shown on the screen is a blue square with the word Gap in white on that blue square and you can see the new logo that they put out, is very different.
The blue square has shrunk, the typeface has changed it's now on a white background.
And they put that brand name out in, into their social media market, and instantly got very, very negative reaction to that brand name.
The consumers hated it.
Within, that brand name was out there, just tentatively, as a test, for one week.
The reaction was so negative that the company pulled it back and that was the end of that.
So it ended up actually being a, a pretty, it was, you know, they got a lot of publicity at the time.
So actually, that this got such a negative reaction, that they found out so quickly, it was, was a benefit for the company.
But because this was somewhat of a famous incident some market research was done, and some fMRI studies, and neurostudies were done to figure out what was so bad about that image.
Why did people not like it.
And there's a couple things that they identified that when I show you, you can see make sense.
And so where that blue box is, behind the P, it, you're, it actually kind of blocks out the P, and you see a hole in the P, and the P is not as strong because you're attracted first to the vision.
So that weakened the whole idea of the brand there.
because the P was kind of weakened because of the visual block on it.
The other thing that, that's different between the two logos is that instead of being all caps, which is in the original one, now this is an initial cap and then smaller letters.
And what that ended up doing was making people think of it as a word, rather then a brand name.
So when we're looking at these things in hindsight, you can kind of see why that wasn't a good choice.
And people just didn't have a very strong emotional reaction to it, also.
There were negative emotions to it that were kind of more on a visceral level, and what I'm explaining here is, you know, more thoughtful.
and the last thing I want to mention in thinking about brand names, is a lot of people now, you've got to think about global business.
And a lot of the business, the future business is in China.
And that's tricky to think about how your brand names might translate into Chinese.
A number of different ways to do it.
But other brands try to change their brand name into Chinese.
And this is tricky because you can do it, Coca-Cola, for example.
what does Coca-Cola mean?
How do you translate that?
And if you just go and look for the Chinese characters that kind of sound like Coca-Cola, well, the characters themselves may mean something.
So when Coca-Cola first did that and tried to pick Chinese characters that sounded like Coca-Cola, it had a very bad brand meaning.
And they had to take that one off the market.
The one they currently had, have means tasty fun, so it kind of sounds like Coca-Cola, and it means something that at least makes sense with a drink.
Reebok did the same kind of thing, the Chinese characters that they chose kind of sound like Reebok and it means, quick steps, which again makes sense.
Colgate picked Chinese characters that they thought was consistent with their brand image, which meant superior cleanliness.
And then the Chinese characters, if you said them, didn't sound very much like the word Colgate.
And Cadillac did it the opposite way.
They took Chinese characters that sounded like Cadillac, but they didn't mean anything in Chinese.
So, when you're translating to a very, very different language, and an important language like China, because of the size of the market, there are some big issues.
And there are a lot of agencies now that are developing to help you choose a name that will make sense in China.
Now that we discussed brand name, let's think about some of the other elements that can go around a brand name and I'm going to talk about two that are extremely important.
One is choosing a color.
And color has very, very strong perceptual cues.
We'll show you some of those things, but people associate a lot with different colors.
So let's start with color first.
There's a few rules about color that you should think about.
First of all, the best use of color if you can possibly get it, is to own a color.
and that's not, very many brands can do it.
There aren't that many colors out there and to really own a color is pretty hard to do.
But, when you do it it's extremely powerful.
This is such an important cue, that the Tiffany empty boxes are sold on Ebay.
And people will purchase those boxes, and then put another product, maybe not a Tiffany piece, in that product.
But, people getting a gift in a Tiffany box, this just shows you how strong the perception is.
But Tiffany's light blue box is extremely valuable brand image for their, I mean it's very high quality, and, and, many times with jewelry, unless your an expert it's kind of hard to necessarily judge quality so people will use this light blue box as a cue for high quality products.
Mary Kay owns the pink color.
color can also be used within a brand to separate product lines.
The green card, the black card, the silver card, all these different kinds of cards.
and you, you infer different qualities to the card as a function of its color.
And that's used in lots of different products, as well.
you have to be careful with color, because color can be experienced differently it can be experienced differently across different platforms.
So a lot of times if you're going to test a color you want to test it on a computer, on a phone, in real life, and the colors may vary a little bit.
And when you want a color to really be identifiable with a particular brand, you want to make sure you have that consistent color across.
and colors also can create very strong perceptions.
If, if you look at a product line and you see some of the products or it's gold or silver or black and white, that cues luxury, and you just assume that product's more expensive than more basic colors like a red and blue.
So that those colors can just signal high quality just because it's gold and silver.
Similarly, you see something that's blue or pink, you think female or male.
just by the color, can be the exact same product but the color changes and you think it's for girls versus boys.
We know that there's two basic axes of color.
There's the arousal axis, you know, how stimulating it is, versus how calming it is.
And there's the affect axis, which means how much people like it or don't like it.
The affect axis is extremely important, but it does vary a little bit by cultures.
Some colors are better liked in some cultures than others.
It is true that high arousal colors are like red and orange.
but then also, if you think about, on that affect, or that liking dimension, the blues and greens tend to be better liked colors in the U.S.
And this may be different in other cultures.
For example, orange is a very popular color in India.
And, there's been a lot of research on color.
and so there's certain things that we know of that the way people automatically react to these colors going back to that perception.
So, red for example, as I mentioned is an exciting color.
It's part of the reason why fire engines are red.
Red also means love.
But red also stimulates appetite.
They all stimulate appetite, and they all have a lot of red in their logo.
Blue, on the other hand, is a calming color and it is not a good color for food, for food.
Blue actually is a color that curbs appetite and some people have said that if you're on a diet and you want to like try not to eat as much, having blue plates can curb your appetite a little.
blue, as I mentioned, is also a color that's frequently preferred by men.
Green is a color that's tranquil.
It means health.
A lot of environmental companies use the green color to give you that green notion.
But green also means fertility.
And if you've seen some of the recent M&M's ads.
She's a pretty sexy M&M.
And that's also that green color.
Brown is reliable, bor-, a little bit boring, practical earth.
people play around with white space.
They can, it can be high design, if there's a lot of white space.
yellow is a very bright color.
It creates a lot of energy.
So, it's kind of maybe not the best color to paint for a newborn's room.
Orange is exciting, warm, it, it's, it, an enthusiastic color.
And pink as I mentioned is more of a girl's co, color.
And so one of the things you can look at is look at some of these different colors and see which companies use these different colors.
So you know, the bright yellow color is used on Nike, on Shell Oil, on Best Buy, on McDonald's, to get, on DHL, to get a lot of attention.
The red colors I already mentioned is used on a lot of food companies like Kelloggs, Coca Cola.
It's also used to get attention.
Purple is more of a creative color.
So, you see Yahoo using it, Barbie uses it, Hallmark, Taco Bell.
Blue is this trust color.
You don't, American Express, GE, a lot of really solid companies, not a lot of food companies.
and then the grey, black and white colors are more of a balance colors.
So you see New York Times is a black logo.
Apple sometimes has a silver apple.
Mercedes Benz is a silver kind of color.
But if you look at the logos and start thinking about them.
And thinking about how the colors are working, we kind of get a sense of what's going on here.
So let's look now, at symbols.
And symbols as I mentioned, Mickey Mouse is a very famous symbol.
Symbols can add a lot of fun, a lot of attention to a brand.
I had some symbols here on the slide.
And what they show is a strong muscular man, so it's assuming that you can have a lot of strength in this product.
And so you can just have fun with these different symbols.
But, the symbols can get out of date and in the last section in this, we'll talk about how you can reposition and rechange these symbols.
Slogans can be tailored to help the positioning strategy, we talked about earlier.
So that, you have a brand name and you want to really communicate that brand mantra.
And sometimes, if you just have, you know, these brand elements, you may want a slogan or a tagline that can help remove some of the ambiguity that's associated with the brand or the symbol.
and can just, because if you have these redundancy in the tagline, is reinforcing the imagery, or the brand name.
You're seeing this multiple times, it makes for a very strong message.
It's similar to a brand mantra, they have to be very short.
Similarly it should be unique, it should be easy to say and easy to remember.
you don't want it to have any negative interpretations, so you have to market test it, particularly when you go across cultures.
and again, if you have a really great tagline like "just do it" you want to trademark it so that it's protected.
And as I mentioned, an emotion if you can evoke an emotion with your tagline, that will make it much stronger.
Just Do It, Think, Invent!
Moving at the Speed of Business, bullish on America, You're in Good Hands.
Another clever one is what VW (Volkswagen) have done with their slogan.
Okay, so let's talk about packaging.
Packaging, as I said, has very strong effects on perceptions.
So let's, let's kind of look at packaging.
we started learning a lot about packaging here in the U.S.
in the 1930s, and what happened in the 1930s was that the, the grocery store was moving from the person behind the counter where you would go to a grocer or you'd go to a butcher or bakery and you talk to somebody behind the counter.
So that the consumers were going to go up and down the aisles of the supermarket by themselves and pick out products without any help.
And so the question was, how will people use packaging cues to choose what they're going to choose in a supermarket.
And so one of the early famous experiments was done with detergent.
And in one package, they had a design that had ciricles, and in the other package they had a design that had triangles.
And they wanted to see which one people would choose.
And it turned out it was very reliable.
What was different was the package.
And they use the detergent from both boxes and then were asked, which detergent did you like better?
That was the beginning of understanding that the package Absolutely in, influences the perception of the product.
And now today if you look at Tide, for example, still has those circles on its product.
even when it goes in different col, countries, things will change in the package, but you will still see those circles which we know were really preferred by consumers for choosing detergent.
So it not only gives you a reason to choose when you're purchasing.
You can identify the product, you can present some kind of information the package can be used to protect the product, it can be used to store the product.
It can aid in consumption, it gives you more information on how to use the product appropriately.
So the package not only using perceptual cues, the packaging not only uses a lot of color.
and so you have to know that packaging aesthetics are and the function are very, very critical.
The colors are used to help grab consumers' attention in, in a sea of competing messages.
And it also though has to be used so that you want to buy the product again and again.
So you want to choose, the, the variations of colors and designs so that they'll make for an impact impactful package.
but you have to, as I mentioned earlier, know your distribution channels.
Because, you don't necessarily control the way the package is ultimately distributed and there are certain, you might do some really cool things with your package and then the retailer doesn't necessarily abide by the way what those, that packages exhibited and that's just the reality and you have to think it through that when you're doing it.
Let me go over some iconic packages and how they've really changed customer perceptions and really helped build market share.
But I'm not going to be redundant and mention color again, so let me focus now on shape.
So one of the new products that came out, Calvin Klein came out - a number of years ago, tens of years, decades ago I think actually, with one of the first products that came out with a fragrance that was designed for both men and women.
And a lot of the ads showed very designy ads, and they showed models that The gender was kind of ambiguous.
And so if you look at this package of the CK Cologne that they came out with, you can see that edginess in the package.
And you can also see that they used a symmetry in their logo, which again, really gave this notion of of edginess.
And a lot of times when people choose fragrance, this is one thing we know for sure, they, they're not really experts at choosing different scents.
And so the packaging and the brand name is very influential in what people choose as the fragrance they like.
This was one of, this campaign I don't think is being used anymore, but it's one of, it was used for about ten years, it's one of the most famous print campaigns around.
And the whole print campaign was predicated on the shape of the bottle.
So vodka, a lot of times people have difficulty telling different vodkas er, apart.
The brand name and the bottle, establishing brand loyalty.
The Absolut bottle was interesting because most of spirit bottles have a longer neck because bartenders are people use a product.
And they really, really focused on the shape of the bottle in the ads.
The ads went through different stages, some of, some of the ads just showed the bottle, some of the ads showed other things in that shape, like I remember a famous one where they had an LA ad.
and they did a lot of, they used celebrities, they used artists, they did a lot of creative things, but it was always around the shape of the bottle.
Another iconic shaped bottle is Coca-Cola.
So Coca-Cola, as I mentioned, is a very very very strong brand name.
But part of that brand imagery comes not only in their logo, in their red color, in their famous polar bear ads and other types of ads they have.
But, also in the shape of their six and a half ounce bottle.
That was their first product and a very distinctive shape that people could tell it was a Coca-Cola from all the other soft drinks out there.
When the bottle went from glass to plastic, originally, when Coca-Cola came out with their plastic bottle, they lost their unique shape, and that was a decided disadvantage.
And so they managed to figure out how to recreate their iconic glass shape in plastic.
Because they understood how important that was.
And another very famous bottle of course is the Heinz ketchup bottle.
People recognize the quality of the ketchup because of the shape of the bottle.
It actually gets in the way of using the product, and yet still it really really define the quality of that ketchup, by the shape of the bottle.
So, shape is extremely important at, at causing at creating brand imagery and brand identity.
And, shape also can be in and of itself an excuse for a new product.
One of the most successful new products in the soft drink industry was the refrigerator pack.
They did some market research and they found out that if the cans of soda were in the back of the refrigerator, people did not consume it as much.
So if they wanted people to consume the product, they needed some mechanism to bring the cans to the front of the consum the refrigerator, so people could drink it.
And that package design single-handedly increased market share for the companies that started doing it.
And it didn't have anything to do with the actual product, but just the packaging.
And similarly, Hunt's came out with a, a package for getting ketchup out that's easier.
And again, that was a successful packaging innovation.
So we talked about budget brand images, and we talked about creating brand perceptions, and how these brand elements work together.
But another part of this brand identity is to persuade consumers.
So let's focus now on this process of persuasion, or changing people's attitudes.
And the dominant model that's used in this, in this way of thinking, or the dominant theory, is called the Elaboration Likelihood Model.
And so we'll talk a little bit about that.
Because they're used frequently to help persuade consumers to have positive beliefs towards a brand.
So let's start off with persuasion.
What is persuasion?
It's an active attempt to change belief and attitude.
So marketers are trying to persuade you to feel favorably towards their brands and their products.
It's difficult for the reasons that I've mentioned all along.
People are ex-, expose themselves, pay attention to and interpret data consistent with what they already believe.
That's not to say it's not possible, but it is difficult.
So the dominant model in thinking about what's the best way to persuade consumers is the Elaboration Likelihood Model.
And this model posits that there's two different ways, or two different routes, to persuasion.
There's the systematic, or central, route and there's the superficial or peripheral processing route.
The central root say that if people are motivated and they're highly involved, and they have the opportunity and the ability to process marketing messages, then the way to persuade them is through central cues in messages.
In other words, cognitive cues.
Things that people have to think about.
Try to make a strong argument.
In order to make a strong argument, people have to be paying attention, they have to be motivated, and they have to have the ability to process this information.
That's one way.
Many times, and this is true a lot with marketing decisions, people just aren't motivated to think that much.
And they, maybe they just don't want to think that much.
Or maybe they're, just don't have the ability, they're too tired or whatever.
In that case, central processing or central route to persuasion will not work.
Which are more automatic reactions, people just make decisions based on these cues.
Are they going to to pay attention and think about your, your message?
If the answer is no, they're not, then that's low involvement.
And then don't give a message they have to think about, use peripheral cues.
And, if the answer to that is yes.
If the answer is no, you have to go back to the peripheral route.
So to get to central routing, the central route where its systematic argument people have to be motivated, and they have to have the ability.
If either one of them isn't true, you gotta go to peripheral cues.
So, what are peripheral cues?
Peripheral cues are cues that people use, in a, it's called heuristic way.
That means a shortcut way.
Classical conditioning says that you persuade people just by putting things together all the time.
So the famous example is Pavlov's dog.
After a while because of classical conditioning, just the ringing of the bell caused the dog to salivate.
So in the same way in marketing, if things are always together.
After a while you don't even think about it, and you just say, well, I'm having a Big Mac, let me have a Coke.
That, that's a kind of notion of classical conditioning.
It's just, I'm persuaded to have a Coke because I always have had one.
Now, that may make sense, it may not, but you're doing it just because, I owe you.
So a lot of times, direct marketers will do things like, put a little gift in a charity appeal.
We'll give you stamps, or sometimes they give you a dollar.
And the idea is, sometimes, I gave you sometime, now you give it back to me.
It's not a cognitive argument, it's a peripheral cue.
Consistency's another peripheral cue.
A lot of times the reason that you like the toothpaste you use, is because that's the one you always use.
That's the one your mother gave you.
It's not like you did this systematic product comparison, and you decided, this is your favorite toothpaste.
You use it just because you always liked it.
That's consistency as the peripheral cue.
So, New York Times lately has had the most emailed articles, people read them, why do you read them?
Well, everybody else emailed them, they must be good.
Or my husband chooses restaurants by the one that has the longest lines.
If everybody's waiting on line for this restaurant, that must be good.
That's a social proof, a peripheral cue.
Liking says if you like me, then you like my ideas.
This is very important, and we'll see later for celebrity spokespeople, if you like the celebrity spokesperson, then you're going to like what they like.
Not necessarily a rational process but it, it makes sense in some, in some ways.
Authority says just because I say so, you should do it.
So, because somebody in authority says you should do something, you should do it.
Just because someone told you to do it.
And the last peripheral cue that I'll just mention today is this peripheral cue of scarcity.
Because there aren't very many of them, it must be good.
So some marketers use this idea of scarcity to create product quality.
And Lululemon purposely does not have, you know, they go to stock outs easily.
If you don't get there quickly, it'll, it'll run out.
And people in, in, infer from that that it's high value, high quality product.
Not well thought out central processing arguments, but cues that people use to persuade themselves of one thing or another.
So now let's think about celebrity endorsements in terms of these two roles of, of persuasion.
So in one way, you can use a celebrity in a central processing way.
And the reason that the celebrity endorsement matters is because that person's an expert and therefore there's information in that endorsement.
Celebrity as a peripheral cue is going to be, because the celebrity's attractive, or because I like the celebrity, then I want to use the products that they use.
Either in a central, or in a peripheral way.
When you're thinking about different celebrities to use to help endorse your products, there's certain things you want to think about.
First of all, who's the target segment, and does that target segment like that celebrity.
As, then another thing you want to think about is how attractive is the celebrity?
Is this a popular, a, a, a positive celebrity?
Because you don't want to take a celebrity that nobody likes, obviously.
Is it worth it?
Maybe that's a better, value for your money.
And nowadays very, very important is the social network.
There's another thing that's out there to rate these different celebrities.
It's called a Q-rating.
And, the Q-rating says, how appealing is the celebrity among those who do not know him.
It's the ratio of popularity and familiarity.
And, it's conducted by a particular company called Marketing Evaluations.
And, you can get Q-ratings for different celebrities to help you judge which is a good celebrity and which is a celebrity that maybe isn't as strong and maybe you don't want to pay as much money for or something like that.
So what's the I think you're probably starting to get the idea of how these celebrities work.
And that's the model that's used to indicate the effectiveness of celebrities.
And what you want to do is transfer the meaning of that celebrity to your product.
So, advertising firms, marketing firms, branding firms try to choose a celebrity that best represents the, the appropriate symbolic properties of the product.
So that that meaning from that celebrity will then transfer to the meaning of the product.
And celebrities are quite powerful.
There have some been some fMRI studies that show that when you show an image of just a normal person, certain areas of the brain light up.
So there's an automatic or visceral reaction to celebrities.
and they can be very, very effective at creating an brand image and, at differentiating a brand.
If a celebrity's associated with one brand, and not another, that can be a very effective differentiation.
And going back to this elaboration likelihood model, when you think of the celebrity as working in a central processing way we talk about that as having a credible source.
So one of the very effective, at the time, spokespeople for Nike was Tiger Woods.
But when Tiger Woods was the first spokesperson for Nike Golf he worked in two ways.
His, he was very credible as an endorser for golf products because he was such a successful golfer and obviously you think there's some expertise in him, in his golfing ability and he knows what he's talking about with regard to product.
That's a central processing kind of use of Tiger Woods and that's source credibility, he's a credible source.
The other way of thinking about Tiger Woods is he's also an attractive source, people liked him at the time, they were very familiar with him.
So he was used as a spokesperson not only for golfing and for Nike, but he's also used for other products which were not necessarily based on his expertise, but just based on his attractiveness.
And when he got into some scandal and some issues where his attractiveness was not as strong, some of those endorsements were dropped because he was no longer an attractive source.
The ones that tended to stay with Tiger were based more on his credibility, as a source.
And you can see when you think about these different methods of persuasion why some companies might keep him and some companies might not want to keep him.
and the ways the celebrities and models are used in these advertisements and endorsements is they can say there's an explicit mode.
They can say, I endorse this product.
I believe in this product.
There's an implicit mode that says, well I use this product.
and then there just can be these co-present that, that, that celebrities around this product.
So, we've talked about lots of things with regard to brands.
We've talked about the initial positioning of a brand.
We've talked about how to create brand elements that go together to create a brand image.
And one of the things I've been emphasizing throughout the whole sessions, is that a brand has to be updated.
And so a very important part of branding, is to think about how to reposition a brand.
You have an initial start, but maybe the times have changed.
And, you have to think about how can you keep this brand fresh.
So, we're gona talk about that now.
And it's this notion that the brand equity must be actively managed over time.
If you wait until a brand is out-of-date, it's much harder then to re-position the brand.
So ideally, the best way to keep a brand fresh is to constantly think about it.
That would be the best way.
A new sources, new, new ways of identifying the equity should be identified.
Well, I can think of at least five reasons and there's probably more reasons than that, but let's go over some of these.
One reason for a brand repositioning is that the initial positioning that you came up with wasn't right.
so, and you might know this because you thought this was really cool and customers were going to be interested.
But, actually you didn't see the interest you anticipated.
Or the sales are just not what you thought and one of the reasons is, is the brand is poorly conceived.
That being the case, you gotta re-position the brand.
Another reason is, maybe you have a perfect positioning, for a particular target audience, but that audience is hard to reach, isn't profitable.
It was a really good idea for a really good customer segment, but it wasn't a good business opportunity.
And so therefore you may need to re-position the brand.
As I mentioned over and over, one of the things about being a marketing professor is that things change.
Then you have to change it.
The other thing could be, it might just lose its edge.
And so you need to do something to make it fresh.
and another idea, it's along those same line as tired.
but those are similar ideas, it just gets old, it's, it's there was nothing wrong with it but you really want it to be new.
And by the way, one of the really big things that happens is, people go out and make purchases sometimes because they have needs and sometimes they make a new purchase.
Just because they want something different, something new.
And if the brand seems same old, same old, that's not enough of a reason to go out and make a new purchase.
When you think about re-positioning a brand, the biggest thing you have to think about is consistency, consistency, consistency.
So, except for that one example where I told you about Google, where they go out of their way to do things that are a little bit different each time, most brands when they do this re-position, they do this re-position, they have to have a position that's consistent with the old position.
Or, at least close enough to the old positioning so that consumers believe it.
there's some examples where that can work, but most of the time, the best way to re-position a brand is to do something that's consistent with the brand DNA.
And this is some very old research that was done on understanding why people smoke.
and it had to do with people's attitudes towards smoking.
And let's say I smoke.
And let's say that I know that smoking causes cancer, cancer causes death.
And I don't want to die.
Now, if that's the case, how do I justify that I smoke?
Because there's this inconsistency.
I'm me, I, I like myself, I don't want to die.
I think smoking causes cancer.
something doesn't work.
And so what, what psychologists found out that was people rationalized.
Or they do something to one of the links of this chain so that it is consistent.
And that's the way they can justify their behavior because people like to be consistent with themselves.
So what are the ways different people kind of rationalize to allow themselves to smoke?
Okay, I smoke.
I don't want to die of cancer.
I don't believe the data.
And so this is the kind of thing where I say you have this buyer selective interpretation.
You, there's experiments that shows, you show the same data to smokers and non-smokers.
And they will interpret it differently.
So people frequently interpret the message or the data, consistent with what they already believe.
This is a theme that I have mentioned all along.
So this is a, a pretty well-known, way to rationalize behavior.
Smoking causes cancer.
I really don't want to die from cancer.
So, what you do is kind of lie to yourself.
And you say, you know, I don't really smoke.
And, so it doesn't really count.
And, therefore I have no inconsistancy.
They make all sorts of rules.
If it's a little bit burnt, I can eat as much as I want.
You know, there's all sorts of rules that people make.
That's that resolution where you kind of figure out a way that you can feel good about yourself.
I know it causes cancer.
But, you know what?
All of these are consistent and that is a very important concept for marketers.
So if you're putting out a message, when you're trying to reposition your brand, that isn't consistent, consumers will reject it and will look for ways to rationalize the message so it makes sense to them.
It's a consistency theory.
and what you do is if it's not consistent, you change whichever one is weakest so that it is consistent.
Oldsmobile was known as a car that was associated with Dad, with my father.
Okay, now one thing that's probably obvious but let me just say it here.
Cars are for young people.
Cars are powerful, performance.
People like young people cars, energy cars.
They don't like old people cars, okay?
That was obvious.
And so what they tried to do was, they came out with a new ad, new excitement, new car to say, no, no we're not a fuddy duddy car.
This is a car for young people.
What happened here?
There's cognitive dissonance here.
The problem is, the association with dad and Oldsmobile was extremely strong.
The association that my dad is not exciting was extremely strong.
So the weak link here was that Oldsmobile cannot be an exciting car.
And that was a very strong inconsistency they couldn't fight.
it was so strongly-associated with my father and fathers are so not exciting that people just, not, believe, did not believe the new ad.
It was obviously hurt even more by the ad.
The slogan at the time was, This is not your father's Oldsmobile.
And anybody knows, as soon as I say, this is not my father's Oldsmobile, what you're doing is reinforcing that it's exactly my father's Oldsmobile.
So this is known as one of, not a good campaign.
And you know, there was another problem here.
Think about the brand name.
It is literally called an old mobile.
But they just could not get themselves out of this cognitive inconsistency.
So this is a very important thing.
A better way to do it is to gradually change these associations in small ways so that people can still maintain that brand familiarity and believe the re-positioning.
so you can do it, and I mentioned this earlier.
You can do it by kind of, updating the symbols.
Or, maybe you can start to change the brand name.
And I can show you how to can show, change the brand name slowly to to, to reflect the evolving identity.
So all of these elements that we talked about before, can be subtly tweaked.
There are two ways to do this.
One of the ways is called the Just Noticeable difference.
And what this says is that you make these little tweaks, very subtle, from point to point to point, so they're barely noticed.
You know, you do this, say, every year.
If you look over 20 years, the difference from the first one to the last one is very very hard.
And so there's a lot of packaging examples which we can show you.
Where just with tiny little tweaks each time, you still believe it's the same product.
But if you look from one, one version to a version, 65 years later, you'll see a radical difference, and the brand stays modern.
Many consumer packaged goods do this kind of just noticable difference positioning.
Anothedr way to do it is what's called the butterfly effect.
You are going to notice that it's different.
It's not a just noticable difference.
It's a bigger difference.
And the reason I'm going to do this is to keep it modern and new.
Because, for some categories, like cosmetics, like clothing, and this is the notion of clothing The idea of keeping it modern and keeping it fresh is part of the reason to buy.
And in that case, I don't need the change from one to another to just be subtle.
So that it is kind of a little bit exciting, and more modern.
But, it doesn't necessarily need to but I, it's, it's more modern, but it still stays within believability.
So it's not so extreme.
That I don't think it's the same thing.
And, so these are two different ones and we can show you a number of different examples on those two different ones.
And, then I can show you some examples of evolving trademarks.
here's the Jolly Green Giant, that was kind of out of date, he And, they made a new Jolly Green Giant that was fitter more athletic.
These are subtle changes.
There was another change, Charlie the Tuna.
I mentioned him earlier, very fun, animated character, kind of got a little outta date.
More recently, there was a transformation on the, the, hamburger chain, Wendy's.
And again, I, I know a little bit more about the market research, so I went into this.
There was a lot of changes here.
One of the changes here is they got out their slogan.
They do more than just hamburgers, so one of the things they pulled out was that slogan.
They went from an old fashioned typeface to a more modern typeface.
People identified with that Wendy character and they liked that Wendy character.
So, they kept the character.
But they made her, you can see she used to be in a little circle and she used to be contained in the circle.
You know, lots of things are possible that you can get in a Wendy's now.
And with these subtle changes, it's still very much identified as a Wendy's.
you can keep the brand, you can keep the brand modern, but connected enough so that it doesn't, people still know it's Wendy's and it's not a surprise.
There are other kinds of ways that people have named that's actually to change the brand name, so Boston Chicken was the original name of the of the chain of restaurants that provides dinner food.
Weather Channel found out that they were going to make a lot of their revenues not off TV anymore but off Apps and different kinds of ways of saying weather.
So, they change their name from the Weather Channel to Weather Companies.
And, Starbucks very famously changed their name from Starbucks coffee to just their image.
But, people still know that it is Starbucks by that image.
So what's the best way to do it?
it, it, BMW was a lot of associations.
It was a certain type of car.
It was an expensive car and it was a car driven by the baby boomers.
In fact, BMW's were called Beemers.
You know, they were thought of as driven by the baby boomers.
the baby boomers got old and they are stuffy.
So, although these associations started out as positive, if they're not carefully cultivated, they could turn negative.
They not only were very careful with their advertising, they, their, they mean performance, which is something that can stay modern.
But they also changed their design of the cars.
They associated their brand name with young, and powerful, and good imagery.
That, with all of those kinds of things, their slogans etcetera.
And, that's a way to do it by constantly positioning your product.
Subtly, sometimes just noticeable difference, sometimes a little bit bigger difference, like a butterfly effect, but always within the brand DNA so that people believed the changes.
Consistency over time is very valuable in building strong brands.
You do, it's kind of, you know, a fine line.
But, if you do something that threatens the consistency chain that I was talking about, people won't believe it.
So, it's got to be something that is consistent, with the brand DNA, but is constantly moving it forward.
When you think about all the brand elements, you want them all to work in harmony to communicate brand identity.
To to change when it's necessary but be careful because if you do things that are too big a change or the customers won't accept, it just won't work.
If you really want to do a good job in keeping your brand modern, you really have to understand the brand mantra, the brand DNA, the brand positioning, your target segment.
These are the things we've talked about in the beginning.
You have to understand what the points of parity are, what the reference frame is.
You have to really understand what the point of differentiation is, what is strong about your brand, what is positive about your brand, and what is unique.
And you have to be consistent with that kind of brand image as you make these adjustments.
I'm Barbara Kahn, and I'm here to give you some recent examples of some of the concepts that we talked about in the first videos that you watched on segmentation, targeting, positioning, how to build a brand.
So let me give you some examples of things that I think are going to work really well, and then some examples I'm not as sure of how they'll work.
And part of the reason, when I'm not so sure, is whether or not they build on some of the tight concepts that we talked about.
So as you remember, we were talking about in building a brand, it's really important to find target segment, a point of difference and a frame of reference for each brand.
And the more tightly you can position that, the better and more likely your brand will be successful.
So what's an example of one that I think is really good?
Now why is she building a really strong brand?
First of all, as an actress, as a performer, as a singer she's very authentic.
She has a very strong identity.
The second thing is, she has a really interesting target segment to start out with.
The Latino market is growing, it's big, a lot of people are trying to target that market and other people haven't been able to do it so well yet.
So she starts in with a tight frame of reference, with her strong point of difference, her persona, her authenticity, and she goes after a very attractive target segment.
That doesn't mean other people may not use the products or like the products, but it's very clearly positioned.
She might go into TV, all sorts of other things she can start to grow her empire because she started out small, tight, with a clear focus.
Really, the concepts of segmentation, targeting and positioning.
And thinking about how you target a key segment with some critical point of difference.
And they're saying these millennial moms, this is the segment that hasn't been really well served by traditional media.
Old fashioned TV, where you sit home and watch soap operas, that's just not what today's millennial moms are doing.
And they don't have some product that's, or a media service that's catering to that different type of behavior.
So Awesomeness TV is coming out with a new product called Awestruck, and it's targeting these millennial moms.
And the idea here again going back to our principles, it's an attractive marketing segment.
And so this should be an opportunity that makes sense, and I'm hoping it'll be successful.
Playboy, which is very well known in the US, kind of soft porn, Hugh Hefner, magazine Playboy Bunnies, is trying to build a brand in China.
Now Playboy is not very well known in China, but the bunny logo is an iconic logo and they think it might work there.
So they're trying it.
I've been looking for recent examples to try to show, or illustrate, some of the principles that we have in our videos about segmentation, targeting, positioning, and building a brand.
In this example, this is a brand that was very successful for a while.
Some of you may know the brand Crocs.
It's a type of shoe.
Its a, well, you can see on the slide that is a shape of a shoe and it has little holes in it.
As with any kind of fashion, sometimes falls in and out and Crocs is trying to revive their brand.
One of the most famous print campaigns is the Absolute Campaign which ran for over ten years.
And the entire print campaign was based on the shape of the bottle as a differentiator.
It was a black bottle with a short neck, which is unusual for Vodka bottles or spirit bottles because a lot of the times you have a long neck so that the bar tender can hold the bottle when they're pouring.
And they absolutely use the shape of the bottle as a differentiator and was really quite successful.
So Crocs is kind of reviving that notion and taking the shape of their shoe, which is unusual to say the least for a shoe, and trying to make it an asset.
And they're looking to revive the brand, revive the fun.
And they're trying to think about it as, think about Crocs in new uses.
Maybe you want to go buy a new pair.
Find a new place to find your fun with this unusual shoe.
So, we've been having this great conversation about customer centricity, what it is, what it isn't, why it matters, some of the surprises that emerge from it.
As we push that conversation ahead, it's not enough just to understand what it is and to feel like, whoa, this is a cool strategy.
But as we start moving toward implementation, we want to think real carefully about the challenges, the barriers, the things that will actually prevent companies from really making progress on it.
So one of the things that I've been working on, and this is real cutting edge right now.
It's not like I have a new book or anything on it.
But something I've just been thinking about, is a list of some of these different challenges that are seen from actually companies that have actually been trying to take some of the content, like what we're covering here and moving forward with it.
So how do we go about finding people who can really do that kind of convergent thinking, in order to figure out how to surround those valuable customers with the right kinds of products and services to enhance their value and so on.
So we've certainly been spending a lot of time, not just in my part of the course, but some things that Barbara Consman talked about on branding.
Well how do we come up with brands that resonate in all the ways that Barbara talks about it but at the same time, does justice to customer centricity?
There's unique challenges there in terms of the name that we choose and the different kinds of communication tactics that we use.
So how do we find that just right balance between the kind of direct marketing activities that we associate with customers centricity and the more product oriented activities that we often associate with a brand or a different strategy?
How about globalization?
Given that the different parts of the world are more open to customer-centric practices, how can a multi-national firm be customer-centric in some parts of the world, maybe be a little bit more product-centric in others.
How can you have a coherent strategy when there might be some global barriers that prevent you from using the same kind of customer centricity, product centricity balance all the way across the globe?
I mentioned that towards the beginning of my session, that the overall objective is to maximize shareholder value.
And while that might be the primary objective, there's also some other objectives that we really should acknowledge.
So, how do we think through some of those other objectives and kind of keep them in mind?
That if we're going to be using some parts of our sales force to surround those valuable customers, to enhance value, and do all that kind of thing.
That we're going to be doing kind of lower cost channel activities for those so so customers.
So how do we incent our channel partners to want to play along?
For those channel partners who are dealing with the lower end, how do we keep them from getting upset?
And how do we use monetary incentives or other kinds of incentives to make them realize that they still play a really important part of the business, even if they're not necessarily dealing with the very best customers?
So we understand that there's very different kinds of performance metrics for a product-centric company versus a customer-centric one.
How do we come up with and communicate the right kinds of performance metrics both internally, to our internal stakeholders, as well as externally?
How do we get wall street on board with some of the more customer-oriented metrics, that their not accustomed to using, that might be a better indicator of just how well we're doing as a company?
I like to say over and over and over, it's not enough to just hang a banner on the lunch room walls saying we are now customer-centric.
Changing the culture within the organization is something that's very difficult.
It takes a long time to do, and a lot of companies are resistant to do it because it's a very risky thing to do as well.
But you can't really succeed with customer centricity unless you want to take that one on.
So that's just a list of some of the barriers and challenges that companies face.
And I'm not really giving you the answers right now.
If anything, I might be making you even more concerned about whether customer centricity might be right for you.
But I think it's important to have that kind of full disclosure.
And I think it's going to be important for us to flesh out this list and understand which companies are doing well or going to struggle with some of these issues.
And to come up with some best practices to try to use whatever resources we have within the companies.
Or to learn from other companies, or to learn from seemingly unrelated industries in order to overcome these barriers.
We either don't have the data, we might not have the analytical capabilities.
We might not have the technology to allow us to serve up different kinds of products or services to our customers.
Or maybe there's regulatory restrictions that prevent us from doing it even if we think we're able to.
I've had some very interesting experiences with companies from around a variety of different industries, one of which was a pharmaceutical company and another one was Google.
Okay, two companies that might have the capabilities to treat customers differently, but they're really hesitant to do so.
So in these cases, and in others, one of the big wins of customer centricity has been for these companies not so much to be customer centric with their own customers, but to teach their customers how to be customer centric with their customers.
So I've had lots of good conversations with these organizations and others.
Basically they're listening very attentively, and I'm going through all these lessons about what customer centricity is and all the strategies and tactics and everything else that we've been covering in the course.
And they're carefully taking notes, not because they're going to do this stuff themselves, but here's their thinking.
If we can teach our customers how to be more customer centric, then they will see us as a trusted advisor.
In the case of Google, if they can teach their advertiser clients how to be more customer centric, then those advertiser clients will be better consumers of, they will buy more, Google analytics products, for instance.
But in a B to B setting you are also going to teach your customers how to do these things with their customers.
Not only is it consistent with everything we say about customer centricity, the whole idea about making these investments and we're in it for the long run, we're not just trying to make a dollar right now.
But the more that you can get others to be basically spreading the gospel for you, the more it's going legitimize some of these practices.
The more people within your organization who are really going to be able to understand them and talk about them and just make this conversation more ubiquitous throughout the entire ecosystem that your company is involved in.
So this is an idea that, really, I didn't have in mind at all when I was writing my book about customer centricity.
It's one of the things that I've been learning as I go ahead.
And so this idea of paying it forward I think is just one of many extensions of customer centricity that's food for thought, something to think about.
I love seeing case studies of customer centricity in action.
And of course, I've shared a bunch with you already, many of which were studies, real world, but I had nothing to do with them.
So whether it's the Harrah's casino chain, whether it's Tesco and so on, it's nice to look at some of those studies, but sometimes they're a few years old.
So I'd like to talk about a couple of the case studies that I've had the chance to really see and, in some cases, to nudge along.
One of the great cases that I love to talk about is Electronic Arts.
And if you think about that kind of company or that industry in general, it tends to be very much a product-centric business.
Very much it's all about blockbusters, it's all about what's going to be the next big game.
Can we come up with that great idea?
And for some games, and for some companies, sometimes that works just fine.
But at the same time, we recognized that there's an opportunity to be customer-centric instead.
Let's look at the game players and try to figure out, who are the most valuable players we have out there?
What kind of games do they like?
And can we use that insight to help us develop new games?
And I love talking about and working with Electronic Arts, in this regard.
But they're equally terrific when it comes to a lot of the customer oriented metrics and insights that I've been talking about, or at least hinting at in our time together.
So for instance, I mentioned lots of time, customer lifetime value.
Well, Electronic Arts is calculating customer lifetime value all the time.
So they can understand what kinds of acquisition strategies are going to bring in the best kinds of customers.
So they can understand what kinds of games or features within games are going to be most appealing to the most valuable customers.
So I don't want to say it's completely transformed the organization.
I don't want to say that they've given up on any product-centeric practises at all.
But they're achieving just a much nicer balance.
And so it's just really nice to look at a big company, and not necessarily one that was born in the online space, like an Amazon.
I love talking about case studies of different kinds of companies that are bringing different aspects of customer centricity into play.
Well that's not true and in fact a lot of these ideas really emerge from a B to B setting.
They're a company out of Atlanta, Georgia, and they basically make a lot of veterinary pharmaceutical products.
And I had a really nice interaction over several years with a gentleman who ran all the marketing for large animals.
His name was Steve Lerner and he heard me talk about some of these ideas, and the CLV models, and everything else that I cover and he said you know what?
This stuff is not only going to work for us, but it's going to work for us in a very unusual way.
Instead, let's give sales people the incentive in a forward looking basis.
So we're calculate our CLV for every one of our customers, and add that up to say, for the level of our sales people or our distributors, how much CLV have they created or destroyed from one month to the next?
So that if someone makes a purchase from you, great!
They didn't necessarily make a purchase.
We didn't necessarily extract any dollars out of them right now, but because the relationship is a little bit tighter, because there's a real conversation going on, their CLV has gone up.
Let's allocate our resources to focus on those customers who would be the best ones for us.
At first, the sales people, the distributors, they kind of look at it skeptically and say oh, it's just those guys in marketing trying something crazy.
But they ran this as an experiment over a period of several years to really show the sales folks that you know what, we really are helping you identify customers who have future looking value in them.
It was a way for them to raise revenue by a significant percent, despite the fact that they're in a very competitive market with a lot of these branded products going off patent, and so on.
And on a forward-looking basis, recognizing that they've created and they've recognized and locked in all of this future value that will continue to manifest over time.
I just love that idea of, first of all, just a nice BDB example, but also that idea of taking CLV, and taking customer centricity, and using in a tactical way, in part of the organization that it wouldn't necessarily be thinking about all the time.
It just shows that if you take some of these ideas, and instead of just trying to replicate some of the examples that we've covered, if you think really creatively about them.
And run those kinds of experiments, and start small, and build from there, and get buy in throughout the organization, amazing things can happen.
I think Meriel is a really good example in that regard.
At the beginning of our time together, I mentioned that I'm the co-director at a research center, the Wharton Customer Analytics Initiative.
But I never really took the time to describe what it is that we do or how it fits in with my overall desire to get companies to understand and become more customer-centric.
So what do we do?
We'll find companies that are sitting on top of lots of interesting customer level data.
We're very agnostic about what we mean by customer, and in all these cases the customers, whoever they may be, we have lots of data on what they're doing over time.
And lots of desires to extract insights from that data to help the company become more customer-centric.
We'll sit down with a company and we'll talk about all the different data assets that they have and all the business problems that either arise from or motivate some of those data assets.
We don't give the data away, but we'll describe the data to academics all over the world.
So all schools, all disciplines, all geographies, we basically say, hey researchers, here's this dataset, or this set of datasets.
You tell us what's interesting, both from an academic and a commercial standpoint, write us a proposal.
We'll sort them into buckets based on what techniques people are proposing or what substantive questions they're attempting to answer.
Then we can go to the company and say, hey, company, here's 40 great ideas.
You pick as many of them as you want.
We'll go back to those researchers, give them the data and say go to it.
And at the end of the process a few months later, we'll have this private symposium where the company gets together with all of these academics to talk about the data and the insights and the commercial value.
But if we have the company that gave us the data and all those academics that have been working on it, they're seeing eye-to-eye.
We'll see just tremendous insights, and again, commercial value that can be tied to meaningful financial results arising from these projects.
It's nice to help companies raise their quantitative literacy.
It's nice to have researchers work on more practical, relevant problems than the usual ivory tower stuff.
And this whole mechanism is just a nice way to bring customer-centricity across.
because while I'm talking to companies and talking about customer-centricity and everything that we've been covering here, sometimes it's hard for them to get going.
So maybe we can start on that side and we can have top academics all around the world show them how they can derive some of those analytics from their data, and it becomes much easier for them to start to do the strategic thing as well.
So it's just a really nice triangulation between the kind of pure talk that we have about the customer-centricity and the research work that we do.
And it all meets together, and it all makes the world a better place.
And, I'm here to talk to you about marketing.
So this, this segment is Marketing 101, the basics, the principles of marketing.
Which is what is marketing?
So what's a market?
But what you need for marketing to exist or for a market to exist is to have an exchange.
And what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's let's look at the basic exchange.
You have one buyer and one seller.
and the real markets are somewhere in the middle.
But you'll see when I start defining this, that it's very useful to use this, this kind of simplification.
So if we think of an exchange between buyers and sellers.
On one extreme we could have what's called a seller's market.
And in the seller's market what that means is the seller has a product, and if you want that product, you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think about it, is marketing should not be the same in the seller's market as in the buyer's market.
So, in the seller's market, what marketing tends to be is what we call product focus market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability.
You should innovate in that product, you should try to reduce cost and you should really focus on the product.
Your business objective in a product-focused market is to sell as much as you can, and profitability from a product-focused market is going to come from volume.
Selling as much as you can.
In the past when we've studied product focus market, we've shown that profitability is tied to market share.
So market share becomes your business objective.
And why does market share increase profitability?
Because the bigger your market share, the more your revenues.
And the bigger your market share, and your volume, the lower the product cost and hint profitability.
Higher revenues, lower cost, more profit.
That's really the goal of a product focused market and when you're product focused, where do you get growth?
Will you develop new products based on your product experience or you go to new markets?
So what's customer focused marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
Well, what's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So where is in product-focused market, I'm the expert, and I create the very best product I can based on my expertise.
In a customer-based market, what I'm going to do is look at what the customer wants, and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside-out, this product focus, and outside-in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer.
What does the customer want?
Well, the first question is which customer?
If we try to give everybody what they want, we'll go out of business.
That's too hard to do.
So the intuition of customer focus marketing, is to pick and choose customers.
Deliver value to some customers.
That's the process of segmentation and they call that, I'm going to talk about that in the next section.
But the idea here is that I go after some customers and I say no to other customers.
Well, then, how do I become profitable in that?
Understand that in a product focused marketing, what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In the customer focused market, we're saying no to some customers and yes to others.
So, how do we make that profitable?
And, the answer is you pick and choose the customers you want to deliver.
You deliver value to that customer, give them exactly what they want and that they're willing to pay for, and where the profitability comes from is not from volume, but it's from creating value.
How can, how can value-based marketing be profitable?
Well, first thing is if I give you exactly what you want, many times, you'd be willing to pay a premium price.
Then the profitability comes in not from reduced cost, which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want, I'll be willing to pay a higher price for it.
So that's one way.
The other way, customer based marketing is profitable is by giving the customer what they want time after time after time.
I don't think about just one transaction, I think about building customer loyalty.
And, delivering value to that customer over time.
That concept is called customer share.
Rather than market share, while I try to get a little bit from everybody, the idea of customer share, or share of wallet is that I go after a more narrow market and try to get more from each of that, their, those customer's wallets.
And it turns out that loyalty is very, can, if you do it right can be very profitable.
When I'm doing a customer based marketing it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but its cheaper to retain those customers over time, and that's where the profitability comes from.
It comes from loyalty.
The other thing, if you're thinking about building share of wallet in the customer-focused market, is that I not only sell one product to you.
Let me give you an example of this notion of cross selling.
The, the cashier or that person behind the counter might say: Oh these are very nice jeans.
Do you think you'll need a belt with that?
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time.
And that's more profitability.
And if you understand their needs, you can not only deprut, sell them one product, but you can cross-sell other products that may also nee, meet their needs.
So in a customer-based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between sellers market says you focus on the product, on what the customer does well, and you push that out.
And in a customer based market, you focus on the customer, what the customer wants.
And you deliver value to the customer better than the competition.
So that's the basic difference between product based marketing and customer focus market.
Now in today's world the market place has changed even more.
What's changed?
Well now not only do you have an exchange between buyers and sellers, but because of globalization and because of the Internet and technology and social media and things like that, it's not a one to one conversation anymore.
Customers can talk to other customers.
That's good and bad.
If you're doing a really good job and meeting the, needs of the customers, the fact that they'll buzz to their other customers and tell their, their other friends about what a terrific service your company is doing.
Well, that's really good news.
On the other hand, if something goes wrong, and they tell their friends something bad, well that's not such good news.
And so you have to be really careful, in every transaction with the customer now, that you deliver not only value, but that you deliver a top notch customer experience.
Because although what I've been talking about in the seller's market and in a buyer's market has focused on transactions.
But in a connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
Lemme give you an example.
It starts way before the transaction, and it goes way after the transaction.
So for example, if a customer told another customer that their experience at a restaurant.
They might say, well I was driving to that restaurant and I hit a lot of traffic, then I got to the parking lot and I couldn't find a parking space, finally when I got into the restaurant, I finally got a table, the meal was really good but then at the end of the meal when I was leaving I tripped and fell.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer then you as a marketer need to focus on the entire customer experience.
So, one of the things, and we'll talk about this later that's changed in marketing in this world of social media and internet and globalization, is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
One thing else to mention, we're seemingly coming out of a recession now, but there was a global recession, and in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
Marketing had some bad names, the financial services industry.
And so with all those changes in the economic environment, there's been a focus again, in marketing.
And marketing now has to focus on authentic, genuine customer value.
In order to be profitable, you not only have to deliver customer value over time and in an experiential way, but now because of the tightness of the economy and the uncertainty there, you really have to cut costs and figure out a way to deliver value in a very discipline manner and be very flexible to changes in the market place.
So let me just summarize what I've just said.
The different types of marketing orientations.
There's the product orientation where you focus on the product and you persuade the customer to want what the firm has.
There's the marketing orientation.
That's a customer focus approach.
The experience orientation says that you not only think about the transaction, and think about the transactions over time.
But you try to manage the customer's entire experience with the firm.
And when times get tough or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of marks in terms of what you offer?
In the production orientation, you're focusing on product innovation, but also reducing costs.
So you tend to see generic products and standardization.
When you're focusing on customer value, you see differentiated products, and we'll talk about that, when we talk about brands also.
In an experience orientation you look at experiential value.
And when you're going to that tight discipline mindframe or mindset you look at genuine value.
And what's the competitive sustainable competitive advantage in each of these markets?
In a product orientation the bigger companies win because they tend to have larger market share and lower cost, and lower cost is a big strategic advantage.
In a marketing orientation, when you're focusing on the customers, the, the companies that do the best are customers, are companies that really know their customers, that can deliver quality, and that have a lot of customer data and know how to use that data to deliver better value.
In an experiential market, you look at transformation.
The customer becomes a co-creator of the value, and it's really making the customer and the product one kind of overall experience.
And in a trust orientation, the sustainable competitive advantage are the companies that you trust.
And what are the measurements of profitability?
In production orientation as I mentioned, market share is tied to profitability.
In marketing orientation, it's share of wallet or customer share, customer loyalty.
In experienced market, when you're looking at customers talking to other customers, we start measuring social networks and buzz and word of mouth and referrals.
So in summary for just this little section, let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to buyer, and get them to buy from you, rather than the competition, you've got to give them real, genuine Customer Value.
That's the Principle of Customer Value.
The second principle is the Principle of Differentiation.
You have to provide customer value to that customer what the customer wants but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation targeting and positioning says when you're in a customer focus market you cannot deliver value to everybody and make money it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of Marketing.
The four P's of Marketing are product, place, promotion, and price.
What the seller puts into the exchange is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer, is called the Promotion.
And the way the seller delivers the product to the customer is the Place Decision.
Typically, when you talk about marketing, you talk about the business world, but you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increases in blood donations.
Now let's think about what is the product for the American Red Cross when they want more blood?
It's not blood, is it?
Because that's not what they're putting into the exchange.
Blood, is actually the price.
It's what the customer puts into the exchange.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes, I gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high school.
And it turned out what, one of the products that the American Red Cross could give to high school kids to give blood, was to allow them to miss class.
So, that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross.
And the place decision was how they got the product delivered to the, and the exchange made.
And in this case the American Red Cross had the Blood Mobile.
And, and went to the customers so that was a very innovative distribution decision.
So you can play around with these four P's in very interesting ways and some of the new businesses that we see now are doing some very clever things with these four P's.
But the basic concept should be clear, product, place, promotion and price.
Let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
What the seller puts into the exchange, is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
Could be advertising, sales, whatever.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
It can be online.
It can be through, downloading.
So those are the four P's of marketing, product, place, promotion and price.
Typically when you talk about marketing, you talk about the business world.
But you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
Blood is actually the price.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And its based off of their framework, although I've adapted it some.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
Whether or not it meets my needs, so is it customized to meet my needs?
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
So, that's a very strong assumption.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
So, those are the assumptions.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Think about what's going to happen in that marketplace, in a very competitive market.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
You have to do the same thing, or what are the product attributes that matter to the customer?
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
And some people more.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
I'm really excited to be starting my module of our introduction to marketing course.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Are we going to focus on all customers the same way?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
Running a business in a performance superior or operationally excellent kind of way and that's going to give us the basic foundation so we can really understand how customer centricity is different.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
Okay you have a certain degree of expertise that has enabled you to bring us the current product.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
How can we take that product expertise, and either extend it to new customers or extend it to new products?
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're going to try to do it as, as efficiently or effectively as possible.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
I'm going to stay in the water.
And this is exactly the kind of issue that many companies are facing today.
It gives them some opportunities for growth.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
And if you look up and down the slide, you won't find a lot that's tremendously insightful, and that's the point I want to make.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
How can we spread it out to other kinds of customers, and other kinds of businesses?
Again, implicity, that's the way that most businesses operate.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
In fact, I'd like you to just take a, a minute or two think about what are some of the changes, today, compared to 15 or 20 years ago, that make product centricity just a little bit different?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
We're doing something that's going to keep us ahead of all of our competitors for a long period of time.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
They would take whatever products or services that we would give them, and they would say, oh, that's great, terrific, thanks very much, I'll figure out how to use it.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
But that they, they clamor for than they ever were before.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
And even if customers were aware of it, customers wouldn't have access to it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
But by no means is it limited to technology.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
They no longer manufacture personal computers.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
He didn't know.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
To be understanding who's buying what.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
So I want to talk about a couple of examples about companies that have used information technology and specifically the data about their customers.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
They turn to a deep understanding about their customers to draw insight and to let them change their business models in a way that actually let them rise to the top of their industries.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
What kinds of messages and offers to provide, at the right time, and through the right channel, in order to create and extract more value from that customer.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
And so when they sit back down again, their threshold is back towards zero.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
And this helped them not only grow the business with those customers, but also helped them to compete more effectively.
So Tesco knew, again, which coupons to send to which households, at which time, in order to really hold on to those customers and bolster their business.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
So while the Harris and Tesco stories are terrific, I will provide pointers to some books that summarize each of those stories quite well.
I want to emphasize that they're not the only ones who have built a business around a deep understanding of their customers, and by no means are they the first.
In fact, the first companies that actually built a business in this manner, around their customers, has happened many, many years ago.
And it emerges from the sector of direct marketing.
They think about infomercials and other, you know, not great marketing activities.
it, it's, it's not the kind of industry that you aspire to be associated with or learn from.
If you, if you look at, at what direct marketing is really all about, it is really building the business around the customer.
But not just, the customer in some generic sense, but around each and every customer.
It's about understanding the relationship with each different customer.
That's what direct marketing is all about.
What's interesting about it is, that direct marketing is not a new concept.
There's actually a lot we can do, we can actually formalize some of these business practices, and come up with some best practices associated with them.
But even if you don't spend a lot of time thinking about direct marketing, a lot of the words and the concepts have already filtered their way into today's everyday marketing conversation.
So, a lot of the segmentation concepts that Barbara discussed are often associated with direct marketing.
Something that you've heard about before, that we're going to spend more time talking about, that's, that, that comes directly from the direct marketers.
We can collect all this data about our customers, about each and every one of them, and we can actually build a business by understanding who the valuable customers are, who the less valuable ones are.
Which messages we should be sending to which customers at which time, and, importantly, what kinds of products we can develop and deliver in order to create more value for our most valuable customers and to try to attract more customers like them.
So the Harris and Tesco stories are wonderful, but they're not unique.
And so I want to spend a lot of time celebrating some direct marketing practices.
And I want to emphasize that a lot of firms out there today might not aspire to be direct marketers, but they don't realize it, but they are.
Has the capability to learn from direct marketing, and I encourage all of you to read books on direct marketing.
Even if you don't think about yourself that way, there's just so many concepts that you can learn and leverage, especially as we enter this world of big data.
And we've discussed some of the cracks in product centricity.
And even some of the opportunities for companies to escape from and maybe do better than a product-centric approach.
And so in order to do that, I want to work with a series of examples here.
In fact, on the slide, you'll see the names of four very famous retailers.
Three of them operate on a global level so Walmart, Apple, Starbucks.
I think, you'll appreciate the story anyway.
So I want you to think about what customer centricity means, in light of our discussion so far.
So think about what customer centricity means and which of these firms qualify in that regard.
Now, I want to be careful about this.
I really like what they do.
But all of them for different reasons fail to be truly customer centric, nearly as much as perhaps some of you thought in deciding which of these firms are or aren't customer centric.
So let me just take a few moments to talk through each one of them and then finally, we'll bring up our definitions of customer centricity.
But Walmart knows surprisingly little about any one of its customers.
Unlike Harrah's, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
Walmart has made very little effort to date to try to figure out exactly what each customer is doing.
So while Walmart might not make a lot of efforts to understand what anyone costumer is going to buy, they make great efforts to understand the costumers as a whole.
They understand regional differences.
They understand when certain kinds of events occur for instance when a hurricane is about to hit the Southeastern US, they need to fill the storage with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way, as a direct marketer would suggest.
That doesn't bother me because Walmart isn't intending to be a direct marketer.
If you think about the Walmart business model its about selling in great volumes, its about bringing the cost way down.
So in many ways, Walmart is a prototypical and a wonderfully successful product-centric firm.
There are few firms in the world that can operate an operationally excellent manner, as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time doing market research to figure out exactly what the customer wants.
They don't spend a whole lot of time focusing on segmentation, and real granular analyses to try to predict what any one customer's going to do over time.
Now Walmart and Apple for the most part are focusing on doing product-centric things.
They are doing some smart things at the margin to understand their customers better.
A mobile app that let's people scan products as they move around the store so as they check out the whole scanning process happens much faster.
It's a brilliant idea that let's them be more operationally excellent, but also let's them start tagging individual customers, and tracking them over time.
So they're starting to take on some more customer-centric initiatives, without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business, but letting them understand their customers a little bit better.
Whether it's tracking people's music preferences through iTunes or some of the activities that they do in the apple retail stores.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
The Barista, the person on the other side of the counter.
The person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store, but just through just casual conversations you have with them, they might know what movies you like?
And often make recommendations to you that are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted adviser to the really good customers, finding ways to lock that customer in, and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they're not that customer centric.
You take your Starbucks loyalty card and you bring it to a Starbucks in another city or another country.
But it's hard for them to be a trusted adviser and to make other recommendations to you, when they have no idea about anything about your history.
So to me that's a really key point.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
It's the balance between focusing on the product and focusing on the customer that so many companies are now struggling with.
And finally, there's Nordstrom, and while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
But whether you shopped at a Nordstrom store or not, you might be familiar with the story that makes Nordstrom so supposedly customer centric, or not.
They sell clothing, shoes, and so on.
Supposedly in Fairbanks, Alaska and wanted to return a set of tires that obviously they could not have bought at Nordstrom.
Perhaps there was a tire store at that location before Nordstrom opened shop.
And Nordstrom's being so incredibly customer-centric gave them the money back for tires that they didn't buy at Nordstrom.
If you think about it for a minute, is that really customer centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
I'm talking about the fact that we expect this customer to be buying so much from us in the future, that if we don't give them enough money back for the tires that they thought they bought from us, if I don't give them the money back today, we're going to lose that value.
If that's the case, we'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer, the future value, the lifetime value of the customer.
If that's sufficiently high, then we will roll out the red carpet for you.
And if it's not and for most customers it wouldn't be then, we would politely decline.
We might still be nice to you of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
And there's a lot to be said for that.
It's a wonderful company.
I like knowing that when I go in there I'm going to be treated really well.
So to me the Nordstrom example is a great example of where product and customer centricity collide.
And what I want to do now is to start focusing on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
How do we determine whether a business really is or isn't customer centric?
In other words, what is the definition of customer centricity?
So in fact, I'd like you to take a minute and just jot down whether it's a full sentence, or even just a few words that you would associate with customer centricity.
Take a minute and do that, and then I'll, then I'll give you my perspective, my definition on what customer centricity is.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
For instance, going back to the IBM example, there was a case where a company was willing to recommend other products and services.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
Let's come up with something for them, something that's going to make them even more locked in, something that's going to create greater long-run value for them, and something that's going to help us recruit even more customers like them.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
It's, it's the way, just changes the conversation, and perhaps the design, within the organization.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Maybe they didn't, by the end of the month.
That we think in the long run we've, we will create much more value that wouldn't have been there.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
And again, I can point to examples of companies, I'm, I'm thinking of a particular pharmaceutical company that changed its sales person incentive program to be forward-looking instead of backward-looking, and wonderful things happened.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
Is it the insurance company?
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
Agreeing, that one of these entities is the customer, we care a lot about the others, we need to keep them in mind, as we go through our planning practices.
So it's important to first sit down and figure out, who the, the customer could be.
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
And before saying, we're going to become customer centric, it's very important to come up with that list, and think real carefully about, existing barriers and new ones, that can be arising, to, to do a real careful inventory, of, of, of barriers towards customer centricity.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
So, there's a, a number of, of, of different ways that we can start thinking in advance, about overcoming the barriers, before the, the barriers actually start impeding our progress.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be an organizational initiative like, My Black Is Beautiful for Proctor and Gamble.
It might be other kinds of experiments that, that a company is going to run.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
So we're going to talk specifically about how to acquire some of those customers that Pete was talking about.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So, let's first start out with, what are perceptions?
Perceptions is probably one of the most important aspects in consumer behavior, and in understanding consumer behavior.
What is a perception?
The perception is the process of developing an interpretation of a stimulus.
Or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever cons, customers perceive, is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
And this process is inherently biased.
It contain, it, the process of perception comes in several different stages.
The first two stages are, the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
Pay attention to what's salient to you.
And we know that that process is very biased.
You only expose yourself to things.
But when you're consciously exposing yourself to things, many times it's a function of what you believe, what you're prior beliefs are.
Let me give you an example.
Say you think that a part of town is not safe.
Well, you won't go to that part of town.
You'll stay away from that part of town.
So you won't expose yourself to something you don't think is safe.
As a result, you never have, ability to change your perception, of that area of town because you don't collect new data.
So we know that exposure can be selective.
Similarly, even if you are exposed to something, if you don't pay attention to it, again it can affect your, your perceptions.
And we know that there's 2 kinds of attention, there's voluntary attention, and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you would had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure, and selective attention.
That means you're not collecting data on things that might be, might be able to change your perception.
So that's first stage of bias.
The second stage of bias is once you are exposed to something, and if you pay attention to it, then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who in interpret what happened in the debate from both parties.
Because we know a priori, the interpretations are going to vary based on their prior beliefs.
And, that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli.
As a result of this, perceptions are frequently biased, and they don't necessarily represent what's true.
So what's the overview of the perceptual process?
There's, we're going to talk about it, brand communication, there's advertising, there's packaging.
And then you are exposed to them, or you're not.
And sometimes the exposure, as I mentioned, is in a bias, bias way.
And then, even if you are exposed to these inputs, you know, and you're exposed to thousands of marketing measures, marketing cues every single day.
But how many of them do you pay attention to?
So, first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it.
And finally, there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that, your perceptions, and I just explained to you your perceptions could be biased, but your perceptions affect your subsequent behavior.
Regardless, it's almost an automatic reaction.
You have a certain perception, and then you automatically respond to that.
And it's very had to control that, even if you think, well I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that, so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So, here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
I mean, the first one, maybe you were a little bit surprised.
And you saw that the word was blue, but the color of the font was red, so the answer was red.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word, and reading the word affected your subsequent behavior, it slowed you down.
That's actually the purpose of the Stroop test.
It's a stress manipulation, it makes people feel a little bit uncomfortable because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches and you can see, it's much easier, it's much faster to say the words.
This is the same thing in the way marketing I'm going to show you that color has an effect, brand name has an effect.
It affects your subsequent perceptions and subsequent behavior, and it's an automatic reaction that's difficult to stop.
So let me just give you, here's an example.
If I told you this is luscious chocolate, and I show you a picture of it if the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh I don't want to eat this, that disgust feeling.
And you know that it's good chocolate, but the shape has an involuntary effect on you.
And that, that's a very important thing to understand.
So marketers need to understand how these things affect your perceptions and your subsequent behaviors.
Because as I say these are automatic reactions.
There's some visual illusions you may have seen these before.
I can show you these two lines on the screen.
I will tell you you can measure them, they are exactly the same length.
However one looks longer than the other, and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you, what is this that I've put on the screen.
You'll answer differently if I show it to you this way versus when I showed it to you this way.
And so that shows you what you perceive that stimulus is, is a function of your prior expectations.
And what the proximity bias says, is if things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that they'll cluster the two lines that are close to each other, rather than say the two bold lines or the two thin, thin lines.
And you can see this in the supermarket, in stores.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception.
That physical distance affects whether things are similar or belong together.
In the mall, stores that are close together or seem to be more similar.
Things that look alike, people assume have the same quality.
So this is the the, the underlying the, theory behind, say, store brands.
You're making an assumption of perceived quality, based on this process of similarity.
And it's a very, very important consumer process for marketers to understand.
It's particularly important in branding.
With the Coca Cola brand on it, people will think it tastes better.
They're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product's exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that, I know.
I can judge certain products by the quality.
And, we know from experiment after experiment after experiment, that, that's just not true.
People are very much influenced by the brand name that's put on the product, independently of the product quality.
it's same way in the Stroop test.
You just can't stop it.
Once you see that brand name, you have certain perceptions.
We know that brand is such a powerful brand as we mentioned before.
The Coca Cola brand name has been estimated to be worth 70 billion dollars as an asset.
Just putting that brand name on a product will change, as I said price premiums people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So ex, for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time, that no one had tasted before, a diet soft drink.
They call it Diet Coke.
And automatically, even though that product was not on the market before, people assume it has hot better taste, it's a higher quality product.
And again they're willing to pay a higher premium price for that product.
And welcome to the first video in An Introduction to Financial Accounting.
In this video, we're going to provide an overview of the financial reporting landscape.
What's required in financial reporting, who makes the rules, who enforces the rules, what are the basic set of financial statements.
Accounting is a system for recording information about business transactions to provide summary statements of a company's financial position and performance to users who require such information.
>> I sure hope not, but to spice things up a little bit, I will bring in some virtual students every now and then to ask questions or to make pithy comments.
Anyway, this definition has three parts.
This part turns out to be a big deal, as not everything a business does gets recorded in the financial statements, and sometimes it'll seem like nothing's happening, yet we'll need to record a transaction anyway.
Large companies have billions and billions of transactions every year.
If they made them available to you in a gigantic database, your first question would be, how can I summarize all this into one or two summary numbers?
And the third part focuses on users, because different user groups would want different summary numbers.
So most companies have to keep three sets of books.
This standardized set of statements is geared toward external users like investors, creditors, customers, suppliers, competitors and any other stakeholder or person that has interest in the company.
However, these financial statements are not used to determine taxes.
There is a separate set of books based upon tax rules that are used to compute how much taxes a company has to pay.
Finally, there's managerial accounting.
We're not going to cover this topic in this course, but I wanted to make you aware of the fact that the financial accounting that we do talk about it is generally not used for internal decision making.
Instead, there are other kinds of numbers that are looked at.
So what are the financial reporting requirements?
This includes a full set of financial statements with a substantial amount of additional disclosure.
The other three-quarters of the year, firms must file a quarterly report, or 10-Q, which has a full set of financial statements but less required disclosure than the annual report.
If anything material happens between quarter ends, companies must file an 8K, or current report.
Material information is generally viewed as anything important enough to move stock price, which means companies file these quite often.
All of these filings have to be prepared in accordance with generally accepted accounting principles, or GAAP.
However, the things that we cover will be applicable globally.
So for instance, even though we're talking about SEC filing requirements in the US, every country in the world that has a securities market has filing requirements like an annual report.
The only difference you might see internationally is instead of a quarterly report, some countries require semi-annual reporting.
So this is a pretty universal set of filing requirements that apply to public and private companies around the world.
For example, let's say we ship goods to a customer in one quarter, but we collect cash in the next quarter.
And let's say we buy some equipment in one quarter, and then use it to manufacture goods over the next 23 quarters.
When we pay cash to buy the equipment or as we use it over the next 23 quarters?
A lot of what we're going to do in this course is try to figure out what quarter to put various business activities into when we put together the financial statements.
So who makes the rules?
Generally accepted accounting principles, or GAAP, are established by the US Congress, but they're usually too busy trying to do things like investigating steroids in baseball or figuring out whether they should shut down the US government again.
They don't have time to deal with accounting standards, so they delegate to the Securities and Exchange Commission.
But they're often too busy trying to catch the bad guy, so they don't have time to make the rules.
So they delegate to the Financial Accounting Standards Board, of FASB, which is a seven-person board in Norwalk, Connecticut, that has the authority to make the accounting rules in the US.
And sometimes they're even too busy to make all the rules, and so there's an emerging issues task force and the AICPA that can also have a hand in making accounting rules, or US GAAP.
Now this is just in the US.
Internationally, there are international financial reporting standards, or IFRS, that are established by the International Accounting Standards Board, or IASB, which is based in London, and are now required in over 100 countries including all of the EU.
But as of now, US GAAP is still required for US firms.
So basically there are two big sets of accounting standards in the world.
But the good news is, for almost all of the introductory accounting topics that we look at in this course, there's a very high degree of overlap in the two standards.
>> Actually, in the summer of 2008, the SEC came out with a roadmap that would move US firms to IFRS by basically now.
But then what happened was, Lehman Brothers went bankrupt, the financial crisis hit and the roadmap dropped way off the SEC's radar screen.
So for the foreseeable future, we're going to have two big sets of standards in the world, US GAAP and IFRS.
But as I just mentioned, the good news is the two standards are getting closer to each other all the time.
The FASB and IASB are working together on any new standards.
So, all the stuff that we talk about that's under US GAAP in this course will be very similar to what you would see under IFRS.
So who's responsible for financial reporting?
We allow managers to put together their own financial statements because they have the most information about what happened in the company.
And we hope that they use their discretion in financial reporting to better communicate their activities.
However, it is important to remember that they may use this discretion to try to manipulate the perceptions, and we need to be on the lookout for such opportunistic behavior.
So we put in a number of checks and balances to try to curb managers' opportunistic behavior.
First, the Audit Committee of the Board of Directors provides oversight of management's accounting process.
However, this is not a foolproof check on managers' behavior.
Which means you could put someone like me on the board and still have these kinds of problems.
So then the auditors are hired by the board to express an opinion about whether the statements are prepared in accord, accordance with GAAP.
This again is not foolproof, because in the case of Enron, their au, auditor, Arthur Anderson, signed off on some of the more aggressive things they did, and part of the reason was because they were being hired by Enron to approve their accounting.
If they lost Enron because of a disagreement over their accounting, then they would have lost the biggest company in Houston and would have had to go to the second biggest company in Houston which is uhh.
Who knows what the second biggest company in Houston is?
And that's why they want to make sure to keep Enron.
The next line of defense is the SEC and other regulators who will take action against the firm if any violations of GAAP or other rules are found.
Now these bodies tend to be very reactive instead of proactive, and it's oftentimes after someone else has brought the fraud to the public's attention that they launch their investigation.
So by and large, it's information intermediaries like stock analysts, institutional investors and the media that provide the biggest check on managers' behavior by either exposing or fleeing firms with questionable accounting.
But by the time one of these parties get involved, it's a very public issue, the stock price drops and you're in bad shape if you're an investor or employee of the company.
So in the end, the only party that's really going to look out for your interest in terms of understanding and trusting financial statements is you.
Which is why it is really important that you learn some basics in terms of reading financial statements.
So what are the required financial statements?
Well, there's four of them.
First, there's a balance sheet, which gives a company's financial position, which is its listing of all its resources and obligations on a specific date.
By over a period of time we mean between two balance sheets, so either a quarter or a year.
And by accrual accounting, it means we're going to recognize things in the income statement based on business activities, not based on cash flows.
Because we have a separate statement for cash flows, the statement of cash flows, which will give you all the sources and uses of cash over a period of time.
And then finally, there's the statement of stockholder's equity, which provides changes in stockholder's equity over a period of time.
This is pretty abstract.
>> Yes, in fact I have an extended example where we go through a simple business and see what the different financial statements can tell us about what's going on at the business.
But it takes another ten minutes or so, so to avoid this being a long first video, why don't we cut it off here and we'll pick it up in the next video.
I'll see you then.
In this video, we're going to take a look at what the financial statements can tell us about a business.
To do so, we're going to look at a very simple business with just a few transactions to see how those transactions would affect the required financial statements.
I'm going to throw a lot of concepts at you in this video.
We're going to go through all these concepts again later on in the course.
Let's get started.
The example we're going to look at is Dave's Car Transport Service.
So Dave starts a business to transport expensive cars.
On December 1, 2015, he receives $50,000 cash from issuing common stock.
He also borrows $80,000 from a bank.
And we'll buy a $100,000 truck.
The truck will be used for 48 months with a $4,000 salvage value.
Dave also paid $12,000 cash upfront, to rent office space for the next year.
During the month of December, Dave's company moves two cars the clients will pay them $40,000 within 30 days.
Dave also pays his employees $10,000 of wages.
Now it's December 31st and the bank wants to see some financial statements.
The bank wants to see financial statements because they want an answer to the question.
Now there's a number of different ways that we could try to answer this question.
The first way would be to just look at all of the cash flows.
So, if we take the facts and look at the cash flows, Dave's company received $50,000 cash from issuing stock, borrowed $80,000 from the bank, and bought $100,000 worth of truck.
They paid $12,000 cash up front to rent office space for a year.
And they did not collect any cash from customers during the month.
But as it turns out, this is a really bad way to figure out whether the company made money or not for December.
What is wrong with that?
Anytime I end the month with cash in the bank, it is a great month.
You get an allowance from your parents.
You borrow some money from your parents.
You spend a bunch of money.
If you end the month with money in the bank, it was a pretty good month.
But this doesn't work so well for companies.
All a company would have to do to post better performance into the system would be to borrow more money or sell more stock.
A better way to look at cash flows would be to separate them into whether they come from operating the business or investing for the future, or financing for the long term.
So let's start with cash flows from operating the business.
This would be cash that was paid for the rent.
We didn't actually collect anything from customers, so the net casual from operating the business was a cash outflow of $22,000.
Then we can look at cash required to invest in the business for the long-term.
So the company spend $100,000 cash to buy a truck, which resulted in a total cash outflow from investing activities of $100,000.
And then finally, we can look at cash used to finance the business.
So, the company received $50,000 in cash from issuing common stock.
They borrowed $80,000 from a bank, which was a net cash inflow from financing activities of $130,000.
But now, we've organized the cash flows based on whether we're operating the business, investing in the business, or financing the business.
And this is exactly what the statement of cash flows will look like.
It's going to report the cash transactions for the company over a period of time like the month of December.
Split up into operating activities which are transactions related to providing goods or services or other normal business activities.
And financing activities, which are transactions related to owners or creditors.
Another way to try to answer the question of whether the company made money in December, is to look at accounting income.
Accounting income tries to look at business activities rather than cash going in or out.
For example, we actually did move two cars during December.
Even though we haven't got paid cash yet, we're likely to get paid cash, so why not book revenue of $40,000 to recognize the cash that we'll eventually get, from providing the service of moving the cars.
Even though we paid $100,000 for a truck, we're going to use that truck over four years.
So why not allocate the cost of the truck over the four years.
So we have a $100,000 truck with a $4,000 salvage value.
Salvage value is how much we think the truck will be worth when we're done with it.
So let's take that $96,000 of value that we're going to use up, divide it by 48 months.
And recognize a $2,000 expensive of using the truck, each of the next 48 months.
We paid $12,000 cash upfront to rent office space for a year, but we've only been in there for one month.
So why not just show one month of expense $1,000, rather than the full $12,000 of cash that we paid up front.
We paid $10,000 of cash to employees for wages.
That was all due to work they provided this month, so we'll show that all as a wages expense.
Net income is a measure of whether we priced our service, moving cars, high enough to cover all of the costs or expenses of running the business, all of the cost of moving the cars.
And this is what the income statement is going to tell us.
We'll have revenues, which are increases in owners' equity from providing goods or services.
And we'll talk more about what owners' equity is in a little bit.
We'll have expenses, which are decreases in owners' equity, which are incurred in the process of generating these revenues.
It's the cost of doing business.
The bottom line or the differences between revenue and expenses is going to be called net income, which is also called earnings or net profit.
And it's important to note that it does not equal the change in cash because it's a measure based upon business activities, not purely cash flow.
How can we record revenue without getting any cash?
What is this depreciation stuff?
We didn't spend $2,000 on a truck, we spent $100,000.
It'll, it'll take a little bit to explain all this to you.
There are two different statements for this month's results.
Which one is better?
Which should we use?
I am going to only use the Cash Flow Statement.
We'll talk about this more.
But you definitely want to use both statements because they tell you different things.
Let's take a look at how these two statements provide different pictures of what happened with the company.
So starting with revenue, that tells you that you moved cars during the period and you are eventually going to get paid $40,000 from customers.
Where as the $0 in the cash flow statement says that you actually didn't get any cash this period.
For the truck, the cashless statement tells you, you spend a $100,000 cash on a truck.
The accounting income says that the cost of the truck used up this period to generate revenue, is only $2,000.
Because we're spreading it over the whole time that we're going to use the truck.
For rent, our cashless statement said we paid $12,000 cash this period for rent.
But our accounting income says that we only used up one month of that.
We still have $11,000 that we haven't used up, that we'll use up over the next 11 months.
Sometimes the expenses and the cash flow are the same as in the case of wages here.
But as you can see from the cash from operations and net income, you're getting very different pictures.
Cashflow from operations of negative 22,000 says that you spent more cash than you had come in based on these operating activities.
Says that you priced your service high enough to cover all the costs of providing the service.
Which even though it didn't get you cash this period should lead to positive cash flow in the future.
The next statement that we're going to preview is the balance sheet which provides the financial position of Dave's Car Transport Company at the end of the month.
By financial position we mean all their resources and obligations.
So the resources are what we call assets, so what are the assets or resources of Dave's company?
Well they have $8,000 cash in the bank at, December, 31 2015.
That's the cash owed by customers on December 31st.
And that's an asset because it's going to eventually turn into cash when you collect from the customers.
Another asset is prepaid rent.
Remember that Dave paid $12,000 for a years of rent.
One month has been used up, but they still have 11 months of prepaid rent.
This is an asset because they can occupy the space for another 11 months, without paying any additional cash.
And then, of course, there's the truck, which is an asset of $98,000.
That's the original cost of $100,000 minus that $2,000 that we depreciated.
So that gives us total assets or resources of $157,000.
Now we can look at all the obligations or claims on these resources which are the liabilities and stockholder's equity.
Dave owes the bank $80,000 at December 31, 2015.
That's a liability called bank debt.
There's $50,000 of stockholder's investment as of December 31.
This is a stockholder's equity called common stock.
And then there are retained earnings of $27,000.
Retained earnings represent all of the net income or accounting income that's been created over the life of the company, minus any dividends that have been paid out, which we'll talk about later.
And when we add it all up, the obligations are the same as the resources of $157,000.
And this is characteristic of the balance sheet which always has to balance, hence the name.
When is this video going to end?
I know I've thrown a lot of new concepts at you in this video.
But don't worry, we're going to go over everything again in more detail.
And there's only a couple more slides, and we're done.
It's going to report the financial position of the company.
We've got assets, which are resources owned by the business, that are expected to provide future economic benefits.
Liabilities are claims on those assets by creditors, or non owners.
Creditors, that represent an obligation to make future payments of cash, goods, or services.
Stockholder's equity, or owners' equity, are claims on the assets by the owners of the business.
Those come from two sources, contributed capital, which arise when you sell shares, and retained earnings, which arise when you operate the business.
We're going to talk about these a lot more in the next few videos.
The last statement is the Statement of Stockholders' Equity.
And we're going to get to this later.
Hopefully, that gave you a good overview of what the financial statements are trying to tell us.
We are now going to start looking at the financial statements in more detail, starting in the next video with the balance sheet and the balance sheet equation.
I'll see you then.
In this video, we'll take a look at the one rule of grammar in the accounting language, the balance sheet equation.
We'll see how the balance sheet equation makes all the financial statements fit together.
We'll also use the balance sheet equation to solve some problems where we're missing one piece of information, but we can fill in everything that we do know into the balance sheet equation and solve for what we need.
Hope you enjoy the video.
Well, the good news about learning the language of accounting is that there's only one rule of grammar, the balance sheet equation or the accounting identity.
This is that assets equal liabilities plus stockholder's equity at all points in time.
>> Can you give me an example of when this is used in the real world?
>> A good example to think about how we use the balance sheet equation in real life, is when we buy something big like a house, or a car.
So, let's us say we wanted to buy a $500,000 house but we only had $50,000 of cash while we would need to go out and borrow $450,000 from the bank in a mortgage in order to buy the house.
Then after we bought it we'd have 500,000 in assets, the house, which is equal to the 450,000 of liabilities, the mortgage.
Plus 50,000 in equity, which is how much cash we put in and which represents our claim on that house.
The most important feature of the balance sheet equation is that it must always balance.
And that's why we're going to talk about something they call double entry book keeping.
If you increase something on one side of the equation, you have to increase or decrease something else to stay in balance.
So, there has to be at least two entries any time you tinker with the balance sheet equation.
And as we'll see, the changes between two Balance Sheets are going to be summarized in the Income Statement, the Statement of Stockholders' Equity, and the Statement of Cash Flows.
So let me show you this graphically.
So let's say we have a balance sheet at the end of December 31, 2014.
We'll split the assets into cash and non-cash assets, and we'll split stockholders' equity into contributed capital and retained earnings, which are concepts we'll talk more about in later videos.
Then we have a balance sheet at the end of the year, so we've got one at the beginning of 2015, at the end of 2015.
The difference in the retained earnings is going to be explained in the income statement for the year end at December 31, 2015.
And the difference in cash, is going to be explained in the statement of cash flows for the year ended December 31, 2015.
>> Here you go again with the difference between income and cash.
>> Okay, let's go back to the house example.
So, your balance sheet at the end of the year would have a million dollar asset, the house, 450,000 of liabilities because the mortgage doesn't change, but your equity would go up from 50,000 to 550,000.
Now, if you look at the statement that explains the changes in two balance sheets.
None of this affects the cash flow statement because there's no cash impact of your house going up in value.
In fact, your cash up should probably went down as you were paying the mortgage.
But your income statement would show a gain of $500,000 from the increase in your equity due to your ownership claim of the house.
Can you give us a more contemporary example?
These are assets because they're claims on collecting cash payments from people that took out sub-prime mortgages.
So let's say a bank had 10 billion of these mortgage-backed securities as assets.
And half a billion of equity.
So now they have to be written down in value from 10 billion to, let's say 1 billion.
Now the liabilities don't change.
And so it's another example where there's no cash flow impact of the change in these two balance sheets, but we end up showing a $9 billion loss on our income statement due to the drop in our equity claims on those assets.
Of course, we also have to mention the statement of stockholders' equity, which explains the changes in stockholders' equity between two balance sheets, which we will talk about more later in the course.
What I want to do next is show you how everything that we're going to talk about fits into this balance sheet equation.
So, we talked about how stockholders' equity is two components, contributed capital, which is the money that we raised from shareholders, and retained earnings, which is what we create by operating the business.
Retained earning is going to equal whatever retained earnings were at the beginning of the period plus any net income, earned during the period minus any dividends paid out to shareholders.
That's why it's called retained earnings, because it's the earnings or net income less any dividends paid out.
And then net income, as we talked about in a prior video, is revenues minus expenses.
I am going to ask you to do some math.
Now I'm going to give you some problems, give you a chance to try to answer the problems, and then we'll talk through the answers.
After I read the problem, you'll see a little pause icon on the screen.
If you want to try to answer the problem before I give you the answer, pause the video at this point, try to come up with the answer and then resume the video.
But, if you want to just roll through and hear the answer right away, then it's okay to keep the video going.
This is going to be the procedure that we follow any time that I give you some questions that I wanted to, want you to try to answer during the video lecture.
Okay, here is the first one.
We know that assets are 100.
Liabilities are 50.
The only thing that's missing is stockholder's equity, which has to be 50.
So that we have 100 on the left hand side, and 100 on the right hand side.
Next, liabilities increase by 100 and stockholders' equity is unchanged.
Again, we can use the balance sheet equation to answer this, but now we're looking at changes in the numbers.
Next, all non-cash assets are 70, total liabilities are 60, total stockholders' equity is 30.
What is cash?
So we have Liabilities of 60 and Stockerholders' Equity of 30, that's 90 on the right-hand side.
Noncash assets are 70.
The only thing missing is Cash, which has to equal 20, so that we have 90 on each side.
We can use the same equation but we have to be a little bit careful.
Now, if we knew that stockholders' equity had not changed, then liabilities would have had to go up by five, so that we have an increase in five on both sides of the equation.
But without knowing what happened to stockholders' equity, we technically don't have enough information to answer this one.
But, I promise that it won't be the last.
Next, we have Retained Earnings increasing by 100, dividends are 50.
Earlier in the video, we looked at the equation for retained earnings, where retained earnings is equal to prior retained earnings, what they were at the beginning of the year, plus net income during the period, minus dividends.
So we know that the change in net income.
We know that dividends is 50, so the only thing missing is net income, which has to be 150 for this to balance.
Next we have revenue increasing by 100, all other categories are unchanged except assets.
We have to use the complete balance sheet equation to solve this one, so that we break Stockler's equity into contributed capital, prior retained earnings, revenues, expenses and dividends.
Everything else is unchanged but assets, which means that assets also have to go up by 100 so that both sides of the equation increase by 100.
So we know that expenses went up by 60, everything else is unchanged except for cash.
The purpose of this exercise was to preview the type of problem that you are going to be doing a lot in this course.
There's going to be a certain piece of information that you need that you're not given.
But, you can take all the other information that you're given, and a set of equations, that will usually be in the form of T accounts, or journal entries, fill in everything you know, and then solve for that one piece of information that you need, that you can't find in the financial statements.
So I'm going to go ahead and wrap up this video, and we'll come back next time and talk in more detail about assets, liabilities and shareholder's equity.
In this video we're going to build on our discussion of the balance sheet equation to talk about assets, liabilities, and stockholder's equity in more detail.
We're going to provide precise definitions for each of them, and we're going to look at situations where we can record them, and situations where we can't record them.
Let's get started.
Let's start with assets.
An asset is a resource that is expected to provide future economic benefits.
That means, it's either going to generate future cash inflows or it's going to reduce future cash outflows.
There are two criteria that we use to decide, when to recognize an asset.
First, it must be acquired in a past transaction or exchange, and second, the value of its future benefits can be measured with a reasonable degree of precision.
So, for example, if we buy a truck, the truck would be considered an asset.
And the value and the benefits of the truck are equal to the price that we paid to buy the truck.
So, both criteria are satisfied, and it would be an asset.
Now we're going to practice applying these criteria to figure out which of the following items would be assets.
I'm going to give you a number of items, and for each one, I want you to try to figure out whether it's an asset or not.
If it's an asset, try to give me the account name and what the dollar amount would be.
If it's not an asset, then try to figure out what criteria would cause it to not be an asset.
I'll bring up the pause sign so if you want to pause and try and answer it yourself you can, but as always you can just roll through and listen to the answers if you'd like.
BOC sells $100,00 of merchandise to a customer that promises to pay cash within 60 days.
This'll be an asset called accounts receivable.
It's an asset because there was a transaction where we delivered goods to a customer, and in return we got a promise from them to pay cash.
It's an asset, because that can turn into cash within the next 60 days.
Next, BOC signs a contract to deliver $100,000 of natural gas to DEF, each month for the next year.
Every exchange of cash, good or services, is going to happen sometime in the future.
Nothing has been exchanged yet, so there can't be an asset for it.
>> That's a great question and the first example the costumers promised to pay us cash, but we've acquired that promise through delivering them goods.
In other words there's been a pass transaction or exchange, which is that first criteria for him asking asset.
In the second case, all we've done is sign a contract.
If the contract was broken, it's not clear we'd have any basis to ask the customer to pay us a $100, 000.
buys $100,000 of chemicals to be used as raw materials.
pays in cash at the time of delivery and receives a 2% discount on the purchase price.
Inventory is a term that we are going to use for any product or raw materials that we buy, that we're going to turn into a finished product that we're going to sell at a markup.
And the value of the benefits is known here because it's what we paid in the market transaction.
And note that the value here is 98,000 not 100,000 because we value it at what we actually paid for it, not some kind of higher sticker price that wasn't what the transactions actually happened at.
BOC pays 12 million for the annual rent on its office building.
This is an asset.
It meets the first criteria because in a market transaction, we paid for the right to occupy space in this office building for 12 months.
But note that, at this point, the value of the benefits is only 11 million.
Not the 12 million that we've paid.
Because we've already occupied it for a month we've used up one month of the future benefits.
So at this point in time, there's only $11 million of future benefits.
So we have prepaid rent worth $11 million.
It's broker said this was a steal, because the land is probably worth $150,000.
This is an asset which we'll call Land.
Meets the first criteria because there was a market transaction where we acquired ownership.
The value of the benefits are assumed to be what we paid for it, which is $100,000.
And so we're not going to use that as the value of the benefits.
BOC is advised by a marketing firm that its brand name is worth $63 million.
>> Are you saying that marketing people do not know what they are talking about?
I definitely respect marketing people.
Some of my best friends are marketing professors.
It's simply a case where accounts have decided to err on the side of reliability or objectivity.
Without a market transaction where the company has acquired the brand, we can't be sure of how much it's worth.
And so we err on the side of leaving it off the financial statements.
Now, we're going to turn to liabilities.
A liability is a claim on assets by creditors or non-owners, that represent an obligation to make future payment of cash, goods, or services.
Let's go on.
Just like assets, there are two criteria for when we recognize a liability.
First the obligation is based on benefits or services received currently or in the past and second the amount and timing of payment is reasonably certain.
And even though the words are different, these are essentially the same two criterias for the assets.
The first one says there has to be some kind of transaction or exchange where you've received something that creates an obligation and the second criteria says you can measure the amount of what the obligation is.
So for an example, let's say we borrow money from a bank, we have an obligation to repay the bank based on receiving the benefit of getting the money now.
The amount and the timing of the payment is reasonably certain, and if there was any question, I'm sure the bank could clarify how much we exactly owe them.
So, borrowing money from a back would meet both criteria.
We're going to do the same exercise now with liabilities.
I'll give you a number of items.
I'll give you chance with the pause sign to try to answer them if you'd like and then we'll talk about what the answer is.
First item, BOC receives $300,000 of raw materials from a supplier and promises to pay within 60 days.
We use that term anytime we owe money to a supplier.
It meets the first criteria because we got the benefit of raw materials in a transaction, which now creates the obligation to pay our supplier and the amount of the obligation is reasonably certain.
So we're going to have an accounts payable liability for $300,000.
Based on this quarter's operations, BOC estimates that it owes the IRS $3 million in taxes.
So a little bit hard to see the first criteria here, because there was no explicit transaction.
But essentially what happened is, the government allowed us to operate our business so that, so we got the benefit of being able to operate our business in this country, and in return it created an obligation to pay them taxes.
>> You said that the amount and timing of payment has to be reasonably certain for there to be a liability.
Why is an estimated amount considered to be reasonably certain?
>> We're going to have to make a lot of estimates in accounting.
As long as we're reasonably certain about the number, we should go ahead and book the liability.
For something like taxes, there are tax forms available on the web.
We have a rough idea of how much taxable income will be during the period, and so we can estimate what our tax liability is.
Now, it may not be 100% correct when we eventually file the form.
But whatever our best estimate is, is a much better estimate than ignoring it completely.
So, we go ahead and put our best estimate on the financial statements.
Next, BOC signs a three-year $120 million contract, to hire Dakota Dokes as its new CEO, starting next month.
Until Dakota actually works for us, and works for us without getting paid, there cannot be a liability.
And even then the liability would only be for the time that he or she has worked without pay.
We wouldn't book a liability for the entire three year contract because we haven't received.
The, benefits for that yet.
Plus, there's too much uncertainty with that because Dakota could quit tomorrow, we could fire Dakota, our lawyers, his or her lawyers could find a way out of the contract.
So we only are going to record a liability for the amount of time the Dakota's worked for us.
Since he or she hasn't worked for us yet, there would be no liability.
BOC has not yet paid employees who earned salaries of $1 million during the most recent pay period.
It does meet the first criteria because there's an obligation based on the benefits we've, we've received.
The employees have worked for us, we've gotten the benefit of their services, and now we have an obligation to pay them for those services.
The amount we owe is reasonably certain, and again, if there were any questions, the employees would surely let us know how much we owe them.
So we'd have an obligation based on past benefits for $1 million, and we'd book a liability called salaries payable for $1 million.
Why is this one a liability, but not the previous one?
Is it because the first one pertains to an executive, whilst the second one pertains to lowly employees?
It has nothing to do with status.
It's simply a matter of, for a liability to exist, there must be some obligation based on benefits or services received in the past.
Employees that have worked for us without being paid, creates a liability for us.
This would be a liability called notes payable, meets the first criteria because we have an obligation based on receiving the benefit of the $500,000 from the bank.
The amount that we owe is reasonable cert, that's $500,000 so it meets the second criteria.
So we have the liability called notes payable for $500,000.
>> Great question, interest is not a liability at this point because we just took out the loan, and we can presumably pay a back rate now without owing any interest.
Interest only becomes a liability as the money is outstanding over time.
And to the extent that we haven't paid it, the amount of interest that we owe but haven't paid becomes a liability.
This would not be a liability.
There's a potential obligation based on a benefit received in the past.
The benefit was we sold products which turned out to be defective.
Doesn't meet the second criteria though, because we can claim that the amount of the payment is still uncertain.
Until we have a settlement or we got to trial we don't know that we have to pay anything, so because of that uncertainty, we don't have to record a liability in this case.
Unlike assets or liabilities, there are not two criteria for how to measure stockholders' equity.
Because if you measure all your assets correctly and you measure all of your liabilities correctly then stockholders' equity is whatever is left over.
But there are two sources of stockholders' equity.
The first source is what we call contributed capital, which arises from selling shares of stock to the public.
So we'll talk about common stock and additional paid in capital.
That's what you record when you issue new shares to the public.
Common stock is for the par value, additional paid-in-capital if for everything you receive above the par value.
And then treasury stock is what we call it when the company re-purchases it's own stock from investors.
Is this why there are so many accountant on the golf course during the day.
>> I'm not sure why you're seeing so many accountants on the golf course, but it has nothing to do with par value.
There used to be laws which said that companies couldn't issue new equity if the value of their stock was below the par value.
Where they couldn't pay dividends if the value was below the par value.
Most of those laws are gone now.
And, par value's main implication is that when we issue equity, we put the par value amount of the proceeds into an account called common stock.
We put the rest into additional paid in capital.
The other source Stockholder's Equity is Retained earnings which arise from operating the business.
So what are dividends?
Dividends are distributions of retained earnings to shareholders.
They're not considered an expense and we record them as a reduction of retained earnings on the date the board declares the dividend, which is called the declaration date.
If we don't pay in cash on that date, which is what usually happens, it will create a liability to our shareholders, until we actually pay the dividend on the payment date.
They are paid in cash like other expenses, and why are they a liability?
First, dividends are not considered an expense because they're not considered a cost of generating revenue.
Instead dividends are a discretionary decision by the board of directors to return some funds back to shareholders that's presumably somewhat independent of the company's performance or sales during the period.
Second, we created dividends payable, because once the board declares a dividend, it's essentially holding the shareholders' money until it sends the check, making the shareholders creditors of the company.
Now, I admit that this one seems weird, because usually liabilities are for non-owners, where as here we have a liability to our owners.
But we consider them creditors in this one specific case.
Dividends are not an expense and when the board declares but doesnt' pay a dividend, we create a dividend payable liability.
And that wraps up our discussions of assets, liabilities, and stockholders' equity.
I'll see you then.
This is the video you've all been waiting for we're gonna talk about debits and credits.
Now I have to admit that there is somewhat of a disagreement in the accounting faculty world about whether we should still be teaching debits and credits.
I am firmly in the camp where I believe that debits and credits are a very useful and powerful tool for learning and teaching accounting.
If I had to figure out some kind of complicated transaction and financial statement, the first thing I would do would be break out the debits and credits to help me crack the problem that I'm trying to solve.
So, hopefully you'll find them useful too.
If nothing else, you're joining an exclusive fraternity of people around the world that can speak in the world of debits and credits.
Let's get started.
As a starting point I have to say that the most interesting thing about bookkeeping is that it's the only word in the English language with three consecutive sets of double letters, oo, kk, ee.
Beyond that, I'm not sure it's that interesting.
But these three fundamental bookkeeping equations I'm gonna show you, are incredibly powerful tools for both learning accounting and then ultimately understanding the information that you're gonna read in financial statements.
The first equation we've seen before.
We're also going to introduce the equation that the sum of the debits has to equal the sum of the credits.
And at the beginning balance of an account plus increases minus decreases has to equal the ending balance in an account.
These three equations must balance at all times.
And this will come in handy because many times we'll be missing one piece of information, but we'll have everything else.
And then we can use one of these equations to figure out the piece of information that we're missing.
So instead of having to constantly go back and recalculate the balance sheet equation, instead, all we have to do is make sure our debits equal our credits, and we know that the balance sheet equation is preserved.
Credit card.
All sounds good to me.
Debit card.
But in the accounting world, debit simply means left, credit simply means right.
All they mean is left and right.
Don't ask me why we abbreviate debit as DR.
It's probably something the British came up with centuries ago and we've always done it that way.
Now lets take a look at how debits and credits can be used to preserve the balance sheet equation.
So here's the balance sheet equation again and in prior videos remember we did a more complex complete balance sheet equation, where we split the stockholders' equity into contributed capital, retained earnings, and then revenues and expenses.
In a prior video, you had dividends in this complete balance sheet equation.
One reason is that I was running out of space on the slide, as you can see.
But the more important reason is, we're gonna not treat dividends as a separate account going forward.
We'll create separate accounts for revenues and expenses but we're just going to treat dividends as a reduction in retained earnings.
The problem with this equation is that we have the negative expenses at the end.
As we saw in a couple videos ago, it can get confusing with working with expenses in this case.
Because with any increase in expense would be an increase in a negative number on the right side of the equation which would make it go down, and it's very confusing.
To solve this problem, we're going to move expenses to the other side.
And it's all positive numbers.
Then we are going to call everything on the left debits and everything on the right credits.
There are a number of rules of debits and credits that we have to keep in mind and follow if we want the debits and credits to stand in for the balance sheet equation.
And as long as that's the case, we'll know that the balance sheet equation will stay in balance.
No negative numbers are allowed.
And as you can see in the balance sheet equation above, now that it's rearranged, we don't need to deal with negative numbers for debits and credits.
And in case you ever wondered, the reason why this is called accounting is because we put everything in these accounts, which are areas where we keep track of similar types of transactions.
That's the type of balance, either debit or credit, that the account carries under normal circumstances.
The difference between the sum of the debits and the sum of the credits, at any point in time will give us a balance for the account.
I was wondering why I wasn't getting any questions.
Okay, let's take a look at how this works in more detail.
Assets and expenses are going to have a normal balance that's a debit, which means it's gonna sit on the left side of the T-account.
For example, let's look at an asset like a Accounts receivable.
Remember this is the money owed to us by customers based on sales we've made in the past.
It's an asset, because it's money we'll collect in the future.
Notice I put a little(A) to denote that this is an asset account.
New sales on account increase accounts receivable, increase the amount of cash that our customers owe us, and we're going to increase the account through a each debit entry.
The customers don't owe us the cash anymore because they paid us.
Then at the end of the period we draw a line, add up the debits, subtract the sum of the credits, and we get an ending balance, in this case of 1,020, which sits on the debit side.
I am so confused.
It all depends on the type of account it is.
It's just left and right.
Now, let's look at accounts that have a normal balance on the credit side.
If we look at an example of a liability like accounts payable, this is money that we owe our suppliers based on on raw materials that we've received in the past.
Put a little (L) to indicate it's a liability because we have an obligation to pay those suppliers in the future.
At the beginning of the period, we owe our suppliers a thousand dollars.
During the year, we pay $80 to our suppliers that reduces the liability, reduces the obligation.
Also during the year we go out and purchase new inventory.
The end of the period we draw a line, add up the credits, subtract the sum of the debits, get an ending balance of 1,020, which sits on the credit side, or right side, because it is a credit balance account.
Or, is it the other way around?
Did I say that right?
Anyway, let's just go on.
One way to represent this graphically is through something we call the Super T-account.
If you think of the whole balance sheet as a big T-account with assets on the left and liabilities and stockholders' equity on the right.
And where it gets a little tricky is revenues and expenses.
Expenses are reductions in net income and hence, reductions in retained earnings.
Dude, can I get a tattoo of this on my arm?
>> Yeah, you could but maybe a less drastic step would be to just print out the slide or maybe write it on your hand with an ink pen.
But I do think it is a good idea to keep a cheat sheet handy to help remind you which accounts are debit balance accounts.
We're gonna follow a very systematic approach in analyzing transactions to figure out how to represent them as journal entries.
First what specific asset, liability, stockholders' equity, revenue or expense accounts does a given transaction effect.
Does the transaction increase or decrease the affected accounts?
And then should the accounts be debited or credited, and here we can look back to something like our super T account as a cheat sheet to figure out whether we debit or credit to increase or decrease the accounts.
The name of the account and the dollar amount.
We indent the credits, put a Cr for the abbreviation, the names of the accounts credited and the dollar amount.
Okay, this is really important.
Raise your right hand and repeat after me.
So, why don't we go ahead and stop the video at this point.
We'll pick it up in the next video with the series of four examples to help pull together everything we've talked about so far, and then we'll practice doing some journal entries.
I'll see you then.
In the last video we introduced a lot of terminology and concepts.
And in this video we're going to practice applying those.
I'm going to, I'm going to start with a series of examples to help review the key concepts from the last video.
Okay, let's reinforce everything that we've learned with a series of four examples.
In the first example, we're going to increase an asset and then increase either a liability or equity.
In this case, we receive $100 cash from a bank loan.
The accounts involved are cash and notes payable, both of which increase by $100.
That's the cash.
Liabilities would go up by 100.
That's the note payable, or obligation of the bank and equity is unchanged.
Cash is an asset.
So we would debit cash to get it to go up by 100.
And what I'll do is, I'll put in parentheses, plus 8, to indicate that this debit is increasing the cash account.
If we looked at this with T-accounts, we would have a cash T-account, which would have an entry on the debit side, a notes payable T-account which would have an entry on the credit side.
If we did a balance sheet equation, sort of drew a line, added up the balance in each account, our balance sheet would balance.
We'd have cash of 100 on the asset side, liabilities of 100 on the liability and equity side with no shareholder's equity.
So here were going to repay $20 of the bank loan.
For the journal entry, we're going to debit Notes Payable for 20.
We need a liability to go down, liabilities have credit balances.
So we credit the cash for 20, we'll reduce it.
For T accounts, we would have a credit entry in the cash the account, a debit entry in the notes payable account.
If we drew a line for the balance in each, our balance in cash is 80 on the debit side, balance notes payable is 80 on credit, aside, our balance sheet equation, would balance where we have eighty of cash, eighty of notes payable, and no stock holders equity.
Okay, okay.
But just two more examples and then we'll do some drill entry practice.
The example transaction is that we pay $10 in cash for inventory.
The accounts involved here are cash and inventory, and cash is going down by $10, inventory is going up by $10.
For the journal entry, we need inventory to go up, inventories and assets.
We need cash to go down.
Cash is a asset, you make a debit balance asset account go down with a credit, so we credit cash for ten.
In terms of the T-accounts, we would have another credit to cash of ten, we would put a inventory T-account.
If we drew lines and added up the balances, we've got 70 in cash, and ten in inventory on the left hand side, so that's 80 of assets.
Final example, we're going to increase a liability or equity and then decrease another liability or equity.
So in this case we're going to issue $80 in common stock to pay off the bank loan.
So the two accounts are common stock and notes payable.
Common stock is a stockholders' equity account going up by 80, the bank loan's a liability going down by 80.
In the balance sheet equation, we'd have nothing on the asset side.
Equity would go up for issuing the common stock.
For the journal entry, we want to debit notes payable for 80, because notes payable is a liability that we want to reduce.
We have 70 in cash, 10 in inventory, that's 80 on the asset side, we have no notes payable, it goes to 0 because we fully paid it off, and a balance in common stock of 80, so our asset equal our liability plus stockholders equity, balance sheet balances, debits equal credits.
Here's the first one.
In this transaction, we're receiving cash, cash is going to increase and we're going to increase common stock accounts.
Cash is an asset.
We make cash go up with a debit, so we're going to debit cash.
The dollar amount is 150,000, which is $15 cash times 10,000 shares.
$50,000 but we have to split it between the par value and the additional paid in capital.
And then we'll credit additional paid in capital for the rest, which is $100,000.
So do you also have more than one debit?
You can have more than one debit.
It's one of those difficult things that you can only come to trained professional like me.
To understand, so you're going to see it a lot.
The accounts involved in this transaction are buildings which are going up, cash which is going down and mortgage payable which is going up.
Buildings are an asset, so we debit buildings by 500,000 to increase the asset.
Cash is an asset.
So to make it go down, we need to credit it with credit cash for $80,000 to reduce that asset.
And then mortgage payable as a liability has a credit balance.
We're not given the amount, but we know it has to be $420,000, because we know our debits have to equal our credits.
Once we credit Mortgage Payable for 420,000, we have 500,000 in debits, 500,000 of credits, and we're in balance.
BOC obtains a three year fire insurance policy.
In this transaction, we're getting fire insurance coverage for three years.
That's an asset that we're going to call pre-paid insurance and it's going up.
We're paying cash, so cash is going down.
Cash is an asset also, but it's going down, so to make cash go down; we credit cash to reduce asset by 3,000.
BOC acquires on account office supplies costing, 20,000.
In this transaction, we're acquiring office supplies and inventory.
Both of those are assets, so we're going to make them go up with debits.
Instead by 35,000 now were not paying any cash instead we owe our supplier $55,000 because we got the stuff on account.
When we owe money to our supplier, let say liability called accounts payable, that's increasing, we make a liability increased though a credit, so we credit accounts payable for 55,000.
So we have 55,000 of debits, 55,000 of credits and we're in balance.
Next, BOC pays $22,000 to its suppliers.
And since we're paying cash, it's going to reduce cash as well.
If we want to reduce it, we credit Cash for $22,000.
And this, by the way, is the journal entry you're going to do any time that you pay cash fo reduce a liability.
In this transaction we're trading one asset for another asset.
We're getting land.
Land is going to go up, so to make land go up, we debit land, 200,000.
Building is going down.
>> How do you know that the land is worth $200,000?
>> Given the information we have, we have to assume the land is worth $200,000 so our debits equal our credits.
And the assumption makes sense because if we are giving up a $200,000 building and just getting land, the two values should be equal.
But that's for another day.
BOC retires $1 million of debt by issuing 100,000 shares of $5 par value stock.
Any time we reduce a liability, we need to debit the liability to make it go down.
So we debit notes payable for $1 million to reduce it by a million.
Now we need to increase stockholder's equity by a million but we have to split it into the common stock and the additional paid in capital.
For $500,000, which is 100,000 shares times $5 a par value.
Then we credit additional paid in capital to make that stockholder's equity account increase.
Sorry, I'm going to make you do par value a lot, get over it.
BOC receives an order for $6,000 of merchandise to be shipped next month.
In this transaction, we're receiving $600 cash.
Anytime we receive cash, we debit cash to increase the asset.
We're also getting an obligation here because now we either owe the customer $600 back or we have to deliver the merchandise.
We only account for the $600, because that's the only part where there's been a transaction or exchange, because we received $600 cash.
For the other $5,400, that's all future stuff.
That's all promises.
We don't have a liability yet because there's no obligation that's based on benefits or services that we've received.
Not until we exchange cash good or services equal to $5,400 in the future.
Finally, BOC declares and pays $8,000 of cash dividends.
Let's start with cash in this transaction, so cash is doing down by 8,000.
Any time cash goes down, we credit cash to reduce the asset.
So now, we know we're looking for a debit.
The other part of the transaction is dividends.
Now remember, dividends are a reduction in retained earnings.
That was a lot of good practice at taking transactions and trying to represent them as journal entries using debits and credits.
You're going to get a lot more practice.
Starting next video, we're going to do an extended case that follows a start-up company, all the way through it's first transactions, to it's first set of financial statements.
And along the way, you're going to get a lot of practice doing journal entires and see a lot more debits and credits.
Starting with this video, we're gonna look at an extended case study, which will illustrate the accounting cycle.
The accounting cycle is all the steps that you have to follow to go from recording transactions, all the way through preparing financial statements.
The case is gonna be spread out over a number of videos, interspersed with new topics that we introduce, which will then illustrate in the case study.
So we've seen in the last couple videos how journal entries and T-accounts can be used to track and record the effect of transactions.
And the key is to make sure that our debits equal our credits when we record these journal entries.
And if we do so, then we know that the balance sheet equation will hold when we add everything up.
>> So, when I buy something at the store and the cashier says debit or credit, should I point out that he is really asking left or right?
We set liabilities, shareholders equity and revenues to have credit balances so that credits will increase these accounts and debits will decrease them.
We also looked at a visual picture that we could use to remember this.
The Super-T account, which shows whether debits or credits increase the decrease the various types of accounts and talked about how you should print this out, keep it handy until you memorize it, or tattoo it on your arm, whatever your inclination may be.
Now we're going to talk about the Accounting Cycle.
Let's take a ride on the accounting cycle.
>> It's not that kind of cycle, but it should be just as fun.
We're going to go through the entire accounting cycle with an extended case, which follows a start up company from its first set of transactions all the way through its first set of financial statements.
And that's what the accounting cycle is set up to do.
First, as the business is operating during a fiscal period, transactions happen and then you have to analyze those transactions to figure out how to come up with journal entries, and then post those journal entries to T-accounts.
Once the period is over, we do something called an unadjusted trial balance to make sure we haven't made any math mistakes, or transposed any numbers.
Then we do something called adjusting entries, which are needed to get the books correct before we do financial statements.
After another trial balance, we prepare the financial statements.
We're gonna start the case with the first part of the accounting cycle, where we analyze transactions.
And then figure out how to journalize them, which is record each transaction as a journal entry in something called the general journal.
Then, we're going to post that journal entry to T-accounts, or general ledger, where we'll keep a running total of the balance in all the accounts.
So now let's take a look at the facts of the case.
In March of 2012, Rebecca Park identified an excellent business opportunity while she was a first-year MBA student at Wharton.
She read a story about an MBA student who tripped while jogging in Fairmount Park and found an ancient gold coin in the underbrush.
It was an old viking coin that was appraised as $77,500.
She realized she could set up a profitable business that rented out portable metal detectors to people that wanted to search Fairmount Park for more Viking relics.
Also Park had the idea of stocking her store with sundries, such as water bottles and energy bars, that she could sell at a huge markup to renters before their expedition into the park.
Park prepared a business plan and approached a fellow student, Jay Girard, who had a sizable trust fund and who she believed would invest in this new venture.
Due to his myriad of other investments and his heavy course load, Girard agreed to invest as a silent partner and allow Park to run the business, which she named Relic Spotter Inc.
So now what we're gonna do is go through a number of transactions for the company.
After each transaction is read you should pause the video and try to do the journal entry.
Then resume the video to see the answer and the explanation.
On April 1st, 2012, Girard decided to invest $200,000 and Park put up $50,000 To purchase a total of 25,000 shares in the new company.
The par value of the shares was $1.
In this transaction, we're receiving $250,000 of cash for issuing equity.
Cash is an asset.
We increase assets through debits so we're going to debit cash for $250,000 to increase this asset.
But remember that we have to split this into two parts, the par value and the additional Paid-in-capital.
So first we have common stock at par, which is going up by 25,000 shares times $1 or $25,000.
We make stockholders equity go up with a credit, so we credit common stock for 25,000.
And then we credit Additional Paid-in-capital for the rest, $225,000, which is the number that we need so that our debits equal our credits.
As we talked about last time the only requirement is that your debits equal your credits.
So we create a T-account for cash, put the 250,000 on the debit or left hand side.
We put a little 1 there so that we can trace this number back to the original journal entry in the general journal.
Of course the balance is on the credit side and the same thing for additional Paid-in-capital.
Transaction 2, Lacking the funds for her initial investment, Park borrowed the $50,000 from the Imperial Bank of Philadelphia on April 1, using her parent's house as collateral.
In other words, Relic Spotter doesn't have to pay this loan back, Rebecca Park does.
So there's something called the entity concept which says the only thing that should go in a company's books are transactions for the company, not transactions for the employees.
So, we want to keep this separate, Rebecca Park's loan.
But for the rest of the case she's doing things on behalf of the company, so you're not gonna see this trick again.
Since there's no journal entry, there's nothing to post to T-account, so we can go right on to transaction 3.
On April 2nd, Park hired a lawyer to have the business incorporated.
Because this was a fairly simple organization, the legal fees were only $3,900.
So let's take a look at the journal entry.
I always recommend starting with cash, if there's cash involved in the transaction, because you'll quickly memorize whether to debit or credit cash based on whether you receive or pay cash.
So in this case we're paying $3,900 in cash for legal fees, which seems quite exorbitant.
But I guess it's a lawyer, so what are you gonna do?
Anyway, if we're paying cash, cash is going down.
Cash is an asset, so assets go down through credits.
Now notice, even though I started with cash and it was a credit, I don't write it first in the journal entry.
As we talked about in a prior video, you always want to write debits first, so I had to skip some space, write the credit second and indent it.
So now we need to find a debit.
So what are we getting for this cash?
So it's going to be legal fee's expense.
Remember that expenses can increase through debits, so we're going to debit legal fee expense, which will increase expenses and reduce stock holder's equity by 3,900.
Why isn't this an asset?
>> I guess you could say this is an asset because the future benefit is that we get to operate the business forever once we've incorporated it.
It's a pretty lame rationale but there were companies that used to call this an asset.
Now the rules are explicit, this kind of expenditure has to be expensed immediately.
Let's post this to T-account, so we bring back our cash T-account.
We put 3,900 on the credit side, or the right hand side with a little 3 to indicate that it's transaction number 3.
And we create a T-account for legal fee expense with 3900 on the debit side or the left side.
To house the business, Park bought an abandoned pizza parlor near Fairmont Park for $155,000 on April 7.
The building was old and needed renovation work.
The purchase documents allocated $103,000 to land, and $52,000 to the building.
Park paid for the building with $31,000 cash, and a $124,000 mortgage from the Imperial Bank.
Wow, this is a big transaction, so it's going to require a big Journal Entry.
Always like to start with cash if we can.
We paid $31,000 of cash.
Cash is an asset, assets go down with a credit, so we credit cash for 31,000.
We acquired land and building.
Land and building are both assets, assets go up with a debit, so we wanna debit building for 52,000 and debit land for 103,000 and make those two accounts go up.
Now at this point our debits don't equal our credits so we can't stop, we're missing one more piece, and that piece is the mortgage.
A mortgage is a liability, liabilities go up with a credit, so we need to credit mortgage payable for $124,000 and now our debits equal our credits.
Won't we have to pay interest on the mortgage?
Those two look like twins.
Anyway, both good questions.
As for the interest question, I think we talked about this in a prior video, but it's good to review it.
We don't own any interest when we take out the mortgage.
We could pay back the mortgage immediately, and not have to pay any interest.
Only as time passes and we owe interest without paying it will we have to record an interest payable.
We've got a lot of posting to do for this journal entry.
We bring back our cash T-account and put another credit on the right-hand side.
Create T-accounts for Building and Land and one for Mortgage Payable.
For this transaction, the first thing we're gonna do is ignore the stuff about salvage value and 25 years.
We'll come back to that in a later video.
Instead, we're gonna focus on the transaction that happened on May 25th, which is when Park paid the cash.
We paid $33,000 of cash, cash is an asset.
We make an asset go down through a credit, so we credit cash for 33,000.
Well we added to the building and so we're going to debit building for $33,000 to increase the balance in the building account.
>> Excuse me, why isn't this an expense instead of an asset?
And the assets seem like expenses.
The general rule is if you spend money on maintenance, an expected cost on maintaining the asset, then you would expense it.
But if you spend spend money for a capital improvement, which would be something that would increase the value of the building or how long you plan to use it, then you get to add that to the building account.
But don't worry about this now.
This is something we're going to talk about in a lot more detail later in the course.
Then we post this to T-accounts, we add another credit to the right-hand side of the cash account and a debit to the left-hand side of the building account.
So now the balance in the building is $85,000.
I would tell you what the balance in cash is, but I can't do math in my head, so you'd have to figure that out on your own.
On June 2nd, Park purchased 240 metal detectors at an average cost of $500 per unit, so that's $120,000 total.
The innovation in the industry is so rapid, that Park felt the units would only last for two years, at which time they would have no remaining value.
We need to record the transaction where we paid $120,000 cash to get metal detectors.
If we're paying cash, cash is going down.
Cash is an asset, goes down with a credit.
Well, we're getting metal detectors.
Metal detectors are an asset.
Wait, why aren't the metal detectors considered inventory?
>> We only use the inventory account for goods that we buy with the intention of selling as quickly as possible at a markup.
We don't call the metal detectors inventory because we intend to keep them for two years and use them over and over and over and over again to generate rental revenues.
Then we post this to T-accounts, we add another credit on the right had side of cash.
So we're about halfway done at this point, so why don't we go ahead and stop this video, and we'll pick up the case in the next video with the next transaction.
See you next video!
In this video, we're going to pick up where we left off last time and continue to do the initial transactions for the Relic Spotter case.
Got a lot to get to, so let's get started.
Let's start back up with transaction number seven.
On June 15th, Park ordered $2,000 to sundries inventory, for instance, water bottles, energy bars, etc., to be delivered on June 30th.
Park was able to purchase the inventory on account, which meant she had up to 30 days after delivery to pay the supplier.
So, I'd like to start with cash, but there's no cash in this transaction.
And we owe the supplier money for the inventory within 30 days.
So let's start with inventory.
Inventory is an asset, assets go up through debit, so we're going to debit inventory for 2,000.
Accounts payable is the term we always use when we owe money to a supplier.
On June 15th we placed the order, but there is no transaction yet, because we haven't had an exchange of cash, goods or services.
It's not until June 30th, when we take physical delivery of the inventory, that we have to record a transaction.
Transaction 8, on June 30th, Park paid $2,100 for a three-year site license to use geo-contour mapping software in the metal detectors.
For the journal entry we're back to paying cash, so we'll start with cash.
Anyway, software is going to be an asset because it's something that we can use to run the metal detectors over three years.
Assets go up with debits, so we debit an asset called Software for 2,100.
I hate to sound like a broken phonograph record, but why is this an asset, and not an expense?
One of the trickier things to pick up in accounting is, when you spend money, do you recognize an asset or do you recognize an expense?
In this case, we did an asset, because we're going to get three years of future benefits from buying the software.
And in future videos, we'll talk about what has to happen for this asset to then turn into an expense, as it will down the road.
We post this journal entry to T accounts by putting another credit on the right hand side of the cash account and creating a new T account for the software asset.
Transaction 9, on June 30th, Park signed a contract with a local advertising agency to provide various forms of advertising for a period of one year.
She paid $8.000 upfront for advertising through June 30th, 2013.
Cash is an asset, we make an asset go down with a credit, so we credit cash for $8,000.
And by this point you should be able to credit cash in your sleep because we've done it so often.
Every time we pay cash, it's a credit to the cash account.
Now we need a debit so what are getting for this cash?
Well, we're getting a year's worth of advertising without having to pay any additional cash, that's an asset.
So we're going to create an asset called prepaid advertising.
>> Do we also get to record the value that this advertising will create as an asset?
Sounds like an asset to me.
>> It's important to note that the asset here, only represents the cost of the advertising that's been prepaid.
It doesn't represent any of the potential value that the advertising could bring us in the future.
We don't record that value as an asset because the benefits cannot be measured with a reasonable degree of certainty.
It's just like the brand name example we looked at in a prior video.
If there's too much uncertainty about the value of the brand or the value of the advertising, we err on the side of reliability and don't include it as an asset.
So we've got another credit to cash on the right hand side and we create a T account for prepaid advertising with a debit of 8,000.
On June 30th, Park needed cash to make a payment on the Imperial Bank loan that funded her purchase of Relic Spotter stock.
She borrowed $5,000 from Relic Spotter at 10% interest, with the principal and interest due in a lump sum on June 30th, 2013.
This transaction looks complicated but let's just start with what we know.
So, what we know is that Relic Spotter paid $5,000 cash to Rebecca Park.
We're paying cash, cash is going down since cash is an asset, assets go down with credits.
So, what is Relic Spotter getting for this cash?
Well, essentially they're making a loan.
That loan is going to be an asset because they're entitled to receive 5,000 of cash back from Rebecca Park at some point in the future.
If an employee owes us money for a loan, we're going to call it a notes receivable.
The last time Park borrowed money for herself, we didn't record it in the company's books.
What's different was that in the first example we saw she was borrowing it from the Imperial Bank.
In this transaction, she's borrowing it from Relic Spotter.
That means that Relic Spotter is giving some of it's cash to Rebecca Park.
And Relic Spotter has to record a transaction for that disbursement of cash to Rebecca.
On June 30th, Park also hired two employees, Linda Carlyle and Charlotte Cafferly to run the shop.
They signed employment contracts promising each salaries of 32,000 per year.
So, the journal entry here, well, let's stop and think for a minute.
We, we haven't paid any cash yet to these two employees.
They haven't done any work for us yet.
There's no journal entry for this employment contract because they haven't worked for us yet, we haven't paid cash yet.
And so we don't consider this a transaction, we don't account for this type of promise.
Where I come from, when you promise something, it becomes an iron clad obligation.
>> I'm sorry to cause so much stress, but, but we did talk about this in the liability video.
Remember.
One of the criteria for recording a liability is the obligation that has to be based on some benefits received currently or in the past.
In fact, they could quit tomorrow and we wouldn't owe them anything.
So it's not until they work for us without being paid, that we would record a liability.
Since there is no journal entry there is nothing for us to post, so let's go on to transaction 12.
Upon hearing that Relic Spotter only had $47,000 of cash left in the bank, Girard became concerned about his investment.
Now, there is more to this transaction, but I want to cut in here for a second to show you how we could figure out how much cash Relic Spotter has in the bank.
If we bring up the cash T account, at this point we could draw a line, add up the debits, add up the credits, subtract the credits from the debits and we'd have a balance of 47,000.
So, at any point you can draw a line and figure out a balance.
And at this point we have 47,000 in the cash account.
Okay, back to the rest of the transaction.
Thinking fast, Park stated she was so confident of Relic Spotter's prospects that she was declaring a $0.10 per share dividend, to be paid on August 31.
So that's $25,000.
because we, we haven't actually paid any cash yet, has there really been a transaction?
Well, as we talked about in a prior video, the custom is that when a company declares a dividend, you make a journal entry at that point even though the cash will be paid later.
So, on June 30th we need to reduce stockholder's equity, reduce retained earnings to recognize the dividend.
We reduce stockholder's equity, a credit account, with a debit entry, so we're going to debit retained earnings for $2,500 to take out the dividend.
The other side of this is that, as we talked about in another video, once you declare a dividend, essentially you're holding the cash that belongs to the owners, until you write the checks.
So, you have this obligation to write those checks and deliver the cash, that obligation is a liability called dividends payable.
I thought you said that we don't account for promises.
Wouldn't it make more sense to wait until they are paid?
Someone need to take a chill pill or something.
We did talk about this in a prior video.
And at that point, the owners become creditors because the company is holding their cash until the dividend checks are sent.
And we have a balance on the debit side and a T account for dividends payable liability where we put in the credit entry.
According to my notes, it is a stockholders' equity account and should have a credit balance.
That makes me feel good.
But to make sure that the balance sheet equation always stays in balance, we need at least one account that can be either a debit or credit balance.
The only way we could get the balance sheet equation to balance would be with negative stockholders' equity.
And so we make an exception for retained earnings and allow it to have either a debit or credit balance because it's the one account that makes sure that the balance sheet equation always stays in balance.
If retained earnings does have a debit balance often times we change the name and call it something like accumulated deficit or accumulated losses.
On July 31st, Park paid the supplier the $2,000 it was owed.
The debit here is that we're paying what we owe the supplier.
So, if we're paying a supplier the liability's going to go down and we make liabilities go down through a debit.
And a debit to accounts payable and notice, at this point, the balance in accounts payable would be zero.
Which makes sense because we don't owe our suppliers any money anymore, we fully paid off the liability.
On August 31st, Park paid the $2,500 dividend that had been declared in June.
For the journal entry here, we're paying $2,500 cash, so that's a credit to cash for $2,500.
The debit is going to be to dividends payable because we are paying off what we owe the shareholders for the dividend, thus we are reducing the dividend payable liability.
So, it looks like every time you pay cash to settle an obligation, you debit some payable and credit cash.
Every time you paid out a liability, you debit the liability and credit cash.
And that's a wrap for the first part of the case.
We'll pick up the case again after we learn about revenues and expenses which will allow us to start generating some profits for Relic Spotter.
I'll see you next time.
Welcome back.
Wow, what a long week of watching videos on the accounting basics.
So, what I want to do in the last video each week, is look at a real financial statement.
So that we can take the things that we learned in the lectures, and see how they play out in a real world financial statement.
And to do this, I want to use the same financial statement throughout the course.
The statement I chose is the 3M company.
In case you haven't noticed, I'm from Minnesota.
There's a Vikings helmet over here and some hockey helmets.
My grandmother worked for 3M for 40 years.
It's a company I have some affinity for.
Hopefully I won't find anything bad in the report.
What we'll do in this video though, is take a quick tour of everything that's in the annual report.
So that you have sort of an overview of where we're going to find things.
And at the end of every week, we'll dive in, in more detail and try to find that week's topics in the 3M annual report.
So we pull up the 3M annual report.
Some smiling kids, some benign looking chemicals.
And then kids drawing pictures.
And then there's the impact they have on smiling, happy children.
We go to the next page and you get a letter from the chairman and CEO.
So this is his explanation of how the company did during the past year.
We get some graphs showing that everything's going up.
Looks like everything is going well with 3M.
By the end of the course, you will not only know what all of these terms mean.
We have to read through the entire annual report.
And if we go to the next page, we get this very ominous-looking black and white page.
Starts with United States Securities and Exchange Commission at the top, form 10K.
From this point forward, we're looking at the filing to the SEC.
And so everything that 3M says or reports here, is subject to all the laws and the Securities and Exchange Acts of 1934.
Then if we go to the next page it gives us the table of contents.
And, part one of the report we're going to learn a lot about the business.
You know, what I'm going to do in a second is just flip through a lot of these quickly.
You'll look at these much more carefully as we go on later in the course.
Part two, is going to give us the financial information.
Which are the star of the show.
And then part three, gives us proxy related information, the directors, officers, how much they're paid.
And then there's any supplemental exhibits in part four.
Part one has the information about the business.
And again, I'm just going to flip through this very quickly.
If you want to go and read it in more detail, see what kind of things are there.
And part two starts some information on stock price, selected financial data.
Now, here's the big thing management discussion analysis.
This is where management tries to explain to the users of the financial statements, what happened during the year.
Tries to provide some kind of explanation so that users can understand the financial statements.
Although management is being very helpful by giving us all this detailed explanation on what they think happened during the prior year.
After all, there have been some companies which have had some big frauds.
So I like to look at the financial statements and the footnotes first.
Come up with my own theories for what happened.
And then come and see what management's saying about it.
Just as a reality check of whether I can believe what they're saying.
So flipping through here, you can see it's going to be pretty extensive and detailed.
And we're going to come back and look at these once we've learned about all of these topics later in the course.
There's disclosures about market risk.
And then we finally get to the financial statements.
Which, as I said, I think are the stars of the show.
Which, right away tells you that the financial statements are probably not going to have all the information we need.
We're going to have to dive into these footnotes to really learn what we need to learn about the company.
And we're going to be doing a lot as we go through the course, is looking at the details of the footnotes.
On the next page, we see two of the reports.
Management's Responsibility for Financial Reporting and Internal Controls.
So as we talked about in earlier lectures, management is responsible for putting together the financial statements.
Now of course, they come in.
The consolidated financial statements listed in the accompanying index present fairly, in all material respects, the financial position of 3M Company.
And its subsidiaries at December 31, 2012 and 2011.
And result of operations and cash flows for the three years ending December 31, 2012.
In conformity with accounting principles generally accepted in the United States of America.
I want to jump in here to point out what the auditor is actually saying here.
They're not saying we are giving you an ironclad guarantee, that 100% of the things in this statement are completely accurate and true.
Instead they're saying, in our opinion these financial statements present fairly in all material respects.
The financial position, results of operations in conformity with US gap.
In other words, we've gone and looked at some of the big things that they're doing.
They seem to be following the rules, at least in our opinion.
So as we've talked about in earlier videos, the auditors give us a little bit of insurance, assurance.
But we still need our own healthy dose of skepticism when reading these statements.
Because, we cannot fully reply on what the auditors have done in terms of guaranteeing the accuracy of everything in these statements.
The rest of the report talks about internal controls.
Thanks to Enron and the Sarbanes-Oxley Act There's a lot of focus now on internal controls that have, companies have.
It's a big part of the job.
It's not something we're really going to talk about in this course.
We'll come back and look at these as we learn more material.
And on, and on and on.
Wow, still not through the footnotes yet.
Still not, okay.
Went too fast.
By the end of the course, you'll be able to work your way through a lot of these and understand what's going on.
The last parts of the report are part three.
Which gives us the proxy information, directors, officers, comp.
We're not going to talk about these, you can look through them if you're interested.
Most of those were incorporated within the financial statements.
Which makes this a fairly short annual report these days.
And I made my students responsible for knowing everything in those 279 pages.
So, you're getting off a little bit easy here.
So that was a quick overview of the 3M annual report.
As I mentioned, every week we will come back to it to try to find what we've talked about during that week's video lectures in the 3M financial statements.
And do a deep dive through that statement to try to find all the things that we've learned about during the course.
I, I realize it was probably a tough week of videos.
We've got a couple more tough weeks ahead of us.
But I think you'll find, by the end of the course it'll be worth it if you stick with us.
This is a fairly important video because we're gonna talk in detail about the difference between accounting income and cash flows.
Accounting income is determined by something called accrual accounting, which tries to measure business activities, and gives a very different picture of the company's performance than merely cash in or cash out.
Let's get started and see how this works.
As we talked about in the opening video, the income statement reports increases in shareholders' equity due to operations over a period of time.
Net income is made up of revenues minus expenses, and there's a couple synonyms that are often used for net income, it's also called earnings and net profits.
Revenues are recognized when goods and services are provided, not necessarily when the cash is received.
Expenses are recognized in the same period as the revenues they helped to generate, not necessarily when cash is paid.
And so, the bottom line is that net income is not the same thing as net cash flow.
So, let's look at revenues and expenses in more detail, starting with revenue.
Revenue is an increase in shareholder's equity from providing goods or services.
There are two criteria that need to be satisfied to recognize revenue.
First, it has to be earned, which means goods and services are provided.
And it has to be realized, which means that payment for the goods and services is either received in cash or something that can be converted to a known amount of cash.
These are called the revenue recognition criteria.
For example, let's say that we make a sale to a customer, we deliver the goods to the customer, and we give the customer an invoice, which has the dollar amount that they owe us and a time period in which they have to pay us.
So in this case we could book the revenue even before we get the cash and what we would do in this case is create an accounts receivable for what the customer owes us.
But, can you give us some examples of when these criteria would not be satisfied?
Thank you for asking.
Here's an example where the first criteria, earned, may not be straightforward.
Let's say you pay $100 to a software company to buy some software for your computer.
For the software company, the $100 is realized because they've collected the cash, but they might not book the full $100 as revenue today because it's not all earned.
So the software company might do is book $80 of revenue today, because that's what they earned by delivering the code, the other $20 of revenue would only be booked later on, as they deliver updates or as they provide technical support over time.
So there used to be this CEO who was a turnaround expert.
I'm not going to mention his name because I don't want to get sued.
But what he used to do is get hired by distressed companies, and he would come in and reduce the work force, streamline the operations, make aggressive accounting decisions, and turn around the company very quickly.
On one of this stops, he ended up shipping out a bunch of product to customers that hadn't ordered the product, right at the end of the quarter.
These shipments allowed the company to book the revenue and meet their earnings targets that analysts had set for that company for that quarter.
The justification for booking the revenue was that it was earned because they had delivered the goods, and it was realized because they gave the customers the invoice.
The problem is that if the customers haven't ordered the product, they're probably gonna send it right back without paying it.
And so the revenue really hasn't been realized because you don't have something that can be converted to a known amount of cash, because you don't know the customers have any intention of actually paying for the goods that you shipped to them.
>> Yes, in fact, the company I'm talking about got in trouble with the Securities and Exchange Commission for this practice.
In fact, well over 50% of the enforcement actions by the Securities and Exchange Commission are for violation of one of these two criteria.
So these criteria have a lot of gray area in trying to interpret them.
Expenses are decreases in shareholders' equity that arise in the process of generating revenues.
Now here we're talking about two criteria, but it's an either/or instead of a both, and we're really talking about a distinction between something called product costs and period costs.
I'll come back and talk about those in a second.
But as an example think of a company that makes video cameras.
For some reason I'm very interested in video cameras.
The product costs would be all the direct costs of producing the video camera.
It would include raw materials such as plastic, the metal, the glass for the lens.
It would include all the labor that went into producing the camera, all the costs of the factory, which we call overhead.
All of these are product costs.
These product costs would stay in inventory until the camera sold.
When the camera sold, those costs would leave inventory and become an expense.
So product costs follow the product.
Now, think of all the other costs of running a business that makes video cameras.
You have to have research and development people, operations personnel, sales force, marketing staff, human resources, top management.
Those people are not directly involved in producing the video camera, but they are costs of running the business.
We call all of these costs, period costs.
Later we're gonna call them SGNA or selling general and administrative cost.
These costs are recognized as expense when they're incurred.
What that means is, when the people work for you, you incur the costs and so you recognize those costs as an expense at that point.
>> What if the company used the CEO's car to transport parts from the warehouse to the factory?
Would that be a product cost or a period cost?
I should come back to this topic when we talk about the income statement in a future video.
The product cost versus period cost distinction is what we call the matching principle, where we try to match expenses to the revenues that they generate.
There's also something called the conservatism principle, which is for unusual events.
This principle says recognize anticipated losses immediately, but recognize anticipated gains only when they're realized.
Another way to look at this is it's the anti-human nature principle.
Human nature would be, hey, something good's gonna to happen in the future, let's record it now.
Whereas, somethings bad's gonna happen in the future, let's just wait until it happens.
The Conservatism principle forces you to do the opposite.
If you anticipate some loss in the future, like an environmental clean-up, or a settlement on a product liability suit, or employee severance cost, restructuring, you don't wait until those costs actually happen to expense them.
You expense them right away as soon as they're anticipated.
But if you expect some big gain to happen in the future, like you've signed a new customer to a contract and you expect big profits in the future, you actually have to wait until those profits come.
You can't recognize them when they're anticipated.
And for this reason, you'll see a lot of big one-time expenses, but not so many big one-time gains.
It's because the Conservatism principle forces you to anticipate future losses, but not anticipate future gains.
I am going to leave if this turn into a biased political polemic.
Now we're gonna practice applying these revenue recognition criteria to figure out how much revenue should be recognized in the month of December for each of the following examples.
As always, you'll see a pause button so if you wanna pause the video and guess the answer, the pause sign will cue you when you should do that.
BOC delivers $500,000 worth of washing machines in December to customers who don't have to pay until February.
The answer is $500,000.
BOC has delivered the washing machines, so they've earned the revenue in December.
BOC's given the customer an invoice which has them scheduled to pay in February.
With both earned,and realized, BOC get's to book $500,000 of revenue in December.
Do we have to cancel out the revenue?
It still seems dodgey to me that you can record revenue before you get the cash.
>> Yes, you are correct that we do have to worry about whether we will collect the cash on this revenue.
Later in the course, we'll see how companies try to estimate how much of their revenue they won't collect in cash, and then, at the time of sale, make an adjustment to reduce their revenue based on the amount they don't expect to collect.
For now, let's just assume that all of the revenue is eventually collected in cash.
BOC collects $300,000 cash in December for washing machines delivered in October.
Presumably, when BOC delivered the washing machines in October, they also sent an invoice so that they could book the revenue of $300,000 in October when those revenue recognition criteria were satisfied.
In December, BOC's just collecting the cash on accounts receivable.
They can't book the revenue again or it, or they'd be double booking it.
So there wouldn't be any revenue in December, it was all booked in October.
Next, BOC Realty leases space to a tenant for the months of December and January for $20,000, all of which is paid for in cash in December.
The answer here is $10,000.
We've received the cash, so we know whatever revenue we're going to record meets the realized criteria.
But the question is how much have we earned in the month of December?
If BOC is getting paid for December and January, the way they earn revenue is by providing space to the tenant for December and January.
That's the amount that's been earned in December.
BOC Aerospace receives an order for a $400,000 jet in December to be delivered in July.
BOC Aerospace has not delivered any goods or services in December.
So they have earned no revenue which means they can't book any revenue until they actually deliver a jet.
>> If this is a long-standing customer that promises to pay us, why can't we book the revenue now?
Even if it's a long-standing customer, the revenue recognition criteria still apply.
We have to deliver goods or services before we can record revenue.
It's just one of those conservative, I mean non-aggressive, practices that accountants use to increase the reliability or objectivity of the financial statements.
BOC Bank is owed $100,000 of interest on a loan for December and receives the payment in January.
The answer is $100,000.
BOC Bank has earned the interest revenue by providing the money outstanding to its customers.
It's provided a service.
Presumably, there's some kind of payment schedule with the customer who borrowed the money on when they should pay, so we can consider it realized.
And so BOC Bank can book $100,000 of interest revenue in December even though they won't get the cash payment until January.
BOC issues 20,000 shares of stock in December and receives $10 per share, which is $2 more per share than they expected.
Companies can only record revenue when they provide goods or services.
You just simply can not book revenue on issuing your own stock.
Revenue is only booked when you provide goods and services.
So for each of these items we're gonna try to figure out how much expense would be recognized in December.
First, BOC Automotive buys engines worth $2,000,000 in December for cash.
BOC has bought engines with cash, but engines are gonna be a product cost so they're not gonna be expensed until BOC actually sells the cars that they make with those engines.
So at this point, no expense.
BOC Automotive uses the engines to make cars at a total cost of $10,000,000 in December.
We know how much the cars cost in total, but the cars are still product costs, and the cost won't become expenses until BOC Automotive actually sells some cars.
In contrast, I'll use the term cost very loosely.
A cost is any cash outlay, whether in the past, present, or future that's required to run the business.
BOC Automotive sells cars costing $8 million in December for $15 million.
The answer is $8 million of expense in December.
The expense will be equal to what it cost to make the cars, which is 8 million.
The $15 million will be the revenue that we earn from selling the cars.
And it's good news in this case because our revenue is greater than our cost, so we've made some profit.
BOC Automotive incurs 180,000 in salaries for its marketing staff in December.
The answer is $180,000.
It's helping us sell cars this period.
So the matching principle would say, let's match the cost of the marketing staff this period to the revenues we generated this period and expense the entire cost of the marketing staff this period.
BOC Automotive pays its auditor $50,000 in December for services to be rendered in December and January.
The answer is 25,000 of expenses in December.
Even though we paid $50,000 cash to the auditor in December, we're paying for work the auditor is going to give us in both December and January.
We can only recognize the amount of work they've done in December as a cost and hence an expense.
If we assume it's roughly divided between the two months, then half of 50,000 will be 25,000 of expenses.
The other 25,000 will be expensed in January when the auditor provides the work for us then.
We paid the auditor $50,000, right?
We're only going to expense the cost of the auditors as they work for us.
BOC paid their auditor $50,000 cash for work the auditor would provide in December and January.
But BOC only wants to expense in December the amount of work the auditor did in December which is half of that, or $25,000.
BOC Automotive pays $1,200,000 in cash dividends in December.
Dividends are never considered an expense because they're not considered a cost to do doing business.
In this video we're going to finally generate some income for Rebecca Park and her Relic Spotter company.
We'll go through a number of revenue and expense transactions for Relic Spotter and see how they performed in their first six months of business.
In a prior video we did the first 14 transactions for this start-up company.
Now we will resume the case with transactions related to revenues and expenses.
Some of the transactions will be summary entries to record six months worth of activity in one journal entry.
After the transaction you should pause the video and try to do the journal entry.
And then resume the video to see the answer and the explanation.
In a search for new revenue opportunities, Park initiated an unlimited rental arrangement with the Penn Antiquities Club on December 1, 2012.
Under this arrangement, the club paid Relic Spotter $1,200 cash upfront for unlimited rentals over the next year.
For this transaction, Relic Spotter is receiving $1,200 of cash.
Cash is an asset, we increase an asset with a debit, so we're going to debit cash for $1,200.
Now we have to look for the credit.
So we're getting the cash, and now we're obligated to provide rentals over the next year.
We have the cash.
We have committed to allowing the club to rent units whenever they need them.
Committing to provide the rentals is not enough to be able to recognize the revenue.
We have to earn the revenue by delivering the service.
And the service here is providing unlimited rentals over time, which means we're going to have to wait until time passes before we can recognize the revenue and record this on our income statement.
Then we post this to T accounts, so we add something on the debit side of cash, so we increase cash on this transaction, and we create a T account for unearned rental revenue, which has a credit balance.
For the six months ended December 31 2012, rental revenues on the metal detectors totaled $124,300.
Most of the rentals were paid in cash immediately.
However, as an initiative to reward repeat customers, Park allowed a select number of frequent renters to charge their rentals and be billed later.
As of December 31, 2012, $4,200 was outstanding under this plan.
To do the journal entry for this one we have to recognize that there were three accounts involved.
We got rental revenues of $124,300.
We have an accounts receivable of $4,200, that's what the customers owe us under the frequent renter plan, and the rest of it we received in cash.
So the difference between 124,300 and 4,200 is 120,100 of cash that we received.
Remember, we always use the term accounts receivable for money owed to us by customers, based on providing them goods or services in the past.
And what we have left to do is record the rental revenue.
Revenue accounts are credit balance accounts, so to increase revenue we credit rental revenue which increases revenue and increases stock holder's equity by 124,300.
Of which 120,100 was received in cash, and 4,200 has not yet been received in cash, but hopefully will turn into cash soon in the coming months.
What happens if we don't collect the cash?
It doesn't seem kosher for them to book all that revenue with no guarantee they'll get the cash.
Same answer as before.
For now we're assuming that the company will collect all the cash, but later on we'll see how companies estimate how much cash they will collect, and then make adjustments for this on their income statement, and in the balance of their accounts receivable.
So just hang on until later in the course.
To post this one, we add another debit to the cash account.
During the period between July 1st and December 31st, Park purchased $40,000 of sundries inventory, of which 38,000 had been paid in cash and 2,000 was still owed at December 31st.
We credit cash for 38,000 to make the asset go down.
So we debit inventory for 40,000 to recognize the inventory that first, we've received.
So we're still missing one part of this and that's the 2,000 that we still owe at December 31.
If you remember from a prior video, when we owe money to a supplier based on getting shipments of inventory we call it accounts payable, which is a liability.
Relic Spotter recorded sales of sundries totaling 35,000 for the 6 months ended December 31, all received in cash.
We're receiving 35,000 of cash, so we debit cash 35,000 to make that asset go up.
Revenue is a credit account, so we make revenue go up with a credit to sales for 35,000.
If we sold sundarees, or whatever you call them, then our inventory should go down.
Where we record the cash and the sales revenue at the selling price.
We'll deal with the inventory part of this transaction in about 15 seconds.
And create a sales T account to keep track of revenue from sundry sales.
The original cost of these sundries was $30,000.
Our debit here is going to be something called cost of goods sold, which is an expense.
This is what we call the product cost when we make a sale.
The original cost of the inventory becomes an expense called cost of goods sold that we match with the revenue that we get from selling the sundries.
So we debit this expense, cost goods sold for $30,000 which then will reduce stockholders' equity.
I mean, anytime you record revenue in an entry, do you have to record COGS in another entry?
>> Please also tell me why the revenue and the COGS were different dollar amounts.
Any time you sell inventory, you need one entry to record the revenue and the cash we're going to collect at the selling price.
And you need a second entry to record the reduction in inventory.
In other words, we've been able to earn a profit on our product.
Let's try that again.
Relic Spotter's two employees were paid wages of 32,000 total during the six-month period.
For the journal entry, we paid 82,000 in cash total.
So we credit cash for $82,000 to reduce the cash account.
The debit is going to be an expense for the employees working for us.
Now, these employees would be period costs, so we're recognizing an expense as they work for us.
We're going to debit salaries and wages expense for 82,000 to recognize this period cost, which then in turn will reduce stockholder's equity as expenses always do.
Then we post this to T accounts, so yet another credit to the cash account.
So, I'm going to bring up Excel and show you how to do this.
I've been showing you the T accounts one by one.
But here's what they would look like all on the same page.
You'll notice that there are some T accounts which have nothing in them yet.
But for all the other T accounts, what you want to do is draw a line and come up with a balance for each account.
So we have 78,800 in cash, 4,200 in accounts receivable, 103,000 in land and so forth.
Then you carry over all the account titles to another page and create a column for debits and a column for credits.
You put in the balance of each account and then just add up the columns.
So we know that we've done everything correct so far because our debits equal our credits.
And now we're ready to go on to the next step in the accounting cycle, which will be adjusting entries.
Wow, there's nothing more thrilling than watching somebody work through Excel on video.
Sorry about that, but that seemed to be the most expeditious way to show this part of the accounting cycle.
Plus, if you're going to learn some accounting, you've got to do some Excel now and then, right?
So in the next video, we're going to talk about adjusting entries which will get us one step closer to putting together financial statements.
In the next two videos, we're going to talk about adjusting entries.
These entries help to get the books in shape, so that we can prepare financial statements.
In this video, we'll talk about adjusting entries conceptually, and go through some examples.
And in the next video, get some practice to do these journal entries.
Let's get started.
Now we're going to move on and take a look at the next step in the cycle, which is adjusting entries.
Adjusting entries are internal transactions that update account balances in accordance with accrual accounting, prior to the preparation of financial statements.
By internal transactions we mean that we're not doing anymore transactions with outsiders.
This is just the accountant sitting at his or her desk doing journal entries to get accounts up to date to do financial statements.
I guess the way to think about this is, if a company's fiscal period ends December 31st.
Everyone else in the company's going to leave at 5 o'clock to go out for New Year's Eve parties.
But the poor accountant has to stay behind, and do these adjusting entries before the company can get ready to do its financial statements for the end of the year.
There's two big categories to these entries.
The first are called deferred revenues and expenses.
In this case, we're updating some existing account balance to reflect its current accounting value.
This happens when there's been some kind of cash flow in the past, but we need to record revenues or expenses now.
Here we have to create some new account balances to record some previously unrecorded assets or liabilities.
This will be situations where we're going to record a revenue or expense now, and there will be some kind of cash flow in the future.
So don't worry, I'm going to go through examples of each of these types of adjusting entries, so you can see exactly what we mean by them.
The first category we're going to look at are deferred expenses.
The accounts that we'll see here are generally called prepaid accounts, like prepaid rent or prepaid insurance.
Depreciation and amortization are also examples of a deferred expense, but we'll talk more about those later in the video, but let's think of something like prepaid rent.
We paid cash in advance of occupying the space, so we create an asset called prepaid rent, but then, as time goes by and we've occupied the space we have to recognize the cost of the rent for the time that we've occupied the space.
So we're going to do an adjusting journal entry where we debit an expense to recognize the cost of the rent that's been used up over time, and we're going to credit the prepaid asset to reduce the balance to how much that's still prepaid, if any, at the end of the year.
So what's happened in this case is, we've received cash prior to providing goods or service.
Wouldn't you know when you had delivered goods, and then just record this entry then?
So, as our poor accountant decides to turn on the TV to watch something like New Year's Rocking Eve, so he can hear some of the music in the background that he's missing at all the parties.
These accounts are all going to be payable type accounts.
What's going on here is that we've incurred some expense over time.
But we haven't yet paid for in cash.
So the adjusting journal entry we need to make is to debit an expense to recognize that expense, and credit a payable liability, to show that we have an obligation to pay for that expense.
For example, if employees have worked for us but we haven't paid them yet.
We have to debit a salaries and wages expense to recognize the cost of the employees working for us and then credit salaries and wages payable to show the liability that we have to pay our employees some point in the future.
S,o as our poor accountant looks at the TV to watch the ball drop at Times Square he hurriedly asks himself, have any revenues accumulated during the period that have no yet been recorded?
An example would be, if we loaned someone else money, time has gone by so now they owe us interest.
And then we would debit a receivable asset, like interest receivable, to show that we have an asset for the amount of cash that we're going to collect in the future.
So, this adjusting journal entry allows us to recognize revenue that we haven't recognized so far.
And then show that we have an asset for the cash that we expect to collect in the future.
>> Again, these examples are about providing a service over time as opposed to delivering specific goods.
It says that it only matters that the revenue show up in the books when we put together financial statements.
It's just easier to do the adjustment entry once at the end of the period, instead of doing it every month or week or hour, minute.
Finally, we're going to talk about depreciation and amortization.
Which are just examples of differed expenses, but there is a lot more to them, so I want to give them their own couple of slides.
The goal of depreciation and amortization is to allocate the original cost of long-lived asset over its useful life.
What we want to do is match the total cost of the asset to the revenues it generates over its period of years.
Dave had bought a truck that he intended to use for 48 months.
Instead of recognizing the cost of that truck as an expense in the first month.
We spread the cost out over 48 months through depreciation to try to match the cost of the truck to the revenue we think it will generate in the future.
There's some terminology here, tangible assets, which are physical assets like buildings or equipment or a truck, we're going to call this process depreciation.
For intangible assets, which are abstract assets like trademarks or customer lists which we've acquired in an acquisition, we're going to call this process amortization.
But the process is going to be very similar, even though the terminology is different.
Now let's talk about the accounting procedure for depreciation and amortization.
Staring with depreciation, depreciation is not deducted from the tangible asset account.
So, in other words, if you were taking depreciation on a truck, you wouldn't deduct it from the truck account.
Instead, the depreciation's going to be recorded in a contra asset account called accumulated depreciation.
Which means that contra assets go up with credits and down with debits.
I think contra is a Latin word which means something like it has the balance on the opposite side where you'd expect the balance to be based in where it is on the balance sheet.
In other words, assets normally have debit balances, so they're increased with debits.
And be increased with a credit, because essentially, the contra asset is keeping track of reductions in a companion asset account.
Amortization is often deducted directly from the intangible account.
So if you're amortizing a trademark, you would deduct it directly from the trademark account.
However, nowadays there are companies that have fairly large intangible assets, and they've started to use accumulated amortization accounts as well.
So that's just another type of contra asset where the accounting works just like accumulated depreciation.
But I think the most common treatment you see is that the amortization just comes directly out of the intangible asset account.
Let me pull up the super T account to show you where a contra assets sits on the balance sheet.
The way to think about it is a contra account is keeping track of the decreases, or reductions in a specific asset account.
It's almost like an expense.
Expenses sit on the shareholder's equity side of the balance sheet in retained earnings.
And, in fact, an expense is just a contra shareholder's equity account.
So, you've actually seen this before.
And you're going to see a lot of it again.
And as you see it over and over I think it'll become more intuitive to you.
When we get to the video where we put together a balance sheet we'll see that the common format for reporting property, plant, equipment is to show the original cost or the property, plant, equipment separate from how much it's been depreciated over time.
And in order to provide that format we have to keep track of this accumulated depreciation in a separate account.
To calculate the amount of depreciation expense every year almost every company uses a method called straight-line depreciation.
The salvage value is what you think the asset is going to be worth when you are done using it.
So in the numerator we're taking how much of the assets is cost you're going to use up.
And then the useful life is the number of periods you expect to use the asset.
So, under straight line depreciation, the amount of the depreciation expense is going to be the same for each year of the asset's life.
Why do almost all companies use straight-line for their financial statements?
>> Yes, there are accelerated methods of depreciation where you recognize higher depreciation in the early years of an asset's life and then much less depreciation in later years of an asset's life.
If you use accelerated depreciation, then your earnings will be more volatile depending on whether you have a lot of new equipment, which is got high depreciation or a lot of equipment which is later in its life, which has much lower depreciation.
>> No, for financial reporting purposes, there is no central government agency that dictates useful life and salvage value.
Managers are supposed to choose the useful life based on how long they intend to use the asset and then the salvage value will be a function how long they intend to use it.
There's a major international airline which has a strategy of only flying pretty new state of the art planes.
They'll buy a brand new plane, fly it for five years, and then sell it to someone else.
So, when they choose their depreciation assumptions, their useful life is five years, and they have a very high salvage value.
Now there's a major domestic airline that tends to fly their planes for 20, 30, 40 years.
I'm not going to mention the name but you probably know who it is.
Their strategy, if they bought a brand new plane, would be to choose a useful life of 20 years and then they would have a low salvage value as a result.
So you get two airlines buy the same plane and have different depreciation assumptions, but that's okay because the depreciation assumptions are supposed to match how the manager intends to use the plane, not anything that has to do with the physical life of the plane.
I'll see you next video where we'll do some more practice with adjusting journal entries.
Anyway, let's get to it.
Okay, let's do some practice with adjusting Journal Entries.
I will give you a series of related transactions.
Some of them will be cash transactions that happen during the regular operating period of the company.
And then other times we'll look at the physical year end and then ask the question about whether there's an adjusting entry needed, and if so, what would it be?
As always, the pause icon will appear if you wanna pause the video and try to come up with a journal entry before I give to you as the answer.
So let's get started.
On September 30th, BOC loans $100,000 to an employee at a 12% interest rate.
This is a cash transaction that's happening during the fiscal period.
BOC is loaning $100,000 cash.
Cash is going down so we credit cash for $100,000.
December 31.
It's the end of the fiscal year and no principal or interest payments have yet been made.
Do we need an adjusting entry and, if so, what would it be?
We've earned interest revenue because we provided the service of having the money outstanding to the employee over the past three months.
We have a contract, we're eventually gonna get paid.
And we're gonna be specific here and call it Interest Receivable, because the asset is that we're owed for cash for interest.
And of course, we don't want to call it cash receivable because we only use that for that customers.
Any time you see an interest rate you should assume it's an annual rate unless it specifies otherwise.
So $100,000 times 12% is $12,000 of interest per year.
But it hasn't been a year yet.
So we take $12,000 times 3/12 because it's been 3 months.
And we end up with $3,000 of interest for the 3 months.
Now it's January 6th, the employee sends a check for three months of interest on the loan.
This is a cash transaction happening in the next fiscal year.
So it's December 31st, it's the end of the fiscal year.
During December, employees earn $400,000 in salaries.
It's the end of the fiscal year, so we have to ask ourselves whether we need an adjusting entry.
We do in this case, because we've had employees work for us, even though they haven't been paid we have to recognize an expense for the amount of salaries that they earned during December.
So we're going create an expense, and we create an expense with a debit.
We haven't paid them cash but we owe cash.
We have an obligation to pay them for the time worked, that obligation sounds like a liability, and in fact, it is so we credit salaries payable liability for 400,000.
I thought earned was one of the revenue recognition criteria.
This is an expense.
>> Yes, earned is one of the revenue recognition criteria, and from the perspective of the employee, the employee earned salary revenue.
The employee provided a service, they have an agreement to get paid, so it's revenue for the employee.
Now it's January 2nd and the paychecks are sent to the employees.
By paying the cash we've gotten rid of the obligation to pay their employees.
So we have to reduce the liability.
We reduce liabilities with a debit, so we debit salaries payable for 400,000.
Next series of transactions on November 20th, BOC pays $10,000 for December's rent.
So we need to credit cash for 10,000.
It's an asset because we're either gonna get the benefit of occupying the space in the future or we're gonna get our money back.
So either way we create an asset called Prepaid Rent for 10,000 at this point.
It's the end of the fiscal year.
Do we need an adjusting entry and if so, what would it be?
We do need an adjusting entry because December has gone by and we've occupied the space for the month of December.
We get rid of an asset with a credit, so we credit prepaid rent for 10,000 which brings the balance down to zero.
So in this example, BOC is a company that sells software.
We've received $60,000 cash as BOC, so we need to debit cash for 60,000.
But BOC hasn't delivered any of the software yet.
Instead they have to create an obligation or a liability for their responsibility to deliver the software over the next three years.
So now, December 31st.
It's the end of the fiscal year.
We do need an adjusting entry because six months of that three years has gone by.
And as time goes by, we get to recognize revenue for the amount of time that's passed.
So we're going to credit Software revenue for 10,000 to recognize six months worth of revenue.
So after this transaction the balance on Unearned Software Revenue would be 50,000.
Which is our obligation to deliver software over the next two and a half years.
>> I know why the answer is $10,000 but maybe you should explain it for the other viewers.
>> Sure, I'm happy to explain how to get 10,000 for the other viewers.
BOC's gonna earn $60,000 of revenue over three years.
It hasn't been a year, it's only been six months.
And BOC gets to book 10,000 of revenue for the six months.
The expected life of the building is 20 years and its expected salvage value is $100,000.
At this point, we have to account for purchasing the building, but we're not gonna do any depreciation yet because we just bought the building.
We received the building a buildings and assets, so we debit building for $500,000.
Now it's December 31st, it's the end of the fiscal year.
We do need an adjusting entry to recognize the depreciation for six months.
The format of the depreciation expense journal entry always looks like this.
And because it's a contra asset, a credit increases the account, increases the contra asset, which, in turn, is reducing total assets.
Now we get 10,000 as the number, where did we get that from?
I've got that one on the slide, so the building originally cost 500,000 and the salvage value was 100,000.
We're doing that over 20 years, so that's 20,000 of depreciation per year.
But, it's only been six months.
How can you possibly know what a building will be worth in 20 years?
>> Both the useful life and salvage value are managers best estimates at the time they buy the building of how long the building will last and how much it will be worth when they're done with it.
Like all estimates they will almost certainly be incorrect.
But at any point if the manager gets better information they can revise their estimate, so if they think they're gonna use it longer or shorter than they originally thought.
And then just change the depreciation expense going forward.
And then when they decide to sell the building, if it's not worth the salvage value, then we'll just book a gain or loss when we sell it.
BOC still has an outstanding order for $300,000 of products that will be delivered and billed in January.
Do we need an adjusting entry at this point?
We do not need an adjusting entry at this point.
We haven't earned any revenue because we haven't delivered any goods or services this year.
We haven't collected any cash so we don't have to account for any cash that we've received.
So basically, there's no transaction yet.
But, is there any way that we can let people know about this order?
>> Yes, companies can always voluntarily disclose additional information that they're not allowed to recognize in the financial statements.
For example, companies often disclose the order backlog in their annual report.
The order backlog is a disclosure of the number of outstanding orders the company has.
but haven't gotten to the point yet where the company could book revenue from them.
So that investors can use this disclosure to find out about upcoming orders even though they haven't yet shown up on the balance sheet or the income statement.
Think about a timeline where we have cash transactions that happen at different times than we recognize revenues or expenses.
So, if we receive cash before we can book revenue, we need a liability, an unearned revenue liability, to bridge the gap.
Or, if we pay cash before we record an expense, we need an asset, a prepaid asset, to bridge the gap.
For Accrued Expenses and Accrued Revenue, now the expense and revenue recognition is happening before the Cash Transaction.
If we have to recognize an expense before we pay cash, we need a liability to bridge the gap, and that liability is gonna be a payable.
So all of the adjusting entries that we talk about, are gonna fit into one of these four categories.
Now that we've done examples of all the possible types of adjusting journal entries.
And that's what we'll continue to do in the next video when we continue the relic spotter case.
I'll see you then.
In this video we're gonna take what we learned about adjusting entries and apply them to the Relic Sputter case, let's get started.
In prior videos, we did all 20 transactions that occurred during Relic Spotter's first six months of operations.
Now it's 5 PM on the last day of the fiscal year, December 31st.
We're not going to record anymore transactions with outsiders.
But before we put together the financial statements, we have to record the internal transactions or adjusting entries.
As in prior videos, I want to try to record the journal entry and post the T account for each required adjusting entry.
I will again put up the pause sign so that you can try the journal entry yourself before I reveal the answer transaction 21.
When Park called her accountant on December 31, 2012, she was pleased to tell him that the company had $78,800 in cash.
By the way, before I go on, if we pull up the cash T account, added up the debits, added up all the credits, you could see that the balance is 78,800.
Park wanted to go out and celebrate, but the accountant reminded her that she needed to stay in to do adjusting entries.
For example, even though it wasn't paid in cash, accrued interest on the mortgage was $4,900.
The adjusting entry here is that we have to recognize interest expense that we have incurred by having the mortgage outstanding during the year.
So, we create the liability with a credit.
>> What does the word accrued mean and why is this an expense if the bank hasn't made us pay the interest yet?
Accrued means to accumulate, grow, or increase as add interest on money.
And that's exactly what happened here.
The loan was outstanding for eight months, and so the interest accumulated, or grew, or accrued for eight months.
Even though we haven't paid that interest in cash, we have to expense it because the money was outstanding during this period.
So that interest cost is a cost of doing business this period, and we need to match that cost to the revenue we generated.
So we need an expense which we create through the adjusting entry.
Then we need to post the CT accounts so we create an interest payable liability.
This will go on the balance sheet to show that we have this obligation to pay interest in the future at the end of the year.
And we create an interest expense to recognize that one of the costs of doing business this period was that we've incurred interest costs, Transaction 22.
The accountant said that depreciation needed to be recorded on the building.
Park was confused by this because she received an unsolicited letter from a mortgage broker informing her that the building had increased in value to $120,000.
Now recall that, in transaction number five Park had renovated the building, bringing its original cost to $85,000.
So for the adjusting entry, remember the format that we used for depreciation Expense.
We debit the expense to create it.
And then we credit Accumulated Depreciation gets the contra asset where we're gonna store up the depreciation over time.
Now where we get the 1500 is we take the difference between the original cost of $85,000 and the salvaged value of ten thousand.
So that's 75,000 we are going to depreciate over time / 25 years of life, would be three thousand of depreciation per year.
>> The building was purchased in April and renovated in May.
Why are we recording only six months of depreciation?
Since we finished the building seven months ago, we could've recorded seven months of depreciation.
But I chose to do six months because Relic Spotter's only been open for six months and I'm trying to match the cost of the building with the revenue we've generated.
Plus, the math was a lot easier with six months rather than seven months.
If the building is worth $120,000, why are we depreciating it?
For non financial assets like buildings, we use an accounting method called historical cost or amortized cost.
What this means is that if the value of the building goes above what it's listed on the balance sheet we never write it up.
But if the value of the building drops below what it is on the balance sheet we write it down.
This is an example of the conservative, I mean the non aggressive nature of accounting where we tend to err on the side of objectivity or reliability.
Because if we allowed managers to write up something that's hard to value like a building, there'd be too much opportunity for manipulation.
So we only them to write it down in value.
And I don't know what the specific principal is called in accounting but we never rely on values from unsolicited letters from mortgage brokers.
Which is probably a life lesson that you should carry out beyond this course.
We post this journal entry to T accounts, we create a T account for accumulated depreciation as a contra asset, that is a credit balance, and then a T account for building depreciation expense.
The accountant also noted that Park Park needed to record depreciation on the metal detectors.
Recall that, in transaction number six, Park purchased $120,000 of metal detectors.
She determined that they would only last for two years, at which time they'd have no remaining value.
Journal entry has the same format as as the last transaction.
And we credit accumulated depreciation to increase the contra asset where we store a depreciation over time.
Where do we get 30,000 from?
The metal detectors originally cost 120,000.
So we're taking that entire 120,000, spreading it over two years to get 60,000 per year.
But it's only been half a year, so the amount that we depreciate is 30,000.
>> So why do you have separate accounts for building and metal detector depreciation expense?
>> You'll see why when we get to the video on financial statements.
But as a little preview, what you'll see is when we do the income statement, building depreciation expense and metal detector depreciation expense are gonna go into different parts of the income statement.
So we need to keep track of them in separate accounts.
But when we do the balance sheet, there's just gonna be one line for all of the accumulated appreciation so we can throw it all into one account.
Wait a minute!
You forgot the land!
Don't we have to depreciate the land as well?
There's a long standing tradition in accounting where we don't depreciate land.
We don't assume that land is systematically used up to generate revenue.
So as long as the value of the land is at or above what it's carried on the balance sheet, we just leave it at its original cost.
But if the value of the land dropped below what it was on the balance sheet, we would write it down to that value, but we wouldn't systematically depreciate it over time.
That's why when we originally bought the land and building together, we had to separate how much of the value was from the land and how much was from the building.
The amount of value from the building is hitting the income statement over 25 years as it's depreciated.
Let's try this again.
Transaction 24, the accountant continued, what about adjusting the software amortization account?
Recall that, in transaction number eight, Park paid the $2100 three-year software license fee on June 30th.
Because software is an intangible asset, we're going to use the term amortization instead of depreciation.
So we're going to debit software amortization expense for 350.
And then because it's amortization I'm gonna credit the software account directly to recognize the amortization.
Where does the 350 come from, well we paid 2,100 for a three year license So that's $700 per year of amortization.
It hasn't been a full year, so we take half a year of that to get $350.
I think historically we've done that because intangible assets have not been that big of a deal on the balance sheet.
Nowadays, more and more companies are starting to have larger and larger intangibles.
We directly reduce the software account with a credit, and then we debit a software amortization expense account.
Wow, we've only done four of the eight adjusting journal entries for Relic Spotter, and we've already recorded 12 minutes of video.
I guess the virtual students have a lot to say today.
So I'm going to end the video here and then we'll pick up in the next video with the last four adjusting journal entries for Relic Spotter.
In this video we are going to wrap up the final four adjusting entries for Relic Spotter.
Let's get started.
The accountant asked, what about the prepaid advertising account?
Recall that in transaction number nine, Park paid $8,000 up front on June 30th, 2012 for advertising through June 30th 2013.
We need an adjusting journal entry to recognize and expense for the six months of advertising that has been used up between June 30th 2012 and December 31, 2012.
So we debit advertising expense to recognize the expense and then we have to credit prepaid advertising to reduce the asset so that it's balance now is how much is prepaid going forward.
And realizing that half a year's gone by, so if you take half a year of 8000, it's 4000 for six months.
For deferred expenses such as a prepaid asset, we allow managers to either allocate it based on time as we're doing here or based on usage.
For example, if the manager thought that the company would have 50 advertisements run over the next year.
Then what the manager would do is take three-fifths of the prepaid asset as an expense this period.
Based on what they think would best match their business activities of the company.
>> If the manager can choose which method to use, then the manager could choose the one with the lowest expense?
I hate to break this to you but there's often no true or correct way to do something in the accounting system.
I often characterize adjusting entries as the creative writing part of the accounting system.
We give managers discretion on how to do their adjusting entries because we want them to best capture the true economics of the true business activities of the company.
In other words, we give some creating to the managers, hoping they'll write better non-fiction books.
Where they've used the creative writing part to write better novels or fiction books.
What you have to do is learn as much accounting as possible.
Then think about managers that instead have to manipulate in a given situation and approach the financial statements with healthy degree of skepticism.
Which you often need to do.
Recall that in transaction number 10, Park borrowed $5,000 from Relic Spotter at 10% interest rate on June 30 2012.
We need an adjusting journal entry to recognize the interest revenue that we've earned, by providing the money outstanding for six months.
The debit here is going to be an interest receivable, to represent the fact that Rebecca Park owes us $250 in cash.
Now, where the 250 comes from is the total interest is going to be $5000 of principal times the 10% annual interest rate is $500 of interest per year.
But it's only been six months, so we take half of that to get $250.
Let's say Santa Claus brought Rebecca park $5,000 as a Christmas gift.
So on January 2nd, she decided to come in and repay the loan on that date, she wouldn't owe us $500 dollars of interest because that's for a year and it's only been six months.
She would only owe the $250 of interest that's been accrued so far.
So the other $250 is not necessarily receivable unless the money continues to stay outstanding for the next six months.
So we can't consider it receivable as of December 31st.
Recall that, in transaction number 15, the Penn Antiquities Club paid Relic Spotter $1,200 cash upfront on December 1, 2012 for unlimited rentals over the next year.
We need an adjusting entry here to recognize the revenue we've earned by providing one month of unlimited rentals so we credit Rental Revenue for 100.
Part of our obligation has gone down by delivering one month of rentals so we need to reduce our liability, we debit Unearned Rental Revenue to reduce this obligation.
We got 1200 dollars up front for a full year, one twelfth of a year has gone by so we only recognize.
>> Could this revenue be recognized based on the number of rentals, instead of based on time?
>> But, wait, with the contract allowing unlimited rentals, it would seem fishy to do this based on the number of rentals.
Yes it would seem fishy if the allocation was done based on number of rentals instead of time, when you have a contract which provides unlimited rentals.
It's important to understand what the actual business activities of the company are.
And then you can see whether the accounting is matching those business activities.
If the accounting matches the business activities as it does in the Relic Spotter case then you can continue to feel comfortable with managers.
But if you saw a mismatch like unlimited rentals being accounted for based on number of rentals in the period, then you start to get skeptical about whether managers are manipulating or not.
We have to deliver 11 more months of unlimited rentals and then we add a credit to the Rental Revenue T-account.
Finally, the accountant noted that Relic Spotter incurred an estimated income tax expense of $630 for 2012.
Even though Park's not going to file her taxes until April, she's incurred taxes by operating the business during 2012.
And we have to show an expense because that's a cost of doing business.
This is money that we owe the government, that's an obligation.
We create an income tax payable so that we can show on our balance sheet that we owe the IRS, $635 of taxes as of December 31 and we create an expense account, income tax expense, which has a debit balance.
There's no adjusting entry for par value, we only worry about par value when we issue new stock but glad you came anyway.
And then we can start doing the balance sheet and income statement for Relic Spotter.
I'll see you next time.
In this video we are going to go to the last two stops on the accounting cycle.
Now we can move onto the next two steps in the accounting cycle, putting together an adjusted trial balance and preparing financial statements.
Then we're gonna use those balances to put together financial statements.
And then finally we'll complete the statement of cash flows and the Statement of Stockholders' Equity.
>> Yes, I will eventually cover the Statement of Stockholders' Equity, but I'm not gonna tell you when.
But what you're gonna see is the most common format used by companies.
On the top line, we have revenues or sales.
So when we get to Relic Spotter, it will be rental revenue from metal detectors and the sales of sundries.
Then we subtract cost of goods sold to get gross profit.
Cost of goods sold is the product costs or the direct costs of producing this revenue.
And then gross profit then would be interpreted as the markup over the product costs.
SG&A stands for selling, general, and administrative.
These are all the period costs, all the other costs of running the business.
It helps answer the question of whether the company priced their product or services high enough to cover all the product and period costs of delivering those goods or services.
Gains or losses we haven't talked about yet, but they're like revenues or expenses except they don't come from your core business.
For example if Relic Spotter sold their building and had a gain, we would put that gain here because they're not in the business of selling buildings.
Then you subtract income tax expense to give you bottom line net income, which is also called earnings or net profit.
>> I always hear my boss talking about things being above the line or below the line.
Most investors and analysts use operating income as a key measure of the performance of the core business.
is there any way that they can move it below the operating income line so that the performance of the core business looks better?
So yeah, managers spend a lot of time worrying about whether unusual gains or unusual expenses will appear above or below this magical operating income line.
For the balance sheet format, assets are listed first, and they're listed in the following order.
So we always see cash come first, then accounts receivable, inventory, and then any prepaid assets which actually never convert to cash.
Then we have non current assets, including the tangible assets, the property plant equipment, and then the intangible assets, which would be things like software, trademarks, or this thing called goodwill which we get from an acquisition.
Starting with current liabilities, which are obligations within the next year.
Again, ordered by liquidity so we'll see bank borrowings, accounts payable and other payables, and the deferred revenues and other noncash, current liabilities last in the section.
So longer-term bank borrowings and bonds, and then other types of liabilities like deferred taxes, which we'll talk about later, and pensions.
Then we have stockholders' equity, where we start with the contributed capital, so the common stock, the initial paid in capital to treasury stock, and then retained earnings.
Hm, I guess the virtual students went out for virtual coffee.
When we finish the financial statements, we're ready for the last stop on the accounting cycle, which is closing entries.
This allows us to get ready to start a new period so that we can do the cycle over and over and over and over and over and over again for the whole life of the company.
What's a temporary account?
It's an account that accumulates the effects of transactions only for a certain period of time, so either fiscal quarter or fiscal year.
These would be the revenue and expense accounts, which then get closed out to retain earnings at the end of the period.
These would be the balance sheet accounts like assets, liabilities, contributed capital and retained earnings.
The actual closing entries are internal transactions that zero out temporary accounts at the end of the accounting period.
Again, by internal transactions, we mean this is the accountant sitting at his or her desk, these are not transactions with outsiders.
And the goal is to transfer the balances and the revenue and expense accounts, and the retained earnings.
So the way the entries look is for revenues, we wanna zero out the revenue account.
And notice in both cases we're not creating any new stockholders' equity, we're just transferring it from one type of account to another, from the temporary accounts to the permanent account retained earnings.
>> When my grampa tried to teach me accounting when I was five, he said something about an income summary account as part of closing entries.
This is a very temporary account and what happens is you close the revenue and expense accounts in the income summary, and then you close income summary into retained earnings.
With the net effect being that there's only one entry that goes into retained earnings Instead of the two that we used in our approach, but you get to the same place so it really doesn't matter which approach you use.
At this point only the permanent account should have balances, all the revenue and expense account should have a zero balance.
And now we're ready to start the next period.
So what we're gonna do to finish up the Relic Spotter case is we're gonna prepare the adjusted trial balance, put together an income statement, record the closing entries and post them to T-accounts, and then prepare the balance sheet.
And we put in the debits and credits for all the adjusting entries.
And as we put everything in, move all the balances over, what we wanna make sure is that for just the adjustments alone, our debits equal our credits, which they do.
Now, what we're going to do is take all of these revenue and expense accounts, which are summarized right here on the trial balance worksheet, and put them in the income statement format.
So we start out with Relic Spotter's income statement for the year ended December 31, 2012, and it's important to note that it's for an entire year, because income statements are always for a period of time.
For revenues, I've split the revenues into two categories, rental revenue and sales of sundries.
That's because Relic Spotter has two lines of business, and so we want to highlight the revenues from the two different lines.
Then we need the cost of revenues.
What I decided was the direct cost of providing that service was the metal detector depreciation expense and the software.
Salaries and wages, legal fees, advertising and building depreciation, gives us total SG&A.
Was the pricing of our product and service high enough to cover all the product costs for our core business and all the period costs?
And in this case it was.
Then below the operating income line we have interest revenue and interest expense.
We don't put interest revenue on the top line because our core business is not making loans.
We're not a bank, so we put it below operating income.
One more thing I want to point out before we leave the income statement Is I separated the depreciation expense into two buckets.
The metal detector depreciation expense is part of the direct cost of providing the rental service, whereas the building depreciation is part of the selling and administrative function.
Hm, I guess I should have let the virtual students know that they're allowed to drink virtual coffee in the virtual classroom.
Oh well, at least you get to see it.
So if we look at something like rental revenue, after we did our adjusting entries, and of course the entry during the period, there was a credit balance of 124,400.
If we look at advertising expense, after doing the adjusting entry, the balance was 4,000 that went on the income statement.
The closing entry is going to credit advertising expense for 4,000, which will zero it out.
So we do that for all the T-accounts and we get these two big, whopping journal entries.
So for the closing entries for revenues, we debit all the revenue accounts, which is gonna zero them out.
And then we add them up and credit the balance to retained earnings.
For expense accounts, we credit all the expense accounts to zero them out.
Total them up and then that's the debit's retained earnings, so if we go back over to our retained earnings T-account.
We can come up with a final balance retained earnings, which is a debit balance of 130.
Huh, so even though we have positive net income, we had more revenues than expenses, we paid that big dividend, and the dividend was bigger than our net income, so we have a debit balance.
After posting everything to T-accounts, we can go back to our trial balance worksheet, where we add a couple columns for the closing entries and the post closing trial balances.
Notice for the permanent accounts, you have the post-closing balance the same as the adjusted balance because we didn't do anything.
The only permanent account that's affected, of course, is retained earnings.
And if you look at the post closing tra balance you see that now, all the revenue expense accounts are at zero, and it was, retained earnings was the only balance that was affected by this process.
Now we're going to take all the balances of the permanent accounts and put together a balance sheet.
We start with assets and list all of our current assets in order of liquidity.
Then we follow up with tangible assets.
And then in one line item we subtract the accumulated depreciation to report something called net property, plant equipment.
Anyway, then we have the intangible assets like software, and that'll give us total assets.
So, the obligations in the next year, ordered by liquidity.
And then retained earnings, which we may want to called accumulated deficit since it's negative, but I guess it's okay to call it retained earnings as well, gives us total stockholders' equity.
In future videos later in the course we will continue with Relic Spotter to put together a statement of cash flows, and then eventually we'll talk about a statement of stockholders' equity.
And with that, we wrap up the basic building block section of the course.
The next step is to put together a statement of cash flows for Relic Spotter, but that's gonna take about a week of videos to learn how to do.
Our trip around the accounting cycle has culminated in the preparation of the first two financial statements.
As is our custom, we'll end the week by taking a look at the 3M company and report to see what their income statement and balance sheet look like.
Let's start with 3M's income statement, which is on page 46 of their annual report.
And to make this interesting, why don't we just compare this directly to what we did for Relic Spotter.
So over here is the Relic Spotter income statement that we prepared.
And we'll just compare it directly to the 3M company.
We started out with net revenue as the top line broken into the two segments.
Then we have the cost of revenues or cost of goods sold.
3M has that as their next item, again only one line item.
Just let me delete that, so that goes away.
And so far, we're seeing the same items in the same order.
Below the operating income line, we get to interest revenue and interest expense.
Now you may be wondering how can a big multinational company like 3M, producer of Post-it Notes and Scotch tape and all sorts of other cool stuff, get away with providing less information in their income statement than Relic Spotter?
If we go back to that MD&A section, management, discussion and analysis this is back on page 18 of the report.
We'll find that here is where 3M gives us a lot more detail about their income statement.
So here's net sales.
For operating expenses like costs of sales, they give you a whole paragraph explaining what happened.
So it includes manufacturing, engineering and freight costs.
One of the effect of the changes year on year was the impact of selling price, raw material, cost changes.
They don't quite give you the same detail breakdown of the components but they do talk about how different line items change, like pension expense, restructuring expenses, cost control and productivity efforts.
Same thing with interest income and interest expense, income taxes, and then as I mentioned, they go through each segment, and for each segment, like industrial and transportation business, healthcare business, consumer and office business, so this is the Post-it Note segment.
Always start with cash, that's the most liquid asset.
In a couple weeks, we'll talk about what these allowances for accounts receivable mean.
As a manufacturing company they have different categories of inventory.
3M just lumps those into other current assets.
Then for non-current assets we had land, building, metal detectors, accumulated depreciation PP&E.
So it's the same treatment of original cost minus total depreciation gives you net, that we saw with Relic Spotter.
And then for intangible assets we just had software, 3M has a lot more, goodwill, intangible assets net, and prepaid pensions, and the always popular other assets.
In terms of liabilities, we had accounts payable, interest payable, income taxes payable, unearned revenue for Relic Spotter.
Here, 3M has their long-term debt.
And as I talked about in the prior video, you can also put the current portion of that in current liabilities, as 3M does.
Gets us down to total liabilities for 3M after there's a couple others liabilities that we didn't have for Relic Spotter.
Basically only 1 cent per share, so almost all of their contributing capital goes into APIC.
Well, it didn't take long to find an exception to that.
We'll talk about these two items much, much later in the course.
There's also this non controlling interest stuff which we'll talk about later, but then bottom line, total liabilities in stockholder's equity.
And the same thing for 3M, no matter how big the company is, the two have to be equal.
Wow, what a mess.
In footnote four of the 10k, which is on page 66, 3M provides us some more detail on the balance sheet.
Same thing with other current liabilities we get a break down into other kinds of payables.
So there's other kind of trade payables, derivative liabilities, restructuring, employee benefits and so forth.
So what 3M decided to do was instead of making their balance sheet two or three pages, they put as few lines as they could get away with on their balance sheet and then provided a footnote which gave us a breakdown of some of the other line items.
For example, here's note three, goodwill and intangible assets.
This'll tell us everything we need to know, hopefully, about goodwill and intangible assets.
So the additional balance sheet information we get, we could usually go through the footnotes and dig it out.
And so that's what we see for the balance sheet and the income statement for the 3M company.
So, that's a wrap for week two.
I hope to see you again next week where we'll talk about preparing the statement of cash flows, the third of the four major financial statements.
I'll see you then.
This week we're going to spend the entire week talking about the Statement of Cash Flows.
And we're going to need the whole week to get through it.
Which is the first step toward putting together and then analyzing the statement of cash flows.
The statement of cash flows is going to report changes in cash due to operating, investing and financing activities over a period of time.
So a period like a fiscal quarter or a fiscal year, any period between two balance sheet dates.
You add them all up and that should be the same as the net change in cash balance.
Like the trade a piece of land for a building.
Those have to be disclosed at the bottom of the statement of cash flows.
But these disclosures either will appear at the bottom of the cash flow statement or somewhere else in the footnotes.
Why divide it into three categories?
Do you always have to make everything so difficult?
In that example we saw why it's important not to look at total cash flow.
Because all Dave had to do to increase his total cash flow is either borrow more money or raise more equity.
What we really want to know is how much cash flow is being generated by operating the business?
How much cash flow is the business investing in the future?
And how is the business financing itself?
That's why it's important to look at these three buckets and separate the cash flows in operating, investing, and financing.
Let's talk about each of these three buckets of activities in more detail starting with operating activities.
These are transactions related to providing goods and services to customers and paying expenses related to generating revenue.
The best way to think about this section is it's the analogy to the income statement.
So transactions that appear on the income statement, we tend to see their cash impact in the cash from operating activities section.
But other sources of, of revenue or positive income like receiving interest or dividends on investment.
And we'll see cash outflows like payments to suppliers, payments to employees, payments of interest and tax.
Other operating disbursements like payments for advertising, legal fees, and other things like that.
Wouldn't that be an investing activity.
Yeah, a case could certainly be made that dividends received and interests received should be investing cash flows.
And the Financial Accounting Standards Board, the FASB decided that they wanted them as part of the operating cash flow.
To provide comparability between the income statement, and cash from operations.
But I have the feeling we'll be talking about these items more as the video goes along.
Because even though they're in the income statement they will not be part of cash from operating activities.
The first type of adjustment is for depreciation, amortization, and other non cash items.
These will affect income, but there's no cash flow involved.
So we need to make an adjustment for them.
Also sometimes we get gains or losses on selling something like property planned equipment, which affect our income statement.
But we don't want to show the cash flow in the operating activities section, we want to show it in investing activities section.
So we need to adjust for that.
We're going to make these adjustments later on in the week, but I just wanted to put them in the back of your mind right now.
The next bucket is investing activities.
So cash inflow is like selling property plant equipment, selling a tangible asset, selling investments, or selling a whole business.
Cash outflow examples would be acquiring a business, acquiring property plant equipment, acquiring intangible assets, or purchasing investments.
>> What if buy stock as an investment, but I only intend to hold it for six months?
Would that be a long-term asset?
Would that be an investing activity?
There's a rule of thumb that any asset that we intend to hold for more than a year would be an investing activity.
Whereas any asset we intend to hold for less than a year would be an operating activity.
But this is a rule of thumb, it's not an iron clad law, and there are going to be places where we see that this rule of thumb is violated.
In the case of investments, there's a whole set of rules around whether the investment should be operating or investing activities.
And we'll talk about those later in the course.
Except for interest payments.
If ifs and buts were candy and nuts, every day would be Christmas.
Interest is paid to creditors.
But this is a situation where the FASB wanted comparability between the income statement and cash from operations.
And so they decided to include interest payments as an operating activity to parallel the interest expense that's in net income.
Having said that, a lot of investor analyst disagree with this classification and want to pull it out.
If you remember earlier in the video I mentioned companies have to report cash paid for interest somewhere in their financial statements.
That disclosures there so if people don't want cash paid for interest in operating cash flows.
So what financing activities will include are cash inflows such as the money you get from issuing new stock or reissuing treasury stock.
That's when you take the stock that you previously bought back, called treasury stock, and then sell it back to the public.
Cash out flows include paying dividends to your shareholders, purchasing your treasury stocks or repurchasing your own stock.
So putting it all together, the statement of cash flows is going to have these operating activities, investing activities and financing activities.
Listed in this order showing you the three different buckets where a companies cash flow comes from or goes to during a period.
>> I believe your classification of interest in dividends is not correct.
After you crashed my question earlier I texted my sister who works in Hong Kong.
She confirmed that interest and dividends received are investing activities.
>> Well, I'm certainly not going to argue with your sister from Hong Kong, especially since we're both right on this one.
Let me jump back to the slide to show you these IFRS differences.
We're talking about transactions where a company receives interest and dividends on investments, or pays interest, or pays dividends.
Under IFRS, interest and dividends received and paid can be classified as operating, investing, or financing.
The idea is as long as the company does the same thing year after year, investors and analysts will know where to find it.
GAAP, these four items all have to be in the buckets that we show on the slide.
There's no discretion.
Now that we've defined operating, investing, and financing activities.
I'd like to do a simple example to show you what we can learn by dividing cash flow into these three buckets.
So let's say we're a start up company.
Not that there's anything wrong with gray hair.
So anyway, all you have to do is pop a pill and you'd no longer have gray hair.
We may have an initial version of our drug that's working, for which we get some revenue.
But we have a lot of negative cash flows as we have a lot of operating costs running the business and we're also investing in R and D.
Because we have to go out and create facilities and buy equipment and invest in all these long term assets to get the business up and running.
And then we have a big positive financing cash flow.
Or venture capital firms we borrowed money from banks or the public market.
To finance our investments and the negative cash of operations.
The bottom line in this case is 0 net cash flow.
That, that doesn't necessarily need to be the case.
Now our company starts to have some breakthroughs.
We move into the early growth stage.
Drug seems to be working pretty well.
People are taking the medication.
Their grey hair goes away.
And we're starting to get positive operating cash flows.
As more and more doctors prescribe our medicine.
We still have big negative investing cash flow because we're trying to grow the business.
And we're trying to invest in new property plant equipment to meet demands for our drug.
And maybe we decide to go and acquire another company to diversify our product line.
So you can take the pill and your hair will turn blonde even if it was say dark brunette to begin with.
Not, not that there's anything wrong with dark brunette hair either.
We cannot fund that investing cash flow just out of operations.
So we have a positive Financing Cash Flow.
As the, we need to go out and raise money either from the stock market or from banks and other creditors.
Can we get more of this?
So, let's get back to it.
We've got patents on our anti-gray hair drug, our pro-blond hair drug.
And we can just print money as a result.
There's a lot of revenue coming in, covering all the expenses of running the business, so we have a high cash from operations.
We still have a fairly high level of investing cash outflows.
Because we're still growing, we have capital expenditures that we need to have to meet the demand for our product.
Maybe we're doing a couple of other strategic acquisitions.
But now we're able to pay back some of the financing, so we have negative financing cash flows.
We use the excess cash operating after covering the investing cash flow.
To go out and buy back stock, or pay back debt, or maybe start to pay dividends to our shareholders.
Then we move into the decline stage of our life cycle.
All of our patents have expired, customers can now buy generic anti-grey hair medication, or generic pro blonde medication.
Our investing cash flows have also gone down substantially, because we just don't have a lot of other ideas for new investments.
And so we end up doing is continue to have a negative financing cash outflow.
We're taking our excess cash from operations and using it to buy back stock, repay debt, or pay dividends.
Which at this point is essentially just saying to our shareholders.
Because we certainly can't.
And then, I guess, the last stage would be, we either go bankrupt or acquired.
So I think this video showed that it's fairly straightforward to classify cash flow activities into the operating, investing, and financing buckets.
But it's not always straightforward.
In the next video, we're going to apply these classifications to the Relic Spotter case.
And there we'll see that there is judgement that does apply in some situations which makes this a bit trickier than it first seems.
I'll see you next video.
In this video, we're going to dig out the Relic Spotter case that we worked on during the first two weeks, and go through its cash flow transactions to classify them into operating, investing, and financing buckets, which is the first step towards putting together Relic Spotter statement of cash flows.
Let's get started.
Let's start with transaction number one for the Relic Spotter case.
In this transaction, Relic Spotter sold shares to investors.
Thousand dollars because the company received cash and then credited common stock in APIC.
The answer here is financing, one of the definitions of a financing activity is cash flows with our owners.
So if we're issuing stock, we're getting stock from the owners of the company which would make it a financing cash flow.
Next, transaction number three.
Or did you make a mistake, as you often do?
Well, at least not yet.
It was the transaction where Park was borrowing money on her own account and we didn't even record it.
The only ones that we have to deal with are the ones that have either debits or credits to cash.
So anyway, in transaction number three, Relic Spotter paid $3900 cash in legal fees to incorporate the business.
The answer here is operating cash flow, because this is one of the costs or expenses that Relic Spotter needs to incur to run the business.
After all, incorporating the business is a long term cash flow.
At least, we hope.
But if you remember we decided to expense this cash flow on the income statement.
So to provide comparability, we're gonna treat it as an operating activity on the cash flow statement.
If we had created a long term asset, then we probably would of treated it as an investing activity.
Relic Spotter bought land and building with a mortgage and $31,000 of cash.
So go ahead and try to classify this cash flow as operating, investing, or financing.
The answer here is obviously 155,000 cash out flow for investing, and 124,000 cash in flow for financing.
We bought land and building.
Why is this not $31,000 of cash flow for investing activities?
>> Okay, I said obviously when I provided the answer, but this one's far from obvious.
The issue here is that we did one journal entry, but there were really two separate transactions.
First, we borrowed $124,000 cash from a bank under a mortgage.
The second is that we used that cash, plus $31,000 of our own cash To buy $155,000 of land and building.
That's an investing activity.
To provide investors and analysts a clear picture of what we're doing, we need to split this into the two transactions we really borrowed a 124,000 from the bank under a financing cashflow.
And we really paid $155,000 cash for land and building, as an investing cash flow.
And that's what we need to show on the statement of cash flows.
Relic Spotter paid $33,000 cash for renovation work to the building.
The answer here is investing.
It should be an investing cash outflow of $33,000.
This seems a lot like routine maintenance to me, which would be an operating activity.
But the key question here is does this expenditure represent a capital improvement, or a routine maintenance?
A capital improvement would be anything that increases the value of the building or its useful life.
We would add that to the building account, and appreciate it over time, and we'd consider the cashflow an investing activity.
Routine maintenance is something you have to do no matter what.
It's already built into the assumptions about the value of the building and its life.
It gets expensed immediately and then it would be considered an operating cash flow.
Transaction number 6, Relic Spotter paid $120,000 cash to buy metal detectors.
Is that transaction operating, investing, or financing?
And the answer is $120,000 investing cash outflow.
Why would the purchase of said metal detectors not be an operating activity?
But we're going to ramp these metal detectors over and over and over for up to two years, which makes them more like equipment, a long term asset.
And makes the treatment of it an investing cash flow more appropriate.
If we are buying these metal detectors and immediately reselling them like inventory, then we would call it operating.
Or if we bought them and we were going to rent them for less than a year.
But the fact that we're gonna have them for more than a year, up to two years, makes this feel more like an investing activity.
And move to transaction eight where Relic Spotter had paid $2,100 cash for a 3 year software site license.
The answer here is an investing cash outflow of $2100.
And before the virtual students jump in I'll just tell you.
So that's gonna make it an investing activity because we're investing for more than a year.
Relic Spotter paid $8,000 cash for advertising over the next year.
Is that operating, investing, or financing?
So, by our general rule of thumb, we would call this an operating activity, rather than an investing activity.
This one year rule of thumb tends to work pretty well.
If you have an expenditure that's gonna benefit you for more than a year, we tend to call it investing.
If it's gonna benefit you for less than a year, we tend to call it operating and there are not many exceptions to that.
Is that operating and investing or financing.
Why isn't this financing?
>> Actually, in this case, Relic Spotter is the creditor because Rebecca Park is borrowing money from the company.
If the company were borrowing money from Rebecca Park, then yes, it would be a financing activity.
So the question now is, if Relic Spotter is lending money to Rebecca Park, is that an operating or an investing activity?
I decided to make it an operating activity because the loan was only one year, if the loan was longer than a year, say two years, or three years, or five years.
Here Relic Spotter paid $2,000 cash to its supplier.
This was for the inventory that it bought out account in transaction seven.
So, this $2,000 cash paid to the supplier operating, investing, or financing.
The answer here is a $2,000 operating cash outflow.
Yeah, a payment to a supplier is one of the examples we use to define an operating activity.
By the way, do you know where the smartest people in America work?
At the US Mint, because all they do all day is make cents.
In transaction number 14 Relic Spotter paid $2500 cash to it's shareholders for it's dividend.
This was the dividend that they declared in transaction 12, it's actually paid in cash in transaction 14.
So is this $2500 cash paid for dividends operating, investing or financing?
>> Yes, paying dividends is one of the examples we use to define a financing activity.
By the way, do you know where you can also find smart reasonable people?
Next in transaction 15 Relic Spotter received $1200 cash from the Pen Antiquities Club for future unlimited rentals.
So how do we consider this cash received for future rentals, operating, investing, or financing?
The answer here is operating.
In transaction 16, Relic Spotter receives cash rental revenue on the metal detectors.
Is that operating, investing, or financing?
The answer here again, is operating.
>> Either these have gotten easier or we have gotten smarter.
In transaction 17 Relic Spotter paid $38,000 cash for inventory.
Is this operating, investing, or financing?
The answer here is operating cash outflow of 38,000, operating because this is a core expenditure for running our business.
Relic Spotter received $35,000 cash from sales of sundries.
Is this operating, investing, or financing?
The answer here is operating.
Finally, transaction 20, Relic Spotter paid 82,000$ cash to its employees for salaries and wages.
Is this operating, investing, or financing?
Paying our employees is one of our key business activities, so this would be an operating activity.
And that was the last cash transaction for Relic Spotter because the rest of the transactions in the case were adjusting entries.
So we can go ahead and total everything up.
Which, if you go back and look, is what we end up having at the end of the year for Relic Spotter.
Now, all we have to do is just list these cash transactions on the cash flow statement in Operating, Investing, and Financing order.
>> I wish that was the case because then we would be done with the week on cash flow statements, but if you looked at the website you can see that we have a lot of videos left to go.
And we'll pick this up next video with the discussion of the two different methods there are for putting together a statement of cash flows.
Unfortunately, all companies use the difficult method, so it's gonna take us a lot of videos to understand that method, which we need to know to understand real companies' financial statements.
I'll see you next video.
In this video, we're gonna talk about the two different methods that you need to know to put together a cash flow statement.
Let's get started.
There are two methods for preparing the statement of cash flows which are rather creatively titled the direct and indirect methods.
So where are all the places that the cash came from, where are all the places that you pay cash out to?
This method is always used for investing and financing activities, but is rarely used for operating activities.
Instead, for operating activities, companies tend to use the indirect method.
This can only be used for operating activities and the goal is to reconcile net income with cash from operations by removing any noncash items from net income, and including any additional cash flows that were not in net income.
So we're gonna see a statement that starts with net income, ends with cash from operations and shows all the differences between the two.
So what this boils down to is for three buckets operating, investing and financing.
Where as investing and financing are always the direct method.
What's good for the goose is good for the gander.
This is just more stupid over-complication.
>> You know I am gonna agree with you that this probably is a stupid over complication.
Because really every company uses the same approach for their cash flow statement.
They do the investing and financing activities using the direct method, and then they use the indirect method for their operating section.
Because even if they did the operating activities under the direct method, you still have to provide the indirect method anyway.
You just list the cash flows based on where they're coming from or where they're going to.
Really the one thing you have to learn that's difficult is this indirect method for operating.
And we're going to spend much of the rest of the video, and much of the rest of the week trying to get a handle on this indirect method for the operating section.
Then it's going to adjust for components of Net Income that are tied to noncash items or to investing activities.
What we need to do is either add back the expenses or subtract the revenues to remove them from Net Income to to get the cash flow.
So for example, Net income includes depreciation expense and amortization expense which are both noncash expenses.
To remove those noncash expenses so that we can get from Net Income to cash from operations, we have to add them back.
Because adding back expenses removes them.
We can also have gains or loses on sale at of property point equipment or investments.
Now there are cash flows associated with those, but we want to count those cash flows in the investing section.
So we need to remove those gains and losses from the income statement.
So, we're going to add back losses or subtract gains, to remove them from Net Income, on our way to cash from operations.
Then, we need to adjust for components of Net Income tied to assets or liabilities created through operating activities.
These are the working capital accounts, like accounts receivable, inventory, all of the payables.
What we need to do here is add or subtract the change in the asset or liability account balance.
And we're gonna use the balance sheet equation to determine whether we should add or subtract.
For example, accounts receivable is a noncash asset.
If accounts receivable went up, we would need to subtract it on the cash flow statement to stay in balance.
If it went down, we would need to add it on the cash flow statement to stay in balance.
On the other side of the equation, accounts payable is a liability.
If accounts payable went up, we would need to add it on the cash flow statement to stay in balance.
And if something like interest payable or wages payable went down, we'd have a liability going down, and we would have to subtract it on the cash flow statement.
What?
That example didn't make it crystal clear on how to do the indirect method?
Okay, okay, we'll do an example, or maybe two, or maybe four our five.
Let's look at some examples of how to put together an indirect method cash flow statement and how it gives you the same answer as the direct method.
We're going to do this for various types of income statements with adding a little bit more complexity each example.
In the simplest case, we have a company that had $100 of sales which were all in cash.
Their cost of goods sold were $60, again all in cash.
So they bough $60 of inventory with cash and sold it all during the period.
And so they end up with net income of 40.
Cash payments of suppliers of 60, gives us an operating cash flow of 40.
And in this case the operating cash flow is exactly the same as Net Income, because everything the company did was in cash.
If we go to the indirect method, under the algorithm we always start with net income.
We didn't end or begin the year with inventory.
Now let's make this a little more complicated and bring in depreciation expense.
So we start with cash sales and cash COGS like in the prior example.
But now the company has a $10 noncash expense depreciation which gives the company a Net Income of 30.
Under the direct method we have cash collections from customers, cash payments to suppliers.
Of course there's no cash flow involved in the depreciation.
Now we need to make sure we get the same answer under the Indirect method.
We add back the depreciation expense of 10.
It's a noncash expense so to remove it from Net Income we add it back.
There are no changes in working capital, because again we didn't begin or end the year with receivables or inventory.
So there's no other adjustments and we end up with operating cash flow of 40 under the indirect method.
Which of course is the same answer under the direct method which always has to be the case.
If a company had say $10 more in depreciation expense it would increase cash flow by $10?
If a company had cash flow problems all it would have to do is take more depreciation.
That's cool.
Just crank up the depreciation expense, and watch that cash flow through the door.
Well, obviously it can't work like that.
And, in fact, I've heard stories about employers asking students this very question to see if they know anything about accounting.
So let me jump back out to the slide and show you how this works.
Okay, let's say we have another $10 of depreciation, that means we would have $20 of appreciation expense total, and we would add back 20.
Now I'm going to ignore taxes for now.
And just assume that our Net Income would drop from 30 down to 20 with the extra $10 of depreciation expense.
So we have 20 plus 20 equals 40 instead of 30 plus 10 equals 40.
It has to get us to the same place because depreciation's a noncash expense.
It can't create more cash flow.
Now one thing I should note is that you can use different depreciation for tax purposes, than you see here on the financial statements.
And changes in depreciation for tax purposes actually can save on taxes and can effect cash flow.
But that's a topic that we're going to deal with much later in the course.
In the next example we're going to still have a $100 of sales but this time lets assume that only $80 is received in cash the other $20 of sales remain on account so that we end the period with accounts receivable.
We still have $60 of COGS which is all in cash and our $10 to depreciation.
Gets us to the same Net Income as we saw in the last example of 30.
When we look at the direct method operating section cash flow statement, we collected $80 of cash from customers.
Now let's see if we can get the same answer under the indirect method.
We start with Net Income and then as we saw in the prior example, add back depreciation expense because it's a noncash expense.
But now we have a change in accounts receivable that we have to adjust for under that third step in the algorithm.
What happened is accounts receivable started the period at 0, Ended the period at 20.
So, that's a $20 increase in a noncash asset.
Which means that we have to subtract it on the cash flow statement.
Because we've got 30 of Net Income, plus 10 of depreciation expense is 40, minus 20 for the increase in accounts receivable, gets us to an operating cash flow of $20, which is the same answer that we got under the direct method.
We sell $20 of goods, and yet, that reduces our cash flow.
Isn't that like cutting off the nose to spite the face?
But anyway let's think through the intuition behind the indirect method.
Make adjustments to get the cash from operations.
All of those sales are legitimate, they meet the revenue recognition criteria.
But $20 of those sales were never collected in cash.
Fortunately, the increase in accounts receivable keeps track of the noncash sales.
Cuz any time we make a sale on credit, we have to increase accounts receivable.
So if we start with Net Income, which includes the $100 of sales.
Subtract the increase in accounts receivable to take out the $20 of noncash sales.
We're going to start with sales of 100 again.
Now, we're gonna make the inventory part a lot more complicated.
So, we'll keep the $60 of cost of goods sold.
But in this case, we actually bought $75 of inventory.
So we bought $15 more of inventory than we sold.
And we only paid $50 in cash.
Which means that $25 of that inventory was acquired on an account, so we have accounts payable of 25.
Then we subtract off the depreciation, and we end up with a net income of 30.
Under the direct method, we collect $80 of cash from customers.
We only paid $50 cash to our suppliers.
So we don't use the COGS amount or how much inventory we bought.
We use the actual cash we paid, which was 50.
We add back depreciation expense, so we've seen those two steps before.
We've also seen the subtraction of the increase in accounts receivable, to take into account that not all the sales were made in cash.
So, what happened was our inventory started the year at 0, and ended the year at 15.
It went up by 15 because we purchased 75 of inventory but only sold 60.
If a noncash asset goes up, we subtract it on the cash flow statement.
So we subtract the increase in inventory.
For accounts payable, they started the year at 0, ended the year at 25, so this liability accounts payable goes up by 25.
That's on the other side of the equal sign, so cash has to go up by 25 to make this balance.
So we can see on the indirect method cash flow statement we have increase in accounts payable of 25 gets added back.
When we add everything up, we get the same operating cash flows under the direct method.
If your inventory goes up during the year, it means that you're buying more inventory than you needed for your level of sales.
That means that you got stuff without paying your supplier.
Not paying your supplier is a source of cash.
That's an extra $25 of cash that you would not have had if you had paid off your supplier's amount.
And so we add that to recognize that it's a source of cash.
We're gonna go through a lot more examples like this in remaining videos to help you get down this intuition.
Do you have some simple formula, or algorithm, we could use?
>> Well I showed you a slide earlier in the video with a simple algorithm for doing the indirect method, and you all went, what, what, really?.
Sorry to be a little peevish there, I guess that's what the cash flow statement will do to us.
I understand that it is hard to get your head around how this indirect method works when you see it for the first time.
So we're gonna do in the next video, is go back to the Relic Spotter case and step-by-step, work through how to put together an indirect method cash flow statement for Relic Spotter.
And then you'll see many more examples later in the week.
Anyway, I'll see you next video.
In this video we're finally gonna finish the Relic Spotter case by putting together its statement of cash flows using the direct and indirect methods.
Let's get started.
Last time we looked at the Relic Spotter case we put all of the cash transactions into operating, investing, and financing buckets.
So now we're gonna go ahead and use these classifications to put together the cash flow statement.
To do the indirect method, we're gonna need to pull some information off the income statement.
I don't remember all of those zeros when we put together the balance sheet.
In fact when we put together the Relic Spotter balance sheet, we didn't have all these zeros in there because we only put together the ending balance sheet.
But when we do a cash flow statement, we need the change in the balances, the difference between the beginning balance and the ending balance.
There was no beginning balance on any of these accounts because Relic Spotter is a start up company.
Once we get that out of the way, then we'll look at operating activities under both the direct and indirect method.
So we have purchase of land for 103,000, purchase of buildings, 85,000.
Add them all up, we get net cash outflow from investing activities of 310,100.
This section will go on the final cash flow statement.
Oftentimes, don't companies simply report a line called capital expenditures?
>> There are generally no specific rules that govern how much or how little detail you break things into on the statement of cash flows.
It's the manager's choice, but usually the manager makes the choice based on what investors and analysts wanna see.
Because if investors and analysts are looking for a piece of information that's not there, they'll just ask the company about it during a conference call or some other communication.
So what you're seeing on the cash flow statement is a joint agreement between managers and the users of the financial statement as to how much detail they wanna see in these various line items about the company.
So here is the column of cash transactions that we classified as financing.
Now we just need to list them.
So we paid dividends of $2,500.
That gives us a net cash inflow from financing activities of $371,500.
Now even though it's somewhat theoretical cuz companies never really report these, we're gonna look at the operating activities under the direct method.
So let me pull in the operating cash flow transactions.
So first, I'm gonna take all the cash we collected from customers.
We received cash on the rental prepayment from the Pen Antiquities Club, the revenues that came in cash from metal detector rentals, and then the 35,000 of cash from the sundries sales.
You add that together, and we have cash collected from customers totalling 156,300.
How can we justify putting that on the cash flow statement?
>> Well, we can justify putting it on the cash flow statement because Relic Spotter actually received cash.
Well you raise a good point, in that a lot of the examples we've seen so far, companies are recording revenue before they receive the cash.
And so, we have a change in accounts receivable.
But, you could have a company receive the cash before they earn the revenue.
Either you might get the cash first, or you might get the cash later compared to when you book the revenue.
Add that up, cash paid to suppliers is 40,000.
Cash paid to employees for salaries and wages was 82,000.
Cash paid for short term loans was 5,000, and then I'll combine legal fees and advertising into cash paid from miscellaneous expenses of 11,900.
Again whether you list those separately or combine them depends on what your financial statement users wanna see in terms of the level of detail.
We add all this up, and we get net cash from operations of 17,400 which is what we had in the operating bucket to begin with.
But, you said that companies rarely use it.
>> So, why do we have to learn the indirect method?
Let's hear your answer.
>> I'm glad you asked that question here, because this is the best place for me to show you why the direct method is not that useful for the operating section of the cash flow statement.
Let me jump out to the slide and show you what I mean.
So, Relic Spotter's cash collected from customers was 156,300.
Is that good or bad?
Relic Spotter's cash paid to suppliers was 40,000.
Is that good or bad?
Well, you can't tell without some kind of benchmark.
You could look at prior year numbers to see if there's a trend.
But, what we really wanna know is, what was the level of activity surrounding these cash collections during the year?
For example, if Relic Spotter at 157,000 of revenue and collected 156,300 in cash, then the cash flow makes sense.
But if Relic Spotter had 500,000 in revenue, but only collected 156,300, then there may be a problem.
Or, let's say that Relic Spotter sold 40,000 of inventory, paid 40,000 to their suppliers.
But what if Relic Spotter only sold 10,000 of inventory?
Then the question is, why did they spend an extra 30,000 in cash to acquire inventory they didn't sell?
What the indirect method's gonna do is start with net income as a benchmark for the expected level of activity or expected level of cash flows during the period.
And then highlight any discrepancies from that level.
This is the kind of thing we'll talk about when we do an analysis of an indirect cash flow statement, after we finally put one together later in the video.
Now we're gonna do the indirect method which will be what we'll show on the final cash flow statement for Relic Spotter.
So I've pulled up the income statement, and at the bottom line we can see net income was $2,370.
So on our indirect method cash flow statement, we start at the top with net income of 2,370.
Notice I already have the answer at the bottom, net cash from operations of 17,400 because, whatever we do in this section, we have to get the same answer that we got under the direct method.
Okay, so far, so good.
Next step in our algorithm was to adjust for components of net income tied to noncash items or investing activities.
We had metal detector depreciation of 3,000, software amortization expense of 350, and building depreciation expense of 1,500.
I'm gonna combine those into one line item called depreciation and amortization of 31,850, and we're gonna add that back to remove that non-cash expense from net income.
One thing I will say here is that generally the only place you can find depreciation and amortization expense in the statements is on the statement of cash flows.
Yes, it's part of the income statement, but it's often combined with other items, and not broken out separately.
But you'll always be able to find it broken out separately in the operating section of the statement of cash flows.
The last step in our algorithm is to go through all the asset and liability accounts related to operating activities, in other words the working capital accounts.
And add or subtract the change in the balance based on the balance sheet equation.
That's a noncash asset going up, which means we need to subtract it on the cash flow statement to stay in balance.
Interest receivable went from 0 to 250, noncash asset going up.
So we subtract it on the cash flow statement.
Inventory went from 0 to 12,000, noncash asset going up.
So we subtract it on the cash flow statement.
And again, non-cash asset going up, we subtract that on the cash flow statement.
>> I think I understand, assets are always subtracted when the indirect method is used.
And so all the assets went up.
In a future video, we'll look at examples where companies do add assets to their statement of cash flows because they've had assets go down during the year.
If we look at the rest of the assets out of the balance sheet, we have land, buildings, metal detectors, software.
We don't do anything with those in the operating section cuz we've already taken care of those in the investing activities.
So we move onto the liability side of balance sheet.
Note we're on the other side of the equal sign with the liability.
So liability going up means that we need to add it to the cash flow statement.
So that's an increase in a liability of 4,900, which we need to add to the cash flow statement to keep the balance sheet equation in balance.
Again, an increase in a liability gets added to the cash flow statement.
That's an increase in liability that gets added to the cash flow statement.
>> And I think I am not wrong to assume that is not necessarily the case that liabilities are always added under the indirect method.
I'm not really sure what the question was.
But you should not assume that liabilities are always added on the cash flow statement.
Again, because we are looking at a start-up, all the liabilities went up in value and so we added them.
Going back to the balance sheet, the next accounts we would have would be mortgage payable, common stock, additional paid-in-capital.
And retained earnings, that's just net income and dividends which we've also taken care of.
So looks like we're done, which is a good thing because we're out of space on the indirect method cash flow statement here on the right.
And if you add everything up, you 'll find that we get the same answer, 17,400, that we got under the direct method.
And then we'll have cash flow from investing and financing activity under the direct method.
In terms of analysis, what this statement tells us is that this company is still in the early growth stage of its life cycle.
We do have positive cash from operations, 17,400, but that's nowhere near enough to cover all the cash outflow for investing activities.
So, Relic Spotter had to go out and raise a lot of cash through financing activities, both through stock and mortgage payable.
Now I want to focus just on the cash flow from operating activities section so we can talk about what we learn from this indirect method presentation.
First thing we learn is it gives us the two different pictures of the company's performance during the year.
So we see Relic Spotter's net income, which answers the question, did Relic Spotter price their rentals and sales high enough to cover all the costs of the, running the business, and thus post a profit?
And we can see they did.
Then at the bottom we see net cash from operations, which answers the question, did Relic Spotter have more cash coming in than cash going out, in activities related to running the business?
And here we see that that was the case also.
Between those two pictures of the business, we see all the discrepancies, all the reasons why we got different answers.
And the biggest discrepancy is the depreciation and amortization.
And that makes sense because net income includes an expense or a charge for using up these fixed assets, using the buildings and metal detector and softwares.
Whereas there is no cash implications of doing that so it doesn't affect cash from operations.
So anytime you look at companies that are very capital intensive, they have a lot of long-term assets.
You'll see this difference between net income and cash from operations is primarily driven by this depreciation amortization.
Then we have all of the changes in working capital that have created discrepancies between net income and cash flow.
And from an analysis point of view, I think these are the most interesting and important lines to focus on in the cash flow statement.
Cuz what these lines are telling you is that some management activity is creating a wedge between cash flows and revenue and expense recognition.
So what you wanna do is focus on the really big numbers and try to understand what's going on.
So for instance, the biggest number is the change in inventories of negative 12,000.
What that represents is that Relic Spotter purchased $12,000 more inventory in cash than they needed for their level of sales which were recognized in net income.
What you wanna do now is dig in and try to find out what caused that.
So did Relic Spotter management buy a bunch of inventory that they couldn't sell because nobody wanted it?
Or, were they getting some kind of volume discounts, and so they were buying excess inventory in advance of future sales, which would be good news.
I mean, the cash flow statement's not gonna tell you which one it is.
But it's gonna tell you, you need to dig into these further.
As another example, a big discrepancy that you often see is changes in accounts receivable, which in case of Relic Spotter, was negative 4,200.
This could be good news if their sales are growing dramatically and they just haven't had a chance to collect them yet.
Again, we don't know which scenario is going on just by looking at the cash statement.
What it does is it highlights we need to dig into these further.
So, you wanna look for the big numbers in these changes in working capital.
So, that was our first trip through putting together an indirect method cash flow statement using the balance sheet and the income statement.
Not clear yet?
I'll see you then.
In this video we're gonna to tackle a number of miscellaneous cash flow topics that I haven't gotten to yet.
And we'll wrap up with a discussion of earnings versus cash flow versus EBITDA versus free cash flows.
So, let's get to it.
First let's look at an example of how to treat a gain on sale of property, plant, and equipment under the indirect method cash flow statement.
So let's say we sold property plant equipment worth $70 on the books for $75 cash.
I bet that never, ever happens in the real world.
But I said how much it's worth on the books or the financial statements.
And remember the book value of property plant equipment is gonna be a function of our depreciation assumptions, because it equals the original cost minus the accumulated depreciation.
So if the depreciation assumptions are incorrect, which they always are, then we're gonna end up selling it for more or less than it's on the books.
So think of it this way, if we depreciate something too much, we drop its value too much, we end up having a gain on sale, which sort of brings it to the true amount of depreciation over the life of the asset.
If we depreciate something too little, then we'll have a loss on sale, which again gets us to the true level of depreciation on the asset over its life.
So this gain or loss on sale helps us adjust our incorrect assumptions and get the true amount of economic depreciation over the life of the asset.
Anyway, that's gonna result in a gain of $5, which will go on the income statement.
Although this gain will go on the income statement and increase that income just like revenue would, we're not gonna consider it top line revenue because it's not part of our core business activities.
In other words, we're not in the business of buying and selling buildings.
One implication of this example is because it's not a core business activity, it's gonna be an investing activity.
And because it's an investing activity, we need to remove that gain out of the operating section and place it into the investing section.
So I'm gonna bring back one of the basic example we did early on, where we have all of our sales in cash, all of our cost to goods sold in cash, and then depreciation of $10.
We're gonna add to that the gain on sale of property plant equipment, which goes on the income statement, which would make our net income 35.
Under the direct method cash flow, all of our sales for cash, so we have collections from customers of 100.
All of our cost to goods sold was in cash, so we have payments to suppliers of 60.
Depreciation, of course, is not cash.
And the gain on sale of property plant equipment, we want to consider that part of the investing cash flow.
And then we have investing cash flow as the full $75 proceeds from sale of PP&E.
Under the indirect method, we start with net income, which is 35.
We add back depreciation expense of 10, because it's a non-cash expense.
And then we have to remove the gain, otherwise we'll double count that cash flow.
A gain increases net income, so to remove it we need to subtract the gain.
And then we have again, the full cash flow from the sale of the PP&E, 75, as an investing cash flow.
Could you provide the viewers a handy algorithm for remembering how to adjust for such gains?
So the way to remember how to deal with gains and losses on investing activities in the operating section is the Hokey Pokey.
You do the hokey pokey and you turn yourself around, that's what it's all about.
Next I want to talk about some of the complications you may run into when looking at a statement of cash flows.
These are not things that we're gonna explicitly cover in the course, but I want you to be aware of them, because you will run into them in practice.
And all these complications surround the question why doesn't the change in the balance sheet numbers often equal the number on the statement of cash flows?
So in all of the examples that we've done so far, when you look at the change in the balance sheet numbers for, say, accounts receivable, it's the exact same number that you see in the operating section on the statement of cash flows.
But in real financial statements, you often see it's not the case for one of these four reasons.
First, there could be non-cash investing and financing activities that relate to the working capital accounts in the operating section.
An example would be, let's say one of our customers who owes us an account receivable can't pay us cash, so instead they give us a piece of land.
It would be disclosed at the bottom of the statement of cash flows.
It would also affect the balance sheet number for accounts receivable, but it wouldn't show up on the cash flow statement because there's no cash involved.
All the cash the companies pay when acquire another company is considered a investing cash flow.
But, part of the things companies acquire are working capital assets and liabilities.
So for instance, let's say a company made an acquisition.
For multinational companies, which have subsidiaries in multiple countries in different currencies, what we do is we take any effect of exchange rate movements and break them out of the operating section of the cash flow, showing them at the bottom.
So a foreign exchange movement would effect the balance of say, accounts receivable or inventory in the balance sheet, but we wouldn't show it in the operating section of the statement of cash flows.
Does anyone even do these in the real world?
>> Do you mean the MTV show The Real World, or in practice?
Because you're talking about the MTV show The Real World.
I don't think they did any foreign currency translation adjustments, it seems more like a Jersey Shore thing.
Anyway, this is a pretty advanced topic, it's something I cover in a second year elective, so, we're not gonna go into this in detail in this course.
I just wanted you to be aware of the fact that all of the effects of exchange rate movements on the cash flow statement are broken out on one line item in the bottom so that when you look at the operating section, what you're seeing are changes in accounts due to real activities, not due to exchange rate movements.
The last complication is that sometimes companies have subsidiaries in different industries, which effect what is considered operating versus investing activities.
So let's think back to our company before that made the pills to cure grey hair.
Not that grey hair needs to be cured.
What would happen then is the pharmaceutical company buys land.
It would be considered an investing activity.
But if the real estate subsidiary buys land, it would be considered an operating activity, cuz that's part of their core operations.
So the same transaction of buying land could show up as either operating or investing.
Now, companies in this situation will sometimes produce separate cash flow statements to help investors see these different activities match up in the different subsidiaries.
Next I wanna talk about disagreements that analysts and investors have over the FASB classification, a couple items.
I know it's hard to believe that people would disagree with the FASB, but there are a couple disagreements out there.
The first, many investors and analysts prefer to classify interest payments as a financing activity and interest and dividends received on an investment as an investing activity.
So one thing that FASB did is they required a disclosure of cash paid for interest, so if investors or analysts wanna take it out of operating, they can easily subtract it because that disclosure's provided.
Another disagreement is that all income tax effects are shown in the operating section, even if the income relates to financing or investing activities.
So if there's an income tax effect from getting, say, a gain on selling property plant equipment, which would be an investing activity, the tax effects show up as operating.
So the FASB requires that all cash taxes paid must be disclosed.
Again, so if you don't think that cash taxes should be part of operating, you can take them all out in your calculation.
Next I want to talk about this measure EBITDA, which is defined as earnings before interest, taxes, depreciation, and amortization.
EBITDA is often used by investors and analysts as a proxy for operating cash flow.
And because it excludes interest and taxes, it solves for that problem that we talked about on the last slide.
However, EBITDA does not do a good job of measuring cash flow if there are large changes in working capital, like accounts receivable or inventory, and in fact, it suffers from the same manipulation potential as net income.
So for example, let's think of a company that does channel stuffing.
Channel stuffing is a situation where at the end of a quarter, the company's trying to meet an earnings target, so they ship a bunch of product to customers in order to book the revenue, which would then increase earnings, and of course then increase EBITDA.
The customers haven't paid us yet.
Instead, accounts receivable will go up.
So, EBITDA would consider this channel stuffing as a cash flow, but it's not a cash flow.
Now, if we took EBITDA, and adjusted for this increase in accounts receivable, then we would have a good measure of cash flow.
And I'm gonna talk about this more in the next video.
Everyone knows that EBITDA is the best measure of cash.
>> Now, I feel pretty strongly that EBITDA is not a good measure of cash flow, because unless you adjust for these changes in working capital, then EBITDA is just as easy to manipulate as earnings is.
What we're gonna do in the next video is a case where we'll highlight some of these drawbacks of EBITDA.
And I'll show you when it's not a great measure of cash flow.
And then one more point on this, you often hear people talking about cash is king, implying that you should only look at cash from operations or EBITDA as a proxy from cash operations and not even look at earnings because it's too easy to manipulate.
Well, there's actually been a lot of academic research that's looked at this question of earnings versus cash flow.
And it finds that earnings are a better predictor of future cash flows than current cash flow from operations.
It's trying to answer the question, are you able to price your product or service high enough to cover all the costs of doing business?
But the good news is, you don't have to choose one or the other.
You get both earnings and cash glow from operations, and academic research it's very clear that if you put both measure in together, you get the best predictions of how a company's gonna do in the future in terms of its future cash flows.
>> I bet that accounting professors did the research to show that earnings is better than cash flow.
Is that really the case in the real world?
>> Yes, it was mostly accounting researchers that did this research, but is there anything wrong with that?
The data that they looked at, though, came from real companies, looking at long time series of data from 1962 to the present, and it's a very robust result that earnings are a better predictor of future cash flows than current cash flows.
But again, the research emphasizes the best prediction comes from including both measures together.
The last topic of this video is that I wanna briefly talk about free cash flow.
Now, this is more of a finance topic, where they use free cash flow a lot.
But since we've been talking about cash flows and these finance approaches generally pull cash flow numbers out of the financial statements, I wanted to briefly give you some cautions that you should have in dealing with free cash flows..
When people talk about free cash flow, they generally mean operating cash flow minus cash used for long-term investments.
There's valuation models out there that show if you forecast out a company's free cash flows, discount them back to present value, you'll get a measure of how much the company should be worth, what its stock price should be.
The problem is that if you look across these measures of free cash flow, there's often no standard measure for operating cash flow.
So I've got a number of accounting and finance textbooks lying around my office, and they all seem to define operating cash flows differently.
One book defines it as cash from operations before interest expense, so using the FASB number and adjusting for interest expense.
Another defines it as NOPLAT, which is net operating profits less adjusted taxed, which would be EBITDA minus cash tax on EBITDA, which is not a good measure of cash flow because it doesn't measure cash.
Without changes in working capital, you won't get a measure of cash.
The next one, NOPAT minus increases in working capital, is a better measure.
NOPAT is net income adding back interest expense, and then adjusting for changes in working capital to get closer to cash flow.
Another book called it net income adjusted for depreciation other non-tax, non-cash items minus an increase in working capital, which I guess would be okay as long as the depreciation was after tax, because net income is after tax.
Another said gross up earnings before interest and taxes and add depreciation, and a lot of them just say EBITDA without defining what it is.
On top of this, another problem you'll encounter is companies will often disclose free cash flows using their own custom definition.
And what you'll find is that definition often changes across companies or companies will change it across years.
So if you're using any kind of cash flow measure, the most important thing is to figure out how it's actually defined, because some of these measures are defined much better than others.
>> I believe a better approach than telling us everyone is wrong would be telling us what is correct.
I'm just saying some people are more correct than others.
I think there's two approaches that would give you a really good cash flow from operations number.
The first approach would be to take the cash from operations from the cash flow statement, which uses the FASB classification, and then subtract out cash paid for interest and cash paid for taxes, which are disclosed somewhere else in the report.
The second way would be to start with EBITDA, and then adjust for these changes in working capital, like receivables, inventories, and payables, using the balance sheet equation like we do under the indirect method.
In the next video, we'll look at a case which will better highlight some of these advantages and disadvantages of these different measures for cash operations.
What we're gonna do in the next video is look at a couple examples which will give us more practice on putting together cash flow statements under the indirect method.
It'll give us some practice on handling gains and losses on sale of property plant equipment in the cash flow statement, and it will allow us to continue our discussion of earnings, versus cash flow, versus EBITDA.
I'll see you then.
In this video, we're gonna end our week looking at cash flows with a look at the 3M company's cash flow statement.
We're gonna take a look at their actual statement, plus the supplemental disclosures about the statement in the footnotes, and the discussion of the cash flow statement in their management discussion analysis, or MDNA section.
Let's get started.
3M's statement of cash flows is on page 51 of their annual report.
The first thing I like to look at is this breakdown of operating, investing, and financing activities, to see what kind of stage or life cycle the company's in.
So 3M throws off about 5 billion of cash from operations every year.
It's pretty steady.
They have cash outflows from investing activities of about 2.6 billion every year.
And they also have net financing cash outflows of about 2 billion, other than a blip in 2011.
So this is sort of the classic, mature company profile.
They're still reinvesting a moderate amount back into the company, back into long term assets, and we'll look at this a little more in a second.
And, they are net cash out flows for financing, so they don't have to borrow.
They don't have to raise money to fund their operations or investments anymore.
Instead their operations are able to fund all of their investing activities, and still throw off some cash that they can use, to pay off debt or repurchase equity or pay dividends.
So just to get some more insight into this, one thing that's often good to look at is comparing depreciation to purchases of a property plant and equipment.
Again it's very rough, but, if you view depreciation as using up your fixed assets, capital expenditures, obviously, is acquiring new ones, it looks like 3M's at about replacement level.
So they are investing a lot in new PP&E, but it's sort of replacing the things that they're using up.
They do have, though, some active acquisitions, so about a billion or so until 2012.
So they bought about 5.4 billion of, 5.5 billion of marketable securities, but then they sold or had those almost all mature within 2012.
So I think what happens is 3M is throwing off a lot of cash, if they don't immediately have an acquisition in mind, or immediately have purchased the property planned equipment, they plow it into markup on securities on investments.
And then when those opportunities to make an acquisition or buy PP&E come, they liquidate the markup on securities and use that to go out and make their acquisitions.
So it's almost like they're serving as their own bank, by buying these marketable securities, holding their cash, getting some return, waiting until they can invest it.
And then in the financing section, we see a lot of the financing cash out flow is purchase of treasury stock, that's probably for stock options.
I think you're ready to do these kinds of life cycle or growth analysis on your own.
So here's what I want you to do, after the videos over, go on the internet, find a firm that you're interested in, take a look at their cash flow statement, and see what you can learn by looking at the company's operating, investing, and financing cash flows.
Now let's dig into the operating section a bit more.
Ignore the noncontrolling interest stuff for now, and just view it as net income.
Nice steady growth in that income, indicating that they are consistently able to price their products enough to cover the cost of running the business.
And, typical of a mature company, you have this steady profitability.
So, very mature, well performing, humming along nicely company.
One of the big discrepancies between net income and net cash in operations is depreciation amortization.
Now, remember that's not a source of cash, even though it looks like it here.
It's non cash, so we have to add it back to get from cash, to get to cash from operations.
Fairly big number for the 3M, because it does a lot of manufacturing, and manufacturing companies tend to have high depreciation amortization.
Then we have a number of other, non cash expenses.
So things like pensions, stock based compensation, deferred taxes, and excess tax benefits.
So first the pension and post retirement contribution, stock based compensation, these are things we recognize as expenses now, which means they're part of net income.
But the cash is either paid in the future, as is the case for pensions and post retirement benefits, or the cash really isn't paid as it is for compensation, although part of it is you're buying back treasury stock to use to satisfy options.
But any case, there's no cash flow this period for these expenses.
And we'll talk more about the stock based compensation later on.
The pensions of post retirements, that's beyond the scope of this course.
You'll have to come and take my course at Warton, my elective, to see more on pensions and post retirements.
These are the changes in working capital, and what we see is the big chunk here are accounts receivable and inventory are negative.
So let's think about what that means.
Negative number on the operating cash flow under the indirect method means that these amounts must be going up on the balance sheet.
Accounts receivable goes up as a non cash asset, to stay in balance we have to subtract it on a cash flow statement.
And yes, even though you can't see it, I am doing up and down arrows with my hand.
Inventories go up on the balance sheet, non cash asset going up, we have to subtract that on the cashflow statement.
Cashflow is also going up, now remember, that's a liability, so if accounts payable a liability increases, it's on the other side of the balance sheet equation, we have to increase it on the cash flow statement.
Bad news scenario would be our customers are not paying us, we're having trouble selling your inventory, we're having to stretch our payables.
So during the year, we're making a lot of credit sales at the end of the period.
We are getting more raw materials at the end of the year in anticipation of production.
And so based on other things I've seen, it probably is a good new scenario that this is representing growth and working capital, rather than, bad news where you can't collect receivables, and you can't get rid of your inventories.
Now, we're gonna look at some other sections to try to get some additional information about what's going on with cash flows.
And yes, while you're looking at those cash flow statements that you downloaded from the internet, you should also take a close look at the operating section.
Look at net income, look at cash operations, and look at all the things that cause differences between the two, to see what kind of items that you would have questions about, or wanna learn more about to understand why the company's net income is different from its cash flows.
So if you remember back to the first video that week I said that there has to be disclosure of cash, taxes paid, and cash interest payments.
So in this footnote we see, the cash taxes and the cash interest.
So if you wanna start with the cash from operations and the cash flow statement, in terms ofi doing some kind of valuation, to measure operating cash flow, but you don't want tax or interest in there, you can pull those numbers using this disclosure.
One last section to look at, related to cash flows, is in the management discussion and analysis which is on page 36.
Remember this is the, the MDNA is the section where 3M management is supposed to provide their own narrative to explain what happened during the year.
So it'll give us more insight into some of the numbers that we saw on the cash flow statement.
They repeat their operating section, and talk about what happened in terms of their cash flows during the year.
The big reason for the year on year in cash flows is net income went up.
They do note that accounts receivable, inventories and payables increased by 312 compared to increases of 484 last year.
But they really don't talk much about what happened with that.
Then at the bottom of the page, they disclose free cash flow.
And as I said a couple videos ago, this is a voluntary disclosure.
That means that there's no requirement by the SEC or the FASB to provide this measure, which also means there's no standardization.
Companies can define this measure, however they want, and, and when they do that, they have to alert investors and analysts that this is a non gap measure, so it's not standardized.
So, remember free cashflow is supposed to be operating cashflow minus investment in the future.
Investing in new property plan equipment which gives them a pretty high free cash flow.
And that's a pretty good definition.
I've seen a lot worse.
This is a pretty good definition of free cash flow.
But again, before you would use this number, you wanna make sure you know what's in the definition, and that you're comfortable with it.
On the next page, we have cash from investing activities.
And what they've done here is they've netted all the marketable securities action into a small number, so instead of showing on the face the 5 billion they bought, and then the almost 5 billion they sold, they just show a net number.
So it really highlights that the big drivers of cash outflows were purchases of PP&E and acquisitions.
And they tell you that PP&E is expanding manufacturing capacity in key growth markets, especially international like China, Turkey, and Poland.
And so we can see that they do still have growth opportunities, and a lot of those growth opportunities seem to be international.
For acquisitions they refer us to note two, you can go there and look I'm probably not going to jump ahead and look at that.
And then finally they talk about cash flows from financing activities.
So remember the big chunks here were proceeds from, I'm sorry, purchases of treasury stock, and the treasury stock they say is for stock based compensation.
Now we'll talk about this later in the course but, basically, stock based compensation is where you award your employees either stock options or stock grants.
So we're almost on 100 years of dividends, and actually again, just consistent with companies that are very mature products throwing off a lot of cash.
3M started pretty early.
And the thing about dividends is they tend to be sticky, once you start paying them, you always want to keep paying them if you ever cut them.
It would be viewed by the market as bad news.
So that's where we find all the cash flow information in the annual report.
And that's gonna wrap it up for our week on cash flow statements.
I know it was difficult, and there were some parts that didn't probably make a lot of sense right off the back.
In this video, we're gonna start our look at ratio analysis.
After all there's not a lot to computing ratios.
It's just dividing one number by another.
The real challenge is to try to understand what the ratios are telling us.
And to do so we need to reverse engineer the financial statements.
We need to think about what underlying transactions must have happened to make the finance statements and the ratios change in the way that they changed.
In this video, we'll talk about some tips for using and misusing ratios.
And we'll also talk about something called the DuPont analysis which is a common ratio analysis technique for understanding changes in one of the most common ratios people look at, return on equity.
Let's get started.
Let's start by talking about how to use ratios.
So ratios are gonna be useful in assessing profitability liquidity and risk.
You're gonna highlight sources of competitive advantage for the company so where the company is doing really well.
But to do this we have to compare the ratios to a benchmark.
There's no absolute benchmark, there's nothing like return on equity greater than 16% is great, below 16% is bad.
Instead you have to compare the company to the same company across time.
We call this a time-series analysis and it helps highlight trends for the firm, and we also have to compare the firm to other firms in the industry doing what we call a cross-sectional analysis.
This is important because sometimes firm trends could really be driven by trends in the economy or the industry.
So to figure out whether it's the company that's doing something well or it's just an industry wide phenomenon, we have to look at the firm compared to its industry or its competitors.
The key is to try to figure out what activity drive the ratio to change and then decide whether that activity is good news or bad news for the company.
And let's talk about a number of examples of this as we go through the videos.
And finally, the key is that ratio analysis does not provide answers but instead it's gonna help you ask much better questions.
She is a long-short hedge fund guru in Hong Kong.
But I have looked at a lot of financial statements in my time, and I'm pretty confident in my claim that ratios provide an excellent diagnostic tool to help you figure out what areas of the finance statements you need to look into further.
But they rarely ever provide you all the answers.
Now, let's talk about how to misuse ratios.
Not that I recommend that, I just recommend avoiding this problem.
So one of the ways that people often misuse ratios is they don't realize standard ratios actually can have multiple definitions.
Different sources will use different definitions.
You wanna always make sure you're using the same definition across time and across companies to make valid comparisons.
Also, choosing the appropriate benchmark for comparison is important.
Any major changes in a firm can distort a time-series analysis.
Differences in business strategy, capital structure or business segments can make it hard to do a cross-sectional analysis.
And then any differences in accounting methods, either across time or across companies can make the comparisons difficult as well.
So for major changes in the firm, imagine a software company goes out and acquires a hardware company so that they can integrate their software into the hardware.
The problem is that this would make it a fundamentally different company.
It would change the amount of manufacturing capacity and the amount of inventory.
All they would tell you is that the company's a different firm if you look over time.
I'll talk about differences in business strategy and example later in the video.
As far as differences in accounting method, one of the ones we talked about earlier in the course was some companies have brand names on their balance sheet.
The final thing to keep in mind is that ratios can be manipulated by managerial action.
So the companies managers think that investors and analysts are all focused on the same one ratio like let's say, an interest coverage ratio.
Then those managers have incentives to manipulate their accounting numbers to make that ratio look good.
So always keep in mind that manipulation is a possibility and more importantly don't just focus on one ratio.
But look at the whole body of ratios because it's hard, in fact impossible to manipulate every single ratio to make it look good.
So is a net income of $10 million good or bad?
>> Yeah, if you were running a lemonade stand where your only assets were a table, a pitcher, some glasses, a bunch of lemonade and maybe a cool Letterman's jacket, then 10 million in net income would be pretty sweet.
But if you were running a company with billions and billions of dollars of assets, $10 million would be pretty meager for net income.
So to assess whether $10 million of net income is good or bad we need to know how much investment was required to get that level of net income.
So to assess to whether a net income is good or bad it depends on the level of investment required to get that net income and that's what return on equity is going to tell us.
Return on equity is defined as net income divided by average shareholders' equity.
The numerator represents how much return the company generated for its shareholders during the year based on accrual accounting.
So that's the net income number that we've generated through the course.
The denominator represents the shareholders' investment in the company.
Now one of the problems we run into is net income happens over a period of time whereas stockholder's equity is at a point of time.
So we have to take an average of the beginning and ending balances of shareholder equity to approximate it's level during the period we were generating net income.
This ROE measure measures a return on investment and if something should increase with the risk of the company.
For example, I could take a dollar and put it in a savings account with a bank, and I'd get roughly one cent of interest.
If I'm gonna take that same dollar and invest it in a company, I'm taking much more risk and so I should get much higher return.
I should get an ROE much higher than 1%.
So ROE is a great starting point because you compare across all of your investments.
And hopefully the ROE is high enough to compensate you for the risk you are taking investing in the company.
To figure out whether a company is getting high or low ROE due to operating performance or due to leverage.
So the first driver for ROE is operating performance, which answers the question of how effectively do managers use the company's resources, in other words, their assets, to generate profits.
The ratio that we look at here is return on assets, or ROA.
ROA is defined as net income divided by average assets.
So it tells you is for each dollar of assets the manager has to play with, how much net income do they generate.
The second driver is financial leverage.
This answers the question, how much do the managers use debt to increase available assets for a given level of shareholder investment?
Financial leverage is defined as the average total assets divided by average stockholder's equity.
So for each dollar of stockholder's equity, how much assets does the company have?
Now the only way that this can be greater than one is if the company also borrows money, takes on liabilities.
So this is a measure of leverage in terms of it measures how much debt the company is taking on to buy more assets than it has in terms of dollars of equity.
One note is that this leverage ratio is very different from the other leverage ratios that we're gonna be talking about this week.
It's gonna work for what we're doing with ROE, but we're gonna use other ratios when we want to measure other kinds of risks due to leverage.
Moreover, she said debt-to-equity is a better leverage ratio than your Financial Leverage.
For now I wanna keep it simple so that you can see the two drivers of ROE.
And yes, there are better measures of leverage for assessing things like bankruptcy risk and long term liquidity, and we'll also get to those later.
But the financial leverage measure that we're looking at here is the right measure if we want to see how much of ROE, a return of equity, is driven by the company going out and borrowing money.
And so you see in the equation, we have ROE equals net income over assets times assets over equity.
Let me do a quick example.
So a company raises $100 from shareholders, borrows $100 from a bank to buy $200 of assets.
Those assets are then used to generate $10 of net income.
So ROE in this case would be 10%, $10 of net income divided by $100 from shareholders, ROA would be 5%, $10 of net income divided by 200 of assets, and leverage would be 2.
Multiplying it together, 5% ROA times a leverage of 2 gives you an ROE of 10%.
And this highlights how these two components drive ROE.
Now our leverage is 4.
Or, let's say that we keep leverage at 2 but we find a way to operate the business more efficiently to get the performance or the ROA up to 10%.
So, either operating performance or leverage can get you to a high ROE.
>> Really sorry to flamboozle you, but I was trying to keep it simple.
I was trying to do an example which clearly shows how these two factors, ROA and financial leverage, combine to drive ROE.
How much profit does the company earn on each dollar of sales?
The ratio we're gonna use here is Return on Sales or ROS, which is defined as Net Income divided by Sales.
So what it's telling you is for each dollar of sales how much net income do you generate.
This answers the question, how much sales does the company generate based on its available resources?
The ratio here is called asset turnover, which is defined as sales divided by average total assets.
So, for each dollar of assets, how much in sales does the company generate?
Now, I'm gonna go through an example of how to do this in a little bit, but first I have to deal with that complication that came up in the question earlier.
So, ideally return on assets would measure operating performance independent of the company's financing decisions.
We want a measure of ROA that's not at all affected by financial leverage.
The problem is the numerator of ROA, net income, includes interest expense.
If you have more leverage it means you have more debt, more debt means higher interest expense, higher interest expense means lower net income, and so now your leverage is affecting your net income.
So to remove the financing effects from ROA, we have to de-lever net income.
So we're gonna define ROA as de-levered net income divided by average assets.
So what we're doing is taking after tax interest expense and adding it back to net income.
Then when we use this de-levered net income as the numerator in ROA, we get a measure of operating performance that's not contaminated by the company's financing decisions.
And it would not hurt to explain what de-lever means.
Here's a quick example to show why we need to de-lever net income to remove the affects of financing decisions.
Let's say we have two companies, one that has no debt and one that has some debt.
Both companies have the same pretax, pre-interest income, so their performance seems identical in an operating sense.
Then the no debt company obviously has no interest expense, so their pretax income is 300, we take off taxes at 35%, and their net income is 195.
For the company that has some debt, they have interest expense.
So if they had 50 of interest expense, their pre-tax income would only be 250.
We take off taxes and their net income is only 162.5.
So if we use net income in the numerator for ROA, then ROA is gonna be affected by the fact that the some debt firm has some borrowing.
For the some debt firm we take net income plus interest expense times 1 minus the tax rate and we end up with de-levered net income of 195 which is identical to the de-levered net income of the no debt firm.
So using de-levered net income in ROA gives us a measure of ROA that only measures operating performance.
So we take the financing out of ROA but we leave the financing in for ROE.
Now I'm gonna try to tie all of this together with something called the DuPont Ratio Analysis Framework.
But yes, this formula was developed by people that worked for the DuPont Chemical Company back in the 19th century.
In 1914, DuPont bought a big stake in this startup company called General Motors which eventually became the largest car company in the world.
And when the DuPont management team started working for General Motors, they would use this formula a lot so much so that the GM people would say hey, give me the DuPont formula analysis.
And that's where the formula got the name, and we've continued to use it since then.
And what this allows us to do is identify whether a company is advantaged or disadvantaged in their ROE is driven by their profitability, by their efficiency or by their leverage.
>> Yes, now I'm gonna do an extended example of how to use the DuPont formula, which will also allow me to show you the importance of choosing firms that are using the same business strategy when you wanna do a ratio analysis comparison.
There's a couple big segments within the retail industry.
So those are the stores that have mart in their name and try to compete on low prices.
And another segment are the high-end retailers, the ones that are located in the really expensive shopping districts.
So their strategy is very low profitability.
They have a small markup over cost and their strategy is to get you into the store with their low prices.
So how do they get high ROE?
By very high asset turnover.
In other words they generate a huge amount of sales for their investment in assets.
How do they do that?
Well their assets are things like fairly simple stores that are not constructed from fancy materials.
They're located in rural districts where the land is pretty inexpensive.
And then when you go in to the store, you don't see a lot of fancy schmancy displays, the merchandise is sort of crammed in there and they're really set up to try to maximize the volume of sales for their level of investment and assets.
So if you're looking at discount type store, you'd wanna compare it to another company doing a discount strategy to see if the company is able to get a little bit extra profitability even though it's low in absolute terms.
Or if they're able to get much higher asset turnover, either one of those would give them an ROE advantage over their competitor.
Their constructed out of expensive materials, marbles, woods, they're located in very expensive real estate areas.
Their asset turnover, the amount of sales they generate for their investment in assets is fairly low.
But when they make a sale it's hugely profitable.
They have very high markup over cost, so if you were looking at a high-end retailer, you'd want to compare it to another high-end retailer to see if they're able to squeeze out even higher markups or if they're able to squeeze out a little bit asset turnover even though it's lower in absolute terms.
And as long as you're comparing companies that are doing the same strategy, find out where a company's competitive advantages or disadvantages lie in trying to execute their business model.
Now that we have the basic framework down, what we're gonna do in the next couple of videos is look at a case study of a company that had some real troubles in their business.
But then they changed their strategy had a nice turn around and now they're performing very well.
So we'll use the DuPont analysis to figure out exactly what parts of their strategy really helped to kick start their turn around.
I'll see you next time.
This video kicks off a three video sequence where we're gonna use ratio analysis to study the case of a growth company and see what we can learn about the sources of their competitive advantages and disadvantages.
In 2009, Plainview lost its largest customer, a defense contractor.
The customer transferred it's business to a foreign competitor which had lower labor costs.
They also built new plants in California and South Carolina to be closer to their customers.
In 2010, Plainview adopted new 6G technology, which provides better manufacturing results at a lower manufacturing cost.
The company's experienced explosive growth after surviving its crisis, and is now picked up a greater following by analysts and investors.
Before we take a look at the ratios, I always think it's a good idea to start with the financial statements.
Then we can keep those in the back of our mind as we go through the ratios.
So here's the asset side of the balance sheet for Plainview.
I'm gonna put up the pause sign, and recommend that you pause the video.
Take a minute or so to look over the balance sheet and see if there's anything that jumps out at you.
And then resume the video and we'll talk about what you're seeing.
My point is that the balance sheet is a good starting point to try to look at what's going on in the company.
Eric noted that there were big increases in accounts and inventory.
But you're right that if the company's growing so much as a whole, it's hard to interpret the balance sheet.
And so later on, we'll look at techniques that will take out the effects of this growth, and let us know whether line items on the balance sheet are going faster or slower than other line items.
Here is the liabilities and stockholders' equity side of the balance sheet.
So please, again, pause the video, take a look and see what you find.
But current liabilities are actually down in 2011.
That it's hard to draw too many conclusions from this part of the balance sheet without taking out the effects of growth.
But there are a few things that sort of leap out as we look through this.
So there are some things that you can occasionally learn by looking at the balance sheet as a starting point.
Here are the last three years of income for Plainview.
>> And yes, we will have to remove the effects of growth to understand this better, which we'll do later in the video.
Even though net income has been growing steadily, cash from operations is, for lack of a better term, quite squirrelly.
Now I think we are getting somewhere.
And it looks like a lot of it is driven by accounts receivable and inventory, which we saw big movements on, on the balance sheet.
Here are the investing and financing sections of the statement of cash flows along with the supplemental disclosures of cash interest paid and cash taxes paid.
>> Although at capital expenditures, proceeds from borrowing and common stock issued mirror the growth in PP&E, debt and equity on the balance sheet.
>> Yes, this part of this statements shows us the company's growing substantially through capital expenditures.
We don't see any acquisitions listed here so it's all internal cap x, which makes since because from the case we know that they built two new factories.
And they're financing this growth with both debt and equity, so we see a lot of cash flow from debt issuances, and we see some cash flow from a couple of equity issuances, so they're financing themselves with both debt and equity.
Now that we've taken a look at all the financial statements, I want to talk about something called common size financial statements.
As we've talked about, it's hard to spot trends in the financial statements when there's tremendous growth.
Basically, the growth in assets and growth in sales drive trends in all of the other line items.
What we really want to know is, are certain line items growing more or less than would be expected given the overall growth in assets or sales?
So we're gonna come up with a common size balance sheet where we'll express all numbers as a percent of total assets, which will remove the effect of the growth of assets.
We'll come up with a common size income statement, where we'll express all numbers as a percent of sales, thereby taking out the growth in sales.
The cash flow statement is typically not common sized.
And it's not clear what we would divide by to common size it.
So it's only the balance sheet and the income statement that are typically common sized.
It is inventory whose growth is out of whack compared to the rest of the company.
So again, pause, take a look and see what you see.
The biggest trend is the increase in liabilities relative to equity.
>> Yes, Eric, the big conclusion we would draw here is that the numbers seem to be squirrely on the liability and stockholders equity side.
The numbers are bouncing up and down.
The only trend that really emerges is total equity has gone down as a percent of liabilities and stockholders' equity over time.
Which means the company is relying more on debt financing and other liabilities and less on equity financing.
We're dividing numbers by sales and any time you divide one number by another number it's a ratio.
And then it's broken down into all of it's components with the definitions at the bottom of the slide.
Why don't you pause the video for a minute or two, take a look at this slide and see what kind of conclusions you draw.
For return on equity we see a large and increasing trend in ROE over the three year period.
It started at 11%, which meant that for every dollar of equity the company generated $0.11 of net income.
And now it's 16% so for every dollar of equity the company generates $0.16 of net income.
So each of dollar of equity is generating an extra nickel of net income which is a pretty big increase over a three year period.
Now let's look at the two drivers of ROE, return on assets and financial leverage to see if Plainview's increase in ROE is due to better operating performance or to taking on more debt.
So for return on assets we see that increase from 7% to almost 10% which means that every dollar in assets is now generating about $0.10 of net income for Plainview compared to only $0.07 a couple years ago.
If we look at financial leverage, it's been fairly flat over this period, around 2.3.
So it seems like the increase in ROE is primarily driven by the improvement in return on assets.
We see another increasing trend in return on sales which means that Plainview sales have become more profitable over this period.
ROS has gone from 5% to almost 7% so each dollar sales now generates almost $0.07 of net income instead of $0.05.
Well if you multiply it times 100 million in sales, it adds up pretty quickly.
Now if we look at asset turnover, it briefly went up but then came back down to around 1.45, which means that for every dollar of assets Plainview generates about $1.45 in sales.
But there's no clear upward trend in asset turnover, so it looks like the sole secret to Plainview success with their ROE is that there sales have become more profitable over this period.
So if you remember from last video, the return in return on equity is net income, but the return in return on assets is delivered net income.
To get it to multiply together cleanly you'd have to add a third factor, or a correction factor, which would be net income divided by after-tax net income.
If you multiply that third factor times ROA and financial leverage, then you will get ROE.
Maybe every company in the industry had better profitability as a result of the new technology.
>> Excellent point Elizabeth, what we talked about in an earlier video is that we need to do cross sectional comparisons.
So what I'll do next is compare Plainview to three of their closest competitors.
If you look at the industry, it looks like Plainview is having much more success than their other three competitors.
They're the only company that had an increase in ROE over this time period.
So to wrap up what we learned from the DuPont analysis is that the big increases in ROE for Plainview were unique for the industry.
Plainview's improved ROA was the source of it's increase in ROE.
Instead, the ultimate source of the ROE increase was improvement in profit margin or return on sales.
In contrast to the competitors, Plainviews' return on sales grew dramatically over this period, whereas his asset turnover was flat much like the competitor's.
So the secret to Plainview's success is that their sales became much more profitable between 2009 and 2011.
Can ratio analysis tell us that?
>> Well, I do have a few more ratios up my sleeve, and we can take a look at those in the next video.
And I'll see you next video, when we continue the ratio analysis for Plainview Technology.
In this video, we're gonna continue our ratio analysis of Plainview Technology.
We've got a lot of ratios to get through, so let's get started.
Let's start by bringing back up the DuPont ratio analysis slide.
I've added a couple boxes to what we had last time.
We're gonna start by looking at the Profit Margin Ratios to try to figure out what are the drivers of Plainview's profitability.
We're gonna look at Gross Margin, which is Sales minus Cost of Goods Sold, divided by Sales.
We'll look at selling general and administrative expenses to sales, so SG&A expense to sales, to get a sense for how much operating expenses are as a percent of sales.
But these are the ratios from the Common Size we looked at before.
We need to look at them again, because to understand drivers of return on sales.
We need to divide the various items on the income statement by sales as well.
I have repeated all of the definitions at the bottom.
>> Maybe the shifts to customize products and to customers in new industries allow Plainview to charge a higher price.
>> And it would certainly help that one large customer does not have monopsony power over Plainview.
Ironically, Plainview is probably afraid to charge the Defense Contractor a high price for fear of losing the business.
It is the shift to automation and the new technology that allowed Plainview to reduce its manufacturing costs, leading to a larger gross profit.
It could be that Plainview's able to charge a higher price for roughly the same cost, and maybe that's by moving into new industries or providing the customized products, or by getting rid of the monopsony relationship.
So maybe it's the automation that's doing that, or it's the new technologies.
We're gonna have to look at a lot more ratios to try to get more evidence on which of these theories is correct.
Let's look at the rest of the ratios.
The ratio of selling general administrative expenses to sales is completely flat over the period.
So as Plainview has grown substantially, it's managed to keep its SG&A expenses in line and not have them grow faster than sales as a whole.
Then if we look at Interest Expense and Effective Tax Rate, there's not much going on.
Interest Expense is pretty flat, and other than a blip a couple years ago, Effective Tax Rate hasn't changed that much either.
If there were economies of scale we might expect the SG&A ratio to go down.
Usually when we look at a ratio and see that not much has changed, we assume that not much has changed.
But it could be the fact that Plainview should have gotten some economies of scale.
So our Profit Margin Analysis tells us that gross margin was the big driver of Plainview's success.
Now we have to think about what are some possible explanations for this improvement in gross margin?
Was Plainview able to reduce production costs while maintaining sales price?
So we have the question, did the entry into new markets, the customized products, allow a higher markup?
Or maybe it's a combination of both.
So, at this point we're gonna have search for confirming or a disconfirming evidence of these explanations elsewhere in the financial statements and the ratios.
And of course, if we were the analyst on the call, we could actually ask management very specific questions about what the source of their improvement in gross margin was.
Can't the ratios tell us more?
I still don't know the answer to how they made their sales more profitable.
Remember, ratios allow us to ask better questions, not necessarily give us the answers.
One place to look for further information on how Plainview's doing, is to do a detailed Asset Turnover Analysis.
Although Plainview's Asset Turnover ratio was steady over the period, looking at the detailed components of the ratio may give us more insight into what happened with Plainview's turn-around.
For example, when there's dramatic increases in sales, like Plainview had, you often see lower inventory levels.
And higher Accounts Receivable levels because the company has to extend credit to riskier customers to fuel its sales growth.
And if you remember on the statements we saw all this weird stuff going on with Accounts Receivable and inventory over the period.
For example, Inventory Turnover of 8 would meant that it builds and sells Inventory 8 times during the year on average.
Purchases, we're trying to get out the purchase of new raw materials, so we calculate that as the difference between ending and beginning inventory, plus COGS.
And then Fixed Asset Turnover is Sales divided by Average Property, Plant and Equipment.
I'm gonna put up the pause sign so you can take a look and see what these ratios are telling you.
Could we think about it that way?
>> Yeah, I've never found these turnover ratios that intuitive either, so I'm gonna recast them in a way that is more intuitive to me, and hopefully will be more intuitive to you a s well.
These ratios will help answer the question, how many days on average are given accounts outstanding?
For example, if you saw a Days Inventory of 45, it means that it takes 45 days on average from the time we start building the Inventory until we sell it.
So the Days Receivable Outstanding Ratio, or Days Sales Outstanding Ratio, which is often called DSO, so if you've heard the term DSO, it's referring to this ratio.
And in fact, that's how the Days Inventory and Days Payable Ratios work as well.
But, by putting these ratios in days, we can come up with a new ratio called the Net Trade Cycle.
The Net Trade Cycle represents the gap between cash outflows, which are the Days Payable, and cash inflows, which come from the Days Receivable that we need to bridge with short-term financing.
So why don't you pause the video, and take a look at them.
So Days Receivable for Plainview has gone down from 60 to 44 over this period.
Now the 44 means that from the time Plainview makes the sale, it's 44 days until they collect the cash.
But instead, we wanna figure out what activity drove the change in the ratio, and is that activity good news or bad news.
For example, this could be good news if Plainview put in new collection efforts, and as a result they get paid more quickly.
And as a result, having been giving up a lot of sales growth and profitability.
>> Clearly, it is the loss of the Defense Contractor that allowed Plainview to collect more quickly.
After the financial crisis ended, customers had better financial health and were better able to pay on time.
Elizabeth suggested it was losing the Defense Contractor that allowed us to collect more quickly.
And certainly, if one big customer has power over us and refuses to pay more quickly, it's gonna hurt our Days Receivable.
Once that customer leaves and we can choose other customers, we can choose customers that pay more quickly.
Dave suggested it's the economy as a whole.
And as we can see, that's not the case.
So, the most likely theory is that it's the fact that we got rid of the Defense Contractor, and moved into the new industries with new customers that's now allowing us to collect 16 days more quickly.
Next, let's look at Days Inventory.
Days Inventory has increased from 81 days to 105 days.
Which means from the first point that Plainview gets raw materials, it's a 105 days before the finished inventory leaves the warehouse to go to the customers.
Well, I guess it depends on what it reflects.
But that's probably not the case for Plainview, given their growth in sales.
It could be good news if they're ramping up their inventory production in advance of future sales.
It takes longer to produce inventory when it is made in customized, small batches.
Plainview can charge more for a product because it is customized and takes longer to produce.
>> But, it is peculiar that Plainview holds inventory longer when its sales are growing so much.
But as long as you're getting paid for that, you should see the Gross Margin increase, which is what we see with Plainview.
Elizabeth raises an excellent point, that it's strange to see Days Inventory go up, when sales growth is also going up quite a bit.
So maybe Plainview sales are not at a level that can support the two new factories to run around the clock, but we wanna run them at capacity.
So, maybe Plainview's over-producing a little bit of inventory now in anticipation of future sales.
Now let's look at the Days Payable ratio.
What could explain that?
Hey, this is fun.
So maybe it is a simple matter that if you collect cash more quickly, you can pay your suppliers more quickly.
And if you take advantage of discounts, your raw materials cost less, which means your cost of it sold is lower and your gross margin is higher.
The Net Trade Cycle is basically a measure of the number of days that you have to borrow from a bank to meet a short-term cash shortfall.
So that's basically the number of days from when you first get raw materials, to when you make the sale and then collect the cash.
So in Plainview's case, it's 105 days inventory, 44 days receivable, 149 days from when you get the raw materials to when you collect cash.
Then we subtract the Days Payable, which is the number of days that you have until you have to pay cash to your supplier.
So, 149 minus 33 creates a gap of 116 days.
That 116 days is the number of days Plainview has to go to a bank to borrow money.
And note that Plainview is borrowing 30 days more now, than they were a few years ago.
Why would Plainview pay it's suppliers more quickly when it would have to turn around and borrow more money from the bank?
>> Yeah, the only way this would make sense for Plainview, is if the discounts that they get by paying their suppliers earlier are greater than the extra interest that they pay from borrowing from the bank longer.
And that's probably the case for Plainview.
We saw earlier that their interest expense as a percent of sales has been fairly flat over time.
So, all in all this seems to be a good thing for Plainview, where by taking advantage of the discounts, they're able to reduce their costs and increase their gross margin.
It seems that for Plainview, the entry into new markets has produced higher-margin sales with faster collections.
How are they able to do this with 40% in higher sales growth?
And why is their cash flow from operations so volatile?
So at this point, we have a pretty good idea of what's going on with Plainview, but it's only a pretty good idea.
We don't know specifics, but we're at a point now where the ratio analysis will allow us to ask much better, much more specific questions to try to get to the bottom of what's going on with the company.
No, I'm not gonna tell you what happened, because if this was real life, you would do the ratio analysis without knowing what was gonna happen in the company's future.
It's about using a systematic approach to looking at ratios to try to figure out what may be working or not working for the company.
But, also to generate a good set of questions that you would then follow-up and do more research, or try to contact the company to find out the answers.
So I'm gonna leave you hanging and not tell you what ended up happening to Plainview.
So we just have one more video to do on Plainview Technology.
I'll see you then.
And then we'll apply those ratios to the plain view technology case.
First we have a number of ratios that are gonna tell us whether we have enough assets that are gonna turn into cash to cover our liabilities in the next period.
And, the third bucket is gonna be the long-term liquidity ratios.
Is there a potential risk of bankruptcy down the road that may cause equity investors to lose their investment?
Those are all the questions that this set of ratios will get at.
So go into that first bucket of short-term liquidity ratios, we're trying to answer the question, does the company have enough cash coming in to cover its obligations to pay out cash in the near term?
Ideally, all the ratios that we look at would be over 1, which means there's more cash coming in than cash we have to pay out.
But again you'd have to benchmark this with the industry, the firm across time cuz for some industries these are not greater than 1.
And basically what this is trying to get at is if current assets are going to turn into cash in the next year, current liabilities have to be paid in cash in the next year.
Do we have enough assets turning to cash to cover the liabilities that we have to meet in cash?
One drawback to this ratio is, as we know, not all current assets turn into cash.
One more ratio is cash flow from operations to current liabilities, so we divide the cash operations by average current liabilities.
It's saying, over the past year did you have enough cash generated from operations to cover your average level of current liabilities?
So here's what the ratios look like for Plainview.
Starting with the current ratio, it looks very healthy.
It's trended upwards from 2.4 to 3.6.
The 3.6 means that Plainview has three and a half times as much current assets as it does current liabilities.
Now as we talked about, a problem with this measure is that inventory and prepaids are not necessarily gonna turn into cash.
So we have the quick ratio, which is cash + accounts receivable over current liabilities.
That also looks good.
When we look at the cash flow to current liabilities ratio, it's not quite as strong.
We see the volatility in cash flow that we've seen earlier in r ratio analysis.
They seem to have enough cash that's gonna come in to cover the payments they need to make out.
Here the question is, does the company have enough cash coming in from operations to cover its interest obligations?
The first ratio is the interest coverage ratio, which is operating income before depreciation / interest expense.
So, this is a picture of interest coverage from an accrual accounting perspective.
And then we ignore depreciation since that's not ever gonna be a cash flow, is that operating income enough to cover what we have in interest expense?
So cash interest coverage is cash from operations + cash interest paid + cash taxes.
What we're doing there is those are subtracted from cash from operations, but we wanna add them back to get pure cash from operating the business.
So the question is, is that cash from operating the business enough to cover the cash interest paid?
I will put up the pause sign, and you can take a look.
Okay, I guess I have been going on too long about ratio analysis, and I do realize you've got an exam to do.
So just give me a few more minutes, and I'll wrap this up.
Okay, so let me go through the interest coverage ratios.
The interest coverage ratio looks really strong.
There's an upward trend, and now it's 6.9, which means that Plainview's operating income before depreciation is almost seven times as much as its interest expense.
When we look at the cash interest coverage, it also looks strong, except for that one year where there was the negative cash from operations.
But the current ratio's 3.8, which means that Plainview's operations is generating 3.8 times as much cash as they need to cover their cash interest cost.
So, it looks like, in general, Plainview's in a good position in terms of generating cash to cover its interest obligations.
These ratios are gonna tell us something about how the company's financing its growth, as well as provide a measure of bankruptcy risk.
The idea is the higher the company's leverage, the bigger the risk that it may have to default on its debt payments.
First ratio is debt to equity, which is just total liability over shareholders' equity.
So for each dollar of investment by shareholders, how many dollars of liabilities has the company taken on?
The next ratio specifically looks at long-term borrowing.
So it's long-term-debt to equity, total long-term debt / total shareholders' equity.
And this is getting at how the company is financing its long-term growth.
So essentially we're trying to get a measure of things like property plant equipment, accounts receivable inventory.
In other words, you can borrow the money with those assets as collateral, whereas intangible assets are harder to collateralize.
So it's the borrowing capacity that the company has based on its collateralizable assets, if collateralizable is a word.
Let me go ahead and put up the pause sign, and you can take a look.
Let's take a look at these long term debt ratios for Plainview.
In this case, lower ratios are generally better than higher ratios because they would indicate less risk, more borrowing capacity to fund growth.
But it's still only 1.05, which means that for every dollar of equity investment, Plainview has about a dollar in liabilities, which is a fairly low leverage ratio.
If we look specifically at long-term-debt to equity, we see that this went up for little bit, probably as they were expanding and building the new factories, and then has come back down and is less than 1.
Similarly for long-term debt to tangible assets, the ratio went up a little bit, came back down.
These are still pretty low ratios indicating that Plainview has a lot of debt capacity that they could use to borrow more money to fund further growth.
So the conclusion for Plainview from the liquidity ratios is that they're in a strong short-term cash position.
They've managed their long-term leverage well through their expansion and growth.
There's been some small increases in debt to equity and long-term debt to tangible asset ratios, but they're still not that big.
We have looked at all of the major ratios that people tend to use.
I'll see you next time.
So, here we are at 3M's financial statements.
So, there's a couple of ways we could do the ratios.
A second way we could do it is try to look the ratios up on the internet.
Before we jump on the Internet to pull some ratios, a quick warning.
There's a lot of bad stuff on the Internet.
Hopefully you aren't thinking that this course is one of those bad things, but the problem with ratios provided on the Internet is, oftentimes the provider does not give you the definitions.
You don't know how they're calculating the ratios.
So one of the best sources on the web that I found to get ratios is Morningstar, because they give you a long time series of ratios that you can use.
So if we look at 3M Company's page there's some summary financial information and then key ratios.
You notice it's sort of been going down the last few years slightly.
It's the profitability.
And you can see the profitability up and then sort of down again.
Which is tracking what we saw with ROA.
But what we really need is to find three or four of 3M's closest competitors, and then compare these ratios to the competitors, to see whether these trends are specific to 3M or whether there's some kind of industry of fact that's going on.
But, based on my knowledge of the industry, these are still pretty healthy ROE and ROA numbers.
And then above, we have the profit margin breakdown, so we have gross margin, which is really high, almost 50%, SGNA to sales, which has been fairly flat, and operating margin.
Then there's the tab for some growth percentages.
3M is in really good shape, current ratio above two, quick ratio above 1.3, 1.4.
Financial leverage, which we saw earlier, and then a more traditional debt to equity ratio.
Looks like 3M is not a very risky company, not very highly levered.
So we can see there's a slight downward trend in 3M's days sales outstanding.
Their inventory turnover's been sorta steady between 75, 85 days and their payables ratio's similar.
What they call cash conversion cycle is what I was calling the net trade cycle.
So it's basically the number of days you'd have to borrow from a bank.
And then one more thing to show you is Morningstar has an extensive glossary, so if you don't know what any of these terms are, like one ratio we didn't talk about is Return on Invested Capital, that's net income divided by stockholders' equity plus long-term debt and capital leases, short-term debt, capital leases.
So basically, it's like ROE except it also adds debt into the denominator.
So, you could just pull the ratios from a source like this, pull them from three or four competitors and then do the comparisons, you don't have to use your own calculator or spreadsheet to calculate all these ratios.
Now it's time for you to focus on the exam.
And, I'm here to talk to you about marketing.
So this, this segment is Marketing 101, the basics, the principles of marketing.
And my focus is going to be on building strong brands because of course the essence of marketing is to have a very strong brand.
Which is what is marketing?
So what's a market?
But what you need for marketing to exist or for a market to exist is to have an exchange.
And what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's let's look at the basic exchange.
You have one buyer and one seller.
and the real markets are somewhere in the middle.
But you'll see when I start defining this, that it's very useful to use this, this kind of simplification.
So if we think of an exchange between buyers and sellers.
On one extreme we could have what's called a seller's market.
And in the seller's market what that means is the seller has a product, and if you want that product, you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think about it, is marketing should not be the same in the seller's market as in the buyer's market.
So, in the seller's market, what marketing tends to be is what we call product focus market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability.
You should innovate in that product, you should try to reduce cost and you should really focus on the product.
Your business objective in a product-focused market is to sell as much as you can, and profitability from a product-focused market is going to come from volume.
Selling as much as you can.
In the past when we've studied product focus market, we've shown that profitability is tied to market share.
And why does market share increase profitability?
Because the bigger your market share, the more your revenues.
And the bigger your market share, and your volume, the lower the product cost and hint profitability.
Higher revenues, lower cost, more profit.
That's really the goal of a product focused market and when you're product focused, where do you get growth?
Will you develop new products based on your product experience or you go to new markets?
So what's customer focused marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
Well, what's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So where is in product-focused market, I'm the expert, and I create the very best product I can based on my expertise.
In a customer-based market, what I'm going to do is look at what the customer wants, and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside-out, this product focus, and outside-in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer.
What does the customer want?
Well, the first question is which customer?
You can't give every customer what they want, and we know customers are going to want all different things, so the reason why a buyer's market or customer focused marketing is so different than product focus, is that every customer out there, wants something different.
If we try to give everybody what they want, we'll go out of business.
That's too hard to do.
So the intuition of customer focus marketing, is to pick and choose customers.
Deliver value to some customers.
Say yes to some customers and no to other customers.
That's the process of segmentation and they call that, I'm going to talk about that in the next section.
Understand that in a product focused marketing, what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In the customer focused market, we're saying no to some customers and yes to others.
So, how do we make that profitable?
And, the answer is you pick and choose the customers you want to deliver.
How can, how can value-based marketing be profitable?
Then the profitability comes in not from reduced cost, which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want, I'll be willing to pay a higher price for it.
So that's one way.
The other way, customer based marketing is profitable is by giving the customer what they want time after time after time.
I don't think about just one transaction, I think about building customer loyalty.
And, delivering value to that customer over time.
Rather than market share, while I try to get a little bit from everybody, the idea of customer share, or share of wallet is that I go after a more narrow market and try to get more from each of that, their, those customer's wallets.
And it turns out that loyalty is very, can, if you do it right can be very profitable.
Because it's the cost of delivering value to the customer.
When I'm doing a customer based marketing it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but its cheaper to retain those customers over time, and that's where the profitability comes from.
It comes from loyalty.
The other thing, if you're thinking about building share of wallet in the customer-focused market, is that I not only sell one product to you.
If you've ever gone into a GAP or some jeans store, and, and you go to the cash register and you buy a pair of jeans.
The, the cashier or that person behind the counter might say: Oh these are very nice jeans.
Do you think you'll need a belt with that?
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time.
And that's more profitability.
And if you understand their needs, you can not only deprut, sell them one product, but you can cross-sell other products that may also nee, meet their needs.
So in a customer-based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between sellers market says you focus on the product, on what the customer does well, and you push that out.
And you deliver value to the customer better than the competition.
So that's the basic difference between product based marketing and customer focus market.
Now in today's world the market place has changed even more.
What's changed?
Customers can talk to other customers.
That's good and bad.
If you're doing a really good job and meeting the, needs of the customers, the fact that they'll buzz to their other customers and tell their, their other friends about what a terrific service your company is doing.
Well, that's really good news.
On the other hand, if something goes wrong, and they tell their friends something bad, well that's not such good news.
And so you have to be really careful, in every transaction with the customer now, that you deliver not only value, but that you deliver a top notch customer experience.
Because although what I've been talking about in the seller's market and in a buyer's market has focused on transactions.
But in a connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
What do I mean by customer experience?
Lemme give you an example.
It starts way before the transaction, and it goes way after the transaction.
So for example, if a customer told another customer that their experience at a restaurant.
They might say, well I was driving to that restaurant and I hit a lot of traffic, then I got to the parking lot and I couldn't find a parking space, finally when I got into the restaurant, I finally got a table, the meal was really good but then at the end of the meal when I was leaving I tripped and fell.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer then you as a marketer need to focus on the entire customer experience.
So, one of the things, and we'll talk about this later that's changed in marketing in this world of social media and internet and globalization, is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
One thing else to mention, we're seemingly coming out of a recession now, but there was a global recession, and in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
People became skeptical of marketing.
Marketing had some bad names, the financial services industry.
And so with all those changes in the economic environment, there's been a focus again, in marketing.
In order to be profitable, you not only have to deliver customer value over time and in an experiential way, but now because of the tightness of the economy and the uncertainty there, you really have to cut costs and figure out a way to deliver value in a very discipline manner and be very flexible to changes in the market place.
So let me just summarize what I've just said.
The different types of marketing orientations.
There's the product orientation where you focus on the product and you persuade the customer to want what the firm has.
That's a customer focus approach.
The experience orientation says that you not only think about the transaction, and think about the transactions over time.
But you try to manage the customer's entire experience with the firm.
And when times get tough or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of marks in terms of what you offer?
So you tend to see generic products and standardization.
When you're focusing on customer value, you see differentiated products, and we'll talk about that, when we talk about brands also.
How you position your product to meet the needs of the customers better.
And when you're going to that tight discipline mindframe or mindset you look at genuine value.
And what's the competitive sustainable competitive advantage in each of these markets?
In a product orientation the bigger companies win because they tend to have larger market share and lower cost, and lower cost is a big strategic advantage.
In a marketing orientation, when you're focusing on the customers, the, the companies that do the best are customers, are companies that really know their customers, that can deliver quality, and that have a lot of customer data and know how to use that data to deliver better value.
In an experiential market, you look at transformation.
The customer becomes a co-creator of the value, and it's really making the customer and the product one kind of overall experience.
And in a trust orientation, the sustainable competitive advantage are the companies that you trust.
And what are the measurements of profitability?
In production orientation as I mentioned, market share is tied to profitability.
In marketing orientation, it's share of wallet or customer share, customer loyalty.
In experienced market, when you're looking at customers talking to other customers, we start measuring social networks and buzz and word of mouth and referrals.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
That's the principle of customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
The four P's of marketing are product, place, promotion, and price.
What the seller puts into the exchange, is the product.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
So those are the four P's of marketing, product, place, promotion and price.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
You can give but, blood donations I think if you're over 16, and it turned out what, one of the products that the American Red Cross could give to high school kids to give blood, was to allow them to miss class.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
So, in this section, what I want to focus on is an introduction of a, a framework that I think you'll find very useful for figuring out how to think competitively to become a leader in your market.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
And the first one is; that you have to know your markets.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
That is the type of marketing most businesses are doing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
The second principle and this is where it's pretty, it's a pretty defined and pretty It's a definite assumption that's being made.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
What happens in the marketplace?
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
And so the three crosshatches here are fair value lines.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
What are customers expectations on each.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Are you meeting fair value or below fair value on each one of these axes?
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
So, in this section, what we'd like to talk about is that concept I mentioned earlier, segmentation.
And this is a critical idea for marketing and very important for where we're going, which is brand positioning.
It's called the STP framework: segmentation, targeting and positioning.
And when we get to positioning, that's when we first start getting to branding which is where we're headed.
So, the positioning process says, yous tart with segmentation, with S of STP.
And segmentation says that you identify variables that allows one to segment the market.
Okay.
So I, we're going to figure out different schemes for how to break up the market into different market segments.
The second part, the T is targeting.
You would evaluate the attractiveness of each of the segments and you choose a segment to target.
And the third piece is positioning.
Once you get your targets segment, you position your brand and your product to meet the needs of that target segment.
STP, segmentation targeting and positioning.
So let me just give you the idea of why this is so important to have segmentation targeting and positioning.
And what I'm putting up on the background now, is a slide that shows you the importance values two different segments have for roof tiles.
So in this graphic, you can see the yellow segment, doesn't think price is that important.
They don't care about whether or not it's a low price.
And they really care about how durable the pu, tiles are.
On the other hand, the blue segment, they care a lot about the price.
They don't really care that much about how it looks, and they don't care that much about how long the tiles last.
If you did not segment this market, the optimal thing to do would be to give average value to everything.
The average value here would not be not a low enough price for the people who care about low price.
In some sense I think that is the lukewarm tea.
You can have hot tea, an ice tea and if you give average it's lukewarm tea and nobody is happy.
So one of the reasons to segment the market is if you don't, you tend to try to reduce cost and go to the average value and you are not meeting anybody's needs.
Going back to that concept of customer focus marketing, if I want to give you exactly what you want, I need to segment the market.
And what you'll see is there's a heterogeneity or differences in preferences.
And then I need to choose or target; which one of these segments I want to deliver to, and deliver value to that segment.
And for example, in this case if I delivered, durable tiles, to the seg-, the yellow segment.
in fact, let me just define it formally here.
Market segmentation is the process of dividing up the market into distinct subsets, where any subset could conceivably be selected and then you pick one of those market seqments to be your target.
And you reach or you deliver to that customer segment, that market segment, with a distinct marketing mix.
Remember what the marketing mix is, the four p's, product, place, promotion and price.
And what that says, when I'm looking at these different segments, they may want different products.
and so that's the definition of market segment, a very, very critical idea in, in marketing.
So the question is how can I divide up the market?
And you might understand the idea that I'm going to go after market segments and I'm going to choose one of them.
And then I'll give a unique product package, or marketing mix, to one of those segments.
Maybe you understand that concept.
But then the question is well, what are the different ways to segment the market?
And there are actually lots of different ways.
The most common way that people most, that usually think about is to divide up the market on characteristics of the customer.
So intuitively, you might think about demographics.
Well, men and women like different things, so let's make a female product and a male product.
Or, old people like things that are different than young people, or rich people have different needs than poor people.
So one of the segmentation schemes people frequently think about are characteristics of the customer.
Another one though, which doesn't really focus on characteristics of the customer says, well people like different things in products.
Some people care about technology, and so it might make sense to divide up the market or segment the market on benefits that people seek.
A third way to think of it is how do people purchase?
Some people purchase online, some people like to go to physical stores, some people like to use their phones or some people purchase very frequently.
Some people only purchase once a year.
Some people like to switch around, other people like to be loyal.
All of these are different characteristics that you can use to segment the market.
Another thing that and I'm sure you've heard of this.
Another way to think about it is cohort analysis.
And what cohort analysis says, it's not really whether you're young or old, it's the life experiences that you've experience as a cohort.
Those things that hit you at that time of your life are critical, and they frame you as a generation.
And so this is the idea, you've heard probably of baby boomers.
Baby boomers were born, there's two cohorts of baby boomers.
and those that cohort of baby boomers.
All come of age at a certain time, certain things happen when they come of age, and they react as a generation.
Generation X is another cohort and what you're hearing about nowadays is really is Generation Y.
Who's in college now, what's that current generation?
Marketers are very interested in the generation as they come of age, when they are in college or when they're this age.
Because many times, you make purchases at this age and then you're loyal to those brands over time.
So it's, marketers feel it's very, very important to get in those people's consideration sets, right, at this time.
So they spend a lot time studying, the cohort of today and today's cohort is Generation Y.
Generation Y is very different from all the other generations.
First of all, it's a generation that was completely brought up on the computer.
they think about the social environment, they're totally comfortable social network, everything's wireless.
They think about things being designed exactly for them.
They're totally used to customization.
This is a generation, electronic generation that's quite different from their parents and from generations beforehand.
And you really need to understand Generation Why or the Millennials in order to market to them.
What they don't like is mass marketing.
They don't like any kind of restricted access.
They like new, they like different, they like customized.
Millenials are big shoppers, but many times the co-purchase with their parents, some of the millenials still live with, and are supported by their parents.
They think about information electronically.
They're very, very comfortable comfortable multi-tasking and co-creating with the product.
So if you're segmenting the market by cohorts and you decide to target the millenials, you would have to design a targeted product or position your brand in a specific way to meet the needs of the millenials.
Another way that markets tend to be segmented are by geography.
It turns out that people who are similar tend to live together in the same neighborhoods.
And there are different ways to segment, there's segmentation scheme called prism.
That actually defines the entire country based on these geographic clusters.
So you could have a geographic cluster with some characteristic sets in California.
And people who live in New York may be in that same, same cluster.
So people who live in say Beverly Hills California, may be similar to people who live in Scotia, Scotia New York.
And those two may be in the same cluster, even though they're separated by 3000 miles.
So the PRIZM clustering, or zip clustering says, if you tell me your zip code, and I'm giving you a United States example.
But this kind of notion of geographic segmentation is true around the world.
People who are similar tend to live in neighborhoods that are similar.
And so you tell me where you live, I have some ideas of the kinds of things you might like, the products you might like, the clothes you might wear.
And what we find out and we'll talk about later on in, in one of the other parts of this program when David Bell comes and talks to you.
So location is a very very important variable when thinking about segmentation.
And there are lots of maps that can divide up say the New York City for example.
Once you define your segmentation variables, then you need to select a target segment.
and so what makes a segment attractive you need to balance the attractiveness of the segment with your capability to deliver to that segment.
And you need to constantly monitor whether the actual buyers that you're targeting are matching what you think that they should be doing.
You determine the attractiveness of the segment, how big is it, how much growth is there, how much money do they have to spend, how stable is it.
Then you think about, well how good are you at meeting the needs of that segment.
How many people are going after that segment?
What's the strength of the competitors?
Are there potential competitors coming in?
And what you want to do is pick the most attractive segment where you have a differential advantage over the competition.
That's the best target segment for you to consider.
And you can have low to high competitive strength.
And the best segment to go after or to target would be the most attractive segment where you are strongest relative to the competition, that's perfect.
Sometimes you can't get the perfect segment and so you may choose something that's a little bit less attractive but still something that you think would be profitable.
Because one of the most important aspects of a brand, is brand positioning.
It's also the positioning in the STP framework, but it's really the essence of the brand, the brand positioning.
So, let's start with what is a brand, and then we'll get into this notion of positioning.
And so I really want to get to this notion of what is a brand.
Formally a brand is just a trademark.
If you have a brand you want to legally protect your brand and trademark it.
and that's if you talk to lawyers about a brand they'll talk about it as a trademark.
A promise of the company of certain specific benefits to the customer.
and that's been the traditional definition of what a brand is.
Because, we mentioned before, this is a connected community, and customers are talking to other customers.
Really, what a brand is, and the real definition of a brand.
That's what the brand is.
What sits in your customer's heads, regardless of what you try to put there, is what your brand actually is.
Then hopefully what Disney thinks their brand is, is what the customers think it is.
But if your message is not so clear and you want your brand to mean something, but what the customers think is something different.
That's what your brand is, what sits in the customers head.
Now when we're talking about the notion of positioning.
And so a positioning statement is a definition or positioning statement for a particular brand.
I have here two examples of positioning statements.
For two brands of personal computers.
These are a little bit old, it's when Apple and IBM were really focusing on personal computers.
But I want to use these examples because they're very clear, crisp positioning statements, and I think we can learn a lot by understanding these positioning statements.
So let's look first at Apple computer's positioning statement.
And if we read that, it says Apple Computer offers the best personal computing experience to students, educators, creative professionals and consumers around the world through its innovative hardware, software and internet offerings.
Compare that to IBM, which was very, very different at the time.
IBM is for businesses who need computers.
IBM is the company you can trust for all of your needs.
Very, very different positioning.
and it should be quite clear by the positioning statement.
Let's break that positioning statement into its parts, so that we can understand what a good positioning statement has.
There's three pieces to the positioning statement.
In the frame of references, who are the other competitors that they are comparing themselves to?
The target segment here, and it you think about Apple, the target segment is students, educators, creative professionals.
So nowadays, Apple's so popular that you know, everybody has an Apple.
You know, somebody who's not a student has an Apple.
not just creative people anymore.
Yet, even though Apples are ubiquitous and lots and lots of people have Apple, Apple products.
It's a very designy brand.
So, it still has a very clear target segment, even if that doesn't limit who might use the product.
It's innovative.
We look for design innovation from Apple, so that's its point of view.
And in this case what's the frame of reference?
In this particular positioning statement it's other personal computers.
So you have these three pieces to a strong positioning statement, the target segment, the point of difference.
And positioning is defining the value proposition in these three terms, the target market, the point of difference, and the point of parity.
Now you can play around with this and if you think about this and get into it a little bit you may realize that your point of difference is going to be relative to the frame of reference.
If the Crest chewing gum was referred to, the frame of reference was other toothpaste products, then Creth, Crest chewing gum's point of difference is it's a toothpaste product.
On the other hand, if you take Crest chewing gum and compare it as a frame of reference to other chewing gums, the point of difference is, this is a chewing gum that has toothpaste in it.
So, these two things go together and part of the art of coming up with a good positioning, is figuring out who's the right target market to go after.
And also, what's the frame of reference, and what's going to be your point of difference, and playing around with those two pieces is a lot of the art of positioning.
Very important concept, but you really need to understand these three ideas, target marketing, point of difference and frame of reference or point of parity.
And what you're going to do is, because once you decide on your positioning statement, you use all of the elements of the marketing mix that we've already talked about, product, price, promotion and place, to position your product to meet the needs of the target segment.
And positioning should be clear and simple and focus on a few key benefits.
the position must be defensible, so you want to take a positioning that you own and that other people can't copy very easily.
And the really important thing is you cannot be everything to everyone.
You must make choices.
You must focus.
You must choose a point of difference.
You must choose a frame of reference to have a clear positioning.
Because if you try to be everything, you're going to end up being lukewarm tea, and that is not a good brand position.
Positioning, once you have the good brand positioning, that should determine what products you develop, and positioning is a strategic idea, so you really want to think about this in terms of what are, what's your target segment, what do customers want, what's your competition, what is your position relative to the competition?
Once you have your brand positioning, you can decide things like, what color should the brand be or what should the symbol be or what should the logo be, and we're going to talk about those in the third, in the third section of my.
At my part here but that's very much tactical and messaging.
Positioning at the level I'm talking about it right here, this is very much a strategic idea.
And a very important piece of this is this point of parity or frame of reference.
These are, so I want to spend a little bit more time thinking about this just so that you understand.
It's a part of the positioning statement, but it's associations that are not unique to the brand.
And you want to think about these point of parity as things that are necessary for the category.
So something a brand must have to be considered in this frame of reference.
So for example, if your frame of reference is a grocery store, then people think, in order to be a grocery store it has to have produce or it has to have fresh product, that's what a grocery store is.
And if it doesn't have that it's not a grocery store.
Are what are the conditions that your brand must have, that they share with the competition to be part of that set?
And then you want to think about points of parity sometimes is ways to negate, a, a, a competitor's point of difference.
So, for example, in toothpaste, when one of the brands, and I can't remember which one, first came out with fluoride and as a cav, cavity preventer.
All of the other brands copied and put fluoride in their toothpaste.
Suddenly it's a frame of reference, it's a point of parity.
All toothpaste now has fluoride.
On January 9th, 2007, a few years ago when Steve Jobs was still here, he used to go out in January and come up with some big innovation every year, an announcement about Apple.
On January 9th of 2007, one of the big announcements at the time was that he changed the name from Apple Computer to just Apple.
Did he change the target segment?
Target segment, still creative young people.
Point of difference, still innovation.
The point of difference, I think is more clear to people what that is.
It's strong, favorable, unique brand associations.
It's a similar concept.
You want a competitive advantage, a point of difference that you can hold, and that it's difficult for competition to copy.
and it can, it can be a lot of different things; it can be product attributes, performance attributes, it can be imagery, it can be benefits, it can be design, it can be anything that you can own and that really differentiates your brand.
When you're choosing a point of difference, you want to make sure that it's desirable to the customer.
Is it relevant, is it distinctive?
So in choosing a point of difference it's very, very critical, it's probably going to be the reason people choose your brand.
But you've gotta make sure it's important and that you can deliver on that criteria.
So we just talked about brand positioning, which is the strategic part of brand position.
And if you really think about brands, you'll realize that although you know some great, crisp brands it's very hard to get to that positioning.
You can have different point of differences, different target segments, different frames of reference with lots, and lots, and lots of different choices.
That's the trick of marketing.
To explain marketing, the concepts aren't that difficult to grasp but they are very, very hard to do right.
There are lots and lots of ways to do marketing wrong.
And the next concept that I'm going to talk about is the brand mantra or an elevator speech.
This is the way you define a brand in 30 seconds.
So we're talking about 30 seconds worth of material.
It sounds so easy, 30 seconds.
The right brand mantra, that takes lots and lots of analysis.
And a lot of wrong turns, and a lot of wrong ways.
maybe you're lucky, but chances are, you haven't given it enough thought.
You really do need to think about of lots of the different positions.
So what I'm going to suggest here, what I'm going to talk about is a relatively easy concept to get, but it's very hard to do well.
Let me tell you where we want to end up and I'll talk about how we get to it.
We want to add up, end up with the 30 second speech, as I said, the elevator speech.
And a brand mantra may be three words; but I want to get down to the right three words.
And how do they think about the category, and how do they think about different brands?
And what a mental map is a kind of a graphic, with circles and arrows and things like that, of what the brand is.
And it's kind of a, a thought association process.
You ask the consumer what comes to mind when you think of the brand.
And then there's lots of different ways to do this and I'll just show you one.
But there are a lot of different ways, and you write down what the brand is, what the essence of the brand is from the consumer point of view.
And some people call this mental map, some people call them schemas.
and there's a lot of different techniques you can do in these mental maps.
The lines that connect one circle to another circle can be the strength of those associations.
But essentially what you're developing is, sometimes it's called a semantic associative network or a mental map.
You're developing a picture of the thought and associations that come up with the brand.
And so what I'm going to show you here is a mental map of McDonald's.
It's good value, and then the yellow circles here are the associations with each one of these points of parity.
Frame of reference characteristics that are unique to McDonald's.
What are the meals that McDonald's has?
Well, it gives hamburgers, it has breakfast, it has fries.
Well, it's always consistent, it's fresh, it's good-tasting.
and these, this is one example of the mental map.
But you can see the idea here is that you have circles and lines that connect these associations.
You can do this in a lot of different ways.
You can do it, the closest ones to the core are the ones that are top of mind, that come up first.
The ones that are further away, you know, come up after a time.
And so there are a lot of things, but what I'm trying to get here is all of the thought associations that come up with a brand.
And then what you want to do is do this over several customers, and do it in market research stages, several different ways.
And essentially, you want to take all these different abstract phrases and concepts that are out there.
And figure out which are the most important maybe five to ten, which are the very most important.
And so, what you're doing is, you're starting with the mental map or the associations that people have with the brand or maybe that with the category and depending upon how well known the brand is you might do it at a category level, you might do it at a what if level.
But you have this big mental map and then you want to hone down that mental map to the core brand values which are the five or ten critical brand values that are important to that brand.
And from that you then want to reduce those five or ten to the key concepts that are going to be the DNA of the brand, the brand mantra.
So, the brand mantra is defined as the heart and soul of the brand, the DNA.
It's the brand essence, the brand promise.
It's just really what people think of as the core of the brand.
It's very important to know this brand mantra because everything you do within this brand mantra, all your products that you come out with, all your new products, all your advertising has to all fit within the essence.
The customer's going to know the brand mantra, the employees are going to know the brand mantra.
And it characterizes everything that's done under the brand name, and that's very, very important.
It's particularly important nowadays as you go online, offline, websites, phones.
Your brand is on lots of different things, and you really want to make sure that the heart and the soul of the brand is consistent across all of these different media, these different platforms, these different products.
So what is the essence of the brand mantra?
It has three basic parts.
Then there's the descriptive modifier that further classifies or clarifies the nature of what the brand is delivering.
Now it's probably easiest to give you some examples.
Before I do that though, let me just say again, what the brand mantra is used for.
By the way, that's a very important idea.
But as importantly it says what a brand is not.
It, it, it has to be short, simple and it should be inspirational.
Nike, they're global brands, Nike, Disney, McDonald's.
so Nike is authentic, athletic, performance.
The all, just do it, be real, you know, the, that's authentic.
But when you think of Nike, you think about athletic, and it's about performance and the, the technique, or the ability to, that can, just do it.
Disney and McDonald's are kind of interesting, because they both are about family fun, and, and they actually both have a lot of things in common.
Disney is about entertainment.
Disney sells quite a bit of food at their parks and in different places that they have.
But when you think Di-, Disney, you think fun family entertainment.
McDonald's, on the other hand, is fun and family.
But its food, and even if you have a McDonalds playground or something like that, you still think of it as the food first.
And so, although these are similar and you know, what.
even though they're going after similar target markets and they're offering similar emotional benefits, they really are quite, quite distinct, different brands and they have very different brand monitors.
So in this last segment, we're really defining what a brand is.
we, we've talked about what marketing is, we've talked about marketing strategies, competitive analysis, customers values.
And brand positioning that's so sharp that you can define it in just three words, in 30 seconds as a brand mantra.
And in this last piece of this, I want to talk about the notion of experiential brand.
And we talked about things changing from the sellers market to a buyers market to the connected community.
In the connected community, that's when this notion of customer experience comes in.
So its not enough to just define a brand in terms of a crisp, clear brand mantra and a crisp, clear brand positioning, but you also have to define all of the experience that exists around the brand.
So, what's an experience?
an experience is a process that occurs as a result of living through a situation.
So it's not just a moment in time, it's a dynamic notion where you sense or feel this experience.
as I'm going to define it later, you'll see that it involves all the senses, it's social, it's behavioral, it's cognitive, it's emotional.
It's stimulations that are triggered to the sense that you think about, that you feel.
they connect the company and the brand to the customer, and they place the the customer action and the, the individual's actions and purchase occasions in a broader social context.
So the experience includes all of these kinds of things.
It's What I've been talking about, up to this point really, is pretty cognitive, pretty rational.
And here's where we bring in the emotions and all these other things, and I know those of you who know and love brands really understand that brands are emotional, they're experiential, they're not just this hard and fast cognitive point of view.
And so that's what I, I'm emphasizing here on the point I want to end with in this section, that a brand is an experience.
I'm going to talk about those but they all have to be augmented to be bigger than that.
That's a principle of marketing, to be differentiated, the point of difference.
So the different, the differentiation is also in the brand experience.
If you're an Apple lover, or you're an Abercrombie lover, or something, you have a relationship with that brand; it's over time, and it defines you.
It's not just brand attributes, these cognitive at-, or these performance attributes, or these product attributes.
It's a personality, you think the brand almost as a friend.
It's not static, it's dynamic.
It's not a mass brand, because you're co-creating with the brand.
So you can see by the types of words I'm saying that Really, really strong brands embody all of this emotional experience.
and so when you define these terms, these things that I've mentioned earlier, than you're not just thinking about brand positioning.
And it should be a multi-sensory strategy.
When you think about brand positioning, experiential brand positioning, you not only want to think about.
You want to think what's the smell of the brand.
What's the emotion you feel when you think about the brand.
And, it, it, it needs to be as any kind of differentiation is, it needs to be distinct from everybody elses.
And then the brand promise the mantra again, it's not just three words, you know, cognitive words.
It also needs To describe what that brand promise is in experiential terms.
And here's where I'm going to be very clear of what I mean by experiential.
So, it need to be what's the vision of it?
What does it look like?
What does it smell like?
Is there music associated with it?
What does it feel like?
What, what, how do you feel about it?
What, what, what are the emotions you feel with this brand?
What do you think about it?
The, the sensuous is across the five senses, you want to have a consistent experience.
You should appeal to the customer's inner feelings and build strong emotions to it.
It can cause you to act in a certain way.
And social is the part of the social system, the culture, that surrounds the brand.
And you want to have these experiential functions delivered through the four P's.
And now we're going to define each one of these four P's in experiential ways.
all of you know about, I'm sure you've seen this self designed, customized Nike.
It's not just a product attribute anymore.
You're part of the process that makes it very experiential.
You choose what you want in your shoes, you choose what you want in your greeting cards.
That's an experiential notion of a product.
advertising that's experiential, I think, one of the one's who's a beginner to really understood this was Apple, when Apple would show their iPad or their iPod when they were first coming out, it was a very experiential ad.
It was music, it was dance, it was.
The little white ear buds that came through was the color, the design.
I think, that's what most people are now just assuming most advertising is that way.
What does it mean to experience price?
Or even the concept of priceline.com where you kind of name your own price, that's very much an experiential notion around price.
Even something As, as cognitive as price which is numbers can be experiential.
these are stores where in, in Ralph Lauren, for example, they built an entire house, the entire, the entire lifestyle.
What kind of furniture would they have?
and, and it's very very experiential, not just, it's not just a store with clothes on a rack, it's stores in the experience, in the context you're going to live and wear them.
This is how cosmetics should be, you know, it's not hidden behind a counter and you can't tell anything and you gotta get a sales person to come and get you.
You want to go and feel the colors, put them on and see them, smell them, that's experiential.
And the very best retailers understand that.
There's a Pop-Tart store, there's an M&M store, you go in to that store and the candies are everywhere, the colors are everywhere, you can taste different kinds of things.
The, it's a lot of fun, it's almost like an amusement park, that's what retailing has come to be.
Each one of these pieces is delivering to the brand mantra in an experiential way through four p's.
This is what's happening in brands.
and it, it's like a religious experience, and we certainly saw that when Steve Jobs passed away.
That was a memorial.
Clarity is very important and it has to be dynamic, that these promises have to be kept over time.
You have rich unique brand equity, strong emotions, strong thoughts with it and they're delivered dependably and consistently and strong brands have really loyal customers who help spread the brand message.
weak brands on the other hand are vague, they change, you don't even know what they're going to do, there's no consistency there's no commitment, there's no.
it's a very spotty reputation, there's doubt about it.
You didn't, never know what it is, pricing can change, you know, one time it looks like this, another time it's shoddy qual, those are not strong friends.
Consistent, clear promises are what make very strong brands.
Every time you get a product experience under this brand name it's the same.
Very important.
There's a very big difference between Disney and McDonald's.
They are very, very distinct brand positioning, and distinct customer experiences, even if the product itself might be somewhat similar.
But it indicates what kind of organization you're going to have, what the priority of your resources are going to be how you allocate those resources, etcetera.
and it's very important, we'll talk about this in the last section, for your brand to stay relevant.
A great brand is flexible and adaptable and changes with the customers.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
I'm here on South street.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
In a world characterized by a performance superiority or operational excellence.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
Either going to new customer segments or to new geographies.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
Both of them share this basic idea.
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're, we're good at doing a certain kind of thing.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
How do they go about running the existing business as well as figuring out how to extend the existing product.
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
And we're going to stay ahead of our competitors by becoming more efficient.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
And this is exactly the kind of issue that many companies are facing today.
It works.
It gives them some opportunities for growth.
And for many companies that's totally fine.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
Again, implicity, that's the way that most businesses operate.
And we hire people who can think divergently, who can take our particular core business, and think about ways of spreading it out, to new markets, and new products and services.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
What would be some of the emerging trends?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
So smarter customers put much more demands on, on companies.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And it's much harder to stay a step ahead.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
So, again, that's another reason why product-centricity just isn't what it used to be.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
So in the old days, it was good enough just for, to, to let the customer take a bunch of products and services and figure out what they're going to do with it.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
It is now much more imperative than it ever was before for companies to be seen as a trusted advisor.
To be providing full fledged solutions to the customer and not just piece meal products and services that the customer will figure out how to combine together.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
So if you think about old companies.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
And for how long, and what other products that they're buying.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
If this customer goes down about say, $150, it's time to intervene.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
But equally importantly, is going to reset their mental account.
So Harrah's was very smart about understanding that kind of messaging.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
So when Wal-mart bought a small chain and entered the UK.
Tesco knew which customers were most vulnerable to switch to Walmart, and which products they'd likely buy from Walmart.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
So while the Harris and Tesco stories are terrific, I will provide pointers to some books that summarize each of those stories quite well.
I want to emphasize that they're not the only ones who have built a business around a deep understanding of their customers, and by no means are they the first.
In fact, the first companies that actually built a business in this manner, around their customers, has happened many, many years ago.
And it emerges from the sector of direct marketing.
When I say direct marketing most people don't have a real positive association with it.
They think about infomercials and other, you know, not great marketing activities.
it, it's, it's not the kind of industry that you aspire to be associated with or learn from.
But when you strip away what most customers see from direct marketers, and look at the actual business practices below the surface, you realize that it's actually quite impressive.
But not just, the customer in some generic sense, but around each and every customer.
It's about understanding the relationship with each different customer.
That's what direct marketing is all about.
What's interesting about it is, that direct marketing is not a new concept.
There's actually a lot we can do, we can actually formalize some of these business practices, and come up with some best practices associated with them.
But even if you don't spend a lot of time thinking about direct marketing, a lot of the words and the concepts have already filtered their way into today's everyday marketing conversation.
So, a lot of the segmentation concepts that Barbara discussed are often associated with direct marketing.
Something that you've heard about before, that we're going to spend more time talking about, that's, that, that comes directly from the direct marketers.
We can collect all this data about our customers, about each and every one of them, and we can actually build a business by understanding who the valuable customers are, who the less valuable ones are.
So the Harris and Tesco stories are wonderful, but they're not unique.
And so I want to spend a lot of time celebrating some direct marketing practices.
And I want to emphasize that a lot of firms out there today might not aspire to be direct marketers, but they don't realize it, but they are.
Any company that has the capability to track a particular customer over time.
Has the capability to learn from direct marketing, and I encourage all of you to read books on direct marketing.
Even if you don't think about yourself that way, there's just so many concepts that you can learn and leverage, especially as we enter this world of big data.
Now that we understand what product centricity is all about and we've discussed some of the cracks in product centricity.
And even some of the opportunities from companies to escape from and maybe do better than a product-centric approach, I want to start moving away towards customer centricity.
So in order to do that, I want to work with a series of examples here.
Three of them operate on a global level, so Walmart, Apple, Starbucks.
So I want you to think about what customer centricity means in light of our discussion so far.
And decide which of these, could be one, could be all, could be none, up to you, would be above the bar in terms of customer centricity.
So think about what customer centricity means, and which of these firms qualify in that regard.
In my book, none of these firms are truly customer centric.
I have great admiration for all these firms.
I really like what they do.
So I'm just going to take a few moments to talk through each one of them, and then, finally we'll bring up our definitions of customer centricity.
Now again, Walmart is a terrific firm, but Walmart knows, surprisingly little about any one of it's customers.
Unlike Harris, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
And how they can influence each customer's behavior.
So while Walmart might not make a lot of efforts to understand what any one customer's going to buy, they make great efforts to understand the customers as a whole.
They understand regional differences.
For instance, when a hurricane is about to hit the south eastern US, they need to fill the stores with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way as a direct marketer would suggest.
And you know what, that doesn’t bother me because Walmart isn’t intending to be a direct marketer.
If you think about the Walmart business model, it’s about selling in great volumes, it’s about bringing the costs way down.
So, in many ways, Walmart is a prototypical, and a wonderfully successful, product-centric firm.
There are a very few firms in the world that can operate in an operationally excellent manner as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time focusing on segmentation and real granular analysis to try to predict what any one customer is going to do over time.
What Apple focuses on, is leveraging its product expertise.
So again, a classic example of product centricity, and they do it better than most company, most other companies on the planet, and they can get away with it.
Operational excellent for Walmart, performance superiority for Apple.
They are doing some smart things at the margin to understand their customers better.
They have a new program they call Scan & Go, a mobile app that lets people scan products as they move around the store so as they check out, the whole scanning process happens much faster.
It's a brilliant idea that lets them be more operationally excellent, but also lets lets them start tagging individual customers and tracking them over time.
So they're starting to take on some more customer centric initiatives without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business that are letting them understand their customers a little bit better.
Slowly but surely, they're starting to develop a better understanding of their customers at a more granular level.
One day, if and when competition catches up and Apple can no longer be the product leader that they are, they could probably turn around and start to be a great customer-centric firm as well.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
At a local level, Starbucks or any coffee retailer, is very, very customer centric.
The Barista, the person on the the other side of the counter, the person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store but just through the casual conversations you have with them, they might know what movies you like, what kind of clothing you’d like to buy, something about your job, your family and they often make recommendations to you.
That are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted advisor to the really good customers, finding ways to lock that customer in and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they are not that customer centric at a national level.
You take your Starbucks loyality card, and you bring it a Starbucks in another city or another country and show it to them and say, I'd like the usual please, they have no idea who you are.
So not only can they not meet your immediate needs, but it's hard for them to be a trusted advisor and to make other recommendations to you when they have no idea about anything about your history.
It's not enough for a company to be customer centric some of the time when they know who you are.
But a truly customer centric company will identify you and will be able to value you and make recommendations no matter what kinds of interactions you have with them.
And they're coming up with all kinds of interesting technologies that are going to let them collect and integrate your data across stores and across other touch points you have with them.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
So again, it's that balance between focusing on the product and focus, focusing on the customer that so many companies are now struggling with.
And while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
And here's the way it goes.
They sell clothing, shoes, and so on.
One thing they don't sell is tires.
Supposedly in Fairbanks Alaska, and wanted to return a set of tires that obviously they could not have bought at Nordstrom's.
Perhaps there was a tire store at that location before Nordstrom's opened shop.
If you think about it for a minute, is that really customer-centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
We'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer.
The lifetime value of the customer.
And for most customers it wouldn't be.
We might still be nice to you, of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom's.
Regardless of the value of that customer.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
I like knowing that when I go in there I'm going to be treated really well.
In the old days it was impossible to do that, but today Nordstrom's, like every other retailer, has the capability to collect the data and use technology to do a little bit more targeting and a little bit more selection to figure out who is worth the extra special treatment.
So to me the Nordstrom's example is a great example of, of where a product and customer centricity collide.
And what I want to do now is, is to start focusing more on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
In other words, what is the definition of customer centricity?
So what I like to ask my students to do is to write that down.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
Hopefully, it's well-aligned with your own definition of customer centricity, but I really do want to emphasize just how different it is.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
It's a tot, totally different way of doing business.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
But it's the mindset, it's the idea of going to R and D and putting these valuable customers front and center.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
And so I want to think now about some of those challenges as well as some of those opportunities.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
We're looking at not which customers have been valuable, but which customers will be valuable using the data, the models, the technology that we have available to us.
So what does that mean?
We're going to reward salespeople based on how much stuff they sold last month or quarter or year.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's do that at the beginning of the month, or the quarter, or whatever.
And then do it at the end of the month or the quarter.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Well, we're closer to making this sale.
That's how I want to reward the sales people.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
So they were working in industry before, spending a lot of time flying.
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
So now that we've laid out the definition of customer centricity, we've spoken a little bit about some of the challenges that it requires companies to meet changing its centric structures and so on.
What I like to do is just to step back and review all the aspects of living in a customer-centric world.
What does that mean?
Now we'll spend a little bit more time talking about some of the other aspects of it.
So, so first, if you live in a customer-centric world, well let me ask you this question.
What's the overarching objective for the commercial enterprise?
You remember I, I asked that and we discussed it before for the product-centric enterprise.
So usually when I ask this question people will give me a lot of customer oriented answers.
Yeah, that's all nice.
That's all terrific.
The overarching objective is the same as it was before, to maximize shareholder value.
To maximize the profits of the company in the short run and the long run, recognizing the time value of money.
That in the end, the overall objective of any commercial enterprise is to make as much money as possible.
The problem is this.
There's too many people who think that the money-making thing is uniquely associated with product centricity, but it's not.
There's lots of different paths that we can follow, and while customer-centricity is quite different in many ways from product centricity, it's a path that actually might help you get there faster and better.
So, If I want to emphasize that point, that we're trying to achieve the same over-arching goal but in a very different way.
So let's talk about how we achieve it.
Again, going back to product centricity, for most firms, the performance superior ones and the operationally excellent ones, it was all about blockbuster idea.
Let's produce a lot of it, let's produce it efficiently, and let's think about the next thing to produce.
And again, that formula has worked for so many companies, still works today.
So what is it in the customer-centric world?
What we celebrate in the customer-centric world is customer heterogeneity.
The idea that not all customers are created equal.
The idea that some customers are just inherently much more valuable, much more profitable than other customers.
They didn't understand how customers were different from each other.
Once they started realizing that customers are different from each other, at first it was a nuisance.
Different customers, we're going to have to talk to them in different ways.
And the more we learned about our customers, the more we realized they are really, really different from each other.
So unless we're going to paint ourselves into a corner, and only work with one kind of customer, we need to acknowledge and celebrate that heterogeneity.
We need to find a way to say that these differences across the customers not only exist, but they're a good thing.
Let's find the kinds of customers who can be very valuable to us.
And, at the same time, let's find ways of dealing with the other prob, customers in a reasonably profitable manner.
One point I want to emphasize along the way, I, I, say this over and, over and, over again, but it is important to make this explicit.
Is that when we're focusing on heterogeneity and we're focusing on the, on the, the profitability of our customers, we're talking about future profitability.
It's great to look at past profitability.
In many cases, that will be a guide towards future profitability but it's not a perfect one to one match.
So we need to use our data, we need to use models and technology in order to project the future value of our customers.
So the celebration of heterogeneity is not only what the customers have been worth.
But is which ones we think will we be most valuable.
Most of the value is what we're going to create and extract in the future.
And that's the really pivotal role of this idea of customer lifetime value.
Okay, we're going to want to measure CLV, we're going to want to manage around it, how do we do that?
So, when we look at a company as it starts changing from being product centric to customer centric, what kinds of tactics change?
So one point that I want to emphasize right now, what were going to go into much greater depth in module three are those three tactics that lie at the heart of customer centricity.
That are the, the tactics that make it possible for companies to potentially make more money being customer centric than product centric.
And a lot, lot of you might be looking those words and saying well that's not new.
Companies have been thinking about the retention and development, making customers more valuable.
That's true!
But in many cases, these ideas are, are, kind of treated at a fairly low level within the marketing organization.
So it's all about, how can we get as much stuff out there as quickly as possible?
And so, instead, as we start to think about how customer's different from each other, we're going to want to ask questions about which kinds of customers should we be acquiring.
How much should we be willing to spend to acquire them.
Or should we be a little bit more selective.
And when it comes to customer development, are there some customers who we can make into better customers than others.
The people who are going to be working on them need to be higher in the organization.
The people who are running the marketing function have to be at least as painfully aware as acquisition, retention, and development, as they are around some of the branding ideas that, that Barbara spoke about.
And so we're going to get back into that.
One point that I've mentioned from time to time, but I want to make a little bit more explicit here would be challenges for the organization itself.
Again instead of having an organization, that's organised purely around the different kinds of products and services, we want to have a customer-centric organizational structure.
Ideally, the whole org chart would be built around the different kinds of customers we have.
And then below them, the different ways that we're going to create and extract the profits from them.
The Walmarts, or other grocery chains who they sell their products to.
But Proctor and Gamble recognizes that with this shift towards customer centricity, with the shift towards direct marketing, that eventually their customer will be me and you.
And they want to start to understand who the really valuable customers are.
And what are things that we can do to create more value for those customers?
So here's an example of a really nice initiative, one of many that Proctor & Gamble is trying out.
It's called My Black Is Beautiful and it's aimed at African American woman.
And P&G is determined that this is a really valuable customer segment for us, we need to be there, we want to be seen as a trusted adviser.
First, look at the bottom of the slide.
You see a number of different P&G brands being advertised together.
It's pretty unusual for a company like P&G, or again other packaged goods manufacturers, to use that kind of umbrella branding, and going back to some of Barber's content.
and if you look, look higher up on the slide, you'll notice that they're also talking about recipes and music and all kinds of things that P&G isn't involved with.
But this should be an example of Procter and Gamble trying to position itself as a trusted adviser.
That they're offering all kinds of products and services to this valuable customer segment that they don't necessarily make any money on, but they want them to see P&G as someone who has their best interest in mind.
And if you look at the bottom of the slide, you'll notice something fairly unusual.
You see here this the mention of, of a line of cosmetics called Covergirl Queen.
But, Queen refers to Queen Latifah, the popular actress, and so they developed a whole line of cosmetics specifically for African American women.
Going to the R&D people and saying, you know what, instead of coming up with a blockbuster product that everybody's going to buy, here's a valuable customer segment.
We want to come up with something for them, that they're going to find very valuable.
Others might buy it too, and that would be great.
I don't even know if this is the right segment to go after.
But given that they are going after this segment this is the right way to do it, this is customer centricity.
And you have to believe that in the Proctor, Proctor, Gamble organizational chart there's some people who are responsible for My Black is Beautiful.
And they're going to bring whatever resources they can what are the products with in the P&G family or outside of it in order to make this customer group as valuable is possible.
The bottom line for customer centricity, is this idea of relationship expertise, if you remember earlier, the key to product centricity was product expertise.
We're always, s, steps ahead of everybody else, but as we discussed, the cracks in product centricity are shortening some of those steps, it's much harder to stay ahead when it comes to product expertise.
But when it comes to relationship expertise, I believe that there are meaningful, sustainable long run advantages.
And I'm not just talking about soft, squishy understand your customers in some generic way.
I'm talking about data.
I'm talking about models.
I'm talking about truly understanding your customer, your customers, celebrating the heterogeneity.
One of the beautiful things about it, is that when you collect the data, and you develop these kinds of forecasts, nobody can ever take it away from you.
And so I believe, if your customers are assets, and I think they are, that investing in the data, in the knowledge, in the heterogeneity, can actually lead to better outcomes to companies than pure product-centricty.
There's one more point I want to raise, to really help us understand the contrast between product and customer-centricity.
And I, and I really focused on the idea of the divergent thinking.
We have this product goodness, what do we do with it?
I hope that you'll see that many of them are entirely consistent with our discussion so far.
The different kinds of metrics customer retention, lifetime value.
We're going to be saying more about those as we go on.
Instead of diversion thinking, what do we do with this product?
What products and services can we develop?
What information can we provide?
What can we do in the relationship to create and extract more value, more value for these really valuable customers?
So again, moving from the product centric world to the customer centric world is very difficult, going from divergents to convergent thinking doesn't happen over night.
It requires all kinds of different incentives, it requires different kinds of people with a totally different mindset.
That's one of the challenges associated with customer centricity and I want to talk about a few more.
I want to spend a little bit more time thinking about the distinction between those really focal, those really valuable customers, and the eh, not so valuable ones.
If you take my words a little bit too literally, I keep focusing on the valuable, valuable, valuable customers.
And I keep saying let's just zoom our whole business around them.
If we were to do that, then we've become very vulnerable.
And what happens if we're wrong about them?
What happens if there's other customers out there who are fairly valuable?
What happens if something changes to our product or in the marketplace that turns those really valuable customers against us?
And so here I, I want to raise an important but subtle point.
The idea that, the more we zoom in on those really focal customers, the more we need the less valuable customers, in order to have a stable mix.
The metaphor that I like to use here comes from finance.
Alright, we want to have some, some really high flying stocks in our financial portfolio.
We definitely want to have some of them.
Those are going to be where the real growth comes from.
So in our customer mix, we want to have that same kind of portfolio approach.
This is where I come up with the notion of The Paradox of Customer Centricity.
It goes like this.
The more we zoom in on those really valuable customers, the more we need those other customers around in order to have a stable balance for the company as a whole.
You see, with only a few exceptions, no company can be truly, purely customer-centered.
If you are a private wealth manager and your customer base consists of four billionaires.
You can be a trusted advisor to each one of them.
But if you have millions or tens or hundreds of millions of customers, it's a matter of finding the just right balance between being truly customer centric with the customer segments that we see as really valuable.
But being products centric with the remaining customers, who aren't as valuable.
Now the difference between a true product centric firm is we're not going to let those so-so customers drive the business.
We're going to continue to focus on the customer-centric ones for growth.
We're going to continue to focus a disproportionate amount of our R&D activity on those really good customers, coming up with products for them, hoping and finding ways to make those same products palatable and attractive for the product-centric customers.
But it's a matter of finding that balance.
That's the paradox of customer centricity and one of the challenges for firms is to figure out how to do that well.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
You can make an argument, that each one of them is the customer and depending on who you talk to, at the pharmaceutical firm, you'll get a very strong argument, one way or another.
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
But, but, one kind of customer matters more than others.
Going back to the Proctor and Gamble example that I mentioned before, there there's a tremendous amount of clarity on it.
Proctor and Gamble knows, that today, their customer is the retailer.
So it's important to first sit down and figure out, who the, the customer could be.
Who are all the different constituents, who could qualify as being the customer?
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
We also want to think about, what are the barriers associated with customer centricity.
There might be reasons why, we can't treat customers differently, for instance in the pharmaceutical space.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
If the company's been focused on, developing and distributing block busters for all of its existence, it's hard all of a sudden, to pivot around the customers.
The ones that I just mentioned are fairly general, they're fairly broad, but every company is going to have its own challenges.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Very often, the resources are going to be financial.
You're going to have to invest money, to build the information technology systems and to hire employees, and to start developing a data infrastructure.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
Sometimes, being the only one doing the customer centric thing, is the way to make it most successful.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
Making plans now, for changes that they can make in a few years.
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be other kinds of experiments that, that a company is going to run.
Let's just set aside, a part of the organization or group of customers.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
Now, of course the virtual world provides great things.
We can buy almost anything we want, at any time we want, on various websites and through various apps and so on.
And yet, government statistics tell us in the United States at least, and this is fairly similar in other parts of the world.
And this will be a really interesting one to follow because currently I think only about one percent of groceries in the United States are actually sold online.
Pete always likes to say that the fraction of groceries sold online in 2013 is roughly what it was in 1713.
First of all there may be the issue of delivery time.
Of course our friends at diapers.com can get us diapers by 6pm in the United States as long as we order them by 9am on the he same day.
But even that may be too long for some of us.
Do you really want to buy your bananas online?
How do you know what they're going to taste like?
Would I really want to buy this shirt online, without knowing how it fits and feels?
But that is a second barrier, uncertainty about what it is that might arrive when it comes to your door.
And then the third thing that's typically voiced by consumers as a problem with the virtual world, is the cost of returning things, even if there are free two-way shipping, and so on.
And so those two worlds are going to continue to coexist like this for some time to come.
So let me again share with you a very, very interesting piece of academic research.
It was done by some of my colleagues up in Toronto, the Canadians, once in a while do some very good things.
So, let me share one of the good things that Canadians actually do.
I'm part of the Commonwealth, so I feel like I can say that.
So, what they looked at is, they looked at sales at amazon.com in various zip codes around the United States, and whether or not those sales would be influenced were a physical store to come into the neighborhood.
All of a sudden, a bookstore opens up across the street from your apartment.
How would this affect the sales at amazon.com, if at all?
When a virtual world store opens up in a zip code, sorry a physical world store opens up in a zip code, virtual world sales do go down, but they don't go down for every product.
You can probably bet that that book is going to be in stock at your local book store, and so you might be able to run across the street and buy it, and indeed that's what the researchers found.
When a real-world store opens up in a zipcode, amazon sells fall, but only for products that are popular.
Now if you wanted to buy another book, probably better than theHarry Potter book but less popular.
There's a book called 101 years of all black trivia.
But if you wanted to buy that youd be unwise to go into the physical store, because the physical store would be unlikely to carry a book thats going to be so low in terms of popularity.
And it's a very, very interesting idea about how products and services that are sold over the internet, change, or the mix of products and services sold over the internet changes when we offer customers more and more variety.
Let's start at the start.
This is module one, online offline interaction, omni channel, and all those great buzz words.
So, as I mentioned earlier we all live now both in the physical world, and also in the virtual world.
So what I want to do to begin our discussion here is to think about the two most important frictions that the real world throws our way.
That the virtual world helps us get over in terms of overcoming those things.
So the first friction that the real world throws our way is a friction called search friction.
So you face the following problem.
It's so very, very hard for you to know.
So, you think, well the closest store to my house is three miles away.
Let me go over there and check out the products and prices.
And you find a price on a TV there, let's imagine it's 2,500 U.S.
And so then you're faced with another decision.
Do you buy the product there at the store for $2,500, or do you incur the cost?
The search cost and the time cost to get in your car and to drive to another store, in the hopes that you might find a cheaper deal.
So this was back in 1987, and this is called the friction of search.
Meaning that if you want to get better deals, better prices, better assortment, better value, higher satisfaction, you've got to go out and search for things and you incur a cost of doing so.
And this is a problem that's been studied by economists for decades and decades.
In fact, a very famous economist who won the Nobel Prize, talked about the economics of information.
And when you should just stop and say okay, enough is enough, let me buy this one.
Now let's fast forward to 2013.
Or even 2011, because that's the Rugby World Cup again, 24 years later.
It's the same two teams playing in the final.
Again in my home town of Auckland, New Zealand.
And now, instead of having to go through that process, you can go onto a website, let's say, milo.com.
M, i, l, o, .com, started by one of our students at the Wharton School at The University of Pennsylvania, and later purchased by ebay.
And milo.com will tell you the prices and the assortment of the various products that you might want to buy.
And so what the Internet has done in that case is, it has reduced the friction of search.
Reduced the friction of search, so that's the first major thing that the online world does, that helps us out in the offline world.
A business like Yelp.
you might want to figure out where you're going to go and eat your dinner.
If you go onto Yelp, you can get reviews of other users about what restaurants are the best restaurants to eat at, the best value in your neighborhood.
So, there are many, many important businesses that have started to reduce the friction of search.
That's the first one.
The second friction that gets thrown your way is the friction of the geography that you end up living in.
So let's imagine that I live in Manhattan.
Let's imagine I lived in New York City.
In New York City everything is available to me all day, all night.
I have all the shops that I want to go to to buy anything that I could possibly Imagine.
If on the other hand, I have a quieter life and I live in Iowa City, there are some benefits of that.
But also in terms of the products and services I have available to me, they are much more limited.
So, there's the friction of geography.
Meaning that the location that you have chosen to live in, offers you certain benefits, but also imposes certain costs on you.
So if you want to fancy pair of designer jeans and you live in New York City, you can probably just walk out of your door and go and buy a pair from any number of stores right there in Manhattan.
If you live in Iowa that's going to be a little bit more difficult.
So you might want to therefore go on to the Internet, step into the virtual world, and purchase products that then can be delivered to your geographic location.
So that's the second thing that the Internet does for us.
It reduces the geographic friction of where we live.
There are other things we could think about as well, like transport frictions and so on.
But search friction and geographic friction are the two most important principles, that help us understand how the real world and the virtual world interact with each other.
So, by now we probably all have a good idea of the basic concept behind the long tail.
So let me explain what's going on here.
the colleagues wanted to try and understand or disentangle the supply side effective the long tail, meaning there's a lot more variety available verses the demand side.
Was explanation for the long tail, which is it's now easier for you to search and find things that you really like that match your tastes, those products in the orange part of the tail.
So what the study authors did at MIT is they got sales data for a large retail company that was selling through two different channels.
And they wanted to see if both of those channels had the same mix of sales going through.
Now the prices and the products were identical in both of those channels, but they wanted to ask the question, is there any difference in the way those channels are delivering the product and customers?
Okay, so let me introduce now a diagram.
It's actually a pretty cool idea and one that you may have come across before, but perhaps not in this context.
The gini coefficient is equal to that area A.
So let me explain what's going on in this diagram.
It's often a diagram that's used to understand the equality or inequality of incomes within a country.
But it can also be used to understand the equality or inequality of sales across various products sold by a particular firm.
So to help us understand this, let's go down to point C there on the diagram.
Point C is about half way between zero and 100% on the X axis.
So the implication there would be, the bottom 50% of people in this particular country have about 20% of all of the income.
So this is a country where the income is a little bit unevenly distributed.
That would be a country where all of the wealth was held by a very, very small number of people.
Similarly, if you thought about products, if you pull that circle or semi circle in, that would be a company where almost all of the sales were just coming from one or two products, that's kind of the idea.
So what they found, the author's of the study when they looked at this, is that the gini coefficient was less concentrated.
So the internet channel looked more like a long tail sales distribution and the catalog channel looked a little bit more like the traditional 80 20.
When the researchers looked at the data in more detail, what they found was, that the sales on the internet channel were more spread out, more niche products were being sold on the internet channel.
Now this is very, very interesting because if you recall, when I mentioned the study at the beginning, the types of products sold were identical on the two channels and also the prices were identical as well.
So there was no supply side explanation in this case.
So perhaps when you're buying on the internet, it's easier for you to find those products that are more niche and less popular.
And that's exactly what the authors of this study found.
They found that on the internet channel, because there are a variety of tools like reviews and ability to search and so forth, that makes it easier for you to find stuff that you wouldn't necessarily come across otherwise.
So isn't that very, very interesting?
The long tail is a supply side story.
I can offer more variety.
I'm more able find things that exactly ma, match my tastes.
And what's clever about this study, is the office controlled the supply side, and they found there was more long tail like sales on the internet compared to the catalog and the reason was this demand side explanation.
Now, maybe you can think of some other thing that you could put on the X axis, why does it just have to be product.
So maybe you're thinking of something right now.
So maybe if I'm diapers.com, I'm selling most of my product in Los Angeles and New York City and San Francisco, those are the locations in the head.
I sell a few things out in some strange little town.
I shouldn't say that.
Because maybe somebody lives there.
I sell a few things out in small towns.
But collectively, all of those small towns throughout America add up to a lot.
So the long tail is also a concept that can be applied to geography.
And I'm just going to show a quick example of that from my own research.
So here on the slide are some of the companies that we've been talking about as we've been going through.
In this case, the research is based not on Diapers.com but on their friends over at Netgrocer.com.
That's a retailer that ships to your house various grocery products that you might otherwise buy in a supermarket.
So, to understand how the long tail works, what we need to do here is to think a little bit about the notion of similarity and differences between different locations in a large country, be it the United States or some other country that we may be looking at.
It's about 2000 miles.
We can also compute the distance between Chicago and Springfield.
That distance is about 200 miles.
So in terms of physical distance, Chicago and Los Angeles are quite far away but Chicago and Springfield are quite close.
However we think about social distance, the type of people that live in Chicago might be more similar to the type of people that live in Los Angeles than to the type of people that live in a small town like Springfield.
So if we were to look at the sales across the United States of a company like diapers.com or netgrosser.com, what might we find?
So I did this, again with my colleague Jonghei and also another friend Sam Wui at, NYU, and what we found was very, very interesting.
We found that the sales of an Internet retailer also spread out in a long tail fashion across geographies.
So I'd just like to wrap up our discussion of the long tail with a couple of other things that I think are really interesting and also to give you a recommendation of a website that really illustrates this point.
So two critiques of the long tail.
First is this idea of the law of natural monopoly.
Things that are unfamiliar also tend to be less well-liked as well.
So those two ideas run a little bit counter to the long tail, but I still think the long tail is a phenomenal concept.
If you want to see the long tail in action, try this out.
I've put a link there on the slide that I think you'll really kind of enjoy.
the most popular things come up first, or the links Google thinks are going to be most relevant to you.
So most of the time, when you do searches on Google, you get exposed to, in terms of our language, really only the things that are in the head, not in the tail.
So then when you search for whatever it is you're looking for, you won't be shown results one to ten on the first page, you'll be shown the results from one million onwards, or one thousand onwards.
You can choose on your own.
And then finally, I put in another link.
If you'd like to learn more about the concept from the gentleman who really created it, Chris Anderson.
So again, thanks for being part of our discussion on the long tail.
To me, this is one of the most interesting concepts in online, offline.
And I think it's one that will be very useful to you guys.
And as a result, local stores, local restaurants, local merchants aren't motivated to give you what you'd like.
most people happened to want to wear blue ties, and you wear a red tie.
Now think about the problem faced by manufacture and seller of ties if there's a cost associated with producing more variety.
The manager of that factory and that store might say, you know what?
Only one fellow wants a red tie.
We're not going to make any red ties.
So I'm going to explain in the next few slides how this problem can be overcome through online intervention, particularly through sellers who operate on the internet.
to make a more personal example here, I often wonder myself in myself in Philadelphia why it is that I can't get Vegemite when I go to the local supermarket.
Let me show you a picture of Vegemite.
Here's a little kid with Vegemite all over his face.
It's a delicious black paste that you have on toast with cheese and avocado and stuff like that.
I look for it all the time when I go to the supermarket in Philadelphia, but I can never find it.
Why?
Because I'm probably one of the only few people that would actually buy it.
So the store manager who wants to stock items that are profitable and sell frequently, is not going to pay attention to my preferences.
I'm a preference minority.
The internet, however, could solve this problem.
So let's go again, a little bit of background.
And, the research for this particular article that I wrote and published with a friend of mine, Jeonghye Choi, at Yonsei University, is based on data that we got from diapers.com.
here's the article itself, the title of the article.
if you want to you can always go and read it for more details, but I'm going to give you the flavor of the main findings.
So, let's see how this works.
The notion is that if you're selling things online, that gives you the ability to aggregate people.
Maybe there's only two people in Philadelphia that like Vegemite, but in all the towns in America maybe there's 100,000 if we added all those people together.
And even though it wouldn't be efficient for us to serve them in individual shops, we could sell that product over the internet, that's the basic idea.
So now let me get into the details and conclusions of this particular study, again using the data from diapers.com that we're all by now, pretty much familiar with.
So, in order to test out our idea, that people who were different from their neighbors weren't getting served adequately by offline stores, Jonghei and I went out, and we did a little bit of a field study, kind of a fun field study, and here's what we did.
Where we went out and we visited different supermarkets in the Philadelphia area.
Now, what's interesting is all of those stores, all the Fresh Grocers, they're all the same size stores.
But their local markets were different with respect to the number of households in the local market that had kids.
Store 3, on the other hand, about 16 percent of the households in that neighborhood where that store was located, had children.
So, what does this mean for our idea or our theory?
Well, the people who live in the market where there's only 10% of households with kids are going to be relatively more neglected by the supermarket than in the market where there are 16% of households with kids.
So if my friend Chris is the manager of the store, he's going to say, you know what, not that many people in the 10% market have kids.
I'll just have Pampers and a few leading brands on the shelf, and I won't worry about having a lot of variety.
If, on the other hand, he's managing the store where 16% of the target market has children, he's going to say, you know what a lot of people in this local neighborhood have kids I'd better cater to their tastes and preferences.
And so what you see in the chart is in neighborhoods where there's a higher fraction of households with kids, the actual stores have more shelf space, more linear square feet, and more variety of product of the shelf.
Now of course this doesn't prove our theory, but it does indicate that local stores pay attention to the composition of the people who live in the neighborhoods, and then they stock merchandise accordingly.
As a little side note, this was kind of a fun thing to do in Philadelphia.
Jeonghye and I had a pink measuring tape, we were running around trying not to get caught by the store managers measuring how much space was allocated to these things.
If you've been to Philadelphia, it's kind of a tough town.
Okay, so let me elaborate a little bit more on this next slide with the actual theory, that we built up to try and explain this concept.
So imagine we have two different markets.
It could be half the people want Vegemite, or any other product that you could come up with.
And so notice in that market there is one store, and the store is 200 square feet in area.
And so the manager of that store says, gee, half the people in the market have this particular characteristic, let's say households with kids So I'm going to allocate half of my store to products that cater to those people.
Now in Market B, again there are 100 people who have the characteristic we're looking for, in this case households with children.
But the total population of the market is 1,000 people.
So these people with kids are a little bit more rare in this case.
They're only 10% of the population.
Now notice however, because Market B has more people in total.
there's more stores.
And we're just assuming that the number of stores grows with the population.
So it, in a market of 200 people, if there's one store, in a market of a 1,000 people, there will be five stores.
Now again my friend Chris who does a lot of store managing I guess.
The customers who live in Market B, everything else held constant, should be more likely to want to buy their products online, in this case from our friends at diapers.com.
So let's see if that is in fact true.
So now Jeonghye and I went and we looked at the real data.
This is just a map, it's a black and white map, but hopefully you can get the idea here.
We call this the Preference Minority Index or PM Index.
And the darker the color, or the darker the shading, that means customers are more isolated.
That's in the top part of the map.
So this is indicating some support for our theory that when customers are isolated, they're more likely to use online merchants instead of offline merchants.
So the next thing that we did after looking at the raw data is do what a lot of us here at the Wharton School will do, whether it's Pete or Barbara or myself, is we ran some statistical analysis or some econometric analysis on the data.
So we controlled for the education level.
We controlled for the number of stores in the area.
We controlled for the population density.
So all of those things were held constant in our study.
And what we found was, yes, there was a highly statisically significant effect of isolation on sales.
And markets where customers were more isolated, they were more prone to go online, and sales at diapers.com were higher.
So now I'm going to explain the magnitude of the effects, which I think is really interesting.
It was also very useful for the company, for the guys at Diapers.com.
But let me explain that, because that's going to be important for understanding these results.
So if you've ever taken a standardized test like an SAT test or a GMAT test, any test at the end of high school or to get into college, those kinds of things.
You'll remember that when you get your score back, in addition to the raw score, you typically get a measure of percentile.
So where is it that you ranked, relative to everybody else that took the test.
That means only 10% of the test takers beat you, and you beat you know, 89 90% of everybody else.
If you're in the tenth percentile, which I'm sure that none of you were, that means that you only beat 10% of the people and in fact 90% of the people beat you.
So, what Jeonghye and I does, we used this same concept, but we applied it to our preference minority index.
So, we looked at all of the locations in the United States.
All of the areas, all of the zip codes that were really, really isolated in terms of people with kids being relatively rare.
So think about that result for a moment.
If we have two zip codes that were absolutely identical in all respects and in particular, these two zip codes had the same total number of households with children, 100 here and 100 here, just like in the example.
If this was a zip code that was more isolated, the online demand at diapers.com was 50% higher.
So we think that's a very interesting finding and also one that internet retailers can actually use when they think about online offline interaction.
And the second one is the second most popular and so on down all the way out into the tail or into the niche products.
So the same thing happened here.
What we found was if we looked at particular products that were niche products, and we compared an isolated market versus a non-isolated market, the sales in the isolated market online for niche products were about 125% higher.
And I'm going to show you this in a diagram to make it easier to remember.
So let me show you what's going on.
There are three pieces to this diagram that are important in terms of understanding the overall concept.
And Market B, the offline retailers, aren't paying much attention to our target customers who are the households with children.
And that's reflected at the bottom of the slide with the little thumbs up and thumbs down in the two markets.
So what does that mean for the way products are sold and bought online versus offline?
So for that, we have to go to the top of the diagram, which is our old friend, the long tail.
And so to just remember, by way of review, that the long tail is an idea or concept that has a plot of all of the products that are available from a particular seller or a particular merchant.
And the X-axis is all products lined up from the most popular to the least popular.
So it just so turns out in the diapers category the most popular brand is Pampers, followed by Huggies, then Loves.
That's a niche product out in the tail that has lower sales than the other tree.
So how do we relate this long-tail idea back to preference isolation and see how the two things come together?
Well if we think about the online retailer, that's our friends at diapers.com, they carry the entire distribution of products.
They offer everything, probably have the largest assortment of baby-related products and diapers.
Probably of anyone in the world actually.
Certainly bigger than any physical store.
Now if we turn to Market A, in Market A there's also pretty good variety.
Meaning that the offline sellers are quite attracted.
Market B, however, most of the sellers are just stocking the popular brand and not really catering to a full range.
So in Market B, the amount of product available is much more limited and is just really focused on the most popular brand.
That's why, in Market B, the customers are more prone to shop online versus offline.
So now we're going to continue our discussion of how the real world and the virtual world interact with each other in online, offline competition.
So if you look at the slide there are five companies that I'm going to speak about.
And this is actually very exciting for me because these are companies I've had the pleasure of working with in terms of analyzing their data and also doing some research trying to also help out the management team a little bit.
And I'm going to show you how that business grew and evolved and try and give you a sense of how it is that e-business companies, e-commerce companies, spread themselves over time and over space in particular markets.
The second company I'm going to talk about is one of my favorite, of course, is part of Quincy family.
In fact, you may see a little bit behind me.
I'm actually still here in the Quincy warehouse again, backgrounded by 1,200,000 square feet of warehouse space, robots and so on shipping diapers and all kinds of stuff all the over United States.
This company was founded in 2010, in February, by four students of the Wharton School.
They wanted to do something very, very interesting.
You would go in to an opticians, get your eyes tested, maybe try on a bunch of different frames and buy glasses in that environment.
Now what the forefounders notices is that at that point in time, less than 2% of that product category in the United States was sold online.
So they built a company to try and change that and sell glasses online and also through offline channels.
So we'll talk about those guys a little bit.
If you happen to be in Boston or New York City, you could even go and visit the flagship store.
It was founded in 2007 by two gentlemen coming out of the Stanford Business School.
The current CEO is still there, Andy Dunn, and their idea was to sell men, for all the guys out there, fashion items at great prices, and also fashion items that really sort of fit you and gave a bit of a feel and trim than other products.
And if we don't have small children ourselves, we might like to gift that to somebody else.
So I'm just going to explain a little bit about what we do as academics when we examine these things, and what I've done with my friends and co-authors.
Is we're able to get the sales data from these companies and match it up with other data, mainly provided by the US government, about the kinds of people that live in different areas of the United States.
And then understand how the characteristics of the physical environment affect the sales of a virtual world company.
So why is it that one zip code has very, very low sales of diapers.com products and another one may have thousands and thousands of customers?
If you're interested in reading this, the article's called What Matters Most in Internet Retailing, it was published by the Sloan Management Group.
So the first thing that we found kind of summarizes some of the other things that we talked about earlier, is that when an online business opens up, it changes the cost benefit for the shopper in particular locations.
And let's imagine the closest one is two or three miles away, when an Internet store opens up.
Let's call it jeans.com.
That changes the relative attractiveness of shopping online versus offline.
So that's the first thing, when an Internet company comes into play, it changes the relative cost and benefit of shopping online versus offline.
So the second principle that I discovered, primarily in the beginning looking at sales from netgrocer.com starting in 1997, is that the way e-commerce companies developed their sales is very structured and very, very predictable.
And so what I'm going to show you now is a very interesting graphic that starts out way back in May, 1997.
And there's a picture of the US, you can see there on the screen, United States.
Those shaded areas, areas with somebody in that location, in that zip code, of which there are more than 30,000 in the United States, had actually placed an order at the website netgrocer.com.
Way, way back in the dark ages of Internet retailing.
That's why the whole map now looks rather dark and rather shaded throughout the entire United States.
How did this business grow?
How did it go from 34 zip codes in 1997 to 3.5 years later in 2001 selling into more than 18,000 zip codes?
And if we were to sit there in January 2001 and say to ourselves, in February 2001, where are the new customers going to come from?
Are they just going to pop up randomly in the United States, or will there be some special structure?
So primarily around California and primarily around the New York City area, and what you can see as the slide rolls through, is that sales tend to pop up in areas around that had existing sales previously.
So you tend to get more new customers showing up in locations that are close to locations that had customers before.
Well, there's really two reasons.
The first reason is perhaps, I buy something and I live in zip code 19123.
And when I'm at my local cafe, or when I'm in my apartment building, I tell one of my neighbors, hey, you really should try soap.com.
The second thing that goes on that's also very, very interesting is it could be the case that customers are observing the behavior of other customers.
You might have asked yourself the question, why is that e-commerce companies have really, really ugly packaging sometimes?
Why does our friend Chris at soap.com ship us stuff in a box that's green and brown and orange, and all kinds of colors that if you were wearing them, you would look rather, we'd say clownish?
So when my order from soap.com comes to the office at the Wharton School and it sits there in the office, anyone coming into the suite is going to see it.
So keep those two things in mind, because when we get to our next module and we're going to talk about how to grow the customer base and how to find those lead users, thinking about leveraging word of mouth and leveraging social observation, is going to be very, very important.
Now let's move on to Principle number 3.
So you might have wondered, and you can go to the website doppleganger.com, who your celebrity doppleganger is.
That is who's your celebrity look-alike?
If you were to walk down the street, would people ping you as George Clooney, Brad Pitt, Jessica Biel?
So perhaps Pennsylvania 19104 is almost the same as another zip code in some other place in Texas.
And so we wanted to examine this idea of whether or not similar locations that were far away from each other will also start to buy things online at roughly the same time.
So the original idea for this actually comes from a very, very interesting study conducted way back on the 1970s by a sociologist.
And what he did is he kind of changed our idea of distance from just purely physical distance to also thinking about social distance.
So in the original study, Professor Fisher showed that if you lived in Chicago, there was a higher chance that you would meet or randomly interact with somebody from Los Angeles, which is very, very far from Chicago.
So even though Chicago and Springfield are close together, in many other ways they're quite different.
Even though Chicago and Los Angeles are very, very far apart in terms of distance, there could be a lot more similarity in terms of the taste of people that live there.
They both like big cities, they both like to consume certain kinds of goods and services.
So continuing with our discussion of Principle number 3, what we found was very, very interesting.
When we looked at the sales in the Internet retailer, initially those sales started to take off in larger cities and spread, like the pattern that I showed you earlier, spread through the notion of proximity.
Meaning, people living close together were either telling each other about the good or the service or perhaps copying each other from seeing discarded boxes and so on.
So in the beginning of the sales process, those sales started to spread out by proximity from one customer to another.
But what happened over time is very, very interesting.
Sales in those key locations started to, for want of a better term, taper out and reach a steady state, and then pick up in other locations that were farther apart from each other, but yet shared very important characteristics.
So you might have two locations in different parts of the United States, maybe even 1,000 miles apart, but the basic profile in terms of the age, income, occupation, education level and so on and also of the retail environment will be very, very similar.
And because those locations are very similar in terms of who lives there and the opportunities for shopping offline, they tend to migrate online at roughly the same rate.
What we did when we discovered this in the beginning through proximity, over time more through similarity of locations, that we were able to develop something we called the long tail plot, again borrowing from our friend, Chris Anderson, but this time a long tail plot over location.
So if you look at the slide, what you'll see is you'll see, on the x axis, different locations in the United States and the y axis is the level of sales.
So the sales start very, very high in the best location, and then they taper down to the lower locations.
But those lower locations that generate small sales levels individually are still very, very important for an e-commerce company.
You can't just survive by hitting the big markets.
You have to also hit the many smaller markets that collectively add up to a lot.
It's the same idea as Chris Anderson's long tail, but this time if you think back to that previous discussion, this time the x axis is about rotation as opposed to being about products.
Okay, let's continue on now to Pete's area, which is customer assets.
And, I'm just again, going to add a couple little things here in terms of digital considerations.
And additional things we have to think about for execution.
So, as Pete told you, I'm sure very, very clearly, your key goals are to attract, engage and retain the right kind of customers.
Some customers, as Pete told you, you actually want to get rid of, because of the heterogeneity, one of our favorite buzzwords here at the Wharton school, in the customer base.
Some customers are just not worth hanging on to.
So, as Pete has told you, you should never, ever pay more to acquire a customer than you can expect to get back.
So, the customer life time value of my friend Chris, who is renting cars from Hertz, should be higher than what Hertz had to pay to get Chris as a customer.
The second thing that's very important though is the CLV, the customer lifetime value when executed in the digital marketing environment needs to also consider what I call RLV.
However, if I'm a popular guy and I tell a lot of my friends about harrys.com, I might have a very, very high referral lifetime value, because I'm bringing other people to the party.
So let me give you an example from data based on diapers.com, one of our case study companies, that just shows how powerful this point is.
So a few years ago, my colleague Jong He and I got all the data from diapers.com, and we looked at the first 100,000 customers that became customers of diapers.com.
And back in those days, if I were a customer of diapers.com and I sent an email referral to my friend Amy, and then Amy made a purchase at diapers.com, I would get a $1 credit towards buying more diapers.
Also, what I could do is, I could print out physical coupons and put them on all the cars on Walnut Street here in Philadelphia and some stranger might pick them up and take my code and enter it, and then I will get a credit if they became a customer.
So, two thing that are very, very interesting to us about this process.
First of all, about 8,000 of those 100,000 customers engaged in this customer based promotion or word of mouth, if you will, that's kind of interesting.
About 8% of the people were motivated to go and try and acquire other customers on behalf of the firm.
Now, of course, the game going back to what Pete talked about, we all know about averages, some important measures, so the average number of people that were brought in by referring customers was about four.
It's a pretty powerful number, but again, in the Internet, it's more than just the average that's important.
There's going to be some customers out there that just love you so much they may go completely nuts, as it were, and so it turned out, when we looked carefully at the data, the top 100 customers were generating about 15,000 other customers.
So think about that.
One of the most important things you can do, is you can encourage your existing customers to refer other customers.
So, non-negotiable, in the black, at the top of the slide, is that you must still attract the right target customers Pete has been talking about for the last few weeks.
However, there are three interesting nuances that come into play here.
First of all, your interaction with customers changes from just a monologue, you sending out messages, now into a conversation.
So, let me give you a personal example.
Recently I've been flying from Philadelphia to San Francisco to our west coast campus.
And sure enough, within a few moments later, Virgin will tweet back to me and engage me in a conversation.
In fact, on a recent flight, I received a direct message from somebody at Virgin telling me if I took a screenshot of my status on United Airlines, that Virgin would match it.
So think about the power of that medium to change from a monologue to a conversation.
So, that's going to be an important thing.
How can we use technology to engage in real conversations with our customers.
The second thing that we can do with customers, is we can amplify activities that go on in the real world, out into the virtual world.
So, an example that I'll get more into a little bit later on is, way back in September 2011.
warbyparker.com, another company that I'll talk about a little bit, staged an event in the New York public library, where their friends, went in there and took over a whole floor, wearing, Warby Parker glasses.
This was of course picked up by the traditional press.
And then, there was an amplification, from that real world event, pushed out through the virtual world.
And then finally, the third point is, we need to be aware of this possibility of what I'll call the long tail leverage.
The long tail is the idea, the conceptual idea, that there are some people who are just sort of extreme, like those customers for diapers.com that referred 150 customers each when the average was only four, so how do we use technology to tap into who those people are.
Okay, one final thing I'd like to mention here, guys.
But it's a very, very interesting distinction that's important for thinking about how to execute with customers.
Through things like loyalty programs and referral programs and so on.
And both of these things are very very important to companies who want to get customers to acquire new customers.
So let's start with the selection effect.
So imagine I'm a customer of diapers.com.
And diapers.com is going to give me some cash, or some points if I refer somebody else.
Now, I happen to refer my friend Chris, just because I know that he recently had twins, now the CEO of diapers.com doesn't know that, but I know that, so I'm better able to find a new customer.
So the person who's doing the referring is deliberately picking out people who are going to be very, very appropriate for the good or ser, for the good or service.
That's the selection effect.
And my colleague here at the Wharton School, Christophe Van den Bulte, has shown that customers who are attracted through word of mouth and through referral, have higher customer lifetime values than those who are not, because of this selection effect.
The second effect is what I'll call the treatment effect.
It wasn't through Google search.
But he got introduced through me, his trusted friend, and because that was the way he found out about something, it's more natural then for him to engage in the same practice.
So, when we looked at that diapers.com data, remember I said on average, there was about an 8 to 10% rate of referal.
Well, if a customer was acquired because of referral, the chance that they then referred went up to about 15 to 18%.
So that's the difference between a treatment effect and a selection effect.
But both of those things are very, very important.
Number one is the brand, we've just through.
Number two is the customer, and then the third one that I mentioned at the beginning of this module is that marketing expenditure itself also should be thought of as an asset.
And, again the naieve way of thinking about marketing is we have top line sales, minus what we spend on marketing or advertising, is equal to our profit.
Now, if we make that marketing span equal to zero, it's not the case that our profit will go up by the same amount.
That's something that we'll be exploring in more detail as we go ahead.
So the first thing I'd like you to do, just over the next few days, is to try and think about some experience that you have buying coffee, paying for something, booking a hotel, communicating with your friends, keeping track of your appointments.
And try and think about how the status quo situation could be solved or fixed.
In the same way that Howard Shultz figured out that the coffee situation in America, was sub optimal and he fixed it by introducing Starbucks.
And try and think about what you've learned from Barbara and also our additional discussion today about how in the digital age a brand needs to be authentic, transparent, and humanized and try and see what elements of the execution in that website touch on those three points.
Hopefully, you'll have a good time doing that.
And that's the end of this particular piece.
So now we're going to get into some very, very interesting material that relates to what we were discussing earlier about lead users and people who are important to reach out to.
We're going to examine that issue in more detail by trying to understand how information spreads from one person to the next, either in an offline environment, or an online environment.
So first of all, I'm going to show you a very, very controversial study.
And I'm going to ask you to click on the link to play it yourself.
It's about a minute 45 seconds.
It's a study on the spread of obesity through a network of people in Boston.
I think you'll find it interesting just in terms of understanding what a network really is and what the elements are.
I'm making the summarize by definition what things take place in networks, do you need individuals, do you need them to be connected and so on.
Instead of the individual, we're going to think about locations.
The first example is going to be some of my own research on Internet retailing.
And we're going to look at how a company called netgrocer.com spread itself throughout the United States through a process of word of mouth, contagion, and so on.
So think of that as being in Facebook, or one of those other social networking environments.
It's going to be looking at a network of physicians in Los Angeles.
So, if I'm friends with Chris, Chris now is the doctor, he's our all-purpose videographer and he's prescribing a certain kind of drug to his patients, maybe because he and I are friends or he's influencing me, I'm going to prescribe the same drug.
That's a study done by some colleagues here at the Wharton School in conjunction with another professor at USC.
This is also going to look at diffusion for an Internet retailing company.
So let's begin.
And it's actually out of a book by some professors at Harvard.
But I'm just showing a visual here on the screen.
Basically, what the study proports to show is that obesity spreads almost like a, a virus.
Like a flu, or something else, that's why it's controversial, from people who are in a network.
Who's perhaps struggling a little bit with obesity then I'm more likely to become obese than somebody who's not in that social network.
That's why it's a little bit controversial because it's hard for us to get our heads around the idea of something like obesity, which is a physical thing, really spreading more like a virus which is a cold and we can imagine that being transmitted.
Again it's about a minute and 45 seconds.
Now that you actually watched that, let me just sort of reiterate what the elements of networks are.
And share what I think are some of the most interesting research findings here.
So one of our colleagues at NYU, Sinan Aral, who does a lot of work in the area of networks, he says, really what a network is, is, involves pathways through which information and resources and support flow between people.
Or, we could also extend this to, to neighborhoods.
So it could be a social network of people who are going to the same church or the same club in Philadelphia.
Or it could be virtual, like Facebook, LinkedIn, Twitter, and so on.
Now what's really interesting here and what's written at the bottom of the slide is that networks usually exhibit something called homophily.
But that's a good one to hang on to.
If you mention it at the next party you're at, you'll be very popular.
So people who are using friends, people who are your close associates.
Probably on average, are more like you, than they are just like random people.
So people have similar cultural backgrounds, similar tastes, similar income levels, tend to kind of flock together, whether it's in a virtual neighborhood, or whether it's in a physical neighborhood.
We'll be coming back to that later on.
So a network can be really, really simple.
Chris and I, we're friends.
So it could also be hundreds, or thousands, or even millions of people.
I guess, by now, at least a billion people are connected in one big social network.
You then need to have some kind of connection between people.
And then also some ability to share information, share resources, and have exchange.
So if you want to see some more background on that, again I've provided another YouTube link for you to be able to do so.
So that's an important thing to keep in mind too.
Is that entering a network, whether it's joining a local club, going to a local church, or participating in a social network, is a choice and presumably other people have made the same choice.
we also decide the networks, whether they're real networks or social networks, virtual networks.
How many people we want to be connected to.
And then thirdly, at the bottom of the slide, an important principle is how embedded we are within a network.
So imagine, for example, that I'm friends with Chris and a whole bunch of other people at the University of Pennsylvania.
And I'm connected to almost everybody on the campus.
If that were true, then I would be a very embedded person.
Because I'd be connected to everyone who's then connected to each other.
So in some sense, I might be more central than other people in th network.
Okay, so, a little bit of interesting research that's been done I guess over the course of the last 40 or 50 years, about how networks work, and how influence works.
I might be influenced just by seeing what other people are doing.
So way back in 1968, some professors at Columbia did the following experiment.
They put a person on a street corner in New York City and the person was, like this, looking up at the sky.
And what they wanted to see was, would other people around also, upon seeing somebody looking up at the sky, also look up themselves?
Now when the experiment is put 15 people around, just standing looking up at the sky, then about 40% of the people who weren't part of the experiment also just looked up.
So what that tells us is, it tells us often times, there's pressure to do things when people around us are engaging in some sort of behavior.
Or it can happen through observing things.
another classic study of influence that was done in the 1960s, really, really helps underly the key concepts here.
It was also repeated in 2002.
So let me explain what that experiment is.
It's a very common phrase, and it's often used to indicate that there's no more than six people between you and anyone else in the world.
So all of us out there enjoying the Coursera class are connected by no more probably than six degrees.
So what do I mean by that?
Let me go back to the original study.
To write a letter to individuals who lived in a different city in the United States, in Boston.
So again, let's imagine they were asked to send letters to people like Chris in Boston.
What they had to do, was to write a letter and send that letter to somebody that they thought was closer to the person in Boston than they were.
New York City is closer to Boston than Nebraska is.
And what they found was it took about six steps, hence the term six degrees of separation.
Now that same experiment was repeated by some professors who did something called The Small World Project, you can look that up on the Internet, in 2002, where they got 98,000 other people to communicate random people around the world, communicate with them.
But this time not through physical letters, but through typing and sending emails.
So I might be asked to send an email to someone who is an orthodontist who lives in Finland.
I'm not allowed to Google that person and email them directly.
I have to email somebody who I think is going to be more likely to know that person than I am.
And again, it seemed to take about six steps.
We're all connected by about six steps.
Now that's connections but connections don't necessarily mean influence.
It turns out that for influence, there are really just three levels or three steps that matter.
What do I mean by that?
So again let me think about my friend Chris in the example here.
So Chris and I are friends.
So if I tell Chris, hey Chris, you should order all your detergent from soap.com.
I might be able to influence his behavior.
And then Chris might tell his younger brother, let's say.
But I almost have zero influence over Chris's younger brother's girlfriend's college roommate.
So that's another very, very important thing to understand in terms of influence.
Influence spreading out from you typically will not go more than about three steps.
So today we're going to talk about pricing devalue as part of our go-to-market strategy.
So let me just give you a little bit of an overview of where we're going to go.
Then we'll talk about a framework for how to understand, how to set a price.
And then we'll spend a little bit of time on customer price sensitivity and how to measure it and how to understand it.
And before I say this, pricing is probably one of the key things to really think about in marketing because often times prices are made really really arbitrarily.
Or people engage in cost plus pricing, many things that they shouldn't be doing, and what we want to do in this session is to think about the right way to set a price.
Here's a little bit of motivation for you from a study that was done by the McKinsey Company that looked at various things that firms could do, over 2,000 companies, to improve their operating profits.
But the thing that they did that had the most impact, if they were able to improve their final realize price by only 1%, they were able to increase their profit operating profit by about 11%.
So price is such a critical level, and it's one that we often get wrong, so let's keep that in mind as we go through.
It's a company that sells a lot of private label product.
I believe it's owned by some German brothers, operates in the United States all over the country, there's one here in Philadelphia.
So one of the products that I like there is they sell goza a dumplings that I can buy and I can steam and I can eat them.
Now let's imagine that those dumplings cost me about $3.99.
And I face a problem.
The problem I face is I can't find that product anywhere else, because it's a private label.
So Trader Joe's recognizes that I have this inference problem, so what do they do?
They take a very very common product like bottled water that's available everywhere and then price it at an extremely low price all the time.
So when I come into the store and I see that the bottled water, a product that I can compare that's available everywhere, I see that that's priced very low, that gives me some confidence that the products I can't compare are also fairly priced.
So this example is showing how sometimes as companies, we want to signal through one kind of product, that we're a good seller.
A similar example, if we think about a company like Wal-Mart.
So that's another example of using the product price to send a signal.
The final one I'll share is a very interesting study done by a friend of mine from New Zealand who teachers at the Sloan management school up there at MIT.
And my friend Duncan did an experiment where he sent out shoe catalogs to people all over the United States.
The other half of the people, this is thousands of peopl,e received an identical catalog except the price of the shoes was $49.
Now economics 101 tells us that as the price goes up demand should go down right, but Duncan found exactly the opposite.
Because when you see $44 the way you encode it psychologically is, gee, that's kind of a weird price, I don't normally see 44.
But when you see 49, you feel like that's a discount from 50.
And so what I'm trying to indicate through these examples is the price is more than just a number that indicates what you have to pay.
So how do we set prices and what's the right framework?
First of all we need to think about the marginal cost of the product I'm going to call that the floor.
Obviously we don't want a price below the floor or at least not for too long.
Then we need to think about the ceiling which is the customer willingness to pay.
So number one is the floor, number two is the ceiling, the customer willingness to pay.
But you can't always charge people their absolute maximum willingness to pay.
Why is that?
Because of competition.
So competition is going to be the third factor that will drop the possible ceiling.
If my customer is willing to pay $10 but he can get that product from a competitor for six, then that's going to drop my price from ten down to six.
And then number four is the amount by which prices have to be raised from marginal cost to give some money to distributors or re-sellers to motivate them to sell it.
I'm also going to show you a couple of examples of something called economic value to the customer.
This is a very, very important concept.
There's a product called the wing dipper.
And the wing dipper is a place where you can put the dip within what you want to, to dip your chicken, chicken wings.
I guess it turns out when people eat chicken wings, I don't eat it a lot myself.
And so therefore the restaurants are losing a lot of money whereas if they had these wing dippers, the wing dipper controls the amount and based on the size of your restaurant and the amount of wings that get eaten you can calculate as a restaurant what the economic value of this product is.
So many times in your communication you're thinking about the economic value to the customer and trying to say that in a persuasive or informative way.
So first of all from a company point of view when your setting a price you might need to think about financial considerations what's my required internal rate of return.
So the price that I'm going to charge for the Toyota Camry is somehow going to be related to the price that I'm charging for the Toyota Corolla.
So you need to think about spacing out the prices in a way that's consistent.
And then thirdly you need to think about your own existing image so it may be very very difficult for Walmart who has a low price image to sell really really expensive stuff.
Similarly it may be very very difficult for Sak's 5th Avenue to sell things very very cheaply because that's also inconsistent with their overall image.
So those are three things that are very important to think about from a company point of view.
From a competitor point of view there's a whole raft of things, but here's the three most important.
The first thing you need to think about is that when you set your price, how will your competitor respond?
Is the competitor going to do things that are rational, does the competitor have a deep pockets and so on.
The second thing you need to think about is when you do something in the market with your price how is that competitor going to respond?
So if you're the market leader, in some sense you have a responsibility to try and keep your prices high.
If you're a follower you might have a different kind of strategy.
So those are three important things with respect to competitors that dictate what you want to do with your pricing.
So are you pricing in such a way that allows the collaborator or distributor who's selling your product to turn the product frequently enough?
So this is where I'm going to spend the most time, and the key idea is customer price sensitivity.
In terms of economics, this is sometimes referred to as a price elasticity.
In economics, price elasticity just means the following: if I raise the price by 1% by how much does demand drop?
So if I raise the price of my product by one percent and demand drops five percent that means that the product is highly elastic, there's a lot of stretch to the price.
If I raise the price one percent and demand only drops 0.2 of a percent, that means that the product is very inelastic, very very little stretch.
If I have an inelastic product, I might be able to raise price.
If I have an elastic product I might want to drop price.
So we're going to get into how as marketers we actually measure that beyond the economic concept of price elasticity.
A second thing we're going to talk about are psychological issues.
The first thing is the ending of the price.
I'll also talk a little bit about something called mental accounting.
I'll give you a short summary of a very famous psychological principal called Prospect Theory or psychological theory.
Actually a noble prize winning theory that has some very very interesting implications for pricing.
Right, so the first thing we want to think about in terms of customers is what is it that drives price sensitivity, this fundamental thing that dictates how high or how low somebody's willingness to pay is for the product.?
So I'm gonna go through some of the most common things that dictate price sensitivity.
The first thing that really drives price sensitivity is ease of product comparison.
So if I have one product, product A, that's say manufactured by Johnson & Johnson, and right next to it on the shelf, I have another product that's made by the retailer, a private brand, as Barbara talked about.
If they're really easy to compare and I can turn the products over and see that they're essentially the same thing, then I might be willing to buy the unbranded or the private label product.
So when comparison is made easy, consumer price sensitivity typically goes up.
So as a seller or as a firm, as an entrepreneur, usually what you want to do is you want to make price comparison across you alternative and the competitor alternative somewhat difficult for the customer.
You want to focus them on other things like the quality of your product, your service, and so on.
So if I'm going out and I'm buying new tires for my car and the tires, $500 versus $600, I might be like man, I think I have to get those $500 tires.
But if I'm buying a car for $20,000 and the dealer Amy says to me you know what?
You can have these fancy tires for 600 or like the rubbish tires for 500, I'm like well, it's only another 100 bucks on 20,000, it's nothing.
So when we're thinking about things in percentage terms or as a small piece of an overall expenditure, our price sensitivity also goes down.
So what's the implication for you, the seller?
You want to try and get the buyer to think about what they're buying as really a small piece of the overall picture.
So maybe I shouldn't say this on a public video, but I've already started down the path so let me do it anyway.
So I try to save the school money when I fly from Philadelphia to San Francisco, usually buying a coach class ticket and then trying to upgrade into first class if I'm lucky.
But sometimes I might actually buy a first-class ticket, but of course I'm being reimbursed for that.
The other thing that's very, very interesting in price sensitivity is when there's a separation in time or method of payment.
So in an earlier video, we spoke about the matching of supply and demand and the example I gave you was Uber, which is a car service where you can take your mobile phone, and you can order a car to come and pick you up.
And then the driver, let's say Chris, takes you wherever you want to go.
Simply what happens is you get a text message, or on the app, you get the bill.
So in that case, I don't really feel the pain of payment.
The pain of payment.
If I had to take $20 out of my wallet every time I used Uber, I might think about walking a little bit more often or taking the subway.
But because the payment is happening just purely in my phone and I'm not feeling it directly, I'm because less price sensitive.
So that's another thing that makes price sensitivity lessened.
So if I needed to hire a lawyer, for example, if I were in some kind of trouble with the immigration service, do I want Amy's cheap lawyers $50 an hour, or do I want Chris's expertise lawyers $500 an hour?
In that case, where there's an inference that the higher price leads to a higher quality, certainly for an important service, then my price sensitivity is again lessened.
So hopefully, those four things give you a sense of how you can have the customer psychologically feel a little bit less price sensitive.
Now, of course, this begs the question of how would one measure price sensitivity?
I'm gonna show on the screen a 2 by 2 matrix that explains these four different ways.
You could measure people in their natural environment, buying things or filling in surveys.
Or you could run an experiment, sort of an unnatural environment, but it's controlled, either in the field or the lab, or you could engage in something called trade-off analysis.
Those are the two columns of this matrix.
And then on the rows, you could either measure actual purchase behavior or you could measure their preferences and intentions.
This was actually done by a colleague of mine at the Wharton school, Steve Hoch, who's a professor here.
And he wanted to try and understand for supermarket retailers whether or not they could raise prices or lower prices.
So what they did is they cooperated with an institution in Chicago, those of you who are in Chicago, called Dominick's Finer Foods.
And what they did was in some of the stores, all of the prices were systematically lowered by about 9% on a bunch of different products, like detergents, paper towels, canned tuna and so on.
And in the third group of stores, all of the prices on those same group of goods were increased by 9%.
So, that's a classic experiment where we have a control group, we manipulate some things downwards, some things upwards, and then we look at what happened.
And what they found was very, very interesting.
So this experiment would indicate that those multi-product retailers could probably increase their price a little bit, and you can probably think of some psychological reasons why that works in a grocery environment.
Like it's not really efficient for me to pay attention to every single price and try to remember it.
It might be a different thing if they did it today in 2013, because again, I could take out my friendly iPhone, and have my entire grocery list on here.
Or I could use an app like the SaveOn app or the SnipSnap coupon app, and from those apps I would be able to remember the prices, or at least my device would do that for me.
Second way that we can measure price, and this is a method that was really developed by one of our former colleagues here at the Wharton school, Professor Paul Green.
So in a conjoint analysis, you present people with different kinds of stimuli.
I'll give a personal example on this.
What should be the price?
Now, we knew, of course, we didn't want to price purely from the cost and the cost plus pricing, we wanted to figure out from the top down the customer willingness to pay the ceiling.
So Amy's group would see a pair of nice blue Warby Parker glasses, and the price would be $75.
And then we'd ask Amy and the other people in the survey how willing they would be to buy that product.
And we did this for four prices, 75, 85, 95, and 105, and through the conjoint analysis we noticed the following.
So from this pretty rigorous statistical analysis it was clear to us that among those four prices, $95 would be the right price.
This is something for those of you out there who want to do conjoint analysis.
There are many very good commercial providers and consulting firms that can help you do this, and a lot of good publicly available information.
I'd encourage you to learn a little bit about conjoint analysis.
We don't have time to go into all the details here, because its also a method that's very useful for trying to value your brand as well as just set prices.
Okay, the other two methods that sometimes get used are just direct surveys.
So the better way to ask that question through a survey is indirectly.
On a scale of 1 to 7, 1 meaning very unlikely to buy, 7 meaning very likely to buy, how likely would you be to buy this product?
And then I take the same survey, and I take it to Chris and a bunch of other people.
That's the best way to do it through a survey.
And, then finally, this is not a direct topic for our course together, but something I do a lot of in my own research, is you could run what's called a regression analysis.
So those are the four ways that you can really measure price sensitivity.
So now I'd like to spend a little bit of time just on psychological factors.
Of course, there are a huge number of books written on consumer psychology and so forth.
So in certain countries or cultures, digits have particular meanings.
And so that's why a lot of products are priced at 3.99, 2.99, 1,999.
So 9's are a special kind of number, at least in Western cultures.
The second thing that's important to notice, from a psychological point of view, is the demand curve is not always smooth.
So let me give you an example of that simple experiment that was done in the UK in some supermarkets over there where the regular price of a product of margarine was about 83 cents.
And at 83 cents the supermarket was selling a couple thousand units every week.
When they discounted the product to 63 cents, the price went down and demand went up, increased by quite a lot, almost 200 percent.
So dropping the price 20 cents led to a 200 percent increase in demand.
However, when the experimenters dropped the price just a little bit more from 63 to 59, then the increase relative to the 83 cent price was 406.
So that's a classic example of a threshold or a nonlinear response to a price reduction.
So those of you who might not have taken a marketing course before, you might have thought yeah, marketing's all that cool kind of advertising.
So let me go through and give a little bit of an overview, as I typically do, of where we're going to go with this last piece of material in module three.
First of all I'm just going to show you some trends and some data how much are we all engaging with various different kind of media.
Not just TV, but radio, our phones, the internet, and so on.
And then finally I'm going to give you some updates in terms of how social media marketing is being done and what's sort of working and not working in that environment.
So first of all, the trends we can go through fairly quickly.
You might want to dig into these a little more, and to, to discuss them, and also look for some of them online.
So the first one here, again, these are US data, but I would imagine they would be somewhat common around other parts of the world, too.
One of the interesting things to me in this particular graph is that TV has remained pretty flat from 2010 projected through 2013.
People still seem to like watching TV, although they may be doing it in different forms now.
If you look at the spending, spending on all media is up fairly considerably, again with TV sort of leading the way.
And then the final chart I wanted to show you is just the expected increase in marketing that's done on the internet.
Search engine optimization, display advertising, mobile marketing and so on.
And again, when we get to the end of this discussion I'm going to give you some of the latest research on those different types of media that we could be engaging in those different types of technologies.
So just to wet our appetites a little bit for what's coming next, I'm going to show you a classic campaign from the United States way, way back when, back in 1992.
So this was the situation that was faced by the Californian Milk Processing Board.
Hopefully your companies out there don't look like this, but you can see a fairly precipitous decline from 1987 to 1992.
Whatever their reasons were, clearly consumption of milk was going down and the California Milk Processing Board wanted to try and address this problem.
So like all good marketers, they did some surveys and they found that basically people thought that milk was healthy.
And so the goal was to increase the consumption of milk by having people store more milk in the home.
When you have more product on hand, you tend to use more of it.
So if you had a 12 pack of Pepsi in the fridge, you're going to drink a lot more Pepsi than if you only had a 6 pack.
And if you're interested in this kind of idea, particularly as it relates to food, go and take a look at Brian Wansink and his book called Mindless Eating.
So here's a commercial, I'd just encourage you to watch this on your own time.
It's a commercial that was put together by the milk processing board, to kind of illustrate the point that it would be very, very important for you not to run out of milk and to have milk in your home.
I won't spoil the punch line for you, but the commercial starts with a fairly obnoxious, obnoxious guy probably in some large US city, perhaps New York City, and he's yelling at somebody on the phone and firing them.
A good ending you might think, but the story continues from there and I'll let you watch that and and see what happens.
So as a result of this campaign, it was very, very effective, for the California Milk Processing Board.
So, first M is the market.
Perhaps there are people who don't like milk for health reasons, so let's focus on current users.
The message content was to encourage people to make sure they have enough milk on hand so that they don't run out.
The media strategy was to use TV and print, of course we're back in 1992 at this point.
Why is this important?
If you're spending $10,000,000 on advertising in stores, five million's wasted.
And this is really the perennial problem of spending money on marketing, is that sometimes, you don't know whether it's effective.
And even if it is effective, you're not sure exactly why.
And that's why I said at the beginning of our time together, we should be thinking about marketing expenditure on advertising and other things, not as a strict expense that's purely negative, but really more like an asset that's going to give us some return in terms of more customer affinity, more loyal behavior, less price sensitivity, more consumption and so on.
So they measured two things in particular.
And firstly was to do with the execution of the campaign itself.
That's important.
So how many people could actually remember the campaign within three months of it being shown?
There's 60% of people could actually remember having seen these series of ads about milk.
You might want to go and look at some of the other ones, in addition to the one that I've put in the slides.
And then secondly, you don't want to just measure the effectiveness of the campaign, but you want to measure the effectiveness of what the campaign is designed to do.
So now we have that classic campaign out of the way.
Perhaps you have your own favorite advertising campaign that you've been exposed to.
Do you think the advertisement was effective?
How would you have measured that effectiveness if you were the one running the campaign?
How am I going to position it?
What are we trying to accomplish here?
How much money are we going to spend and in particular what return on investment can we expect to get?
And then finally the Measurement.
This is absolutely critical.
You want to measure both the effectiveness of the campaign itself, do people like it, remember it, understand it?
Did I sell more, did people like me more as a result, did people change their opinion about what it is that I'm doing?
Okay, so we've mentioned this a little bit earlier on, so some of this is going to be somewhat of a recap and a repeat, but I hope that's useful for you too.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So, let's first start out with, what are perceptions?
Perceptions is probably one of the most important aspects in consumer behavior, and in understanding consumer behavior.
What is a perception?
The perception is the process of developing an interpretation of a stimulus.
Or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever cons, customers perceive, is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
And this process is inherently biased.
It contain, it, the process of perception comes in several different stages.
The first two stages are, the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
Pay attention to what's salient to you.
And we know that that process is very biased.
You only expose yourself to things.
But when you're consciously exposing yourself to things, many times it's a function of what you believe, what you're prior beliefs are.
Let me give you an example.
Say you think that a part of town is not safe.
Well, you won't go to that part of town.
You'll stay away from that part of town.
So you won't expose yourself to something you don't think is safe.
As a result, you never have, ability to change your perception, of that area of town because you don't collect new data.
So we know that exposure can be selective.
Similarly, even if you are exposed to something, if you don't pay attention to it, again it can affect your, your perceptions.
And we know that there's 2 kinds of attention, there's voluntary attention, and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you would had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure, and selective attention.
That means you're not collecting data on things that might be, might be able to change your perception.
So that's first stage of bias.
The second stage of bias is once you are exposed to something, and if you pay attention to it, then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who in interpret what happened in the debate from both parties.
Because we know a priori, the interpretations are going to vary based on their prior beliefs.
And, that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli.
As a result of this, perceptions are frequently biased, and they don't necessarily represent what's true.
So what's the overview of the perceptual process?
There's, we're going to talk about it, brand communication, there's advertising, there's packaging.
And then you are exposed to them, or you're not.
And sometimes the exposure, as I mentioned, is in a bias, bias way.
And then, even if you are exposed to these inputs, you know, and you're exposed to thousands of marketing measures, marketing cues every single day.
But how many of them do you pay attention to?
So, first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it.
And finally, there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that, your perceptions, and I just explained to you your perceptions could be biased, but your perceptions affect your subsequent behavior.
Regardless, it's almost an automatic reaction.
You have a certain perception, and then you automatically respond to that.
And it's very had to control that, even if you think, well I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that, so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So, here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
I mean, the first one, maybe you were a little bit surprised.
And you saw that the word was blue, but the color of the font was red, so the answer was red.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word, and reading the word affected your subsequent behavior, it slowed you down.
That's actually the purpose of the Stroop test.
It's a stress manipulation, it makes people feel a little bit uncomfortable because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches and you can see, it's much easier, it's much faster to say the words.
This is the same thing in the way marketing I'm going to show you that color has an effect, brand name has an effect.
It affects your subsequent perceptions and subsequent behavior, and it's an automatic reaction that's difficult to stop.
So let me just give you, here's an example.
If I told you this is luscious chocolate, and I show you a picture of it if the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh I don't want to eat this, that disgust feeling.
And you know that it's good chocolate, but the shape has an involuntary effect on you.
And that, that's a very important thing to understand.
So marketers need to understand how these things affect your perceptions and your subsequent behaviors.
Because as I say these are automatic reactions.
There's some visual illusions you may have seen these before.
I can show you these two lines on the screen.
I will tell you you can measure them, they are exactly the same length.
However one looks longer than the other, and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you, what is this that I've put on the screen.
You'll answer differently if I show it to you this way versus when I showed it to you this way.
And so that shows you what you perceive that stimulus is, is a function of your prior expectations.
And what the proximity bias says, is if things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that they'll cluster the two lines that are close to each other, rather than say the two bold lines or the two thin, thin lines.
And you can see this in the supermarket, in stores.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception.
That physical distance affects whether things are similar or belong together.
In the mall, stores that are close together or seem to be more similar.
Things that look alike, people assume have the same quality.
So this is the the, the underlying the, theory behind, say, store brands.
You're making an assumption of perceived quality, based on this process of similarity.
And it's a very, very important consumer process for marketers to understand.
It's particularly important in branding.
With the Coca Cola brand on it, people will think it tastes better.
They're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product's exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that, I know.
I can judge certain products by the quality.
And, we know from experiment after experiment after experiment, that, that's just not true.
People are very much influenced by the brand name that's put on the product, independently of the product quality.
it's same way in the Stroop test.
You just can't stop it.
Once you see that brand name, you have certain perceptions.
We know that brand is such a powerful brand as we mentioned before.
The Coca Cola brand name has been estimated to be worth 70 billion dollars as an asset.
Just putting that brand name on a product will change, as I said price premiums people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So ex, for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time, that no one had tasted before, a diet soft drink.
They call it Diet Coke.
And automatically, even though that product was not on the market before, people assume it has hot better taste, it's a higher quality product.
And again they're willing to pay a higher premium price for that product.
So now that we see how important a brand is at creating perceptions of quality, let's get into some of the inner workings of a brand and talk about the different elements of the brand.
So there's a variety of brand elements that can be chosen.
and they will totally identify or enhance the brand awareness.
And if you choose them right, they can help facilitate the formation of strong, favorable and unique brand associations.
And so the things we'll talk about are the brand name, which is the first one, the anchor.
different brand logos, symbols brand characters, packaging, brand slogans and brand colors.
When you're looking at all of these brand elements, you gotta ask a couple of questions.
First of all, you have to make sure all the brand elements work together to create a unique identity for the product and service.
So make sure that everything you've chosen is, is of one, one thought, one, one belief and work together in unison.
And the second thing to think about is if people see the brand elements or whatever you do create for that brand identity independent of the product, what would people think of just that brand label?
and when we consider each of the different ones, and I'll go over all of them in, you know, in various detail.
But, when you think about all of them, you should think about these criteria for choosing a good one.
The first thing, when you, when you think about choosing different brand elements, you really want them to be memorable.
You want people to be able to recognize it very easily, and you want them to remember what they've seen.
The other thing you want to have happen when you choose these elements is that they're meaningful.
And they can be meaningful in two different ways.
And the other thing that we're looking at is remember these, this brand label is forming a perception.
So you also want these brand elements to work together to persuade the customer of something usually of something positive.
You want it to be rich visual imagery.
And you also, if you have visual and verbal image, imagery, you have to think about how those two things work together.
Again, you want a congruent unified vision here.
Another thing to think about, and this is very important, is can you protect your identity?
And so many times, if you have a good brand name, you trademark it and then it's against the law for people to copy your brand name.
But they may do something that looks similar and they can kind of steal your identity by just looking similar.
And so you not only want to have legal protection, but you want to try to identify a brand image and brand elements that work together that are hard to copy.
So that you have some sustainable competitive advantage, in addition to the legal protection that you may have.
When you're thinking about this brand, remember, it's very expensive to create a strong brand name and it's an extremely valuable asset.
And so the other thing you want to think about is how adaptable is this brand name to go, to stay modern?
times change, consumer's taste change, competition changes, and so you don't want a brand name that is so, is so static that it can't adapt with changing times, and it's not flexible, and it's not updateable.
And along this line, you also want a brand name, if you can, or a brand image, with all these elements that work together that you can use them to go on to different products, if you introduce new products.
So I mention Coke started out on a regular a full calorie cola drink, and they stretched that brand name to go to a diet cola drink.
So you want to think of brand images that can go, not just on your initial product, but could perhaps go on other products in the future as the company grows.
And similarly, you want a product that can go across cultures.
Into and that's some, a brand name, I mean, that can go across cultures.
So you don't want something that won't be understood or be interpreted differently or inappropriately in other cultures.
And each element in, in thinking about this brand image, are going to play a different role in creating those overall perceptions.
They all have different strengths and weaknesses.
but you really want to think about how you can use them strategically, to achieve some kind of balance and overall impact.
And again, as I mentioned before, they have to work together to, to form a unique, consistent image.
It's the anchor and it's very, very important that you can choose a, a, a good brand name.
Sometimes you're, there's legacy brand names and you have a great deal of awareness with a particular brand name.
And maybe it wasn't the best one to choose, but you have to use some of the other ones to build it up.
They actually weren't such great brand names because they don't have the advantage of a good brand name of being quick, easy to process, easy to remember.
And in both of those cases the marketers us other elements to, to, to help with the brand names.
But if you can choose it in the beginning, it's better to choose one that's easy to process and recall.
Because, the disadvantage of a brand name, is once you bring up that or develop that brand awareness and people really understand what it is, it's pretty difficult and expensive to change.
It's not impossible.
But a lot of the whole brand imagery is really anchored on the name.
So the name, and I'm going to spend some time thinking about that going forward, is extremely important to think about.
They can reinforce any of your brand identity.
they, they can be ambiguous.
Not all brands have a character, but a character, if you do have one, can be very quick, very attention getting.
Think about what happens if you see Mickey Mouse on something.
I mean that's a world famous character, recognized every where and people understand it's fun, it's kids, it's exciting.
and so characters can work very well, but they can get outdated, or they can be culturally bound, and certainly not all brands have a character.
A slogan and a jingle, if it's done well, gives you a few more words and can give you music to add to the brand element, so it can be used to convey meaning.
Nike's Just Do It is an extremely strong slogan, that adds to the Nike brand name.
but again, sometimes it's difficult to translate.
Sometimes if you do jingles, musical tastes are different, and not everybody likes it.
Some people think mus, some of these jingles are annoying.
and we go back to this notion of perceptions.
So this has a very very strong effect on creating perceptions.
The difficulty with packaging is many times you don't control how it ultimately reaches the consumer.
So for example, if you want the package oriented in a certain way, like front on, it may not appear that way on the shelf.
Or if it's supposed to be refrigerated, it may not be at the right temperature, etcetera.
So the problem with packaging is that, these channel issues.
If you choose them strategically, they can work very well to create a very strong brand image.
Let's look specifically at this notion of brand names.
Now, the brand name is extremely important for many, many audiences.
Obviously, and what we've been focusing on here, it matters to consumers and customers.
And, it can, as I mentioned before, seriously affect the likelihood of purchase.
It also effects people who work for you, for employees.
People can be very proud of the company they work for.
and the reputation and brand name of the brand may make it easier or harder to hire people, to retain people, and may affect their morale and productivity.
it also, the brand name, affects growth opportunities, like I mentioned.
If the brand name is not adaptable and not transferable, it may be difficult for the firm to go into new markets or to go into different products.
And so it affects the growth potential of the firm, and it affects investors.
So just, investors are people too, and they can be very much affected without even realizing it by the brand name.
about using the value of the brand name to infer make inferences about the merits and strengths of the firm as an investment opportunity.
So the brand name matters a lot in lots of different ways.
There's lots of examples, and I'll just go through this kind of quickly.
We can look at this chart here.
You know exactly what the product is by the brand name.
A lot of the legacy brand names are based on people's names.
So Ford or Ralph Lauren, those are real people.
And the brand name was chosen for, because it's based on a particular person.
Sometimes there's brand names where the word means something, but it's not really clear how it applies to the product.
Apple's a great example of, of that kind of.
You know what the words mean and now, certainly, they're very famous brand names, so you understand what they are.
They kind of sound like they're a real word, but actually they're not, like Lucent or Spotify.
You kind of have a sense what those brands mean, and you think you know what those words are, but they're not real.
Or you can have a new word that's created by blending together two other words.
Facebook is a great example of that that, that's not a real word, but you know what it is, a book of faces.
and they worked very very well, and they were all very different.
And somehow or another, that name just seemed to spark interest, and they said, well, if we started a record company, we'd be virgins in that business, so let's use that name.
And apparently that's how that name was chosen.
He mentioned that, at the time, it was considered a pretty risky brand name and it was hard to register for a while.
But now, it's become an extraordinarily strong brand name.
And, it, there, it's a funness to it that actually works really well with a lot of his products and markets.
you know, if you know what that business is, you know it's absolutely about establishing a line of prices.
It's quite clear what it means and it has been very useful in that way, in, in a different way than Virgin.
And finally Google, which you know has now become a verb, people Google things, with, it's interesting that brand name was chosen by mistake.
they meant it to be the word Googol, which is not spelled the way the brand is spelled, and that, that's a very, very large number.
Google's a very, very interesting brand name from a marketing point of view because one of the things that we argue is extremely important in brand names is consistency.
And Google has met, because it is so well known, and people identify it in just little pieces of the brand name.
They identify the colors, they identify the typeface, that Google plays around, as I've showed you on this screen, where they'll show you its trademark differently everytime you see it.
Whenever you go to the browser, you'll see a different version of the brand name.
That's a sign of an extraordinarily strong brand name that has very, very high brand awareness, that you can see it even when it's not exactly the same every single time.
But these are all fairly new brand names that have been very, very successful.
When you look at new startups now, a lot of the trend in the new startups, and there was a recent Wall Street Journal article about this.
the new startups are, are making up brand names, and so a lot of the new businesses come up with brand names that are, just these invented words like Mibblio or Kaggle or Shodogg or Zaarly.
You don't even know how to pronounce some of these words.
Why is that happening?
Part of the, part of the reason is, in today's world, when you have a, a brand new business, you need a, a website right away.
And most of the recognizable URLs have already been taken and so one of the ways to get a URL that's uniquely identified with your business, is to invent a new word.
Then you're going to have to use the other elements of the brand mix to try to give some kind of identity to this brand name.
The Gap brand name, a few years ago now, I'm not sure exactly when.
And one of the things they were trying to do to modernize it was to change the trademark, or change the brand logo.
So the original brand logo as shown on the screen is a blue square with the word Gap in white on that blue square and you can see the new logo that they put out, is very different.
The blue square has shrunk, the typeface has changed it's now on a white background.
And they put that brand name out in, into their social media market, and instantly got very, very negative reaction to that brand name.
The consumers hated it.
Within, that brand name was out there, just tentatively, as a test, for one week.
The reaction was so negative that the company pulled it back and that was the end of that.
So it ended up actually being a, a pretty, it was, you know, they got a lot of publicity at the time.
So actually, that this got such a negative reaction, that they found out so quickly, it was, was a benefit for the company.
But because this was somewhat of a famous incident some market research was done, and some fMRI studies, and neurostudies were done to figure out what was so bad about that image.
Why did people not like it.
And there's a couple things that they identified that when I show you, you can see make sense.
And so where that blue box is, behind the P, it, you're, it actually kind of blocks out the P, and you see a hole in the P, and the P is not as strong because you're attracted first to the vision.
So that weakened the whole idea of the brand there.
because the P was kind of weakened because of the visual block on it.
The other thing that, that's different between the two logos is that instead of being all caps, which is in the original one, now this is an initial cap and then smaller letters.
And what that ended up doing was making people think of it as a word, rather then a brand name.
So when we're looking at these things in hindsight, you can kind of see why that wasn't a good choice.
And people just didn't have a very strong emotional reaction to it, also.
There were negative emotions to it that were kind of more on a visceral level, and what I'm explaining here is, you know, more thoughtful.
and the last thing I want to mention in thinking about brand names, is a lot of people now, you've got to think about global business.
And a lot of the business, the future business is in China.
And that's tricky to think about how your brand names might translate into Chinese.
A number of different ways to do it.
But other brands try to change their brand name into Chinese.
And this is tricky because you can do it, Coca-Cola, for example.
what does Coca-Cola mean?
How do you translate that?
And if you just go and look for the Chinese characters that kind of sound like Coca-Cola, well, the characters themselves may mean something.
So when Coca-Cola first did that and tried to pick Chinese characters that sounded like Coca-Cola, it had a very bad brand meaning.
And they had to take that one off the market.
The one they currently had, have means tasty fun, so it kind of sounds like Coca-Cola, and it means something that at least makes sense with a drink.
Reebok did the same kind of thing, the Chinese characters that they chose kind of sound like Reebok and it means, quick steps, which again makes sense.
Colgate picked Chinese characters that they thought was consistent with their brand image, which meant superior cleanliness.
And then the Chinese characters, if you said them, didn't sound very much like the word Colgate.
And Cadillac did it the opposite way.
They took Chinese characters that sounded like Cadillac, but they didn't mean anything in Chinese.
So, when you're translating to a very, very different language, and an important language like China, because of the size of the market, there are some big issues.
And there are a lot of agencies now that are developing to help you choose a name that will make sense in China.
Now that we discussed brand name, let's think about some of the other elements that can go around a brand name and I'm going to talk about two that are extremely important.
One is choosing a color.
And color has very, very strong perceptual cues.
We'll show you some of those things, but people associate a lot with different colors.
So let's start with color first.
There's a few rules about color that you should think about.
First of all, the best use of color if you can possibly get it, is to own a color.
and that's not, very many brands can do it.
There aren't that many colors out there and to really own a color is pretty hard to do.
But, when you do it it's extremely powerful.
This is such an important cue, that the Tiffany empty boxes are sold on Ebay.
And people will purchase those boxes, and then put another product, maybe not a Tiffany piece, in that product.
But, people getting a gift in a Tiffany box, this just shows you how strong the perception is.
But Tiffany's light blue box is extremely valuable brand image for their, I mean it's very high quality, and, and, many times with jewelry, unless your an expert it's kind of hard to necessarily judge quality so people will use this light blue box as a cue for high quality products.
Mary Kay owns the pink color.
color can also be used within a brand to separate product lines.
The green card, the black card, the silver card, all these different kinds of cards.
and you, you infer different qualities to the card as a function of its color.
And that's used in lots of different products, as well.
you have to be careful with color, because color can be experienced differently it can be experienced differently across different platforms.
So a lot of times if you're going to test a color you want to test it on a computer, on a phone, in real life, and the colors may vary a little bit.
And when you want a color to really be identifiable with a particular brand, you want to make sure you have that consistent color across.
and colors also can create very strong perceptions.
If, if you look at a product line and you see some of the products or it's gold or silver or black and white, that cues luxury, and you just assume that product's more expensive than more basic colors like a red and blue.
So that those colors can just signal high quality just because it's gold and silver.
Similarly, you see something that's blue or pink, you think female or male.
just by the color, can be the exact same product but the color changes and you think it's for girls versus boys.
We know that there's two basic axes of color.
There's the arousal axis, you know, how stimulating it is, versus how calming it is.
And there's the affect axis, which means how much people like it or don't like it.
The affect axis is extremely important, but it does vary a little bit by cultures.
Some colors are better liked in some cultures than others.
It is true that high arousal colors are like red and orange.
but then also, if you think about, on that affect, or that liking dimension, the blues and greens tend to be better liked colors in the U.S.
And this may be different in other cultures.
For example, orange is a very popular color in India.
And, there's been a lot of research on color.
and so there's certain things that we know of that the way people automatically react to these colors going back to that perception.
So, red for example, as I mentioned is an exciting color.
It's part of the reason why fire engines are red.
Red also means love.
But red also stimulates appetite.
They all stimulate appetite, and they all have a lot of red in their logo.
Blue, on the other hand, is a calming color and it is not a good color for food, for food.
Blue actually is a color that curbs appetite and some people have said that if you're on a diet and you want to like try not to eat as much, having blue plates can curb your appetite a little.
blue, as I mentioned, is also a color that's frequently preferred by men.
Green is a color that's tranquil.
It means health.
A lot of environmental companies use the green color to give you that green notion.
But green also means fertility.
And if you've seen some of the recent M&M's ads.
She's a pretty sexy M&M.
And that's also that green color.
Brown is reliable, bor-, a little bit boring, practical earth.
people play around with white space.
They can, it can be high design, if there's a lot of white space.
yellow is a very bright color.
It creates a lot of energy.
So, it's kind of maybe not the best color to paint for a newborn's room.
Orange is exciting, warm, it, it's, it, an enthusiastic color.
And pink as I mentioned is more of a girl's co, color.
And so one of the things you can look at is look at some of these different colors and see which companies use these different colors.
So you know, the bright yellow color is used on Nike, on Shell Oil, on Best Buy, on McDonald's, to get, on DHL, to get a lot of attention.
The red colors I already mentioned is used on a lot of food companies like Kelloggs, Coca Cola.
It's also used to get attention.
Purple is more of a creative color.
So, you see Yahoo using it, Barbie uses it, Hallmark, Taco Bell.
Blue is this trust color.
You don't, American Express, GE, a lot of really solid companies, not a lot of food companies.
and then the grey, black and white colors are more of a balance colors.
So you see New York Times is a black logo.
Apple sometimes has a silver apple.
Mercedes Benz is a silver kind of color.
But if you look at the logos and start thinking about them.
And thinking about how the colors are working, we kind of get a sense of what's going on here.
So let's look now, at symbols.
And symbols as I mentioned, Mickey Mouse is a very famous symbol.
Symbols can add a lot of fun, a lot of attention to a brand.
I had some symbols here on the slide.
And what they show is a strong muscular man, so it's assuming that you can have a lot of strength in this product.
And so you can just have fun with these different symbols.
But, the symbols can get out of date and in the last section in this, we'll talk about how you can reposition and rechange these symbols.
Slogans can be tailored to help the positioning strategy, we talked about earlier.
So that, you have a brand name and you want to really communicate that brand mantra.
And sometimes, if you just have, you know, these brand elements, you may want a slogan or a tagline that can help remove some of the ambiguity that's associated with the brand or the symbol.
and can just, because if you have these redundancy in the tagline, is reinforcing the imagery, or the brand name.
You're seeing this multiple times, it makes for a very strong message.
It's similar to a brand mantra, they have to be very short.
Similarly it should be unique, it should be easy to say and easy to remember.
you don't want it to have any negative interpretations, so you have to market test it, particularly when you go across cultures.
and again, if you have a really great tagline like "just do it" you want to trademark it so that it's protected.
And as I mentioned, an emotion if you can evoke an emotion with your tagline, that will make it much stronger.
Just Do It, Think, Invent!
Moving at the Speed of Business, bullish on America, You're in Good Hands.
Another clever one is what VW (Volkswagen) have done with their slogan.
Okay, so let's talk about packaging.
Packaging, as I said, has very strong effects on perceptions.
So let's, let's kind of look at packaging.
we started learning a lot about packaging here in the U.S.
in the 1930s, and what happened in the 1930s was that the, the grocery store was moving from the person behind the counter where you would go to a grocer or you'd go to a butcher or bakery and you talk to somebody behind the counter.
So that the consumers were going to go up and down the aisles of the supermarket by themselves and pick out products without any help.
And so the question was, how will people use packaging cues to choose what they're going to choose in a supermarket.
And so one of the early famous experiments was done with detergent.
And in one package, they had a design that had ciricles, and in the other package they had a design that had triangles.
And they wanted to see which one people would choose.
And it turned out it was very reliable.
What was different was the package.
And they use the detergent from both boxes and then were asked, which detergent did you like better?
That was the beginning of understanding that the package Absolutely in, influences the perception of the product.
And now today if you look at Tide, for example, still has those circles on its product.
even when it goes in different col, countries, things will change in the package, but you will still see those circles which we know were really preferred by consumers for choosing detergent.
So it not only gives you a reason to choose when you're purchasing.
You can identify the product, you can present some kind of information the package can be used to protect the product, it can be used to store the product.
It can aid in consumption, it gives you more information on how to use the product appropriately.
So the package not only using perceptual cues, the packaging not only uses a lot of color.
and so you have to know that packaging aesthetics are and the function are very, very critical.
The colors are used to help grab consumers' attention in, in a sea of competing messages.
And it also though has to be used so that you want to buy the product again and again.
So you want to choose, the, the variations of colors and designs so that they'll make for an impact impactful package.
but you have to, as I mentioned earlier, know your distribution channels.
Because, you don't necessarily control the way the package is ultimately distributed and there are certain, you might do some really cool things with your package and then the retailer doesn't necessarily abide by the way what those, that packages exhibited and that's just the reality and you have to think it through that when you're doing it.
Let me go over some iconic packages and how they've really changed customer perceptions and really helped build market share.
But I'm not going to be redundant and mention color again, so let me focus now on shape.
So one of the new products that came out, Calvin Klein came out - a number of years ago, tens of years, decades ago I think actually, with one of the first products that came out with a fragrance that was designed for both men and women.
And a lot of the ads showed very designy ads, and they showed models that The gender was kind of ambiguous.
And so if you look at this package of the CK Cologne that they came out with, you can see that edginess in the package.
And you can also see that they used a symmetry in their logo, which again, really gave this notion of of edginess.
And a lot of times when people choose fragrance, this is one thing we know for sure, they, they're not really experts at choosing different scents.
And so the packaging and the brand name is very influential in what people choose as the fragrance they like.
This was one of, this campaign I don't think is being used anymore, but it's one of, it was used for about ten years, it's one of the most famous print campaigns around.
And the whole print campaign was predicated on the shape of the bottle.
So vodka, a lot of times people have difficulty telling different vodkas er, apart.
The brand name and the bottle, establishing brand loyalty.
The Absolut bottle was interesting because most of spirit bottles have a longer neck because bartenders are people use a product.
And they really, really focused on the shape of the bottle in the ads.
The ads went through different stages, some of, some of the ads just showed the bottle, some of the ads showed other things in that shape, like I remember a famous one where they had an LA ad.
and they did a lot of, they used celebrities, they used artists, they did a lot of creative things, but it was always around the shape of the bottle.
Another iconic shaped bottle is Coca-Cola.
So Coca-Cola, as I mentioned, is a very very very strong brand name.
But part of that brand imagery comes not only in their logo, in their red color, in their famous polar bear ads and other types of ads they have.
But, also in the shape of their six and a half ounce bottle.
That was their first product and a very distinctive shape that people could tell it was a Coca-Cola from all the other soft drinks out there.
When the bottle went from glass to plastic, originally, when Coca-Cola came out with their plastic bottle, they lost their unique shape, and that was a decided disadvantage.
And so they managed to figure out how to recreate their iconic glass shape in plastic.
Because they understood how important that was.
And another very famous bottle of course is the Heinz ketchup bottle.
People recognize the quality of the ketchup because of the shape of the bottle.
It actually gets in the way of using the product, and yet still it really really define the quality of that ketchup, by the shape of the bottle.
So, shape is extremely important at, at causing at creating brand imagery and brand identity.
And, shape also can be in and of itself an excuse for a new product.
One of the most successful new products in the soft drink industry was the refrigerator pack.
They did some market research and they found out that if the cans of soda were in the back of the refrigerator, people did not consume it as much.
So if they wanted people to consume the product, they needed some mechanism to bring the cans to the front of the consum the refrigerator, so people could drink it.
And that package design single-handedly increased market share for the companies that started doing it.
And it didn't have anything to do with the actual product, but just the packaging.
And similarly, Hunt's came out with a, a package for getting ketchup out that's easier.
And again, that was a successful packaging innovation.
So we talked about budget brand images, and we talked about creating brand perceptions, and how these brand elements work together.
But another part of this brand identity is to persuade consumers.
So let's focus now on this process of persuasion, or changing people's attitudes.
And the dominant model that's used in this, in this way of thinking, or the dominant theory, is called the Elaboration Likelihood Model.
And so we'll talk a little bit about that.
Because they're used frequently to help persuade consumers to have positive beliefs towards a brand.
So let's start off with persuasion.
What is persuasion?
It's an active attempt to change belief and attitude.
So marketers are trying to persuade you to feel favorably towards their brands and their products.
It's difficult for the reasons that I've mentioned all along.
People are ex-, expose themselves, pay attention to and interpret data consistent with what they already believe.
That's not to say it's not possible, but it is difficult.
So the dominant model in thinking about what's the best way to persuade consumers is the Elaboration Likelihood Model.
And this model posits that there's two different ways, or two different routes, to persuasion.
There's the systematic, or central, route and there's the superficial or peripheral processing route.
The central root say that if people are motivated and they're highly involved, and they have the opportunity and the ability to process marketing messages, then the way to persuade them is through central cues in messages.
In other words, cognitive cues.
Things that people have to think about.
Try to make a strong argument.
In order to make a strong argument, people have to be paying attention, they have to be motivated, and they have to have the ability to process this information.
That's one way.
Many times, and this is true a lot with marketing decisions, people just aren't motivated to think that much.
And they, maybe they just don't want to think that much.
Or maybe they're, just don't have the ability, they're too tired or whatever.
In that case, central processing or central route to persuasion will not work.
Which are more automatic reactions, people just make decisions based on these cues.
Are they going to to pay attention and think about your, your message?
If the answer is no, they're not, then that's low involvement.
And then don't give a message they have to think about, use peripheral cues.
And, if the answer to that is yes.
If the answer is no, you have to go back to the peripheral route.
So to get to central routing, the central route where its systematic argument people have to be motivated, and they have to have the ability.
If either one of them isn't true, you gotta go to peripheral cues.
So, what are peripheral cues?
Peripheral cues are cues that people use, in a, it's called heuristic way.
That means a shortcut way.
Classical conditioning says that you persuade people just by putting things together all the time.
So the famous example is Pavlov's dog.
After a while because of classical conditioning, just the ringing of the bell caused the dog to salivate.
So in the same way in marketing, if things are always together.
After a while you don't even think about it, and you just say, well, I'm having a Big Mac, let me have a Coke.
That, that's a kind of notion of classical conditioning.
It's just, I'm persuaded to have a Coke because I always have had one.
Now, that may make sense, it may not, but you're doing it just because, I owe you.
So a lot of times, direct marketers will do things like, put a little gift in a charity appeal.
We'll give you stamps, or sometimes they give you a dollar.
And the idea is, sometimes, I gave you sometime, now you give it back to me.
It's not a cognitive argument, it's a peripheral cue.
Consistency's another peripheral cue.
A lot of times the reason that you like the toothpaste you use, is because that's the one you always use.
That's the one your mother gave you.
It's not like you did this systematic product comparison, and you decided, this is your favorite toothpaste.
You use it just because you always liked it.
That's consistency as the peripheral cue.
So, New York Times lately has had the most emailed articles, people read them, why do you read them?
Well, everybody else emailed them, they must be good.
Or my husband chooses restaurants by the one that has the longest lines.
If everybody's waiting on line for this restaurant, that must be good.
That's a social proof, a peripheral cue.
Liking says if you like me, then you like my ideas.
This is very important, and we'll see later for celebrity spokespeople, if you like the celebrity spokesperson, then you're going to like what they like.
Not necessarily a rational process but it, it makes sense in some, in some ways.
Authority says just because I say so, you should do it.
So, because somebody in authority says you should do something, you should do it.
Just because someone told you to do it.
And the last peripheral cue that I'll just mention today is this peripheral cue of scarcity.
Because there aren't very many of them, it must be good.
So some marketers use this idea of scarcity to create product quality.
And Lululemon purposely does not have, you know, they go to stock outs easily.
If you don't get there quickly, it'll, it'll run out.
And people in, in, infer from that that it's high value, high quality product.
Not well thought out central processing arguments, but cues that people use to persuade themselves of one thing or another.
So now let's think about celebrity endorsements in terms of these two roles of, of persuasion.
So in one way, you can use a celebrity in a central processing way.
And the reason that the celebrity endorsement matters is because that person's an expert and therefore there's information in that endorsement.
Celebrity as a peripheral cue is going to be, because the celebrity's attractive, or because I like the celebrity, then I want to use the products that they use.
Either in a central, or in a peripheral way.
When you're thinking about different celebrities to use to help endorse your products, there's certain things you want to think about.
First of all, who's the target segment, and does that target segment like that celebrity.
As, then another thing you want to think about is how attractive is the celebrity?
Is this a popular, a, a, a positive celebrity?
Because you don't want to take a celebrity that nobody likes, obviously.
Is it worth it?
Maybe that's a better, value for your money.
And nowadays very, very important is the social network.
There's another thing that's out there to rate these different celebrities.
It's called a Q-rating.
And, the Q-rating says, how appealing is the celebrity among those who do not know him.
It's the ratio of popularity and familiarity.
And, it's conducted by a particular company called Marketing Evaluations.
And, you can get Q-ratings for different celebrities to help you judge which is a good celebrity and which is a celebrity that maybe isn't as strong and maybe you don't want to pay as much money for or something like that.
So what's the I think you're probably starting to get the idea of how these celebrities work.
And that's the model that's used to indicate the effectiveness of celebrities.
And what you want to do is transfer the meaning of that celebrity to your product.
So, advertising firms, marketing firms, branding firms try to choose a celebrity that best represents the, the appropriate symbolic properties of the product.
So that that meaning from that celebrity will then transfer to the meaning of the product.
And celebrities are quite powerful.
There have some been some fMRI studies that show that when you show an image of just a normal person, certain areas of the brain light up.
So there's an automatic or visceral reaction to celebrities.
and they can be very, very effective at creating an brand image and, at differentiating a brand.
If a celebrity's associated with one brand, and not another, that can be a very effective differentiation.
And going back to this elaboration likelihood model, when you think of the celebrity as working in a central processing way we talk about that as having a credible source.
So one of the very effective, at the time, spokespeople for Nike was Tiger Woods.
But when Tiger Woods was the first spokesperson for Nike Golf he worked in two ways.
His, he was very credible as an endorser for golf products because he was such a successful golfer and obviously you think there's some expertise in him, in his golfing ability and he knows what he's talking about with regard to product.
That's a central processing kind of use of Tiger Woods and that's source credibility, he's a credible source.
The other way of thinking about Tiger Woods is he's also an attractive source, people liked him at the time, they were very familiar with him.
So he was used as a spokesperson not only for golfing and for Nike, but he's also used for other products which were not necessarily based on his expertise, but just based on his attractiveness.
And when he got into some scandal and some issues where his attractiveness was not as strong, some of those endorsements were dropped because he was no longer an attractive source.
The ones that tended to stay with Tiger were based more on his credibility, as a source.
And you can see when you think about these different methods of persuasion why some companies might keep him and some companies might not want to keep him.
and the ways the celebrities and models are used in these advertisements and endorsements is they can say there's an explicit mode.
They can say, I endorse this product.
I believe in this product.
There's an implicit mode that says, well I use this product.
and then there just can be these co-present that, that, that celebrities around this product.
So, we've talked about lots of things with regard to brands.
We've talked about the initial positioning of a brand.
We've talked about how to create brand elements that go together to create a brand image.
And one of the things I've been emphasizing throughout the whole sessions, is that a brand has to be updated.
And so a very important part of branding, is to think about how to reposition a brand.
You have an initial start, but maybe the times have changed.
And, you have to think about how can you keep this brand fresh.
So, we're gona talk about that now.
And it's this notion that the brand equity must be actively managed over time.
If you wait until a brand is out-of-date, it's much harder then to re-position the brand.
So ideally, the best way to keep a brand fresh is to constantly think about it.
That would be the best way.
A new sources, new, new ways of identifying the equity should be identified.
Well, I can think of at least five reasons and there's probably more reasons than that, but let's go over some of these.
One reason for a brand repositioning is that the initial positioning that you came up with wasn't right.
so, and you might know this because you thought this was really cool and customers were going to be interested.
But, actually you didn't see the interest you anticipated.
Or the sales are just not what you thought and one of the reasons is, is the brand is poorly conceived.
That being the case, you gotta re-position the brand.
Another reason is, maybe you have a perfect positioning, for a particular target audience, but that audience is hard to reach, isn't profitable.
It was a really good idea for a really good customer segment, but it wasn't a good business opportunity.
And so therefore you may need to re-position the brand.
As I mentioned over and over, one of the things about being a marketing professor is that things change.
Then you have to change it.
The other thing could be, it might just lose its edge.
And so you need to do something to make it fresh.
and another idea, it's along those same line as tired.
but those are similar ideas, it just gets old, it's, it's there was nothing wrong with it but you really want it to be new.
And by the way, one of the really big things that happens is, people go out and make purchases sometimes because they have needs and sometimes they make a new purchase.
Just because they want something different, something new.
And if the brand seems same old, same old, that's not enough of a reason to go out and make a new purchase.
When you think about re-positioning a brand, the biggest thing you have to think about is consistency, consistency, consistency.
So, except for that one example where I told you about Google, where they go out of their way to do things that are a little bit different each time, most brands when they do this re-position, they do this re-position, they have to have a position that's consistent with the old position.
Or, at least close enough to the old positioning so that consumers believe it.
there's some examples where that can work, but most of the time, the best way to re-position a brand is to do something that's consistent with the brand DNA.
And this is some very old research that was done on understanding why people smoke.
and it had to do with people's attitudes towards smoking.
And let's say I smoke.
And let's say that I know that smoking causes cancer, cancer causes death.
And I don't want to die.
Now, if that's the case, how do I justify that I smoke?
Because there's this inconsistency.
I'm me, I, I like myself, I don't want to die.
I think smoking causes cancer.
something doesn't work.
And so what, what psychologists found out that was people rationalized.
Or they do something to one of the links of this chain so that it is consistent.
And that's the way they can justify their behavior because people like to be consistent with themselves.
So what are the ways different people kind of rationalize to allow themselves to smoke?
Okay, I smoke.
I don't want to die of cancer.
I don't believe the data.
And so this is the kind of thing where I say you have this buyer selective interpretation.
You, there's experiments that shows, you show the same data to smokers and non-smokers.
And they will interpret it differently.
So people frequently interpret the message or the data, consistent with what they already believe.
This is a theme that I have mentioned all along.
So this is a, a pretty well-known, way to rationalize behavior.
Smoking causes cancer.
I really don't want to die from cancer.
So, what you do is kind of lie to yourself.
And you say, you know, I don't really smoke.
And, so it doesn't really count.
And, therefore I have no inconsistancy.
They make all sorts of rules.
If it's a little bit burnt, I can eat as much as I want.
You know, there's all sorts of rules that people make.
That's that resolution where you kind of figure out a way that you can feel good about yourself.
I know it causes cancer.
But, you know what?
All of these are consistent and that is a very important concept for marketers.
So if you're putting out a message, when you're trying to reposition your brand, that isn't consistent, consumers will reject it and will look for ways to rationalize the message so it makes sense to them.
It's a consistency theory.
and what you do is if it's not consistent, you change whichever one is weakest so that it is consistent.
Oldsmobile was known as a car that was associated with Dad, with my father.
Okay, now one thing that's probably obvious but let me just say it here.
Cars are for young people.
Cars are powerful, performance.
People like young people cars, energy cars.
They don't like old people cars, okay?
That was obvious.
And so what they tried to do was, they came out with a new ad, new excitement, new car to say, no, no we're not a fuddy duddy car.
This is a car for young people.
What happened here?
There's cognitive dissonance here.
The problem is, the association with dad and Oldsmobile was extremely strong.
The association that my dad is not exciting was extremely strong.
So the weak link here was that Oldsmobile cannot be an exciting car.
And that was a very strong inconsistency they couldn't fight.
it was so strongly-associated with my father and fathers are so not exciting that people just, not, believe, did not believe the new ad.
It was obviously hurt even more by the ad.
The slogan at the time was, This is not your father's Oldsmobile.
And anybody knows, as soon as I say, this is not my father's Oldsmobile, what you're doing is reinforcing that it's exactly my father's Oldsmobile.
So this is known as one of, not a good campaign.
And you know, there was another problem here.
Think about the brand name.
It is literally called an old mobile.
But they just could not get themselves out of this cognitive inconsistency.
So this is a very important thing.
A better way to do it is to gradually change these associations in small ways so that people can still maintain that brand familiarity and believe the re-positioning.
so you can do it, and I mentioned this earlier.
You can do it by kind of, updating the symbols.
Or, maybe you can start to change the brand name.
And I can show you how to can show, change the brand name slowly to to, to reflect the evolving identity.
So all of these elements that we talked about before, can be subtly tweaked.
There are two ways to do this.
One of the ways is called the Just Noticeable difference.
And what this says is that you make these little tweaks, very subtle, from point to point to point, so they're barely noticed.
You know, you do this, say, every year.
If you look over 20 years, the difference from the first one to the last one is very very hard.
And so there's a lot of packaging examples which we can show you.
Where just with tiny little tweaks each time, you still believe it's the same product.
But if you look from one, one version to a version, 65 years later, you'll see a radical difference, and the brand stays modern.
Many consumer packaged goods do this kind of just noticable difference positioning.
Anothedr way to do it is what's called the butterfly effect.
You are going to notice that it's different.
It's not a just noticable difference.
It's a bigger difference.
And the reason I'm going to do this is to keep it modern and new.
Because, for some categories, like cosmetics, like clothing, and this is the notion of clothing The idea of keeping it modern and keeping it fresh is part of the reason to buy.
And in that case, I don't need the change from one to another to just be subtle.
So that it is kind of a little bit exciting, and more modern.
But, it doesn't necessarily need to but I, it's, it's more modern, but it still stays within believability.
So it's not so extreme.
That I don't think it's the same thing.
And, so these are two different ones and we can show you a number of different examples on those two different ones.
And, then I can show you some examples of evolving trademarks.
here's the Jolly Green Giant, that was kind of out of date, he And, they made a new Jolly Green Giant that was fitter more athletic.
These are subtle changes.
There was another change, Charlie the Tuna.
I mentioned him earlier, very fun, animated character, kind of got a little outta date.
More recently, there was a transformation on the, the, hamburger chain, Wendy's.
And again, I, I know a little bit more about the market research, so I went into this.
There was a lot of changes here.
One of the changes here is they got out their slogan.
They do more than just hamburgers, so one of the things they pulled out was that slogan.
They went from an old fashioned typeface to a more modern typeface.
People identified with that Wendy character and they liked that Wendy character.
So, they kept the character.
But they made her, you can see she used to be in a little circle and she used to be contained in the circle.
You know, lots of things are possible that you can get in a Wendy's now.
And with these subtle changes, it's still very much identified as a Wendy's.
you can keep the brand, you can keep the brand modern, but connected enough so that it doesn't, people still know it's Wendy's and it's not a surprise.
There are other kinds of ways that people have named that's actually to change the brand name, so Boston Chicken was the original name of the of the chain of restaurants that provides dinner food.
Weather Channel found out that they were going to make a lot of their revenues not off TV anymore but off Apps and different kinds of ways of saying weather.
So, they change their name from the Weather Channel to Weather Companies.
And, Starbucks very famously changed their name from Starbucks coffee to just their image.
But, people still know that it is Starbucks by that image.
So what's the best way to do it?
it, it, BMW was a lot of associations.
It was a certain type of car.
It was an expensive car and it was a car driven by the baby boomers.
In fact, BMW's were called Beemers.
You know, they were thought of as driven by the baby boomers.
the baby boomers got old and they are stuffy.
So, although these associations started out as positive, if they're not carefully cultivated, they could turn negative.
They not only were very careful with their advertising, they, their, they mean performance, which is something that can stay modern.
But they also changed their design of the cars.
They associated their brand name with young, and powerful, and good imagery.
That, with all of those kinds of things, their slogans etcetera.
And, that's a way to do it by constantly positioning your product.
Subtly, sometimes just noticeable difference, sometimes a little bit bigger difference, like a butterfly effect, but always within the brand DNA so that people believed the changes.
Consistency over time is very valuable in building strong brands.
You do, it's kind of, you know, a fine line.
But, if you do something that threatens the consistency chain that I was talking about, people won't believe it.
So, it's got to be something that is consistent, with the brand DNA, but is constantly moving it forward.
When you think about all the brand elements, you want them all to work in harmony to communicate brand identity.
To to change when it's necessary but be careful because if you do things that are too big a change or the customers won't accept, it just won't work.
If you really want to do a good job in keeping your brand modern, you really have to understand the brand mantra, the brand DNA, the brand positioning, your target segment.
These are the things we've talked about in the beginning.
You have to understand what the points of parity are, what the reference frame is.
You have to really understand what the point of differentiation is, what is strong about your brand, what is positive about your brand, and what is unique.
And you have to be consistent with that kind of brand image as you make these adjustments.
I'm Barbara Kahn, and I'm here to give you some recent examples of some of the concepts that we talked about in the first videos that you watched on segmentation, targeting, positioning, how to build a brand.
So let me give you some examples of things that I think are going to work really well, and then some examples I'm not as sure of how they'll work.
And part of the reason, when I'm not so sure, is whether or not they build on some of the tight concepts that we talked about.
So as you remember, we were talking about in building a brand, it's really important to find target segment, a point of difference and a frame of reference for each brand.
And the more tightly you can position that, the better and more likely your brand will be successful.
So what's an example of one that I think is really good?
Now why is she building a really strong brand?
First of all, as an actress, as a performer, as a singer she's very authentic.
She has a very strong identity.
The second thing is, she has a really interesting target segment to start out with.
The Latino market is growing, it's big, a lot of people are trying to target that market and other people haven't been able to do it so well yet.
So she starts in with a tight frame of reference, with her strong point of difference, her persona, her authenticity, and she goes after a very attractive target segment.
That doesn't mean other people may not use the products or like the products, but it's very clearly positioned.
She might go into TV, all sorts of other things she can start to grow her empire because she started out small, tight, with a clear focus.
Really, the concepts of segmentation, targeting and positioning.
And thinking about how you target a key segment with some critical point of difference.
And they're saying these millennial moms, this is the segment that hasn't been really well served by traditional media.
Old fashioned TV, where you sit home and watch soap operas, that's just not what today's millennial moms are doing.
And they don't have some product that's, or a media service that's catering to that different type of behavior.
So Awesomeness TV is coming out with a new product called Awestruck, and it's targeting these millennial moms.
And the idea here again going back to our principles, it's an attractive marketing segment.
And so this should be an opportunity that makes sense, and I'm hoping it'll be successful.
Playboy, which is very well known in the US, kind of soft porn, Hugh Hefner, magazine Playboy Bunnies, is trying to build a brand in China.
Now Playboy is not very well known in China, but the bunny logo is an iconic logo and they think it might work there.
So they're trying it.
I've been looking for recent examples to try to show, or illustrate, some of the principles that we have in our videos about segmentation, targeting, positioning, and building a brand.
In this example, this is a brand that was very successful for a while.
Some of you may know the brand Crocs.
It's a type of shoe.
Its a, well, you can see on the slide that is a shape of a shoe and it has little holes in it.
As with any kind of fashion, sometimes falls in and out and Crocs is trying to revive their brand.
One of the most famous print campaigns is the Absolute Campaign which ran for over ten years.
And the entire print campaign was based on the shape of the bottle as a differentiator.
It was a black bottle with a short neck, which is unusual for Vodka bottles or spirit bottles because a lot of the times you have a long neck so that the bar tender can hold the bottle when they're pouring.
And they absolutely use the shape of the bottle as a differentiator and was really quite successful.
So Crocs is kind of reviving that notion and taking the shape of their shoe, which is unusual to say the least for a shoe, and trying to make it an asset.
And they're looking to revive the brand, revive the fun.
And they're trying to think about it as, think about Crocs in new uses.
Maybe you want to go buy a new pair.
Find a new place to find your fun with this unusual shoe.
So, we've been having this great conversation about customer centricity, what it is, what it isn't, why it matters, some of the surprises that emerge from it.
As we push that conversation ahead, it's not enough just to understand what it is and to feel like, whoa, this is a cool strategy.
But as we start moving toward implementation, we want to think real carefully about the challenges, the barriers, the things that will actually prevent companies from really making progress on it.
So one of the things that I've been working on, and this is real cutting edge right now.
It's not like I have a new book or anything on it.
But something I've just been thinking about, is a list of some of these different challenges that are seen from actually companies that have actually been trying to take some of the content, like what we're covering here and moving forward with it.
So how do we go about finding people who can really do that kind of convergent thinking, in order to figure out how to surround those valuable customers with the right kinds of products and services to enhance their value and so on.
So we've certainly been spending a lot of time, not just in my part of the course, but some things that Barbara Consman talked about on branding.
Well how do we come up with brands that resonate in all the ways that Barbara talks about it but at the same time, does justice to customer centricity?
There's unique challenges there in terms of the name that we choose and the different kinds of communication tactics that we use.
So how do we find that just right balance between the kind of direct marketing activities that we associate with customers centricity and the more product oriented activities that we often associate with a brand or a different strategy?
How about globalization?
Given that the different parts of the world are more open to customer-centric practices, how can a multi-national firm be customer-centric in some parts of the world, maybe be a little bit more product-centric in others.
How can you have a coherent strategy when there might be some global barriers that prevent you from using the same kind of customer centricity, product centricity balance all the way across the globe?
I mentioned that towards the beginning of my session, that the overall objective is to maximize shareholder value.
And while that might be the primary objective, there's also some other objectives that we really should acknowledge.
So, how do we think through some of those other objectives and kind of keep them in mind?
That if we're going to be using some parts of our sales force to surround those valuable customers, to enhance value, and do all that kind of thing.
That we're going to be doing kind of lower cost channel activities for those so so customers.
So how do we incent our channel partners to want to play along?
For those channel partners who are dealing with the lower end, how do we keep them from getting upset?
And how do we use monetary incentives or other kinds of incentives to make them realize that they still play a really important part of the business, even if they're not necessarily dealing with the very best customers?
So we understand that there's very different kinds of performance metrics for a product-centric company versus a customer-centric one.
How do we come up with and communicate the right kinds of performance metrics both internally, to our internal stakeholders, as well as externally?
How do we get wall street on board with some of the more customer-oriented metrics, that their not accustomed to using, that might be a better indicator of just how well we're doing as a company?
I like to say over and over and over, it's not enough to just hang a banner on the lunch room walls saying we are now customer-centric.
Changing the culture within the organization is something that's very difficult.
It takes a long time to do, and a lot of companies are resistant to do it because it's a very risky thing to do as well.
But you can't really succeed with customer centricity unless you want to take that one on.
So that's just a list of some of the barriers and challenges that companies face.
And I'm not really giving you the answers right now.
If anything, I might be making you even more concerned about whether customer centricity might be right for you.
But I think it's important to have that kind of full disclosure.
And I think it's going to be important for us to flesh out this list and understand which companies are doing well or going to struggle with some of these issues.
And to come up with some best practices to try to use whatever resources we have within the companies.
Or to learn from other companies, or to learn from seemingly unrelated industries in order to overcome these barriers.
We either don't have the data, we might not have the analytical capabilities.
We might not have the technology to allow us to serve up different kinds of products or services to our customers.
Or maybe there's regulatory restrictions that prevent us from doing it even if we think we're able to.
I've had some very interesting experiences with companies from around a variety of different industries, one of which was a pharmaceutical company and another one was Google.
Okay, two companies that might have the capabilities to treat customers differently, but they're really hesitant to do so.
So in these cases, and in others, one of the big wins of customer centricity has been for these companies not so much to be customer centric with their own customers, but to teach their customers how to be customer centric with their customers.
So I've had lots of good conversations with these organizations and others.
Basically they're listening very attentively, and I'm going through all these lessons about what customer centricity is and all the strategies and tactics and everything else that we've been covering in the course.
And they're carefully taking notes, not because they're going to do this stuff themselves, but here's their thinking.
If we can teach our customers how to be more customer centric, then they will see us as a trusted advisor.
In the case of Google, if they can teach their advertiser clients how to be more customer centric, then those advertiser clients will be better consumers of, they will buy more, Google analytics products, for instance.
But in a B to B setting you are also going to teach your customers how to do these things with their customers.
Not only is it consistent with everything we say about customer centricity, the whole idea about making these investments and we're in it for the long run, we're not just trying to make a dollar right now.
But the more that you can get others to be basically spreading the gospel for you, the more it's going legitimize some of these practices.
The more people within your organization who are really going to be able to understand them and talk about them and just make this conversation more ubiquitous throughout the entire ecosystem that your company is involved in.
So this is an idea that, really, I didn't have in mind at all when I was writing my book about customer centricity.
It's one of the things that I've been learning as I go ahead.
And so this idea of paying it forward I think is just one of many extensions of customer centricity that's food for thought, something to think about.
I love seeing case studies of customer centricity in action.
And of course, I've shared a bunch with you already, many of which were studies, real world, but I had nothing to do with them.
So whether it's the Harrah's casino chain, whether it's Tesco and so on, it's nice to look at some of those studies, but sometimes they're a few years old.
So I'd like to talk about a couple of the case studies that I've had the chance to really see and, in some cases, to nudge along.
One of the great cases that I love to talk about is Electronic Arts.
And if you think about that kind of company or that industry in general, it tends to be very much a product-centric business.
Very much it's all about blockbusters, it's all about what's going to be the next big game.
Can we come up with that great idea?
And for some games, and for some companies, sometimes that works just fine.
But at the same time, we recognized that there's an opportunity to be customer-centric instead.
Let's look at the game players and try to figure out, who are the most valuable players we have out there?
What kind of games do they like?
And can we use that insight to help us develop new games?
And I love talking about and working with Electronic Arts, in this regard.
But they're equally terrific when it comes to a lot of the customer oriented metrics and insights that I've been talking about, or at least hinting at in our time together.
So for instance, I mentioned lots of time, customer lifetime value.
Well, Electronic Arts is calculating customer lifetime value all the time.
So they can understand what kinds of acquisition strategies are going to bring in the best kinds of customers.
So they can understand what kinds of games or features within games are going to be most appealing to the most valuable customers.
So I don't want to say it's completely transformed the organization.
I don't want to say that they've given up on any product-centeric practises at all.
But they're achieving just a much nicer balance.
And so it's just really nice to look at a big company, and not necessarily one that was born in the online space, like an Amazon.
I love talking about case studies of different kinds of companies that are bringing different aspects of customer centricity into play.
Well that's not true and in fact a lot of these ideas really emerge from a B to B setting.
They're a company out of Atlanta, Georgia, and they basically make a lot of veterinary pharmaceutical products.
And I had a really nice interaction over several years with a gentleman who ran all the marketing for large animals.
His name was Steve Lerner and he heard me talk about some of these ideas, and the CLV models, and everything else that I cover and he said you know what?
This stuff is not only going to work for us, but it's going to work for us in a very unusual way.
Instead, let's give sales people the incentive in a forward looking basis.
So we're calculate our CLV for every one of our customers, and add that up to say, for the level of our sales people or our distributors, how much CLV have they created or destroyed from one month to the next?
So that if someone makes a purchase from you, great!
They didn't necessarily make a purchase.
We didn't necessarily extract any dollars out of them right now, but because the relationship is a little bit tighter, because there's a real conversation going on, their CLV has gone up.
Let's allocate our resources to focus on those customers who would be the best ones for us.
At first, the sales people, the distributors, they kind of look at it skeptically and say oh, it's just those guys in marketing trying something crazy.
But they ran this as an experiment over a period of several years to really show the sales folks that you know what, we really are helping you identify customers who have future looking value in them.
It was a way for them to raise revenue by a significant percent, despite the fact that they're in a very competitive market with a lot of these branded products going off patent, and so on.
And on a forward-looking basis, recognizing that they've created and they've recognized and locked in all of this future value that will continue to manifest over time.
I just love that idea of, first of all, just a nice BDB example, but also that idea of taking CLV, and taking customer centricity, and using in a tactical way, in part of the organization that it wouldn't necessarily be thinking about all the time.
It just shows that if you take some of these ideas, and instead of just trying to replicate some of the examples that we've covered, if you think really creatively about them.
And run those kinds of experiments, and start small, and build from there, and get buy in throughout the organization, amazing things can happen.
I think Meriel is a really good example in that regard.
At the beginning of our time together, I mentioned that I'm the co-director at a research center, the Wharton Customer Analytics Initiative.
But I never really took the time to describe what it is that we do or how it fits in with my overall desire to get companies to understand and become more customer-centric.
So what do we do?
We'll find companies that are sitting on top of lots of interesting customer level data.
We're very agnostic about what we mean by customer, and in all these cases the customers, whoever they may be, we have lots of data on what they're doing over time.
And lots of desires to extract insights from that data to help the company become more customer-centric.
We'll sit down with a company and we'll talk about all the different data assets that they have and all the business problems that either arise from or motivate some of those data assets.
We don't give the data away, but we'll describe the data to academics all over the world.
So all schools, all disciplines, all geographies, we basically say, hey researchers, here's this dataset, or this set of datasets.
You tell us what's interesting, both from an academic and a commercial standpoint, write us a proposal.
We'll sort them into buckets based on what techniques people are proposing or what substantive questions they're attempting to answer.
Then we can go to the company and say, hey, company, here's 40 great ideas.
You pick as many of them as you want.
We'll go back to those researchers, give them the data and say go to it.
And at the end of the process a few months later, we'll have this private symposium where the company gets together with all of these academics to talk about the data and the insights and the commercial value.
But if we have the company that gave us the data and all those academics that have been working on it, they're seeing eye-to-eye.
We'll see just tremendous insights, and again, commercial value that can be tied to meaningful financial results arising from these projects.
It's nice to help companies raise their quantitative literacy.
It's nice to have researchers work on more practical, relevant problems than the usual ivory tower stuff.
And this whole mechanism is just a nice way to bring customer-centricity across.
because while I'm talking to companies and talking about customer-centricity and everything that we've been covering here, sometimes it's hard for them to get going.
So maybe we can start on that side and we can have top academics all around the world show them how they can derive some of those analytics from their data, and it becomes much easier for them to start to do the strategic thing as well.
So it's just a really nice triangulation between the kind of pure talk that we have about the customer-centricity and the research work that we do.
And it all meets together, and it all makes the world a better place.
So this segment is the Marketing 101, the basics of principle of marketing.
Which is what is marketing?
So what's a market?
A market is an exchange between two partners.
Frequently a buyer and a seller, but marketing also applies to non-profit or things where there isn't necessarily money being transacted.
But what you need for marketing to exist or for a market to exist is to have an exchange, and what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's look at the basic exchange.
You have one buyer and one seller, and I'm going to give a very simplified view to make a point.
No markets are ever quite this simple, and I'm going to look at the two extremes just to make my point here.
And the real markets are somewhere in the middle but you'll see, when I start defining this that it's very useful to use this kind of simplification.
And in the seller's market what that means is the seller has the product and if you want that product you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think of that.
It is marketing should not be the same in the sellers market as in the buyers market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability, you should innovate in that product, you should try to reduce costs, and you should really focus on the product.
And profitability from a product-focused market is going to come from volume, selling as much as you can.
In the past, when we studied product-focused markets, we've shown that profitability is tied to market share.
So market share becomes your business objective, and why does market share increase profitability?
Because the bigger your market share, the more your revenues, and the bigger your market share and your volume, the lower the product cost, enhanced profitability.
Higher revenues, lower cost, more profit.
Will you develop new products based on your product experience or you go to new markets?
That's product-focused market.
So what's customer focus marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer-focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
What's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So whereas in a product-focused market, I'm the expert and I create the very best product I can based on my expertise.
In the customer based market, what I'm going to do is look at what the customer wants and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside out is product focus, and outside in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer, but think about it.
What does the customer want?
Well, the first question is well which customer?
So the reason why a buyer's market or customer-focused marketing is so different than product focused is that every customer out there wants something different.
If we try to give everybody what they want, we'll go out of business that's too hard to do.
So, the intuition of customer-focused marketing is to pick and choose customers.
Deliver value to some customers.
That's the process of segmentation.
And the call that, I'm going to talk about that in the next section.
But the idea here is that I go after some customers, and I say no to other customers.
Well then how do I become profitable in that?
Understand that in a product-focused marketing what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In a customer-focused market, we're saying no to some customers, and yes to others.
So how do we make that profitable?
And the answer is you pick and choose the customers you want to deliver.
And where the profitability comes from is not from volume, but it's from creating value.
Well the first thing is, if I give you exactly what you want.
Many times you'd be willing to pay a premium price.
Then the profitability comes in, not from reduced cost which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want I'll be willing to pay a higher price for it.
So that's one way.
I don't think about just one transaction, I think about building customer loyalty and delivering value to that customer over time.
That concept is called customer share.
The idea of customer share or share of wallet is that they go after a more narrow market and try to get more from each of those customers' wallets.
And it turns out that loyalty, if you do it right, can be very profitable, and why is loyalty more profitable?
When I'm doing a customer based marketing, it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants, and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but it's cheaper to retain those customers over time, and that's where the profitability come from.
It comes from loyalty.
The other thing if you're thinking about building share of wallet in a customer-focused market is that I not only sell one product to you, I think that other things that you might need and I try to cross sell around it.
Let me give you an example of this notion of cross selling.
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer-focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time, and that's more profitability.
And if you understand their needs, you cannot only sell them one product, but you can cross sell other products that may also meet their needs.
So in a customer based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between seller's market says you focus on the product, on what the customer does well and you push that out.
And in a customer based market, you focus on the customer, what the customer wants and you deliver value to the customer better than the competition.
So that's the basic difference between product phase marketing and customer-focused market.
Now, in today's world, the marketplace has changed even more.
What's changed?
Well now, not only do you have an exchange between buyers and sellers, but because of globalization, and because of the Internet, technology, and social media and things like that, it's not a one to one conversation anymore.
Customer's can talk to other customers.
That's good and bad.
The fact that they'll buzz to their other customers and tell their other friends about what a terrific service your company's doing.
Well, that's really good news.
On the other hand, if something goes wrong and they tell their friend something bad, well that's not such good news.
And so you have to be really careful in every transaction with the customer now that you deliver not only value, but that you deliver a top notch customer experience.
In the sellers market I talked about a single transaction, and in a buyers market I talked about transactions over time, or customer loyalty.
But in the connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
Let me give you an example.
It starts way before the transaction and it goes way after the transaction.
So for example, if a customer told another customer about their experience at a restaurant.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer, then you as a marketer need to focus on the entire customer experience.
So one of the things, and we'll talk about this later, that's changed in marketing in this world of social media, and Internet, and globalization is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
And in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
People became a skeptical of marketing.
And so with all those changes in economic environment there's been a focus again in marketing.
And marketing now has the focus on authentic genuine customer value.
But now, because of the tightness of the economy and the uncertainty there, you really have to cut costs, and figure out a way to deliver value in a very discipline manner, and be very flexible to changes in the market place.
So let me just summarize what I've just said the different types of marketing orientations.
There's the product orientation where you focus on the product, and you persuade the customer to want what the firm has.
That's a customer-focused approach.
The experience orientation says that you not only think about the transaction and think about the transactions over time, but you try to manage the customer's entire experience with the firm.
And when times get tough, or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of markets in terms of what you offer?
In a production orientation, you're focusing on product innovation but also reducing costs, so you tend to see generic products and standardization.
And we'll talk about that when we talk about brands also.
In an experience orientation, you look at experiential value, and when you're going to that tight disciplined mind frame, or mindset, you look at genuine value.
And what's the sustainable competitive advantage in each of these markets?
In a product orientation, the bigger companies win because they tend to have larger market share and lower cost.
In a marketing orientation, when you're focusing on the customers, the companies that do the best are companies that really know their customers, that can deliver quality, and that have a lot of customer data, and know how to use that data to deliver better value.
And in experiential market, you look at transformation.
The customer becomes a co-creator of the value and it's really making the customer and the product one kind of overall experience.
And that means you've had a long history with them, they're transparent and you trust them overtime, and what are the measurements of profitability?
In production orientation as I mentioned market share is tied to profitability.
In marketing orientation, it share of wallet or customer share, customer loyalty.
In experience market, when your looking at customers talking to other customers.
And in the trust orientation, we really focus on reduced costs.
Let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
What the seller puts into the exchange, is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
Could be advertising, sales, whatever.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
It can be online.
It can be through, downloading.
So those are the four P's of marketing, product, place, promotion and price.
Typically when you talk about marketing, you talk about the business world.
But you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
Blood is actually the price.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And its based off of their framework, although I've adapted it some.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
Whether or not it meets my needs, so is it customized to meet my needs?
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
So, that's a very strong assumption.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
So, those are the assumptions.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Think about what's going to happen in that marketplace, in a very competitive market.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
You have to do the same thing, or what are the product attributes that matter to the customer?
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
And some people more.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
I'm really excited to be starting my module of our introduction to marketing course.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Are we going to focus on all customers the same way?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
Running a business in a performance superior or operationally excellent kind of way and that's going to give us the basic foundation so we can really understand how customer centricity is different.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
Okay you have a certain degree of expertise that has enabled you to bring us the current product.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
How can we take that product expertise, and either extend it to new customers or extend it to new products?
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're going to try to do it as, as efficiently or effectively as possible.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
I'm going to stay in the water.
And this is exactly the kind of issue that many companies are facing today.
It gives them some opportunities for growth.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
And if you look up and down the slide, you won't find a lot that's tremendously insightful, and that's the point I want to make.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
How can we spread it out to other kinds of customers, and other kinds of businesses?
Again, implicity, that's the way that most businesses operate.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
In fact, I'd like you to just take a, a minute or two think about what are some of the changes, today, compared to 15 or 20 years ago, that make product centricity just a little bit different?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
We're doing something that's going to keep us ahead of all of our competitors for a long period of time.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
They would take whatever products or services that we would give them, and they would say, oh, that's great, terrific, thanks very much, I'll figure out how to use it.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
But that they, they clamor for than they ever were before.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
And even if customers were aware of it, customers wouldn't have access to it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
But by no means is it limited to technology.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
They no longer manufacture personal computers.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
He didn't know.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
To be understanding who's buying what.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
So I want to talk about a couple of examples about companies that have used information technology and specifically the data about their customers.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
They turn to a deep understanding about their customers to draw insight and to let them change their business models in a way that actually let them rise to the top of their industries.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
What kinds of messages and offers to provide, at the right time, and through the right channel, in order to create and extract more value from that customer.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
And so when they sit back down again, their threshold is back towards zero.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
And this helped them not only grow the business with those customers, but also helped them to compete more effectively.
So Tesco knew, again, which coupons to send to which households, at which time, in order to really hold on to those customers and bolster their business.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
So while the Harris and Tesco stories are terrific, I will provide pointers to some books that summarize each of those stories quite well.
I want to emphasize that they're not the only ones who have built a business around a deep understanding of their customers, and by no means are they the first.
In fact, the first companies that actually built a business in this manner, around their customers, has happened many, many years ago.
And it emerges from the sector of direct marketing.
They think about infomercials and other, you know, not great marketing activities.
it, it's, it's not the kind of industry that you aspire to be associated with or learn from.
If you, if you look at, at what direct marketing is really all about, it is really building the business around the customer.
But not just, the customer in some generic sense, but around each and every customer.
It's about understanding the relationship with each different customer.
That's what direct marketing is all about.
What's interesting about it is, that direct marketing is not a new concept.
There's actually a lot we can do, we can actually formalize some of these business practices, and come up with some best practices associated with them.
But even if you don't spend a lot of time thinking about direct marketing, a lot of the words and the concepts have already filtered their way into today's everyday marketing conversation.
So, a lot of the segmentation concepts that Barbara discussed are often associated with direct marketing.
Something that you've heard about before, that we're going to spend more time talking about, that's, that, that comes directly from the direct marketers.
We can collect all this data about our customers, about each and every one of them, and we can actually build a business by understanding who the valuable customers are, who the less valuable ones are.
Which messages we should be sending to which customers at which time, and, importantly, what kinds of products we can develop and deliver in order to create more value for our most valuable customers and to try to attract more customers like them.
So the Harris and Tesco stories are wonderful, but they're not unique.
And so I want to spend a lot of time celebrating some direct marketing practices.
And I want to emphasize that a lot of firms out there today might not aspire to be direct marketers, but they don't realize it, but they are.
Has the capability to learn from direct marketing, and I encourage all of you to read books on direct marketing.
Even if you don't think about yourself that way, there's just so many concepts that you can learn and leverage, especially as we enter this world of big data.
Now that we understand what product centricity is all about and we've discussed some of the cracks in product centricity.
And even some of the opportunities from companies to escape from and maybe do better than a product-centric approach, I want to start moving away towards customer centricity.
So in order to do that, I want to work with a series of examples here.
In fact, on this slide, you'll see the names of four very famous retailers.
Three of them operate on a global level, so Walmart, Apple, Starbucks.
What I'd like you to do is take a moment, and from your experience with, your perceptions of these firms, decide which of them would be highly customer centric.
So think about what customer centricity means, and which of these firms qualify in that regard.
Now, I want to be careful about this.
I really like what they do.
Fail to be truly customer centric, nearly as much as perhaps some of you thought when in deciding which of them, which of these firms are or aren't customer centric.
So I'm just going to take a few moments to talk through each one of them, and then, finally we'll bring up our definitions of customer centricity.
Now again, Walmart is a terrific firm, but Walmart knows, surprisingly little about any one of it's customers.
Unlike Harris, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
Walmart has made very little effort to date to try to figure out exactly what each customer's doing.
So while Walmart might not make a lot of efforts to understand what any one customer's going to buy, they make great efforts to understand the customers as a whole.
They understand regional differences.
For instance, when a hurricane is about to hit the south eastern US, they need to fill the stores with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way as a direct marketer would suggest.
If you think about the Walmart business model, it’s about selling in great volumes, it’s about bringing the costs way down.
So, in many ways, Walmart is a prototypical, and a wonderfully successful, product-centric firm.
And let's figure out ways to extend our product goodness, and, and all the aspects that I mentioned for product-centricity apply to Walmart.
There are a very few firms in the world that can operate in an operationally excellent manner as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time doing market research, to figure out exactly what the customer wants.
They don't spend a whole lot of time focusing on segmentation and real granular analysis to try to predict what any one customer is going to do over time.
What Apple focuses on, is leveraging its product expertise.
Operational excellent for Walmart, performance superiority for Apple.
They are doing some smart things at the margin to understand their customers better.
They have a new program they call Scan & Go, a mobile app that lets people scan products as they move around the store so as they check out, the whole scanning process happens much faster.
It's a brilliant idea that lets them be more operationally excellent, but also lets lets them start tagging individual customers and tracking them over time.
So they're starting to take on some more customer centric initiatives without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business that are letting them understand their customers a little bit better.
Slowly but surely, they're starting to develop a better understanding of their customers at a more granular level.
One day, if and when competition catches up and Apple can no longer be the product leader that they are, they could probably turn around and start to be a great customer-centric firm as well.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
At a local level, Starbucks or any coffee retailer, is very, very customer centric.
The Barista, the person on the the other side of the counter, the person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store but just through the casual conversations you have with them, they might know what movies you like, what kind of clothing you’d like to buy, something about your job, your family and they often make recommendations to you.
That are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted advisor to the really good customers, finding ways to lock that customer in and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they are not that customer centric at a national level.
You take your Starbucks loyality card, and you bring it a Starbucks in another city or another country and show it to them and say, I'd like the usual please, they have no idea who you are.
So not only can they not meet your immediate needs, but it's hard for them to be a trusted advisor and to make other recommendations to you when they have no idea about anything about your history.
It's not enough for a company to be customer centric some of the time when they know who you are.
But a truly customer centric company will identify you and will be able to value you and make recommendations no matter what kinds of interactions you have with them.
And they're coming up with all kinds of interesting technologies that are going to let them collect and integrate your data across stores and across other touch points you have with them.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
So again, it's that balance between focusing on the product and focus, focusing on the customer that so many companies are now struggling with.
And finally, there's Nordstrom's.
And while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
But whether you've shopped at a Nordstrom store or not, you might be familiar with the story that makes Nordstrom so supposedly customer-centric or not.
And here's the way it goes.
Nordstrom's a high end department store.
They sell clothing, shoes, and so on.
One thing they don't sell is tires.
Supposedly in Fairbanks Alaska, and wanted to return a set of tires that obviously they could not have bought at Nordstrom's.
Perhaps there was a tire store at that location before Nordstrom's opened shop.
And Nordstrom's being so incredibly customer centric, gave them the money back for tires that they didn't buy at Nordstrom's.
If you think about it for a minute, is that really customer-centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
If that customer is incredibly valuable to you, and I'm talking about future value, I'm talking about the fact that we expect this customer to be buying so much from us in the future that if we don't give them money back for the tires that they thought they bought from us, if we don't give them the money back today, we're going to lose that value.
We'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer.
And for most customers it wouldn't be.
We might still be nice to you, of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom's.
Nordstrom's offers such wonderful service.
Regardless of the value of that customer.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
I like knowing that when I go in there I'm going to be treated really well.
So to me the Nordstrom's example is a great example of, of where a product and customer centricity collide.
And what I want to do now is, is to start focusing more on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
How do we determine whether a business really is or isn't customer centric?
In other words, what is the definition of customer centricity?
So in fact, I'd like you to take a minute and just jot down whether it's a full sentence, or even just a few words that you would associate with customer centricity.
Take a minute and do that, and then I'll, then I'll give you my perspective, my definition on what customer centricity is.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
For instance, going back to the IBM example, there was a case where a company was willing to recommend other products and services.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
Let's come up with something for them, something that's going to make them even more locked in, something that's going to create greater long-run value for them, and something that's going to help us recruit even more customers like them.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
It's, it's the way, just changes the conversation, and perhaps the design, within the organization.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Maybe they didn't, by the end of the month.
That we think in the long run we've, we will create much more value that wouldn't have been there.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
And again, I can point to examples of companies, I'm, I'm thinking of a particular pharmaceutical company that changed its sales person incentive program to be forward-looking instead of backward-looking, and wonderful things happened.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
Is it the insurance company?
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
Agreeing, that one of these entities is the customer, we care a lot about the others, we need to keep them in mind, as we go through our planning practices.
So it's important to first sit down and figure out, who the, the customer could be.
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
And before saying, we're going to become customer centric, it's very important to come up with that list, and think real carefully about, existing barriers and new ones, that can be arising, to, to do a real careful inventory, of, of, of barriers towards customer centricity.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
So, there's a, a number of, of, of different ways that we can start thinking in advance, about overcoming the barriers, before the, the barriers actually start impeding our progress.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be an organizational initiative like, My Black Is Beautiful for Proctor and Gamble.
It might be other kinds of experiments that, that a company is going to run.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
So we're going to talk specifically about how to acquire some of those customers that Pete was talking about.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So let's first start out with what are perceptions?
Perceptions is probably the one of the most important aspects in consumer behavior and understanding consumer behavior.
What is the perception?
The perception is the process of developing and interpretation of a stimulus, or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever customers perceive is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
The process of perception comes in several different stages.
The first two stages are the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
And we noted that process is very biased.
But when you're consciously exposing yourself to things, many times, it's a function of what you believe, what your prior beliefs.
So let me give you an example.
Say, you think that a part of town is not safe.
As a result, you never have ability to change your perception of that area of town because you don't collect new data.
So we know that exposure can be selected.
Similarly, even if you are exposed to something, if you don't pay attention to it, again, it can affect your perceptions.
And we know that there's two kind of attention, there's voluntary attention and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure and selective attention.
That means you're not collecting data on things that might be able to change your perception.
So that's the first stage of bias.
The second stage of bias is, once you are exposed to something and pay attention to it, well then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who interpret what happened in the debate from both parties because we know a prior, the interpretations are going to vary based on their prior beliefs.
And that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli, but you interpret it subject to your prior expectations.
As a result of this, perceptions are frequently biased.
So what's the overview of the perceptual process?
Brand communication, there's advertising, there's packaging.
And then, you are exposed to them or you're not.
And sometimes the exposure as I mentioned is in a biased way.
And then, even if you are exposed to the inputs, you know when you are exposed to thousands of marketing measures marketing cues every single day.
But how many of them do you pay attention to?
So first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it and finally there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that your perceptions, and I just explained to you your perceptions could be biased.
You have a certain perception, and then you automatically respond to that.
And it's very hard to control that.
Even if you think, well, I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word and reading the word affected your subsequent behavior.
That's actually the purpose of the Stroop Test.
It makes people feel a little uncomfortable, because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches, and you can see, it's much easier and much faster to say the words.
This is the same thing in the way marketing, I'm going to show you that color has an effect, brand name has an effect.
It affects you subsequent perception and your subsequent behavour and it's an automatic reaction that is difficult to stop.
So here 's an example, if I told you this is luscious chocolate and I show you a picture of it in the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh, I don't want to eat this, that disgust feeling.
And you know that it's good chocolate but the shape has an involuntary effect on you.
And that's a very important thing to understand, so marketers need to understand how these things affect your perceptions and your subsequent behaviors, because as I say, these are automatic reactions.
You may have seen these before.
I can show you these two lines on the screen.
I will tell you, you can measure them, they are exactly the same length.
However, one looks longer than the other and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you what is this that I've put on the screen?
You'll answer differently if I show it to you this way, versus when I show it to you this way.
And so, that shows you what you perceive that stimulus is, is a function of your prior expectations.
There's a perception bias that's called the proximity bias.
And what the proximity bias says is that things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that the cluster, the two lines that are close to each other rather than say the two bold lines or the two thin lines.
And you can see this in the supermarket, in stores.
Say, in a salad section in where there's vegetable marketers may put, or grocers may put salad dressing near those salad.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception that physical distance affects whether things or similar or belong together.
In the mall, stores that are close together are seen to be more similar, and there's a lot of use of this particular bias.
Things that look alike, people assume have the same quality.
If a store brand makes itself look very similar to the national brand, you assume the quality is the same, even though you haven't tested it.
You don't know if that's the case.
You're making an assumption of perceived quality based on this process of similarity.
And it's a very, very important consumer process for a marketers to understand.
It's particularly important in branding.
With the Coca-Cola brand on it, people will think it tastes better, they're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product is exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that.
I know, I can judge certain products by the quality.
And we know from experiment after experiment after experiment that that's just not true.
People are very much influenced by the brand name that's put on the product independently of the product quality.
It's the same way in the Stroop Test.
You just can't stop it.
Once you see that brand name you have certain perceptions.
We know that brand is such a powerful brand, as we mentioned before, has so much influence.
The Coca-Cola brand name has been estimated to be worth $70 billion as an asset.
Just putting that brand name on a product will change, as I said, price premiums, people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time that no one had tasted before, a diet soft drink.
They call it Diet Coke, and automatically, even though that product was not on the market before, people assume it has better taste, it's a higher quality product, and again they're willing to pay a higher premium price for that product.
And, I'm here to talk to you about marketing.
So this, this segment is Marketing 101, the basics, the principles of marketing.
Which is what is marketing?
So what's a market?
But what you need for marketing to exist or for a market to exist is to have an exchange.
And what I'm going to argue is that what marketing means is going to differ as a function of different aspects of those exchange.
So let's let's look at the basic exchange.
You have one buyer and one seller.
and the real markets are somewhere in the middle.
But you'll see when I start defining this, that it's very useful to use this, this kind of simplification.
So if we think of an exchange between buyers and sellers.
On one extreme we could have what's called a seller's market.
And in the seller's market what that means is the seller has a product, and if you want that product, you have to come to the seller.
So the seller has all the power.
And what I would argue, and I think would make sense to you too if you think about it, is marketing should not be the same in the seller's market as in the buyer's market.
So, in the seller's market, what marketing tends to be is what we call product focus market.
You have the product.
If the customers want it, they're going to come to you.
In that case, you should develop that product to the best of your ability.
You should innovate in that product, you should try to reduce cost and you should really focus on the product.
Your business objective in a product-focused market is to sell as much as you can, and profitability from a product-focused market is going to come from volume.
Selling as much as you can.
In the past when we've studied product focus market, we've shown that profitability is tied to market share.
So market share becomes your business objective.
And why does market share increase profitability?
Because the bigger your market share, the more your revenues.
And the bigger your market share, and your volume, the lower the product cost and hint profitability.
Higher revenues, lower cost, more profit.
That's really the goal of a product focused market and when you're product focused, where do you get growth?
Will you develop new products based on your product experience or you go to new markets?
So what's customer focused marketing?
Is it the opposite?
In fact, it's quite a different type of marketing.
Let's think about it.
Customer focused marketing means that I need to focus on the customer to get that customer to buy from me rather than the competition.
Well, what's the best way to get the customer to buy from you rather than from the competition?
The best way to do it is to look at what that customer wants, and deliver a product that meets the needs of that customer.
So where is in product-focused market, I'm the expert, and I create the very best product I can based on my expertise.
In a customer-based market, what I'm going to do is look at what the customer wants, and try to create product to meet that customer's need.
That's a very different point of view.
Some people call it inside-out, this product focus, and outside-in is customer focus.
Okay, so now we're going to look at what the customer wants to deliver value to that customer.
What does the customer want?
Well, the first question is which customer?
If we try to give everybody what they want, we'll go out of business.
That's too hard to do.
So the intuition of customer focus marketing, is to pick and choose customers.
Deliver value to some customers.
That's the process of segmentation and they call that, I'm going to talk about that in the next section.
But the idea here is that I go after some customers and I say no to other customers.
Well, then, how do I become profitable in that?
Understand that in a product focused marketing, what we did is sell as much as we can.
We sold that product to anybody who wanted that product.
In the customer focused market, we're saying no to some customers and yes to others.
So, how do we make that profitable?
And, the answer is you pick and choose the customers you want to deliver.
You deliver value to that customer, give them exactly what they want and that they're willing to pay for, and where the profitability comes from is not from volume, but it's from creating value.
How can, how can value-based marketing be profitable?
Well, first thing is if I give you exactly what you want, many times, you'd be willing to pay a premium price.
Then the profitability comes in not from reduced cost, which we saw in the seller's market side, but from increased price premium.
If you give me exactly what I want, I'll be willing to pay a higher price for it.
So that's one way.
The other way, customer based marketing is profitable is by giving the customer what they want time after time after time.
I don't think about just one transaction, I think about building customer loyalty.
And, delivering value to that customer over time.
That concept is called customer share.
Rather than market share, while I try to get a little bit from everybody, the idea of customer share, or share of wallet is that I go after a more narrow market and try to get more from each of that, their, those customer's wallets.
And it turns out that loyalty is very, can, if you do it right can be very profitable.
When I'm doing a customer based marketing it's actually quite expensive to give the customer exactly what they want.
Once I figure out what that customer wants and I deliver it to them the first time, it's cheaper to deliver it to them time after time after time.
So it's more difficult and more expensive to acquire new customers, but its cheaper to retain those customers over time, and that's where the profitability comes from.
It comes from loyalty.
The other thing, if you're thinking about building share of wallet in the customer-focused market, is that I not only sell one product to you.
Let me give you an example of this notion of cross selling.
The, the cashier or that person behind the counter might say: Oh these are very nice jeans.
Do you think you'll need a belt with that?
So I'm selling other things to you besides that one specific product.
All of these are the idea of increasing customer share and that's a very important part of customer focused marketing.
Give the customer exactly what they want.
They'll be willing to pay a premium price for it.
Give them what they want, and keep delivering value over time, they will stay loyal to you, and they'll buy over time.
And that's more profitability.
And if you understand their needs, you can not only deprut, sell them one product, but you can cross-sell other products that may also nee, meet their needs.
So in a customer-based market, where profitability come from is premium price, loyalty, and cross selling.
Difference between sellers market says you focus on the product, on what the customer does well, and you push that out.
And in a customer based market, you focus on the customer, what the customer wants.
And you deliver value to the customer better than the competition.
So that's the basic difference between product based marketing and customer focus market.
Now in today's world the market place has changed even more.
What's changed?
Well now not only do you have an exchange between buyers and sellers, but because of globalization and because of the Internet and technology and social media and things like that, it's not a one to one conversation anymore.
Customers can talk to other customers.
That's good and bad.
If you're doing a really good job and meeting the, needs of the customers, the fact that they'll buzz to their other customers and tell their, their other friends about what a terrific service your company is doing.
Well, that's really good news.
On the other hand, if something goes wrong, and they tell their friends something bad, well that's not such good news.
And so you have to be really careful, in every transaction with the customer now, that you deliver not only value, but that you deliver a top notch customer experience.
Because although what I've been talking about in the seller's market and in a buyer's market has focused on transactions.
But in a connected community, if your message is being transmitted by customers to other customers, they talk about the customer experience.
Lemme give you an example.
It starts way before the transaction, and it goes way after the transaction.
So for example, if a customer told another customer that their experience at a restaurant.
They might say, well I was driving to that restaurant and I hit a lot of traffic, then I got to the parking lot and I couldn't find a parking space, finally when I got into the restaurant, I finally got a table, the meal was really good but then at the end of the meal when I was leaving I tripped and fell.
That may be the way they describe the experience at the restaurant.
And if that's the way your message about your product is going to be transmitted from customer to customer then you as a marketer need to focus on the entire customer experience.
So, one of the things, and we'll talk about this later that's changed in marketing in this world of social media and internet and globalization, is that the marketer has to be completely transparent, has to be authentic, and has to focus on the entire customer experience.
One thing else to mention, we're seemingly coming out of a recession now, but there was a global recession, and in the last few years, probably starting about 2008, we had some real strong economic uncertainty.
Marketing had some bad names, the financial services industry.
And so with all those changes in the economic environment, there's been a focus again, in marketing.
And marketing now has to focus on authentic, genuine customer value.
In order to be profitable, you not only have to deliver customer value over time and in an experiential way, but now because of the tightness of the economy and the uncertainty there, you really have to cut costs and figure out a way to deliver value in a very discipline manner and be very flexible to changes in the market place.
So let me just summarize what I've just said.
The different types of marketing orientations.
There's the product orientation where you focus on the product and you persuade the customer to want what the firm has.
There's the marketing orientation.
That's a customer focus approach.
The experience orientation says that you not only think about the transaction, and think about the transactions over time.
But you try to manage the customer's entire experience with the firm.
And when times get tough or customers stop trusting markets, then you need to remember to build that relationship based on authenticity, on trust, and on discipline.
And what's the difference in these different types of marks in terms of what you offer?
In the production orientation, you're focusing on product innovation, but also reducing costs.
So you tend to see generic products and standardization.
When you're focusing on customer value, you see differentiated products, and we'll talk about that, when we talk about brands also.
In an experience orientation you look at experiential value.
And when you're going to that tight discipline mindframe or mindset you look at genuine value.
And what's the competitive sustainable competitive advantage in each of these markets?
In a product orientation the bigger companies win because they tend to have larger market share and lower cost, and lower cost is a big strategic advantage.
In a marketing orientation, when you're focusing on the customers, the, the companies that do the best are customers, are companies that really know their customers, that can deliver quality, and that have a lot of customer data and know how to use that data to deliver better value.
In an experiential market, you look at transformation.
The customer becomes a co-creator of the value, and it's really making the customer and the product one kind of overall experience.
And in a trust orientation, the sustainable competitive advantage are the companies that you trust.
And what are the measurements of profitability?
In production orientation as I mentioned, market share is tied to profitability.
In marketing orientation, it's share of wallet or customer share, customer loyalty.
In experienced market, when you're looking at customers talking to other customers, we start measuring social networks and buzz and word of mouth and referrals.
So in summary for just this little section, let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to buyer, and get them to buy from you, rather than the competition, you've got to give them real, genuine Customer Value.
That's the Principle of Customer Value.
The second principle is the Principle of Differentiation.
You have to provide customer value to that customer what the customer wants but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation targeting and positioning says when you're in a customer focus market you cannot deliver value to everybody and make money it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of Marketing.
The four P's of Marketing are product, place, promotion, and price.
What the seller puts into the exchange is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer, is called the Promotion.
And the way the seller delivers the product to the customer is the Place Decision.
Typically, when you talk about marketing, you talk about the business world, but you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increases in blood donations.
Now let's think about what is the product for the American Red Cross when they want more blood?
It's not blood, is it?
Because that's not what they're putting into the exchange.
Blood, is actually the price.
It's what the customer puts into the exchange.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes, I gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high school.
And it turned out what, one of the products that the American Red Cross could give to high school kids to give blood, was to allow them to miss class.
So, that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross.
And the place decision was how they got the product delivered to the, and the exchange made.
And in this case the American Red Cross had the Blood Mobile.
And, and went to the customers so that was a very innovative distribution decision.
So you can play around with these four P's in very interesting ways and some of the new businesses that we see now are doing some very clever things with these four P's.
But the basic concept should be clear, product, place, promotion and price.
Let me say that there's three principles of marketing that I've discussed.
and this is the essence of what marketing is.
The first principle is, if you want to provide something to a customer, to a buyer, and get them to buy from you rather than the competition, you've got to give them real, geniune customer value.
The second principle is the principle of differentiation.
You have to provide customer value to that customer, what the customer wants, but you have to do it better than the competition.
So you have to differentiate your offering.
And the third principle is the principle of segmentation, targeting and positioning says, when you're in a customer focused market, you cannot deliver value to everybody and make money, it's just too difficult to do.
So what you do is segment the market into different segments.
You target or choose a segment you want to focus on, and you position your brand to meet the needs of that target segment.
And what are the tools that you use to deliver these three marketing principles?
They're the four P's of marketing.
What the seller puts into the exchange, is the product.
What the buyer puts into the exchange is the price.
The way the seller communicates the benefits about that product to the buyer is called the promotion.
Could be advertising, sales, whatever.
And the way the seller delivers the product to the customer, is the place decision.
It can be in a physical store.
It can be online.
It can be through, downloading.
So those are the four P's of marketing, product, place, promotion and price.
Typically when you talk about marketing, you talk about the business world.
But you can use these principles of marketing in non-profit marketing as well.
Think about blood donation.
The American Red Cross used marketing principles to get increased in blood donations.
Now, let's think about, what is the product for The American Red Cross when they want more blood?
It's not blood, is it?
Because, that's not what they're putting into the exchange.
Blood is actually the price.
It's what the customer puts into the exhcnage.
So what is the product?
What the American Red Cross did was try to figure out ways to get people to be more willing to donate more blood.
So in one way they did, you know, feel good about yourself, you're going to help save lives.
That worked for some people.
For some people, that wasn't enough.
They needed a little sticker that said, yes I s, gave blood today and I saved lives.
For other people, the orange juice and the cookies were enough.
And it turned out that some of the best blood donation successes they had were in high schools.
So that was the product there.
The promotion again is the way they communicate the benefits of giving blood to the American Red Cross, and the place decision was how they got the product delivered to the, and the exchange made and in this case the American Red Cross had the blood mobile and, and went to the customer.
So that was a very innovative, distribution decision.
So, you can play around with these four P's in very interesting ways.
And, some of the new businesses that we see now are doing some very clever things with these four P's.
But, the basic concept should be clear product, place, promotion, and price.
And what I'm going to go over is based on a, a book that was written by Tracy and Wiersema it's called Market Leadership.
And its based off of their framework, although I've adapted it some.
And, the framework or the, well I'm going to think of it as kind of the graph or the strategic tool, is based on a set of principles.
These principles have to be true and you have to believe in them in order for this framework to work.
And they're very strong principles.
I don't think they're that controversial, but they're not vague, they really are very strong, and in order for this technique to work, you really need to abide by them.
Now before I mentioned a lot of, most businesses are now in customer fosed market, customer focused marketing.
because most businesses are very competitive, they're global.
There's a lot of competition out there and the only way they're going to win in their market place is to focus on the customer.
And furthermore, you know how your competitors are likely to react.
And so what you are trying to do is what I mentioned that principle of differentiation.
You're trying to find a way to provide customer value, better than the competition.
And the only way you can really deliver this.
And you can't just guess.
You have to do market research and you have to really understand what your customers want and how your competition's likely to react.
So that's the first principle.
And the assumption says and what I've written here is customers have the final say.
And what that means is the customers are going to choose what they want.
But the assumption is a strong assumption because we assume the customers go through this decision process.
They look at all the data and all the values and all the attributes and all the products in the market.
And, so what they do is they kind of chunk a bunch of different things together into kind of three bundles.
But delivery, service, reliability, those, all of those kinds of things are considered operational things.
The other bundle is product features or designs, so product attributes style, innovation, technology and they put that in another bundle.
Whether or not it meets my needs, so is it customized to meet my needs?
And what the customers have the final say says, is that customers look at these three, they kind of classify the products into these three bundles and they kind of give them a score in each one of these three dimensions.
And then they decide which one of those dimensions is the most important to them and they pick the product that's the best on one of those dimensions and good enough on the other two.
So, it's says, you can't be pretty good in all three of them.
Or if they care about how much it meets their own needs, they're going to go for something that meets their needs the best, as long as the product delivers satisfactorily or good enough on the other two dimensions.
So, that's a very strong assumption.
But if you think about it, it kind of approximates the way customers make decisions.
If you believe that assumption, that the customers have the final say and they choose the product that delivers the best on the bundle of attributes they care the most about, that suggests that if you want to be the first in the markets that you serve.
And that should be your market strategy and once you decide on which type of thing you going to be the best at, the market leader at, then that have indications for the way you structure your business, the way you prioritize resources, the way you allocate resources, the type of people you hire into your company.
It has all sorts of implications for your business organization so that you can deliver total value and total quality and guarantee the customer satisfaction on this dimension.
So, those are the assumptions.
Now, before I show you the framework I have to introduce one other concept and this concept is what I'm going to call, fair value.
And what I have on the screen here is a value map.
And you have on the vertical axis, relative costs to the customer.
And on the horizontal axis, relative benefits.
And what the map says is that if you offer more benefits, customers are willing to pay a higher price.
If you charge a lower price, customers will expect fewer benefits, as long as what you offer appears to be fair.
If you offer something inferior and it's not fair value, then customers won't buy that.
So it, you won't make it in the market.
And what the framework says is that you need to offer fair value on two of those bundles, but offer something better than fair value on one of the bundles, on the bundle you are going to be the leader on.
So if you can imagine a marketplace where everybody is trying to deliver fair value and somebody is delivering something of superior value.
Think about what's going to happen in that marketplace, in a very competitive market.
Somebody comes out, let's say Apple comes out with a better design and so the iPad comes out and it's a much better design.
It, it fair price on these other axis, but there are, their tablet is better than everything else.
And what happens is everybody tries to copy and mitigate the advantage.
And so what happens is what's perceived to be fair value, that fair value line is not a static line.
It's constantly moving up, moving to the lower right as the market gets more and more competitive.
So what's fair value is constantly changing over time.
So although I say what you need to do in this framework is to deliver the best of something and state fair value on the other two bundles, the problem is fair value's not a static constant concept.
It's constantly changing as a function of competitive reaction.
So, with that said as background, here's the framework.
And here are the three bundles; one of them is operational excellence, the other's performance superiority, that's the bundle that delivers on product design and style.
And the third is customer intimacy, which says give the customers what they want.
And, you're intimate with customer needs and you try to deliver something that's responsive to their needs.
Now I had them drawn symmetrically on this axis, but it doesn't have to be symmetric.
What you need to do is, if you want to use this framework.
Is in your marketplace, figure out, what are the product attributes that relate to operational excellence in your market.
You have to do the same thing, or what are the product attributes that matter to the customer?
Are they design, technology, whatever it is, what are those attributes and define that dimension.
And then you have to figure out how much customization is there in your market and define that dimension.
That's the first thing you do.
The second thing you do with this framework, is anticipate where fair value is.
This is the trickiest part of this framework.
And where is the reference point or the fair value line on each of these axis points.
Sometimes people think about fair values, the average of what everybody offers.
Like for example, I would say in the airline business, people expect an operational excellence, constant on time arrival.
And we know very few airlines deliver to that fair value.
What I think people expect and I would say, most of the competitors in the market are below fair value.
Sometimes, everybody's above fair value.
In some mature markets, people don't care about some of the bells and whistles that come out.
And everybody's delivering at least what they need.
And some people more.
But people didn't even care about that.
So figuring out exactly where fair value is and each of these axis is a very tricky thing and you need market research to do that.
Once you figure out where your value is, on these, the next part is to plot, where your company is delivering, on each of these axes relative to fair value.
Then you figure out where you competition is on each one of these axes and then you start playing the market strategy game.
You think about a short-term strategy, a long-term strategy and you figure out What should you be doing right now in order to beat the competition?
And what you're ultimately looking for in a long term strategy is to be the best at one dimension and good enough on the other two.
That's the long term strategy.
In the short term it might be that let's say your long term strategy is to be customer intimate, but you're not at fair value in operations.
So in the short term you might be looking to hit fair value in operations, but in the long term you're looking to be the leader in customer intimacy.
And once you decide what your leadership strategy is then that has implications for everything you do in your firm.
So for example if you are an operational company and that's what you want to be your leadership strategy, that tends to be a very hierarchical strategy that, with allocation of resources prioritized to information technology et cetera.
If you are a performance superiority company, that tends to be more of an R and D company.
Very innovative, they don't like structure, they don't like top-down organization, you really need to give them a lot of free reign.
And in a customer intimacy, you really have to focus on prioritizing market research, customer knowledge and you kind of have a consulting, a yes culture.
You have to let the customer come first.
So each, once you decide on your leadership strategy has a lot of implications for the rest of the firm.
Hi, I'm Pete Fader, I'm the Pei-Yuan Chia Professor of Marketing at the Wharton School and co-director of the Wharton Customer Analytics Initiative.
I'm really excited to be starting my module of our introduction to marketing course.
But the fact that I run a research center called, The Customer Analytics Initiative suggests that I'm a data guy, and that's true.
I love looking at data about customers, try to figure out which customer is doing what and for how long and for how much money, and what kind of tactics can companies use to create and extract more value from the customer.
So for me, it's all about the customer behavior, the, the patterns that we see over time and the kinds of strategies that companies can build around those patterns or to do better for themselves.
So I want to start by going back to one of the frameworks that Barbara Kahn used in her modules.
And a couple of these strategies are really clear.
It's, it's just having the very best product out there.
So whether you're an Apple, a BMW or a luxury product like a Louis Vitton or a Gucci.
Operational excellence is also pretty clear.
you want the lowest price, you want the most efficient operation or the most efficient experience for your customer.
So whether you’re talking about a Walmart or an IKEA or a Zara, you are really interested in keeping the cost low, keeping the process very efficient.
But it's the third leg of this diagram that we're going to spend a lot of time on.
This idea of customer intimacy.
Let's focus on the customer.
But exactly what does that mean?
Who is the customer?
Are we going to focus on all customers the same way?
Just how intimate do we want to get.
And how do we actually make more money on something that actually adds costs than some of these other strategies.
So that's going to be the main focus of our efforts, is taking this idea of customer intimacy.
Clarifying what it isn't, motivating why it's important, and trying to get firms to make a well informed decision about whether they want to pursue that kind of strategy.
And, whether when or how to actually go after it.
So that's going to be the focus of our work.
One of the popular shopping areas in Philadelphia.
And all around me would be stores that represent the different kinds of, of strategies that Barbara spoke about.
Just over my right shoulder, you'll see one of my favorite pizza places.
Right down the block, there's a number of fast food restaurants.
But what about customer intimacy?
What kinds of stores would really be customer intimate, or customer-centric, as I like to say.
So let's really understand how these different strategies compare with each other, and then take the deeper plunge.
So give me a few minutes to review the traditional steps of running a business.
Running a business in a performance superior or operationally excellent kind of way and that's going to give us the basic foundation so we can really understand how customer centricity is different.
And some of the opportunities that customer centricity can provide, that you might not be able to achieve, with a performance superiority or an operational excellence strategy.
So let's take a step back and review these traditional steps of running a business.
For most commercial enterprises the overall objective, beyond everything else, beyond all the tactics that a company is, is using and the strategy that it's hoping to follow, it's all about making money.
And again, Barbara reviewed this and you don't need to be told this.
it's all about maximizing the value of the whole corporation.
It's looking at the money that we make today, the money that we'll make tomorrow, the money that we'll make ten years from now.
When we take the discounted flow of the company's profits, that in theory, gives us the overall value of the corporation.
That part is pretty easy, conceptually.
But the question is, how do companies achieve it?
And that takes us back to those core strategies that Barbara laid out.
And when you think about the most traditional one among them, again performance, superiority, operational excellence.
Coming up with a brilliant idea that puts us steps ahead of all of our competition, and then figuring out ways to bring that idea, that product or service to market.
And so the key, for most firms for making money, isn't only coming up with that idea but then figuring out ways to produce lots and lots of it.
And one of the things that we've discovered over the years, is that producing lots and lots of quantities of this product or service that we want to deliver, not only helps us make greater revenue.
But the fact that we're producing and distributing so, so much of it also brings our cost down.
So the, the core focus of most traditional businesses is high volume, low cost.
And again, coming up with a great idea that enables us to do that.
So, so many companies have built their business.
And even today a common question that we always ask ourselves, particularly when we have a new business is will it scale?
So that's, that's, that's the basic way that most companies operate.
And over the years, many different metrics have arisen that help companies understand how well they're doing it.
Are costs coming down as we develop and deliver more and more of this product or service?
For instance, a very powerful metric is market share.
There's a lot of research that goes back to the 1960's, the 1970's that shows that market share is not only a good backwards indicator of how well you've done, but a leading indicator of how well you will likely be doing in the future.
So, so many other metrics, like market share and others, are central to this product superiority, or operationally excellent strategy.
And in fact, they're mandated to have growth.
It's not enough just to do what you're doing a little bit more efficiently and effectively.
They want more.
What are the sources of, of major growth that, that a company can enjoy?
And we really see two different sources, that at first sound fairly distinct from each other, but when we think about it a little bit more carefully they're actually just different flavors of the same kind of growth.
So let's think about them a little bit.
One source of growth is taking the products and services that we've been delivering already and bringing them to new customers.
So it's taking this great product or service and bringing it to new customers.
That's clearly a new source of growth.
The other source of growth that I'm sure all of you could think about, would be innovation.
So let's go back to the folks who developed these great products and services in the beginning, and say give us some new products and services.
Okay you have a certain degree of expertise that has enabled you to bring us the current product.
What more can you do to bring us either variance of that product, or entirely new ones that haven't existed before?
So that's an obvious source of growth would be new products, or extensions to existing products.
So at first, this idea of taking our current product and bringing it to new customers, or coming up with new and different products seem fairly different from each other.
And indeed the tactics associated with them, the expertise within the corporation does indeed have to be a bit different.
When we step back and think strategically, both of them actually have a lot in common.
How can we take that product expertise, and either extend it to new customers or extend it to new products?
So regardless of the specific way that you go after growth, the main source of growth is extending our overall product or service delivery.
And that's what most companies have to be really good at.
We're going to try to do it as, as efficiently or effectively as possible.
Now how can we take that product expertise and extend it in new directions?
And how do companies go about doing that?
Well if you look at the organizational chart of almost any company on the planet.
So you'll have a product manager or a brand manager, but it's all about having separate silos around the different products or services and then organizing all the activities that way.
And so, so, very often each of these different silos will be responsible not only to run its own operation as efficiently as possible, but think about it's own way of extending that kind of product expertise.
And so, if we sum up the way that most companies operate, it's all about this idea of product or service expertise.
That's the competitive advantage that so many managers, so many academics, so many industry experts have focused on for so many years.
We are the best at conceptualizing, developing, delivering a certain kind of product or service.
By going to new markets, and always developing new products and services that are going to keep us a step ahead.
So what I've just described to you is pretty standard stuff.
For most of you, if you look at your experience as a consumer or through your work experience, you'll realize that that's the way that most businesses operate.
And instead of just calling it business, we can now put a label on that.
But today, we're seeing different kinds of business models emerging.
And so we want to now distinguish the set of practices that I just described.
And realizes, uh-oh, I'm in a different environment now.
I'm going to stay in the water.
And this is exactly the kind of issue that many companies are facing today.
It gives them some opportunities for growth.
But for other companies, whether it's out of desperation or out of opportunity, they're looking for different kinds of environments.
They're looking for different kinds of strategies.
We're seeing more and more companies, jumping out of the water, and saying is it better out here?
How can I operate out here?
Should I operate out here?
And that's why we're now going to put a specific label on the old way of doing things, product centricity.
So again, most of you understand that, this is business as usual.
And just to sum up the product-centric world before we kind of start moving away from it, I have this one other slide for you here.
And if you look up and down the slide, you won't find a lot that's tremendously insightful, and that's the point I want to make.
Is that the traditional product centric approach to business, again, focusing on performance superiority or operational excellence.
So if you look at as the slide shows, the kinds of customers that we're going after, the kinds of metrics that we're using, the overall focus in the organization and the business, it's pretty standard stuff.
The idea of the mental process.
And it goes back to an idea I mentioned a few minutes ago.
We have this product expertise, what can we do with it?
How can we spread it out to other kinds of customers, and other kinds of businesses?
Again, implicity, that's the way that most businesses operate.
Okay, so we've reviewed the product-centric approach to business.
We understand that for most companies, again those focusing on performance priority, or operational excellence, it's all about coming in with that blockbuster idea, reducing a lot of it, keeping the cost down, and using appropriate metrics for it.
Now, we're going to start talking about some alternative approaches, but I don't want to suggest that product centricity is doomed to fail.
I don't want to suggest that that's a recipe for disaster.
But I do want to suggest that there are some aspects of product-centricity that make it not quite as great as it used to be.
So as you can on this slide over here, I like to say that there are some cracks in product-centricity.
There are just a, a, a number of trends going on today, things that didn't really exist say 15 or 20 years ago.
In fact, I'd like you to just take a, a minute or two think about what are some of the changes, today, compared to 15 or 20 years ago, that make product centricity just a little bit different?
Most of which are trends that are here to stay, that might make a company think twice about whether they want to focus on product-centricity, or start looking towards a different kind of strategy.
Take a moment and think about that, and then we'll run down a list of some of the leading factors that, that take some of the edge off of product-centricity.
So I bet first and foremost on everyones list, is the idea of commoditization.
See back in the old days, it was so hard to come up with and, and manufacture a new product, or deliver a service.
That you would stay steps ahead of all of your competitors for a long period of time before they could come, come up with an equivalent idea.
Companies know that as soon as they launch something new, they have to have the next new thing already in process.
Here's a way of thinking about it.
In the product-centric world, every company is counting on some kind of natural monopoly.
We're doing something that's going to keep us ahead of all of our competitors for a long period of time.
But as those life cycles shorten, as things commoditize, it takes away some of that natural monopoly power.
It's a big one, but by no means the only.
It used to be that our customers were much more passive.
They would take whatever products or services that we would give them, and they would say, oh, that's great, terrific, thanks very much, I'll figure out how to use it.
But today's customers are much different from yesterday's customers.
And again, a big reason for this is, the internet.
Information technology.
Customers are so much more aware of options that are available to them, or options that might not yet be available to them.
But that they, they clamor for than they ever were before.
And make it harder for them to extract as much value out of the products and services that they deliver.
And a third way that technology makes life a little bit more difficult for product-centric companies, is, is the idea that products are, are now available everywhere instantaneously.
If you think about what FedEx, or DHL, or UPS, does they take away some of that natural monopoly power that a company had.
In the old days, companies would rely on the fact that no one else had a product like them.
But even if other companies did have a product like them, customers wouldn't be aware of it.
And even if customers were aware of it, customers wouldn't have access to it.
But today, because distribution technology brings everything, everywhere overnight if you want it, it's much harder to protect yourself from other products and services that are, that are available in, in in other regions.
But by no means is it limited to technology.
So, so customers are, are much more actively looking for products and services from other regions than they ever were before.
And then there's the issue of deregulation.
That they were the only game in town and customers had no choice.
But as one industry after another deregulates, companies need to be much more competitive.
And in some cases, it's not deregulation, but it's re-regulation.
It's regulations that are making markets much more competitive.
A sixth reason comes back to the customer again.
Not only is the customer smarter, but as I mentioned before, customers are far more demanding than they ever were before.
Figure out how those different products and services are going to help them solve the problems that they have.
But today's customer is much more demanding, and is insisting that companies not only deliver them one product or service at a time, but, but bundled together products and services.
Sometimes, including products and services that the company might not make any money on.
They were just the best at coming up with, and developing certain kinds of products, business machines, computers and so on, better than anybody else.
But they had a revelation in the mid 1990s, that they could actually make more money being a trusted advisor.
Instead of saying here, customer, buy our machine, telling a customer what set of machines and services to be buying.
That there are actually higher margins, especially as computers and other information technology equipment commoditizes, they can actually do better being a solution advisor.
And slowly but surely, as many of you know, IBM spun off many of its business machines.
They no longer manufacture personal computers.
their, their presence in most other hardware areas has diminished.
But where they're making their money today, is from being a customer centric solution provider.
Is going to the customer and saying, here are the set of products and services you should be buying.
And so that idea of moving away from just selling products, to being a full scale solution provider is a major change in the last 15 to 20 years.
And there's one more point that I want to talk about with you.
And it's not necessarily the most important crack in product-centricity, but it's one that I like to think about a lot.
And that's the data.
See, today's technology enables us to collect and manage, and utilize data about customers, in a way that we just could have never imagined before.
Think about Henry Ford, who was one of the, the real originators of product-centric thinking.
He didn't know whether he was selling one car to each of ten million different people, or whether he was selling ten million cars to one person.
He didn't know.
And frankly he didn't care that much.
Because he was so product-centric in his thinking, that it was just a matter of turning that crank, of pushing products out the door.
But today given these other cracks and product-centricity, it's much more important for companies to be using the data about their customers.
To be understanding who's buying what.
So the information systems give us the possibility of developing business models that were unimaginable before.
But could actually be more successful than the product-centric approach.
And I want to give you a couple of examples of that.
So I want to talk about a couple of examples about companies that have used information technology and specifically the data about their customers.
To come up with business models that are quite distinct, from product centricity.
In many, in many ways the stories are quite similar.
Despite the fact that they're very different companies operating different businesses and different geographies.
They weren't nearly as large as some of their competitors, they didn't have the resources to compete head-to-head, in a traditional, product-centric manner.
And so they turn to the data.
They turn to a deep understanding about their customers to draw insight and to let them change their business models in a way that actually let them rise to the top of their industries.
It was hard for them to develop the products and services to compete on a head to head basis.
So Harrah's instead turned to its data, and in particular, developed an amazing loyalty program.
Now many companies develop loyalty programs, but few of them were able to draw the actionable insights that Harrah's was to truly understand at a granular level what each customer's doing.
And to understand, when that customer is likely to change his behavior, when he's likely to walk away from the table, and what kinds of things that Harrah's itself could do to change their behavior for the better.
What kinds of messages and offers to provide, at the right time, and through the right channel, in order to create and extract more value from that customer.
It's time to offer them a meal or some kind of other activity which is going to make them feel great.
And so when they sit back down again, their threshold is back towards zero.
And it's a very similar story for Tesco.
Sansbury, Morrisons, and so on.
They really understood their customers in some very clever ways, they would understand which households were buying a lot of their meals and, and other products from TESCO.
So, Tesco knew which kinds of coupons to send to which kinds of households, at which time, in order to get them to buy more.
And this helped them not only grow the business with those customers, but also helped them to compete more effectively.
So Tesco knew, again, which coupons to send to which households, at which time, in order to really hold on to those customers and bolster their business.
TESCO is able to do a great job defending itself against Wal-mart and, and staying at top of the grocery business in the UK.
So those are only two examples of companies that have turned to the data in addition to developing fine products and services but really leaning heavily on the data and a rich deep understanding of their customers.
In order to pivot their business model, in a way that they could never achieve, through products and services alone.
So while the Harris and Tesco stories are terrific, I will provide pointers to some books that summarize each of those stories quite well.
I want to emphasize that they're not the only ones who have built a business around a deep understanding of their customers, and by no means are they the first.
In fact, the first companies that actually built a business in this manner, around their customers, has happened many, many years ago.
And it emerges from the sector of direct marketing.
They think about infomercials and other, you know, not great marketing activities.
it, it's, it's not the kind of industry that you aspire to be associated with or learn from.
If you, if you look at, at what direct marketing is really all about, it is really building the business around the customer.
But not just, the customer in some generic sense, but around each and every customer.
It's about understanding the relationship with each different customer.
That's what direct marketing is all about.
What's interesting about it is, that direct marketing is not a new concept.
There's actually a lot we can do, we can actually formalize some of these business practices, and come up with some best practices associated with them.
But even if you don't spend a lot of time thinking about direct marketing, a lot of the words and the concepts have already filtered their way into today's everyday marketing conversation.
So, a lot of the segmentation concepts that Barbara discussed are often associated with direct marketing.
Something that you've heard about before, that we're going to spend more time talking about, that's, that, that comes directly from the direct marketers.
We can collect all this data about our customers, about each and every one of them, and we can actually build a business by understanding who the valuable customers are, who the less valuable ones are.
Which messages we should be sending to which customers at which time, and, importantly, what kinds of products we can develop and deliver in order to create more value for our most valuable customers and to try to attract more customers like them.
So the Harris and Tesco stories are wonderful, but they're not unique.
And so I want to spend a lot of time celebrating some direct marketing practices.
And I want to emphasize that a lot of firms out there today might not aspire to be direct marketers, but they don't realize it, but they are.
Has the capability to learn from direct marketing, and I encourage all of you to read books on direct marketing.
Even if you don't think about yourself that way, there's just so many concepts that you can learn and leverage, especially as we enter this world of big data.
And we've discussed some of the cracks in product centricity.
And even some of the opportunities for companies to escape from and maybe do better than a product-centric approach.
And so in order to do that, I want to work with a series of examples here.
In fact, on the slide, you'll see the names of four very famous retailers.
Three of them operate on a global level so Walmart, Apple, Starbucks.
I think, you'll appreciate the story anyway.
So I want you to think about what customer centricity means, in light of our discussion so far.
So think about what customer centricity means and which of these firms qualify in that regard.
Now, I want to be careful about this.
I really like what they do.
But all of them for different reasons fail to be truly customer centric, nearly as much as perhaps some of you thought in deciding which of these firms are or aren't customer centric.
So let me just take a few moments to talk through each one of them and then finally, we'll bring up our definitions of customer centricity.
But Walmart knows surprisingly little about any one of its customers.
Unlike Harrah's, unlike Tesco, unlike so many other retailers out there, Walmart does not have a loyalty program.
Walmart has made very little effort to date to try to figure out exactly what each customer is doing.
So while Walmart might not make a lot of efforts to understand what anyone costumer is going to buy, they make great efforts to understand the costumers as a whole.
They understand regional differences.
They understand when certain kinds of events occur for instance when a hurricane is about to hit the Southeastern US, they need to fill the storage with water and batteries and so on.
So they understand the customer in a generic way but they make very little effort to understand the customers in a very specific granular way, as a direct marketer would suggest.
That doesn't bother me because Walmart isn't intending to be a direct marketer.
If you think about the Walmart business model its about selling in great volumes, its about bringing the cost way down.
So in many ways, Walmart is a prototypical and a wonderfully successful product-centric firm.
There are few firms in the world that can operate an operationally excellent manner, as well as Walmart can.
It's a similar but different story for Apple.
They don't spend a whole lot of time doing market research to figure out exactly what the customer wants.
They don't spend a whole lot of time focusing on segmentation, and real granular analyses to try to predict what any one customer's going to do over time.
Now Walmart and Apple for the most part are focusing on doing product-centric things.
They are doing some smart things at the margin to understand their customers better.
A mobile app that let's people scan products as they move around the store so as they check out the whole scanning process happens much faster.
It's a brilliant idea that let's them be more operationally excellent, but also let's them start tagging individual customers, and tracking them over time.
So they're starting to take on some more customer-centric initiatives, without sacrificing the operational excellence.
And Apple is also starting to do a number of things.
Again, small initiatives not driving the business, but letting them understand their customers a little bit better.
Whether it's tracking people's music preferences through iTunes or some of the activities that they do in the apple retail stores.
But today, it's not quite as mission critical as it is for other firms.
The third company on our list, Starbucks, is a very interesting contradiction.
The Barista, the person on the other side of the counter.
The person who makes your coffee, knows a lot about you if you're a regular customer.
Not only does he or she understand your coffee preferences and what other items you might buy in that store, but just through just casual conversations you have with them, they might know what movies you like?
And often make recommendations to you that are going to make your life better even if Starbucks itself isn't making a penny off of those recommendations.
Okay, being a trusted adviser to the really good customers, finding ways to lock that customer in, and so on.
So, the paradox is, while Starbucks is very customer centric at a local level, they're not that customer centric.
You take your Starbucks loyalty card and you bring it to a Starbucks in another city or another country.
But it's hard for them to be a trusted adviser and to make other recommendations to you, when they have no idea about anything about your history.
So to me that's a really key point.
They recognize that the opportunities and the necessity for customer centricity is at least as important as it is to come up with the next great coffee flavor.
It's the balance between focusing on the product and focusing on the customer that so many companies are now struggling with.
And finally, there's Nordstrom, and while that might be the least familiar company on the list, especially to those of you outside the US, it might be the most interesting example to help us understand what customer centricity really is and isn't.
But whether you shopped at a Nordstrom store or not, you might be familiar with the story that makes Nordstrom so supposedly customer centric, or not.
They sell clothing, shoes, and so on.
Supposedly in Fairbanks, Alaska and wanted to return a set of tires that obviously they could not have bought at Nordstrom.
Perhaps there was a tire store at that location before Nordstrom opened shop.
And Nordstrom's being so incredibly customer-centric gave them the money back for tires that they didn't buy at Nordstrom.
If you think about it for a minute, is that really customer centric or is it actually kind of stupid?
Does it make sense to give someone money back for a product that they couldn't possibly have bought from you?
For me, I say, most of the time it's probably a bad idea to do that.
When would it make sense to give someone money back for a product that they couldn't have possibly bought from you?
And here's the answer.
I'm talking about the fact that we expect this customer to be buying so much from us in the future, that if we don't give them enough money back for the tires that they thought they bought from us, if I don't give them the money back today, we're going to lose that value.
If that's the case, we'll happily give you the money back for the tires that you didn't buy.
So it all depends on the value of the customer, the future value, the lifetime value of the customer.
If that's sufficiently high, then we will roll out the red carpet for you.
And if it's not and for most customers it wouldn't be then, we would politely decline.
We might still be nice to you of course, but we're not going to give you money back if we don't see the value in it.
And that's the problem with Nordstrom.
And that's the problem with Nordstrom's, is that because they fail to focus on figuring out the future value of each and every customer, they're just going to treat everybody really well.
And there's a lot to be said for that.
It's a wonderful company.
I like knowing that when I go in there I'm going to be treated really well.
So to me the Nordstrom example is a great example of where product and customer centricity collide.
And what I want to do now is to start focusing on what customer centricity really means.
And that's what we're going to do next.
Just to review in module one we looked at traditional ways of doing business, particularly for a strategy associated with Performance superiority or operational excellence.
and we looked at the different characteristics of businesses that do that kind of thing, which of course I called product centricity.
So what about your business, or what about these businesses around me here on South street?
How do we determine whether a business really is or isn't customer centric?
In other words, what is the definition of customer centricity?
So in fact, I'd like you to take a minute and just jot down whether it's a full sentence, or even just a few words that you would associate with customer centricity.
Take a minute and do that, and then I'll, then I'll give you my perspective, my definition on what customer centricity is.
I'm going to show you mine.
I want you to think about how this definition of customer centricity, and what it implies, just how radically different it is from conventional product-centric business practices.
In fact, I want you to look at these words and tell me, if you were to start doing exactly these kinds of tactics, if your company was to start having these kinds of perspectives, why you'd be fired?
Okay, if you look at it, there's a lot of things that might make sense.
One of them would be this idea of select set of customers.
In the product-centric world, you can't have a select set of customers.
In the product centric world, we're so dependent on generating as much volume as possible, on the selling as much stuff as we can, that we can't really afford to be selective.
It's going to be hard to keep our costs down if we're selective.
So the whole idea of having and emphasizing a select set of customers, very much runs against the grain of, of many businesses.
Another would be the bottom line on this definition.
The idea of really focusing on maximizing the long-term financial value of certain kinds of customers.
In most situations it's hard for a company to do that.
Given the pressures of Wall Street, and just the conventional ways we look at business.
Whereas in the customer-centric world, and going back to many of the examples that I mentioned before, we want to invest in the right customers.
We're willing to, to recommend products and services that we're not going to make any money off of.
For instance, going back to the IBM example, there was a case where a company was willing to recommend other products and services.
But locking in customers for the long run, being seen as a trusted adviser in some cases can be worth it, that the long run profits that we can get from customers can be greater than just trying to get them to buy another thing right now.
So again that's a radically different way of doing business.
Another part, higher up in this definition, is the idea of aligning our research and development activities around our customers.
The way it usually works is, we go to the R and D people and we say, hey R and D guys, gals, come up with the next block buster for us.
You've been so good at, at coming up with these terrific products and services.
Let's come up with something for them, something that's going to make them even more locked in, something that's going to create greater long-run value for them, and something that's going to help us recruit even more customers like them.
The fact is, they like the products and services that we develop, and so if we leave it up to the R and D people, whatever they come up with next our, our customers will probably love it anyway.
It's, it's the way, just changes the conversation, and perhaps the design, within the organization.
That's what starts making it customer-centric.
See, there's a lot of companies that might adopt that definition or something else like it, and then put a big banner on the lunchroom wall for all the employees saying we are now customer centric.
Well, it's not that easy.
There's a lot of challenges in actually bringing this definition and this mindset to life.
So we can see in the rest of the slide over here about what customer centricity really implies.
And I want to give you a few examples about that.
Think about it this way If you have that kind of backwards-looking program, you're encouraging, you're incenting your salespeople to try to close sales that were going to happen anyway.
Like, you know, hey, I've got to get this one done before the month ends so I can get my bonus.
In order to have real long-run benefits, you have to be future-looking.
I want a company to calculate the lifetime value of each and every customer.
And let's ask ourselves, not, not just how much stuff we sold to the customer, but how much did we elevate their lifetime value?
So instead of us going to customers who are going to buy things anyway, and just watch them buy things they were going to buy, let's try to build relationships with customers.
Maybe they weren't inclined to buy, and you know what?
Maybe they didn't, by the end of the month.
That we think in the long run we've, we will create much more value that wouldn't have been there.
On future value that they're sowing the seeds to create.
But if you can do it, and I'm aware of a number of firms that have in a variety of different businesses, then you're actually much better off.
Think about it from the salesperson's perspective.
Instead of just rewarding them based on what they've done.
You want them to invest in the customers, even if they're not getting anything out of it right away.
I mean, after all, that's what sales people want to do.
They don't want to just close sales and move on.
And again, I can point to examples of companies, I'm, I'm thinking of a particular pharmaceutical company that changed its sales person incentive program to be forward-looking instead of backward-looking, and wonderful things happened.
The salespeople were happier, the company made more money, and the salespeople actually looked to the marketing people to say hey, can you help me identify other good prospects that I should be going after?
So instead of just trying to, you know, shake down customers, to just make sales right away, that kind of relationship building is good for absolutely everybody.
Think about airlines, think about MBA students.
I spend a lot of time thinking about MBA students.
What happens to our Wharton students when they come to school?
Now what happens for the two or so years, that they're at Wharton?
Their status with the airline drops, and then when they start on a new job after graduation, they have to start all over again.
If the airlines were really forward looking, they would recognize that some of these students, are going to take a temporary hit on their travel.
But after they graduate, they're going to be traveling even more, far more than they ever did before.
So if the airlines were smart, they would go to our students, the day they were admitted, and so you know what?
We're going to put you in the Presidents Gold Medal Chairman's Red Carpet Club for the next five years.
That's what I'm talking about, and that's what we don't see a lot of.
Customer centricity requires us to look ahead, figure out who the valuable customers will be and do things for them to help them recognize that we have their best interests in mind.
That's the kind of investment that I'm looking for.
As we wrap up our discussion about what customer centricity is, I just want to offer a few more reflections or questions, associated with customer centricity.
Again, is it the end consumer, who's buying and using the product?
If you think about many situations, it's not so clear.
I work with a lot of pharmaceutical firms, when I ask people at those firms, who is the customer, I'll often get four different answers.
Is it the hospital or the medical practice?
Is it the insurance company?
So one of the important steps on the road to customer centricity, is getting some agreement on that question.
Agreeing, that one of these entities is the customer, we care a lot about the others, we need to keep them in mind, as we go through our planning practices.
So it's important to first sit down and figure out, who the, the customer could be.
And then having a healthy discussion, to try to come up with the consensus about, which one we're going to focus on, and which other ones, might still be on our horizon.
There might be cultural reasons, it's just impossible for this company, to move from a product centric, to a customer centric view.
And before saying, we're going to become customer centric, it's very important to come up with that list, and think real carefully about, existing barriers and new ones, that can be arising, to, to do a real careful inventory, of, of, of barriers towards customer centricity.
And of course at the same time, you want to think about the resources that you could bring in, to address or maybe preempt, some of those barriers.
Sometimes, they're going to be cultural, we're going to have to hire the right kind of people, who can think around, conversion thinking around the customer, instead of diversion thinking around the product.
So, there's a, a number of, of, of different ways that we can start thinking in advance, about overcoming the barriers, before the, the barriers actually start impeding our progress.
It's interesting, that in some cases, seeing your competitors taking moves toward customer centricity,is a very strong incentive for you to do so.
So, for instance, we see a number of industries where customer centricity has really made great strides, such as, financial services, such as, hotels and hospitality, where's it's competitive pressures.
But in many cases, the best motivations to move towards customer centricity, it's the entire opposite of that, hey no one's doing it, let's be the first.
In the end, the big question is, do you want to be customer centric or not?
Does it make sense for your company?
And if not now, when should you be customer centric?
And as you decide, whether to be customer centric, the timing about it, you want to start laying some of the, the baby steps towards it.
So, it might be developing technology initiatives like, the Scan and Go Program, that I mentioned for Walmart.
It might be an organizational initiative like, My Black Is Beautiful for Proctor and Gamble.
It might be other kinds of experiments that, that a company is going to run.
Let's treat them differently and see if we can.
Those are the kinds of decisions, I want to see companies making.
And I think, its very important for all companies, to at least be thinking about it, so they can make an informed decision, about what customer centricity might mean for them.
It's David Bell here from the Wharton School.
By now you would have been spending time with my colleagues, Barbara and Pete.
Pete will have talked a lot about customers, and what I'm going to talk about is execution.
So we're going to talk specifically about how to acquire some of those customers that Pete was talking about.
We're going to talk about the interaction between the online world, which is increasingly prevalent.
And then finally some tactical things about advertising, search engine optimization, pricing, and all those good things that we need to do to really interact and acquire our customers.
I also want to explain where we are.
We're somewhere quite interesting and different today.
We're at the site of Quincey in Western Pennsylvania.
And the idea really comes from a former student of ours Mark Lore and his friend, childhood friend who founded a company way back in 2005 called 1-800-Diapers.com.
So for those of you out there who may have what you make think is a crazy idea.
Be encouraged, don't be discouraged because the crazy idea of Mark and Was to sell baby products and diapers over the internet.
So, you can have a great idea.
You can have a great brand.
You can think you know who the target customer is, but to really get things off the ground, you have to execute.
And that's what we're going to be focusing on here.
So today, we're going to talk about brand messaging and communications.
And talk again about the way the consumers perceive your brand messaging and marketing.
So, let's first start out with, what are perceptions?
Perceptions is probably one of the most important aspects in consumer behavior, and in understanding consumer behavior.
What is a perception?
The perception is the process of developing an interpretation of a stimulus.
Or in other words, deciding exactly what the stimulus means.
This is really, really an important, crucial area in consumer behavior for two reasons.
First, whatever cons, customers perceive, is what affects their subsequent actions and behavior.
And second, and this is what's interesting, what they perceive is not necessarily what's true.
Well, the process of perception is constructive.
And this process is inherently biased.
It contain, it, the process of perception comes in several different stages.
The first two stages are, the stages of attention and exposure.
Before you can form any kind of perception, you need to be exposed to the stimuli.
And you need to pay attention to that stimuli.
Pay attention to what's salient to you.
And we know that that process is very biased.
You only expose yourself to things.
But when you're consciously exposing yourself to things, many times it's a function of what you believe, what you're prior beliefs are.
Let me give you an example.
Say you think that a part of town is not safe.
Well, you won't go to that part of town.
You'll stay away from that part of town.
So you won't expose yourself to something you don't think is safe.
As a result, you never have, ability to change your perception, of that area of town because you don't collect new data.
So we know that exposure can be selective.
Similarly, even if you are exposed to something, if you don't pay attention to it, again it can affect your, your perceptions.
And we know that there's 2 kinds of attention, there's voluntary attention, and involuntary attention.
So involuntary attention is something like big bang, and you pay attention to it regardless of whether you would had intended to.
But for voluntary attention, that again is selective.
So we have the possibility of selective exposure, and selective attention.
That means you're not collecting data on things that might be, might be able to change your perception.
So that's first stage of bias.
The second stage of bias is once you are exposed to something, and if you pay attention to it, then you have to interpret it.
And we know that you interpret data subject to what you already believe.
So for example, most people know if you watch a presidential debate, it's important to have representatives who in interpret what happened in the debate from both parties.
Because we know a priori, the interpretations are going to vary based on their prior beliefs.
And, that's the same thing for any kind of consumer behavior.
You're exposed, pay attention to certain stimuli.
As a result of this, perceptions are frequently biased, and they don't necessarily represent what's true.
So what's the overview of the perceptual process?
There's, we're going to talk about it, brand communication, there's advertising, there's packaging.
And then you are exposed to them, or you're not.
And sometimes the exposure, as I mentioned, is in a bias, bias way.
And then, even if you are exposed to these inputs, you know, and you're exposed to thousands of marketing measures, marketing cues every single day.
But how many of them do you pay attention to?
So, first there's the issue of exposure.
Then there's the issue of whether or not you pay attention to it.
And finally, there's the issue of interpretation.
Let me give you an example here.
This is a psychological test.
It's called a Stroop Test.
And what I want to show you is that, your perceptions, and I just explained to you your perceptions could be biased, but your perceptions affect your subsequent behavior.
Regardless, it's almost an automatic reaction.
You have a certain perception, and then you automatically respond to that.
And it's very had to control that, even if you think, well I understand that my perceptions might be biased, and therefore I'm going to try to do something to control that, so I don't react inappropriately.
But these perceptions are automatic things, and it's very hard to block their effect.
So let me just give you a little test here.
I'm going to show you several words on the screen, and what I want you to do is tell me the color of the font.
So, here are the words.
Here's the second one.
The third one.
Now, by the fourth one, you probably got what was going on.
I mean, the first one, maybe you were a little bit surprised.
And you saw that the word was blue, but the color of the font was red, so the answer was red.
By the fourth one, you understood the pattern, but it was still hard to break it.
You couldn't stop yourself from reading the word, and reading the word affected your subsequent behavior, it slowed you down.
That's actually the purpose of the Stroop test.
It's a stress manipulation, it makes people feel a little bit uncomfortable because of that dissonance.
If I put the words up where the words match the color of the font, the task is much simpler.
So here's four words where the color matches and you can see, it's much easier, it's much faster to say the words.
This is the same thing in the way marketing I'm going to show you that color has an effect, brand name has an effect.
It affects your subsequent perceptions and subsequent behavior, and it's an automatic reaction that's difficult to stop.
So let me just give you, here's an example.
If I told you this is luscious chocolate, and I show you a picture of it if the shape of a cow pie, it's very hard to stop that first initial feeling of, ooh I don't want to eat this, that disgust feeling.
And you know that it's good chocolate, but the shape has an involuntary effect on you.
And that, that's a very important thing to understand.
So marketers need to understand how these things affect your perceptions and your subsequent behaviors.
Because as I say these are automatic reactions.
There's some visual illusions you may have seen these before.
I can show you these two lines on the screen.
I will tell you you can measure them, they are exactly the same length.
However one looks longer than the other, and you just can't stop that feeling.
Even though I tell you they're exactly the same length and I can prove it to you, you still have the perception that the one on top is longer.
So if I ask you, what is this that I've put on the screen.
You'll answer differently if I show it to you this way versus when I showed it to you this way.
And so that shows you what you perceive that stimulus is, is a function of your prior expectations.
And what the proximity bias says, is if things are close to each other, you assume they're more similar.
So if I asked you which lines are similar to each other, most people will say the two lines that are clustered together are similar.
So that they'll cluster the two lines that are close to each other, rather than say the two bold lines or the two thin, thin lines.
And you can see this in the supermarket, in stores.
There's an implicit assumption that if the product is near another product, they belong together.
So that's a perception.
That physical distance affects whether things are similar or belong together.
In the mall, stores that are close together or seem to be more similar.
Things that look alike, people assume have the same quality.
So this is the the, the underlying the, theory behind, say, store brands.
You're making an assumption of perceived quality, based on this process of similarity.
And it's a very, very important consumer process for marketers to understand.
It's particularly important in branding.
With the Coca Cola brand on it, people will think it tastes better.
They're willing to pay a higher price.
They'll make all sorts of other inferences, even if the product's exactly the same.
Once we put a brand on it, it changes the perceptions of the product.
And people think, I'm not subject to that, I know.
I can judge certain products by the quality.
And, we know from experiment after experiment after experiment, that, that's just not true.
People are very much influenced by the brand name that's put on the product, independently of the product quality.
it's same way in the Stroop test.
You just can't stop it.
Once you see that brand name, you have certain perceptions.
We know that brand is such a powerful brand as we mentioned before.
The Coca Cola brand name has been estimated to be worth 70 billion dollars as an asset.
Just putting that brand name on a product will change, as I said price premiums people are willing to pay, the quality, etc.
When you know that that brand is worth so much, many times people look for ways to leverage the brand for growth.
So ex, for example, you know Coca-Cola is associated with the cola soft drink.
In 1982, Coca-Cola took that brand name and put it on a brand new product at the time, that no one had tasted before, a diet soft drink.
They call it Diet Coke.
And automatically, even though that product was not on the market before, people assume it has hot better taste, it's a higher quality product.
And again they're willing to pay a higher premium price for that product.
Hello and welcome to the Social Marketing Specialization course developed by Northwestern University and Coursera.
This five MOOC specialization is designed to give you the hands on experiences and expertise to develop profitable social marketing programs for your organization, regardless of its size.
This program is based on a similar marketing program used today by the graduate and undergraduate students in the Northwestern Medel Integrated Marketing Communications, or IMC program.
Over the last five years, our students have developed marketing programs for organizations ranging from start ups to large multinational corporations, for profit, not for profit, and governmental entities in markets ranging from global to the hyper-local.
It is a course that will give you the skills, tools, and expertise to impact any market you want to develop.
My name is Randy Hlavac.
For the last nine years, I have been the instructor of the undergraduate and graduate Digital, Social and Mobile Marketing courses in the North Western Medill IMC program.
Also, I am the author of the new book, Social IMC, Social Strategies with Bottom-Line ROI, or return on investment.
Many of our speakers have written great books in their area of expertise.
These, and other important books, can be found in our bookstore.
You will find they represent a wide range of important specializations you need to build effective social marketing programs.
Today, your prospects and customers are using social media to engage with each other to discuss personal and business topics.
To succeed in social, you need to focus your resources in three related areas.
First, you need to build your professional persona to connect with the markets you want to develop.
Second, you need to manage your organizational persona.
Finally, you need the right social strategies to profitably grow your organization.
As you will learn in this course, there are different social strategies.
We will teach you how to match the right strategy with the different markets you want to develop.
Our goal is to provide you with the hands on knowledge, skills, tools, and capabilities to begin growing your social marketing program starting with this MOOC.
MOOC 1 will give you an overview of social and the frameworks you need to build successful social strategy.
MOOC 2 is designed to give you the information, insights, and tools you need to listen to social conversations important to your organization.
You'll receive free tools to immediately begin developing your social marketing programs, and you'll see how real-time social data is used to drive crisis management in real time marketing war rooms.
MOOC 3 focuses on the engagement marketing and the nurture marketing strategies.
MOOC 4 focuses on different types of content, how to use social networking sites to advertise to key markets, and the social IMC marketing strategy.
This strategy has you building private virtual communities to create holistic, two way engagements.
The final MOOC is on the business of social.
We will start with the discussion on the legal considerations you need to build social marketing programs.
We will follow it with an analysis of how you can measure, justify, and manage these programs.
Our goal is to give you an in-depth education, heavily focused on hands-on experiences, and an examination of actual social programs, to let you determine the best ways to grow your organization.
One of the most important things I learned In developing my Social, Digital, and Mobile marketing class was the importance of knowing the experts in key social fields.
We are bringing this important lesson to you in this MOOC specialization.
Every MOOC, starting with this one, will feature an array of knowledge experts in fields you need to understand.
Many will be providing you with free tools and their expertise to help you build successful programs.
In addition, each of these experts are people you need to follow on Social, and use as you develop your social programs.
In each of our MOOCs, you'll find two social marketing toolkits, one for the participants who want to take the MOOC for free, and another for the participants who are paying for the individual MOOC, or have paid for the MOOC specialization.
The paid member tool kit will have longer review periods, tools available only to the paid members, and special videos, eBooks and other content to better develop their social programs.
Regardless of which way you choose to participate, both tool kits will give you the knowledge, skills, and information you need to be successful in this course.
Finally, I want to leave you with something I say in every one of my classes.
Social is a great way to network, share, and build meaningful relationships with each other and with the markets you want to develop.
We will show you the best ways to create this engagement, and we want you to use that knowledge every day to be a success.
Each MOOC, contains an assignment which is designed to systematically develop your professional persona.
In MOOC 1, we will give you a toolkit to create the social assets you will need to develop your professional persona.
In addition, we will ask you to define the target markets you want to develop, and predict what they are doing on social.
We will see if you are correcting your assumptions in MOOC 2.
MOOC 2 is an assignment called listen, you'll be given sophisticated social monitoring tools and will be shown how to use them.
In this assignment, you'll monitor your target markets and identify what they are discussing in social.
At this point, you'll begin to develop relationships with these influencers and experts, to make them aware of you.
This article will be designed to appeal to your high value markets and encourage them to engage with you.
MOOC 4 will teach you how to market your blog.
We will give you the tools and knowledge to let you conduct sophisticated A/B split testing to determine the messages, which best engage your audiences.
In MOOC 5, you will use a series of real time measurement tools to measure the impact of your blog, in all of your social engagement efforts.
As you work through these MOOC assignments, you will not only be building your professional persona, but will also be developing the social habits, you will need to continue to grow and expand your professional social networks.
For each MOOC assignment, you'll be given a social marketing tool kit.
One for the people taking the MOOC for free, and another, more value added tool kit for those paying for the course or for the specialization to maximize your assignments.
Each MOOC will network you with business and social experts, and even the peers within your course.
We will work as an integrated team to help you build your social marketing programs and your professional persona.
In addition, we want you to tell the social cloud about your experiences.
We will use our course hashtag in this and in every future MOOC to communicate on Twitter.
In addition to the experts and hashtags, we have discussion boards to talk about important topics.
We also have speaker resource center, where you can learn more about every expert in the program.
Our social bookstore, we'll feature the books developed by many of our course experts.
We will also have special events and will be giving you social tools and other assets to grow your professional persona, and build your social marketing programs.
The course, assignments, and discussion boards will give you the skills, knowledge, and tools to create a successful social marketing program.
The Capstone is where you will make that happen.
This course is not a discussion of theory, but a hands on course to build your social skills from start to finish.
The Capstone Program will bring together your social skills, strategies, and insights using a realistic case project.
This project is designed to give you skills needed to successfully design, develop, deploy, measure, and justify social marketing programs.
In Insights, you'll use the output from sophisticated social monitoring systems to analyze a market.
Your assessment will identify the needs of the market and the mission they are on.
In the empowerment phase, you'll design an empowering program to attract the desired target market.
The engagement phase will have you developing gamification and two-way engagement systems, to build a long-term database driven real time relationship with community members.
In the planning phase, you will build a budget and the key performance metrics you need to be profitable.
Finally, you'll use a planning information to justify the program to senior management.
There's an extensive Capstone tool kit containing templates, software, success tips from our experts, and additional resources to make the Capstone a success for you.
In addition, we have special resources, discussion boards, and expert access to ensure your plan will be a success.
When you have developed your plan, it will be reviewed by a team of your peers to provide you feedback.
The Capstone is where your social marketing knowledge, our proven methodology, and your business and social insights, will combine to create a successful, profitable, social marketing program for you.
In this session, we will be watching two videos on key social marketing trends of 2015.
As you are watching them, I want you to consider which trends are the most important to you.
The first video is by Buzz Social Media and shows the impact of social on business and society.
And as you will see, social media is transforming the ways we engage throughout the world.
The second video is the Social Marketing Revolution, developed by Erik Qualman, the author of the book Socialnomics.
This video approaches social from a social plus mobile perspective.
I like this video because it makes an important point.
Often we think of social and mobile as similar, but in reality they are very different.
It is a way for people to reach you, and a way for you to reach them.
Social is a media which uses mobile devices to attract, engage, and conduct business with an individual.
In this program, we will show you how the convergence of mobile and social can create new opportunities for your organization.
Now that you have watched both videos, I want you to identify one trend from each.
To discuss on our social marketing discussion boards.
Identify the trends that gave you a flash of insight or an aha moment.
Go to the discussion boards and discuss why each is important to your future.
Then go to Twitter and tell us the most important trend using our course hashtag.
As you are seeing, social and mobile are changing everything in our lives.
We need strategies to use them to your best advantage.
That is the purpose of this social marketing specialization program.
Did you know most organizational managers don't really understand the speed and depth of real time data?
While we conceptually know social as real time, few know the massive amount of data that rides along with each piece of social content.
As you begin to develop your social strategies, it is important to know the data you can use to build successful, personalized social engagements.
To illustrate the speed and depth of social data, let's take a look at the site, We Feel Fine.
This site was one of the first to use social data to find, analyze, and display important social insights.
Created in 2007, it was the first to use social monitoring to analyze social chatter.
When most managers think about social media, they see the social cloud consisting of thousands of individual sites throughout the world.
To analyze and use them effectively, they envision having to write APIs or Automatic Programming Interfaces, to extract data from each one.
In reality, while each individual site, networking, blog, forum, or even video is generating big data you can use, the information from these sites is being collected by a small number of companies.
Their role is to gather the social data globally, structure it, remove the bad stuff, and then send it to companies where this big data can be developed into big information.
At the bottom of this inverted pyramid is one of those companies called Socialgist or Board Reader.
Steve Dodd to learn more about the collection of social data and the countries where social is growing the fastest.
What this means from a business perspective is you can go to a single system to analyze social conversations from the global to the hyper-local level.
You can switch between levels to compare and contrast types of conversations happening in different social geographies.
The social monitoring systems we will give you in MOOC 2 will allow us to examine specific social sites and listen in social conversations.
These systems will give you total control to develop your target market.
The amazing part of social monitoring that people don't realize is that this chain of events is happening at lightning speed.
Data flows into comments like Socialgist, where it is structured for analysis.
It then flows in to companies like Lexalytics and Semantria where it is analysed and key information is developed, like you saw in We Feel Fine.
Finally, big insights are developed with social monitoring tools like IBM social media analytics, Radian 6, and a number of free systems you will use in MOOC 2.
To succeed in the future you need to hone your social listening skills.
This is the objective we have in week two.
When you think about content in Social, one of the things that makes Social very unique is the real-time and immediate nature of it.
But a lot of times when you hear those words, you don't really understand exactly how deep that is, and what we can really find out using Social.
And so one of the sites I like to use is called wefeelfine.org.
This was started in 2007 as a demonstration of new pieces of software called social monitoring.
And what it was designed to do was to show you exactly how deep and how important the types of findings that can come out, as a result of social monitoring software.
So this is the home screen and it was actually designed by researchers in Princeton and Stanford.
And so what you do is you click on we feel fine.
You will see it will go out and you'll be presented with a lot of different colors flying around.
You're probably wondering what these are.
These are actual conversations that are happening right now.
In other words, they you know, started about a minute ago, and go back to about ten minutes ago, of people throughout the world that are talking about their feelings.
It could in any of a hundred countries.
And what's happening, and think about this, in less than a minute, they're being translated into English, read through, and if they find the word feel or feelings, they then go through and find the most representative sentence, and they bring it into the system.
And so one of the things with this is called madness.
It's rather difficult to see what's going on, so if we go over here to the next one down called murmurs.
What you see now are these sentences falling out of the Cloud of different conversations people are having, or different sentences they're doing, that have the word feel in it.
Each one of these is a separate conversation, so I want you to think about this.
In less than a minute this software is reading hundreds of thousands of blog,s and different sites like Facebook and those across the country, across the world that do the same thing.
And essentially, it's picking out the biggest sentence, the best sentence, that has the word feel.
As dropping it out for us to use.
But that's not all.
In that same minute is not only going out and identifying the sentence, but it's going through something that we call tone and sentiment analysis, which we're gonna see in a software piece called social mention a little bit later.
And what that means is, it's not just looking for the word feel, it's saying what are we feeling about.
And so it's not only reading it, but it's classifying it into what our feelings are about, and as a result of that, it assigns the correct shape and color To that particular feeling.
For example, if I say I'm feeling blue, it'll classify me as a blue triangle, so that those colors you saw flying around actually have meaning.
In addition to that, it goes on.
It'll take a minute to do this so I won't show you, but it's actually going through in that same minute and deep diving to identify a relevant picture.
And so if it finds a picture of you on the site, so it's not just doing your text reading and analysis, it's actually looking for video and pictures.
And after a minute or two this would actually come into play.
And so think about what's happening here.
In less than a minute it's going out and reading, it finds the right sentence, it finds a tone and sentiment, it gives you the right color.
But then what it also does, it begins to database this.
And in addition to taking the deep dive to find your picture, It also looks at your age and your gender, and it classifies that as well.
In addition, it date-timestamps it as to when you wrote it, and it then looks at the geolocation on your computer to figure out exactly where you are in the world.
The country that you're in, the state or province that you're in, and the city that you're in, to further build the database.
And then what it does, it takes the date/time stamp and your geolocation, and in that same minute it goes out to the Weather Channel, and figures out what the weather was like when you wrote that sentence.
So if I want to say, I want to know all the people who feel abnormal, who are females, in their 30s, while it was raining in any one of these countries.
And I can do it for any of the years that it's been running.
But the important thing to take home is that social monitoring systems like this actually work not only for the word's feelings, but it could be for your company.
It could be for a specific topic, and what we'll be looking at social monitoring software like Social Mention, that will allow you to go out and analyze anything with the same depth that this one is doing for the word feeling.
And so We Feel Fine kinda started it all and shows us the real depth that we can get from social monitoring software.
Now, let's examine each level of the social pyramid, starting with the social networking sites.
This level is great for real-time marketing.
I just dropped my iPhone is a signal to companies that you're likely to be in the market for a new phone.
Social networking sites are great for one-way social engagement, but there are other strategies you might want to use on your highest-value prospects and customers.
These are enterprises focusing on covering news and special-interest topics.
They have great reach, especially the ejournals and emagazines.
If they are used by your high-value markets, getting an article or advertisement into them increases your reach.
You can also use them with banner ads and other traditional forms of advertising.
The third level is the passion connections.
Passion sites are where people share their passions with each other.
If that is where your target audiences are, they are vital.
However, for many consumer and most business markets, they may not be worth the investment.
Don't be tech-centric.
When you think about video, think about video sites like YouTube and streaming sites like Meerkat and Periscope.
These sites are creating engagement in unique ways.
Thought leaders are one of the most important levels in the pyramid.
Thought leaders identify topics and trends of importance and they talk to hundreds, thousands, or even hundreds of thousands of people who are likely to be your high-value target audiences.
Virtual communities and private virtual communities are the lowest level.
For any topic, there are virtual communities engaged in deep, long-term discussions of key issues and topics of concern to the community.
Today, there are likely to be many communities containing the audiences you want to develop.
And the good news is they are seeking expertise and thought leadership from people exactly like you.
Here is a private virtual community of seven million engineers talking engineering.
This organization has created communities based on different types of engineers.
Within the communities, they are talking about trends, issues, and subjects of interest to their community.
This one has 75 million parents talking about how to best raise their children as well as themselves as their children age.
While it is called Circle of Moms, members of all genders are welcome and serve as equal partners in the community discussion.
Today, the keys to managing social change are first think audience.
Learn their social habits and the levels of the social pyramid they use.
You'll learn more about how to do this in MOOC 2.
Your high-value audiences are engaging in most levels of the social pyramid at the same time.
Think multimedia to reach them all.
Don't waste time and resources developing social sites which aren't used by the audiences you want to develop.
Don't follow the trendier and newer sites unless you know your markets are there.
Finally, focus your resources.
If you are a startup, or have a small marketing budget, you need to focus your resources on the sites which give you your greatest success.
We will show you how to quantify and evaluate them in MOOCs 2 and 5.
We will be using the social pyramid from this point forward in our social marketing specialization.
Now that you've learned about the social pyramid, comment on it using our course hashtag.
While many executives know a great deal about social networks like Facebook, LinkedIn, Renren, VK, and others, many don't understand the tremendous power of virtual communities.
They are the large base at the bottom of the social pyramid and are the place where the deepest conversations happen.
As I discussed in my book, Social IMC, virtual communities are where you want to be known as an influencer or an expert.
It is where peer-to-peer recommendations are the strongest and where people make many of their purchase decisions.
Their primary mission is to allow for conversations and the exchange of pictures.
The creators of social networks are entrepreneurs who want to eventually monetize their site.
Many, like Twitter, start by focusing on communication.
Then after they grow, they add some type of revenue-generation device.
Most social networking sites use registration as a way to identify members.
For members, the registration page allows them to claim a spot on the site to develop their profile and provide other information to attract people with similar interests.
The registration process is important for you to understand.
While registration is the means by which network members can contact and engage with others, it has an important role for the entrepreneur.
Because you must login each time you visit the social networking site, your activities can be tracked, analyzed, and aggregated into markets the company can use to sell to advertisers.
They can also evaluate your behaviors to determine the intensity of your interest over time.
While the registration process provides some information to the site owner, the profile page adds a great deal more.
This type of information is used by the entrepreneurs who add it to their advertising offerings.
Virtual communities are the exact opposite of social networks.
Rather than joining to socially engage, virtual communities are on a mission.
Most communities are created by members who also manage them.
Their conversations are deep and focus on subjects of interest to the members.
They too have registration and profile pages, but they are used for very different reasons.
In virtual communities, the members control the site and often reward users for supporting it.
While virtual community members analyze member activities like the social networking sites, it is used primarily to improve the site by growing the content members enjoy and to remove members if they are causing the community problems.
When a virtual community requires registration, we call it a private virtual community.
I like to restore muscle cars, and I'm currently working on a numbers matching 1968 Roadrunner, a Mopar car.
As I am restoring this car, I seek virtual communities for help and expertise.
Unlike social networking sites, virtual communities exist on many different levels.
Which one I frequent depends on the types of experts I want to engage, regardless of the type of virtual community.
At the center are the experts.
This is where you will want to position your company or organization.
Their outreach, like their blog publications and tweets advertising them, engage members and draw them into the community.
Members are the largest group and are the people interested in the community topics.
They have different levels of engagement, depending on the strength of their interest.
As we examine our social strategies in MOOCs 3 and 4, we will want to consider engaging virtual communities to reach the target audiences we want to develop.
However, in the social IMC strategy, we will actually develop a private virtual community to attract, engage, and develop two-way relationships with communities of high value to your organization.
As we will see in MOOC 4, private virtual communities are an effective way to build long-term relationships with our most profitable markets.
Over the course of the five MOOCS, our objective is to let you build your expertise in a market that you want to develop.
To accomplish this, we're first going to identify what that market is in the second assignment in this MOOC.
Then in MOOC two, we're going to give you social monitoring tools that will allow you to connect up with the experts and the influencers in the markets you want to develop.
To do this, we're going to give you two different types of assets.
Speaking to you in 2018, a lot has changed since we made our program.
First off, you're going to be developing two types of assets.
These are sites like Twitter, LinkedIn, WeChat, Sina Weibo, and other ones that are useful for you to connect to the markets you want to develop.
In fact in MOOC two, we'll be giving you a lot of analytics as well as social analysis sites, so you can hear your high-value market, quantify them, vet, and be able to understand or better understand how they're using social.
We're trying to keep up with it.
But if you find a great site, be sure to let me know through Twitter or LinkedIn, and we'll include those into the program.
I've just put out, for example, here in 2018 that in September, a whole series of new videos, so that you can get the hottest analytics tools that you can use for free.
So, if you have any sites that you really find useful, be sure to let me know.
One of the things people are concerned with is they may not be totally into this let's build a professional network.
If you're one of those people, here's something you can do.
There are basically all of these sites register you by an email address.
So, if you're concerned about using your company email or something like that, go out to one of these two sites.
First up, Gmail which is run by Google, or Outlook which used to be called Hotmail, and is run by Microsoft.
You might use your name or your nickname in there.
But having it as a Gmail account might put it out of view from your company, which at the first start will work.
Gmail is also a good way to do it because when you sign up for a Gmail account, you also get a Google Plus account, which allows you to use those assets.
The first tool I want you to sign up for is Twitter.
What you do is you go out to www.twitter.com, and you're going to sign up for a free account.
What you'll want to do is they'll ask you for your email address.
So, you put that in and some other information, and it gives you your own Twitter account, and then it'll give you your at handle for Twitter.
The key is Twitter is used to engage communities.
So, what I'd like you to do is to sign up there first.
The reason we're going to use that first is all of the other systems and things we're going to do will let you sign up using your Twitter account.
So, it just makes it a little easier if you start with Twitter.
The next tool is LinkedIn.
LinkedIn is where professionals link up with other professionals.
So, what you want to do is go out to www.LinkedIn.com, and develop your LinkedIn community.
You should be able to use your Twitter sign up to go into LinkedIn.
If not, just fill out the form and get that setup.
If you have a Gmail account, you'll get the Google Plus account.
But it's a great way where you might connect up with some communities.
There're a lot of communities in Google Plus that are professional, and it may be one that's just right for you.
What it allows us to do is to take a big address for an article that we find, and make a very small Bitly link that we could use in Twitter, LinkedIn, and Google Plus.
Hootsuite is essentially a scheduler.
It could be a message, it could be a graphic.
The thing is that Hootsuite will then go automatically go through and set it out at the time you have identified.
It's really good when you're marketing in a global sense.
Because while you're sleeping, the other markets across the globe are awake.
So, Hootsuite can send them messages at a time convenient to them.
Do not pay for Hootsuite.
What we'll do is we'll use this extensively when we're marketing our blog and testing different messages into the Ojai valley community to see what works.
So, the final thing we want you to do is go out and tweet the following.
Social Marketing at coursera using social BigData and SocialMediaMarketing to become an influencer using Twitter and LinkedIn, and if you want add another site to your country to make it more personal, and enjoy the course.
After you complete our time together, you are going to be able to describe the difference between productive versus unproductive work.
You're going to be able to determine your high priority tasks.
You're going to learn the definition of work/life balance, and you'll know how you actually really truly do spend your time.
This is really about you and you getting the most from your time.
I hope that sounds good because it's time for us to get going, so let's go.
But if you do the work in this course, you're gonna find approaches that can support your personal and professional productivity.
And when you do find yourself working overtime, you're gonna be able to do so in a much more efficient manner.
Wouldn't that be nice?
Have you ever had a day when you're absolutely busy busy busy from the minute you woke up until the minute you fell into bed and fell asleep?
And at the end of this super busy day do you know what you did?
Or was it one of those days where you know you worked, you know you worked hard all day, you know you're tired, but you're not exactly sure where your time went?
Well if you worked and worked all day long, and you're not 100% certain at where your time went, you might have been engaged in unproductive work.
How can there even be such a thing as unproductive work?
You weren't lounging, but you weren't completing the work that was really gonna further your goals right at that time.
You weren't completing the work that really needed to be completed right at that time.
Sometimes this means you get distracted by something that is work related but not related to the task at hand.
Maybe you start looking for some information that you do not need until later.
Let's take a look.
It's noon on a Friday afternoon, and Sam plans to leave the office at 5 P.M.
Before Sam leaves he needs to complete a report for his boss.
He also wants to go through some emails he's been saving and make sure that he has addressed them appropriately.
He's not sure how long that is going to take.
The email says, Sam, when you have time, would you look these numbers for me?
They don't balance, and I need to discuss them with our vice president next Thursday.
Sam begins to look at the sales numbers.
The numbers don't make sense, and he doesn't know where the numbers came from.
So he begins to look through sales reports from the past six months in hopes of deciphering how these numbers were created, and he works very hard tracing each month into the next, looking to see if he can find any errors or miscalculations.
And as he does, he notices that it's 4 P.M., and his boss is calling him about the report that was due at 3 P.M.
Sam had become so engrossed in researching the sales numbers that he had not even started the report yet nor had he started his status report.
That is work that he could've completed next week.
He became distracted, and he didn't work on his two priorities for the day.
How would you have prioritized Sam's Friday afternoon?
Something that would've made Sam's life easier is if he had a plan.
So if Sam had created a plan to get through his Friday afternoon, and if he had stuck to his plan, he probably wouldn't be working overtime on a Friday evening.
Well, the plan would have shown what to do and in what order to do it.
It would have shown when something was due, and it would help him to assess any new requests as they came in.
And then this last thing I'm gonna tell you sounds weird, but the plan would help Sam change his plans.
How is it that a plan helps you change your plans?
And that way you can understand what will happen to the rest of the work now that you've been asked to make a change.
Let's go back to Sam, and now take a look at how this might work out for him.
Let's say that Sam's boss calls him at 1:30 on Friday and says, Sam, I need your status report early.
I need to go give the status to our vice president at 3:30.
Well Sam knows, because he has a plan, that it will take him an hour and a half to finish the report and that it's due at 3:00.
And if he does this he might complete his status report exactly at 3:30, if he transitions right to the status report without taking a break.
So, what do you think he should do?
One approach would be for Sam to put the report on hold and transition to his status.
He could complete the status at approximately 2 P.M.
report could be turned in at say 3:45 or 4:00, and then this way he's able to make these suggestions because he has a plan.
Each day, each week, have a plan.
Know what you want to accomplish and what you need to accomplish.
We've been discussing work, but you know it never hurts to have some plans for your personal time.
Now some people don't like the idea of planning their personal time.
It's your preference.
I am suggesting that if you have something specific you want to accomplish, a plan is what's gonna help get you there.
There are all kinds of time management systems, and you can use them.
I'm not standing here with a preference for one or the other.
And the purpose of this course is not to sell you a time management system.
Sometimes your employer will provide a time management system or send you to time management training, and if they do, go and pay attention and consider what is presented to you.
It's possible that your employer has this preference for this specific system, and when this is true, it's really in your best interest to try to learn their system of choice.
Otherwise, don't feel compelled to use a system just because everyone says it's the best system.
The best system is the one that helps you to be productive and effective.
What really goes into your plan that's part of this system?
Well in many ways, your plan is your task list.
Rather than just write down things to do, you want to organize them.
You wanna organize them by priority, due date, steps that need to be taken, start date, who is it for, how long is it gonna take, what information, what do you need?
In your sample work plan you might have something like priority, the item, a description of what it is you're doing, a due date, the name of who it's for, the steps that have to be taken, an estimate of how long, and when you're going to get it started.
And you could create a table and a quick template and use it.
And see what works for you and what doesn't work for you.
We often, maybe even mostly, let our schedule schedule itself, ignoring the fact that time, not money, is our only true leadership asset.
Tom Peters is a leadership guru who's known for In Search Of Excellence and also Brand You.
Year ago, you know, he hit, hit upon the idea that we are each our own individual brand.
What is the one resource you can never have more of?
Did you say time?
We cannot create time.
There are only 24 hours in a day, 7 days in a week, 365 days in a year.
And so it's important that you spend your time in the most beneficial way possible.
And by beneficial, I really mean beneficial to you.
Spend your time in the way that's gonna bring you what you want from your life.
It is time to talk about work-life balance.
I'm gonna share with you the secret formula to work-life balance, so listen carefully.
I cannot tell you exactly how many hours to work and how many hours to play, or spend with your family.
It's a personal decision.
It's, it depends on your values, and it changes.
When I was brand new in the workforce, I was eager to work and to learn.
And to get ahead, I worked many hours.
My coworkers were my friends anyway.
We were all there together, new out of college.
There have been times in my life where, although I enjoyed my work, it was more important for me to spend time with my family and friends away from the office.
And that was completely happy doing that.
And there have times when I worked 40-hour weeks and I was completely happy doing that.
The key was that my work life fit my definition of work-life balance.
And then to manage your work and your life in a way so that most of the time you achieve your work-life balance and know it's gonna change, and know that, that is okay.
You've got more control over this than you think.
Remember in our previous module we talked about Sam?
And he wound up staying late on a Friday evening because he didn't pay attention to doing his work at the right time, in the right order.
And he didn't have a plan.
So if working late on a Friday evening goes against his idea of work-life balance, then he was probably not very happy.
But he did have a bit of control over this situation.
And I'm not promising you that you will never be asked to work more hours than you want.
And I'm not promising you that you will never have to work late, or to work a weekend.
But if you do not think about what you want, you do not know how to put yourself in the right situations.
You teach people how to treat you.
A client of mine was unhappy because her boss would text her 24 hours a day, seven days a week.
And if she heard a text come in at 2 a.m and she was sleeping, she would wake up and she would reply to it.
And I asked her about her job description and about the expectations that had been set when she came, what was mapped out for her when she started.
And I asked, does everyone in the office answer your boss 24, 7?
And she said that she had always done this from the very first day because she wanted to make a good impression on him.
Sure, you know, some people do expect you to answer them 24, 7.
But sometimes you're the one setting the example by being available 24, 7, and that's exactly what my client had done.
And then she became afraid to change the nature of her communications relationship with her manager.
After you complete our time together, you are going to be able to describe the difference between productive versus unproductive work.
You're going to be able to determine your high priority tasks.
You're going to learn the definition of work/life balance, and you'll know how you actually really truly do spend your time.
This is really about you and you getting the most from your time.
I hope that sounds good because it's time for us to get going, so let's go.
But if you do the work in this course, you're gonna find approaches that can support your personal and professional productivity.
And when you do find yourself working overtime, you're gonna be able to do so in a much more efficient manner.
Wouldn't that be nice?
Have you ever had a day when you're absolutely busy busy busy from the minute you woke up until the minute you fell into bed and fell asleep?
And at the end of this super busy day do you know what you did?
Or was it one of those days where you know you worked, you know you worked hard all day, you know you're tired, but you're not exactly sure where your time went?
Well if you worked and worked all day long, and you're not 100% certain at where your time went, you might have been engaged in unproductive work.
How can there even be such a thing as unproductive work?
You weren't lounging, but you weren't completing the work that was really gonna further your goals right at that time.
You weren't completing the work that really needed to be completed right at that time.
Sometimes this means you get distracted by something that is work related but not related to the task at hand.
Maybe you start looking for some information that you do not need until later.
Let's take a look.
It's noon on a Friday afternoon, and Sam plans to leave the office at 5 P.M.
Before Sam leaves he needs to complete a report for his boss.
He also wants to go through some emails he's been saving and make sure that he has addressed them appropriately.
He's not sure how long that is going to take.
The email says, Sam, when you have time, would you look these numbers for me?
They don't balance, and I need to discuss them with our vice president next Thursday.
Sam begins to look at the sales numbers.
The numbers don't make sense, and he doesn't know where the numbers came from.
So he begins to look through sales reports from the past six months in hopes of deciphering how these numbers were created, and he works very hard tracing each month into the next, looking to see if he can find any errors or miscalculations.
And as he does, he notices that it's 4 P.M., and his boss is calling him about the report that was due at 3 P.M.
Sam had become so engrossed in researching the sales numbers that he had not even started the report yet nor had he started his status report.
That is work that he could've completed next week.
He became distracted, and he didn't work on his two priorities for the day.
How would you have prioritized Sam's Friday afternoon?
Something that would've made Sam's life easier is if he had a plan.
So if Sam had created a plan to get through his Friday afternoon, and if he had stuck to his plan, he probably wouldn't be working overtime on a Friday evening.
Well, the plan would have shown what to do and in what order to do it.
It would have shown when something was due, and it would help him to assess any new requests as they came in.
And then this last thing I'm gonna tell you sounds weird, but the plan would help Sam change his plans.
How is it that a plan helps you change your plans?
And that way you can understand what will happen to the rest of the work now that you've been asked to make a change.
Let's go back to Sam, and now take a look at how this might work out for him.
Let's say that Sam's boss calls him at 1:30 on Friday and says, Sam, I need your status report early.
I need to go give the status to our vice president at 3:30.
Well Sam knows, because he has a plan, that it will take him an hour and a half to finish the report and that it's due at 3:00.
And if he does this he might complete his status report exactly at 3:30, if he transitions right to the status report without taking a break.
So, what do you think he should do?
One approach would be for Sam to put the report on hold and transition to his status.
He could complete the status at approximately 2 P.M.
report could be turned in at say 3:45 or 4:00, and then this way he's able to make these suggestions because he has a plan.
Each day, each week, have a plan.
Know what you want to accomplish and what you need to accomplish.
We've been discussing work, but you know it never hurts to have some plans for your personal time.
Now some people don't like the idea of planning their personal time.
It's your preference.
I am suggesting that if you have something specific you want to accomplish, a plan is what's gonna help get you there.
There are all kinds of time management systems, and you can use them.
I'm not standing here with a preference for one or the other.
And the purpose of this course is not to sell you a time management system.
Sometimes your employer will provide a time management system or send you to time management training, and if they do, go and pay attention and consider what is presented to you.
It's possible that your employer has this preference for this specific system, and when this is true, it's really in your best interest to try to learn their system of choice.
Otherwise, don't feel compelled to use a system just because everyone says it's the best system.
The best system is the one that helps you to be productive and effective.
What really goes into your plan that's part of this system?
Well in many ways, your plan is your task list.
Rather than just write down things to do, you want to organize them.
You wanna organize them by priority, due date, steps that need to be taken, start date, who is it for, how long is it gonna take, what information, what do you need?
In your sample work plan you might have something like priority, the item, a description of what it is you're doing, a due date, the name of who it's for, the steps that have to be taken, an estimate of how long, and when you're going to get it started.
And you could create a table and a quick template and use it.
And see what works for you and what doesn't work for you.
We often, maybe even mostly, let our schedule schedule itself, ignoring the fact that time, not money, is our only true leadership asset.
Tom Peters is a leadership guru who's known for In Search Of Excellence and also Brand You.
Year ago, you know, he hit, hit upon the idea that we are each our own individual brand.
What is the one resource you can never have more of?
Did you say time?
We cannot create time.
There are only 24 hours in a day, 7 days in a week, 365 days in a year.
And so it's important that you spend your time in the most beneficial way possible.
And by beneficial, I really mean beneficial to you.
Spend your time in the way that's gonna bring you what you want from your life.
It is time to talk about work-life balance.
I'm gonna share with you the secret formula to work-life balance, so listen carefully.
I cannot tell you exactly how many hours to work and how many hours to play, or spend with your family.
It's a personal decision.
It's, it depends on your values, and it changes.
When I was brand new in the workforce, I was eager to work and to learn.
And to get ahead, I worked many hours.
My coworkers were my friends anyway.
We were all there together, new out of college.
There have been times in my life where, although I enjoyed my work, it was more important for me to spend time with my family and friends away from the office.
And that was completely happy doing that.
And there have times when I worked 40-hour weeks and I was completely happy doing that.
The key was that my work life fit my definition of work-life balance.
And then to manage your work and your life in a way so that most of the time you achieve your work-life balance and know it's gonna change, and know that, that is okay.
You've got more control over this than you think.
Remember in our previous module we talked about Sam?
And he wound up staying late on a Friday evening because he didn't pay attention to doing his work at the right time, in the right order.
And he didn't have a plan.
So if working late on a Friday evening goes against his idea of work-life balance, then he was probably not very happy.
But he did have a bit of control over this situation.
And I'm not promising you that you will never be asked to work more hours than you want.
And I'm not promising you that you will never have to work late, or to work a weekend.
But if you do not think about what you want, you do not know how to put yourself in the right situations.
You teach people how to treat you.
A client of mine was unhappy because her boss would text her 24 hours a day, seven days a week.
And if she heard a text come in at 2 a.m and she was sleeping, she would wake up and she would reply to it.
And I asked her about her job description and about the expectations that had been set when she came, what was mapped out for her when she started.
And I asked, does everyone in the office answer your boss 24, 7?
And she said that she had always done this from the very first day because she wanted to make a good impression on him.
Sure, you know, some people do expect you to answer them 24, 7.
But sometimes you're the one setting the example by being available 24, 7, and that's exactly what my client had done.
And then she became afraid to change the nature of her communications relationship with her manager.
So, when we look at food and the functions that food fulfills in our lives, we can sort of separate this into two equally important categories.
The first category is nutrition.
It's, it's fuel, right?
It helps us to think and it helps our bodies to repair certain parts when they're damaged and they need repair.
But on the other side, we have the social functions of food.
From the first day of life, and up to the most, kind of extended social networks.
Food is a way of communicating.
It's a way of showing care for one another.
It's a way of celebrating together.
It's also a way of passing on our family's history and our traditions.
So the first thing we need from our food in terms of nutrition, and we sometimes forget about this, is water.
We are actually, human beings are made up of 50% water by weight.
And water faciltieates all of the bodily functions we need to survive.
Then the next thing we need, is energy.
And we get energy from our food in the form of something called macronutrients.
And they're called macronutrients because we need a relativity larger amount of these compared to the micronutrients that we'll talk about in a minute.
But macronutrients, I bet you've heard of them, They are things like carbohydrates, proteins, and fats.
And then protein provides us with some energy, but also with important building blocks or repair and maintenance in growth in our bodies.
Fats, the last of these categories of macronutrients, provides us with a large amount of energy.
So it's a, it's a good storage form for energy, but that also means that it's easy to sometimes overcompensating.
Take in too much energy in the form of fats.
So, the next things we need are micronutrients, and I bet you've heard of these, too.
These are things like vitamins and minerals.
And vitamins are organic substances made by plants or animals and minerals are inorganic elements that come from the earth, soil, and water, and they're absorbed by plants.
So animals and humans absorb minerals from the plants that they eat.
And both vitamins and minerals are micronutrients that a body needs to grow, to repair, and to function normally.
And it protects the health of our digestive tract.
If we look at the other side, at the social functions of food, we see that food provides a very powerful means of communication.
When we eat together with other people, we communicate.
And those social connections that we solidify, that we establish, by spending time around a table and eating and talking together, they actually contribute to the emotional health of our children.
There's quite a bit of, of research saying that children who eat family meals actually do better in terms of their emotional well-being.
And finally, eating together and, doing that over time for many, many years is a way in which we pass on our families traditions.
A way in which we record our memories and pass those on.
So while we recognize the importance of the nutritional contribution of food.
It certainly is.
The first priority for the companies that make processed food, is that they sell that food to consumers, so that the company makes a profit.
That's one of the main reasons why companies process foods in the first place.
When a food manufacturer takes a relatively cheap raw ingredient, like corn for example, and then strips that food of most of its nutrients, the food is going to last longer.
Because pests like mold for example, are less attracted to foods that are low in nutrients.
By disguising the starting material in many different ways.
The same base ingredients, corn for example, can be made to look like many different products.
And we, the consumers, feel that we have a lot of choice when we go shopping for food.
Now, because so many companies are competing for our food dollars, the marketing of these different variations Has become extremely sophisticated.
Billions of dollars are spent every year marketing processed food to us and to our children.
And in the US, there are no rules about which foods can be marketed to which age groups.
Also, the more time our children spend in front of a screen, the more likely they are to be exposed to this kind of food marketing.
So what can we do?
Let's launch a counter-marketing campaign.
We, the parents of the world have a special kind of consumer access, because the consumers are our children.
As they're growing up, we get to see them on a regular basis.
So, even though our campaign maybe less flashy or less colorful than the ads they see in the world around them, our campaign can be pretty powerful, too.
For example, if they see us loving our fruits and vegetables, we are advertising those foods to our children.
If we choose less processed foods most of the time, and if we go out of our way to find foods that are grown or raised closer to home, these actions will likely have an effect on their future choices.
If you have a farmer's market nearby, take your children there.
If you have space in your garden, or even on your window sill, plant something that you can later eat with your children.
Explain to them in whatever language is appropriate to their age that ads can sometimes make things seem better than they really are, and that often, ads can make us want things that we don't need and that aren't even good for us.
Keep it fun and light-hearted of course, and try to limit their exposure to screen-based ads for processed foods.
But most importantly let them know that they have a choice and they can use that choice wisely to keep themselves healthy and happy.
Especially in countries like the United States, that have adopted diets that are rich in refined or processed foods.
And, for the most part, along with that shift, rates of obesity have increased in these countries.
So in 1992, and without giving away my age, this is the one that I remember learning about in my first university courses on nutrition.
It was a simple way of showing people approximately how much of each of the major food groups they should be eating, relative to the other food groups.
So, breads and cereals in those days were considered to be sort of the foundation of our diets, in many parts of the world they still are.
But because in the US we've kind of gone a bit over board on our consumption of carbohydrates.
Especially heavily processed carbohydrates.
Our recommendations have changed over the years.
The next layer was divided into fruits and vegetables.
And it was recommended that we eat three to five servings of vegetables and two to four servings of fruit every day.
The problem was, and the problem still is, that the average American person didn't actually know and is still unclear today on exactly what constitutes a serving.
And we had three to five veggie servings and two to four fruit servings.
Then above that, we saw in decreasing quantities on one side protein foods like meats and legumes and eggs.
Beans and alternate sources of proteins.
And then on the other side of that, we saw dairy products.
At the very top, there was this tiny triangle for fats and sweets.
And that was meant to suggest to the public that they should eat their cupcakes and drink their soda in moderation.
Okay then, in 2005, the USDA's My Pyramid Was released.
And it had nice, bright colors and pictures often of the corresponding foods in the groups below the picture, but sometimes the triangle was just left with colors and the words of those groups.
There were the grains, vegetables, fruit, milk and meat and the alternates or protein foods.
But by 2005 obesity rates were rising in the US, so the USDA added a flight of stairs.
And, and an active person going up those stairs.
This was supposed to remind us that even small additions of physical activity, like taking the stairs for example, could add up to health benefits.
Then enter First Lady Michelle Obama who made it a national priority to address childhood obesity.
And, of course on the top corner there was a circle to represent dairy products in the diet.
This representation doesn't prescribe which foods, it just suggests the types of foods.
But if I had, if this were really my plate, if I had, let's say, two or three wishes, I would add a few things.
The first thing that I would add is a glass of water.
I think we often forget how important water is in our children's diets and even in our own diets.
It just sets up a, sort of normal view of what a portion size is or what a reasonable portion is.
And then, the last thing I would love to add is some suggestion that variety in, in food and in our diets is a good thing.
And also, it maximizes the spectrum of micronutrients or vitamins and minerals that we're getting in our foods because we're eating a lot of different types of, of fruits and vegetables.
But in general I think a diagram like MyPlate is an effective way to communicate a lot of information to a large number of people across a spectrum of ages and educational backgrounds.
If I had to choose six things that I would have in my kitchen, it would be these six things in front of me.
I think with these things in your kitchen, you can make a healthy, tasty meal for your family just by going out and buying whatever's fresh.
Whatever you feel like eating that night, you can make it if you have these things in your home.
There are a bunch of different receptors on your tongue.
So, the more receptors we can hit in our dishes, the tastier they'll, they'll be.
So the first thing is olive oil.
And there are like $30 bottles of olive oil and then there are $10 bottles of olive oil.
Buy any kind of olive oil you want.
So olive oil is a must.
It's good for sauteing onions, and it tastes nice.
Salt, always good to have.
You can add it to pasta while it's boiling or to sauces to flavor them.
It's up to you how much you like.
They add a nice balance to all of these flavors.
And then these are the two key ingredients to any savory dish.
So, when I was little, my mom used to make something called a toad in the hole for breakfast.
I think it's an English thing, but I'm not sure.
The nice thing is that it gets both the carbohydrate and the protein from the egg into one piece.
A piece of this bread and you can save that because they'll actually eat that, as well.
And what we're going to do is, we're going to fry it with some egg in the middle.
And I'm just turning this down to medium.
So, that's fine.
So, you're going to take your nice piece of bread that you cut the hole in.
But if you don't, if you can't get farmer's market eggs, just try and buy you know, natural, organic, or cage-free eggs.
And then when this gets nice and hot we're going to crack the egg into that hole.
What's this?
>> You want to crack it in that hole and make a toad in the hole?
I'm going to break the yolk just so that its easier to get it cooked a little bit through.
You can tell he's been doing this with me alot.
You got all three things in the meal.
And this is a nice warm breakfast for them on a cold day when they're getting ready for school.
So, I'm going to flip it.
And this is never neat, guys, this is always a bit of a mess, see how it kind of came out of the one side.
You know a little bit of real butter, is much better for children than a lot of artificial fat like margarine.
So rather use a tiny bit of real butter and make a nice tasting egg and then they'll feel satisfied, you'll feel satisfied if you have this for breakfast too, and then you're good to go until lunch time.
I'm going to cut it up for you.
So, smoothies are a great way to get a little bit of extra fruit and vegetable into your children's morning routine.
I either start the day with a smoothie or with some kind of cut up fresh fruit.
You just have to make sure you wash the fruit.
This is probably the fastest and easiest thing to make.
You put some blueberries in.
So you can just make them a little glass each, it's just perfect.
And you choose any yogurt that you like, it can be any kind of yogurt but pick something natural with not too much sugar in it and this one I have to mix up because the fruit's on the bottom.
One trick, don't brush your children's teeth before you try to feed them fruit in the morning, because toothpaste is so sweet that any fruit they'll eat after that can't really compete.
So try and brush their teeth after breakfast and you'll have more luck getting them to drink their smoothie or eat their fruit.
And that's like a couple of at least one fruit serving of their five a day that's recommended, so done.
Okay, so we're going to make a stir-fry.
You can put a bit of melted butter on your steamed vegetables or some sauces on your stir fry, because then they have kind of a positive experience with their vegetables.
Apparently, it's hard to get the smell of onion and garlic out of a wooden board, so you don't want to chop your onion and garlic on a wooden board.
And now what I'm going to do, is cut up any way, any shape, any size.
In medical school they taught us, never to feed a child anything round like this, because it's exactly the size of their windpipe.
And the only other thing that I have to tell you about stir-fries, is that there's a famous chef in the Bay area called Alice Waters.
And she does so much great work with organic foods, and getting the school food programs to serve really healthy lunch alternatives to children.
And she's done so much work, that I think she once made a comment, where she said, we've come so far since the days of the stir-fry.
Then I'll stop making it.
I'm going to cut up some cauliflower.
You're just trying to separate the little florets, in ways that will be attractive and yet bite-sized.
Here, I've got my broccoli now, and I'm going to cut this up.
I'm just going to pull the inside part with the seeds out.
You can use orange ones and yellow ones as well.
And the final thing is a little baby zucchini, which cooks quite quickly, and adds a nice different kind of crunch to the stir-fry.
Okay, so that was it.
You can put a splash of sesame oil in if you have it, but you don't have to have ten different kinds of oil in your cupboard either.
This is ginger.
If you want to add a bit of really Asian flavor to your stir-fry, this smells so fresh and nice, and it's easy to use.
You just peel the skin off and cut a little chunk, and you can push it through the same kind of press that you would use for garlic.
And if you don't have one of these, you can use a little pot and just pound it up, or cut it with a knife into small pieces.
Okay, be careful that you don't get splattered, because hot oil is not fun to have on your skin.
The nice thing about stir-fry, is its got the sweet and the sour and the salty, and it's got so much color.
It, like, hits all of the children's senses at once.
I think with a dish like this, if you show the children that you enjoy eating it, that you look forward to, not only to making it but to eating it with them, I think they'll be much more motivated and much more likely to try it.
So we're going to move this over here, and I'm just going to shove my carrots in, and give those just a minute or two.
And if I want, if your pan seems like it's a little bit dry, you can already add a little bit of your soy sauce.
I'm using a gluten-free soy sauce.
You can hear it sizzling away.
Now we get to add the flavor.
This is plum sauce.
It's a little bit sweet and a little bit sour, and it's just delicious.
And a little bit more soy sauce.
So the one last thing I have to say about stir-fries, you don't want to overcook them.
You want the vegetables to be a little bit crunchy, the kids prefer it that way.
And with a smell like this, they'll taste this at least, especially if you give it to them before you put the pasta and the chicken, and the other parts of the meal out.
When we make a meal for our children, of course we want to make it balanced.
And there's been a lot of talk about, how much carbohydrate, how much protein, how many vegetable servings everyday we should give to our children.
And that is important, but we can't lose sight of the fact that a meal is so much more than nutrients.
A meal shows our children that we care for them, that we love them.
And that's not to say that parent's who are too busy to cook for their children, can't find other ways of showing them love and showing them care.
But the fact is that from the minute our children are born, they're dependent on us for food.
So, if we do have even half an hour or 20 minutes in the day to make a fresh meal for them, it's really so much more than providing them with nutrients.
This is a standard dinner plate.
And Michael Pollan's advice is great, I think.
So he suggests making vegetables or fruits take up the biggest part of your plate.
And, one other thing I have to add to that, is that children do not need to eat off of a plate this size.
In fact, neither do we in most cases.
If we go back to smaller size dishes, a plate like this that's covered in food, is just as satisfying, looks just as appetizing and appealing to a child as a plate this size.
Drinks are the same.
I like to feed my children water for most meals.
Because it's really the best liquid that they can drink.
But, if you want to feed your children fresh juice once in a while, that's great.
Just choose a cup this size.
I'll show you.
And I say, here you go.
What if you handed him this?
I can almost guarantee you he'd say, wait a minute, that's not full.
I want a full cup of juice.
And even for the adults in the family, this is probably a good size dinner plate.
Except when you're having company over and they might think you're a little bit weird to have such small plates.
So, when we put together a meal, let's start by thinking, what am I going to serve for my vegetables for this meal?
Or am I going to make steamed vegetables with a white sauce on top?
Could I make a quick fish in the oven?
Could I make some chicken, homemade chicken nuggets on the stove for the kids tonight?
And after that, think about what the starch is going to be.
And, of course, the more whole grain the starch is, the better it is for your children.
So, if you can use brown rice, instead of white rice.
Or if you can choose quinoa pasta instead of plain white pasta or even whole wheat pasta if your children can eat wheat.
Then that's much better for them than the processed version.
Go unprocessed as much as possible with children.
And I think the last thing to say about meals is that if even one of the parents can find the time to sit with the children, it is amazing what kinds of stories come out during meal time.
And there's also been a lot of research about the importance of family meals and how children who have family meals do better in school.
They have an outlet for their thoughts, for their problems and they have a partner in their dialogue.
So, let's try and sit down.
Let's remember that we're serving our children more than just nutrients.
And that name is polysaccharide.
And the name comes from the fact that starchy foods are made up of many sugars.
Poly meaning many and saccharide is another chemical name for sugars.
And those sugars are linked together by chemical bonds.
Now, the other kinds of foods that come to mind when we're talking about dietary carbohydrates are simple carbs, or simple sugars.
And the simplest simple sugars are single unit sugars called glucose.
You might've heard of this one.
Fructose.
Aand also galactose.
Now when glucose and fructose are combined, or linked together, they form another kind of sugar that I'm sure you've heard of called sucrose.
And that is regular table sugar.
So, interestingly, table sugar has gotten kind of a bad rap in recent years.
It's even been called a toxin in our diets by many scientists.
And the truth is that the way in which we consume sugar, much, much, too much of it in many cases, it does make this kind of sugar into a toxin.
But, you might be surprised to hear that most of the excess sugar in the average western diet is from processed food.
And these often have huge amounts of sugar added to increase their palatability, to increase their taste, or to increase the shelf life of packaged foods.
But actually if we use sugar in moderation, if we don't drink the big two liter soda everyday, and we use small amounts of table sugar, It's probably okay for individuals who are healthy individuals, who have no medical conditions, it's probably okay to have a small amount of sugar in our diets.
The other two unit sugar that you may have heard of is called lactose.
And it's a combination of glucose and galactose.
It's the sugar found in milk.
What happens then is that the lactose passes through the part of the gut where it's supposed to be absorbed, and that part is called the small intestine, and it gets digested in the large intestine.
But it goes into the large intestine, where it gets digested by gas-producing bacteria in the large intestine instead.
And that's why people with lactose intolerance can feel sometimes bloated and uncomfortable if they drink regular milk that's quite high in lactose.
But it's important.
And it's called dietary fiber.
There's soluble fiber and insoluble fiber.
Soluble fiber, you might've guessed it from the name, it dissolves in water.
It's believed to support the health of the intestinal walls, or the walls of the gut.
And there's also evidence that it might help regulate cholesterol levels, also a good thing for many of us.
Insoluble fiber doesn't dissolve in water, but instead it absorbs water, kind of like a sponge.
And because it absorbs water, it acts as a stool softener.
It prevents us from getting constipated.
And it also speeds up the passage of food through the intestinal tract or through our digestive system.
By the way, fiber is also a polysaccharide.
But our bodies can't break these bonds, so it doesn't give us any energy.
Now, both types of fiber are found in fruits and veggies.
When we choose things like brown rice over white rice, or when we choose whole grain bread over white bread, we're basically making a choice that increases the amount of fiber that's connected to our starchy carbohydrates.
And this is better for our health, and will also prevent us from getting hungry again too quickly.
This has been such a huge topic of debate over the past 30 years, that I'm sure I'm going to offend somebody in the next four or five minutes.
But I'm just going to tell you what I know.
Okay first, I have to tell you that dietary fats are really important for the healthy growth and development of our children.
They're especially important in brain development and development of the nervous system.
They also help to protect and cushion vital internal organs, and the kind of fat under the skin called subcutaneous fat is both an important storage form of energy, and it also serves to insulate our children's bodies.
In addition to that, when our children consume a meal that has a certain amount of fat in it.
And that certain healthy fats, in the diet, may actually protect us from this kind of disease.
So, we can divide dietary fats into two major categories.
And I bet you've heard these terms.
We usually divided them into saturated fats and unsaturated fats.
So the first thing that comes to mind, of course, is our good old friend, butter.
And the other thing that people often thing of when they're talking about saturated fat, is red meat.
Unsaturated fats can also be divided into two types.
So they exist the way they do because of the fact that we've altered them somehow.
Naturally occurring unsaturated fats are found in oils, vegetable oils like Olive oil for example.
The oils in nuts are also usually quite rich in unsaturated fats.
These kinds of unsaturated fats are definitely less healthy for us and they're the ones that we've altered.
So the fatty acids found in naturally unsaturated fats are kinked in a very specific way and that means they can't stack together as tightly as the saturated fatty acids.
And so these kinds of fats tend to be the liquids at room temperature.
When we chemically alter the fatty acids in unsaturated fats, like we do when we make margarine or when we fry french fries over and over again in the same oil, the kinks in these fatty acids end up looking really different and we end up with something called trans fat.
Now these trans fats do two things in our bodies.
Neither of which is very good for us.
And the other thing that trans fats do is that they reduce the good cholesterol in our bodies.
The kind of cholesterol that is believed to be protective against these arterial plaques.
And while saturated fats have also been shown to raise the amount of bad cholesterol in our bodies, they haven't been shown as much to lower the good cholesterol.
Also, if we replace all of the saturated fat in our diets with foods that are high in refined or simple carbohydrates, things like sodas and white bread, and other processed foods, then this may also be contributing to the build up of arterial plaque.
Eat small amounts of naturally occuring foods of all kinds with a focus on unsaturated, naturally occuring oils like those found in olive oil.
And avocados and nuts and small amounts of saturated fat in our diet are probably okay as well.
I want to talk briefly about dietary proteins, or the proteins that are in the foods we eat.
Now, if you're raising children, you're probably aware, or you've probably heard that proteins are a really important part of a balanced diet, because they form, sort of, the building blocks of out children's growing bodies.
An example of that is the fact that protein make up a large portion of the muscle in our children's bodies and our own.
But proteins also play a whole bunch of other important roles in our bodies and our children's bodies.
So, for example, when we get sick, our immune system is activated.
And, I don't know why my mother used to always make me wear a scarf when I had a cold, but .
And then proteins act as transporters in a variety of different roles in the body.
Proteins also help us maintain the right fluid distribution in our bodies.
So the fluid stays where it should be because of the fact that the proteins keep it where it should be.
So If we're thinking of proteins as the building blocks of our children's bodies, then we can think of amino acids as the building blocks of the proteins.
There are 20 different kinds of amino acids.
And we can actually make a lot of them.
But there are 9 of them we call essential because we have to get these 9 from the foods that we eat, foods that are rich in protein.
You probably already know a lot of these.
But usually we think of, the first thing we think of are animal sources of protein, things like eggs and chicken, red meat and fish.
Dairy products are also a good source of protein.
Things like milk and cheese and yogurt.
But there are also many vegetable sources of protein.
And those are things like tofu, or nuts, or beans, and other legumes like lentils.
The important thing to note Is that the animal sources of protein tend to be complete.
That means that they contain all of the 9 essential amino acids in sufficient amounts to support growth, and repair, and maintenance of our children's bodies.
Whereas the non-meat sources, for example, the dairy and the vegetarian sources of protein, tend to be incomplete.
So they might contain all of the essential amino acids, but usually not in sufficient amounts to support growth if they're eaten by themselves.
But here's the trick.
If you combine vegetarian sources of protein with other foods, then you can end up with a meal that provides a complete set of amino acids.
These foods naturally complement each other and provide you with a complete set of amino acids.
As with all diets, variety is the key to a healthy vegetarian diet.
The ability to moderate when we eat and when we cook is the most important and all too often the missing link in our diets.
Especially here in the US, we tend to eat either too much of something or try to eliminate that food altogether.
On the one hand, we have supersized everything, and on the other hand, we see claims like fat-free or sugar-free everywhere in the supermarket.
And these claims attract customers because they're absolute.
We live in an all or nothing kind of culture.
And, often, we value quantity over quality in the things we eat.
When we read about food and nutrition, we find ourselves looking for simple advice from our scientists and our nutrition researchers.
We want to know, is salt bad for us?
But, as with so many of these health-related questions, the real answer is this.
And, in most cases, it depends on the amount.
Now, no medical person in their right mind would argue that the average American's sugar consumption is healthy.
We use words like "toxic" to emphasize how dangerously high sugar consumption has become, but the truth is that, without any sugar, our bodies would shut down.
We need a certain amount of sugar to fuel our brains.
A homemade treat made with a reasonable amount of sugar is almost certainly healthier than a processed food treat.
If we can learn to feel comfortable with the concept of moderation, then we can truly succeed in balancing our long-term health with our long-term enjoyment of the foods we eat.
If we practice moderation, then no food is forbidden.
As long as the choices we make most of the time are healthy ones, then there's room for everything in our diet.
Now, if you're the kind of person who likes to have clear guidelines, then try Michael Pollan's simple, helpful guide called Food Rules, where he suggests some good starting points for learning how to moderate.
For example, he suggests that we only have sweets and second helpings on days that begin with S.
So Saturday and Sunday.
In this way, we can begin to learn moderation when we eat.
Or, if you like, you could try having a rule that you can only eat cakes, cookies, and other treats if you bake them at home.
And, by the way, homemade cakes will almost certainly be healthier because you're using real ingredients in amounts that you control and without any preservatives or additives.
If you like the idea of starting with some simple rules like this, go ahead.
You'll find that, over time, you probably won't need those rules anymore.
There will be times when you you'll feel you've indulged a bit too much.
When you're on holiday or visiting family and friends.
Because if you make moderation into a way of life, then there's room for that kind of variation.
Remember, it's how you eat most of the time that will help you protect your health and the health of your children.
Oatmeal is a great staple for breakfast when you are serving little kids and the nice about it is you can put it on and then do and do something else like pack their lunches for ten minutes and when you come back it will be ready.
And so easy to make and so much than buying that ready made stuff, instant oatmeal that you have to put in the microwave, that's full of sugar and junk.
I just, I like these because they're kind of chewy.
So, 1 cup of oats to 2 cups of water.
It doesn't have to be exact.
You can always add a bit more milk or a bit more water if it gets too thick.
And then, put your stove on about medium til it boils and then turn it down to low and you've got oatmeal.
Very rich in soluble fiber, oatmeal, very good for their digestive tract.
Okay, so now our oatmeal is boiling.
Mix it up, blow on it to make sure it's not too hot.
You can see all the bubbles coming up, and this is the first step to making pasta.
And this is where you want to use your less expensive olive oil.
We're just adding it so that the pasta doesn't stick together.
And then, we're just going to add some pasta.
Give it a little stir.
So this is where everything starts.
If you do this quickly You won't even cry.
So I'll just pop it in a ziplock bag.
And then the other thing I'm going to do is cut up a clove of garlic.
To get this skin off the garlic, I use the flat part of the blade and go like this .
Basically you just have to be careful of your fingers.
I remember when I was a medical student and we would do our Emergency room shifts in the evening and at eight o'clock on the dot.
There would be a line up of mums coming in to have fingers stitched up.
Because they had been chopping onions for their dinner.
You just want to expose as much as you can to the olive oil.
I don't even know what this is called but it makes it into smaller pieces.
See you don't need a lot of equipment to cook.
Okay, so let's get some tomatoes now.
But, not everybody has the luxury of a backyard with a garden.
So, any kind of tomato you can get from the market is fine.
Just cut it in half.
And then there are a couple of different alternatives.
You could either put it in a blender and just blend it up like a smoothie and put it in or you can just chop it.
Except that we're keeping our fingers away from the blade of the knife.
And there we have the basis for a homemade tomato sauce.
And once you've had a homemade tomato sauce, you will never go back to the bottled kind.
So, we're going to head over to the stove and start making our tomato sauce.
You want to take a tomato?
Okay.
I have children who like eating fresh tomatoes.
I'm so happy about that.
It's time to drain our pasta.
It's not overcooked.
I'm just going to pour it into the colander, to let all of the water off.
If you want, you can rinse it with hot water.
And the first thing we're going to add, and this is the best smell that can fill your kitchen is our chopped up onions and garlic, and we're just going to add that in.
You can hear it and smell it at the same time.
This is the first step to every savory vegetable based dish.
You can add mushrooms to that.
You can add any fresh vegetable and it will taste good.
Even if you just want to flavor it with salt and pepper, it'll taste great.
And then, we're going to add a little bit of sugar to this sauce just to balance it off.
And if you want, you can add spices like paprika for example.
Are you going to stir for me?
Okay, so those tomatoes are just going to stew in here, and then you have to make a decision If you don't mind your runny sauce, you can just leave it like this.
You can see now that our sauce has gotten a little but thicker.
It's basically just a really nice, mild kind of cheese with a lot of calcium and protein in it.
And what I do, is just slice some thick slices of this, and you're going to basically just layer this with your pasta and your sauce.
Okay, so we've got our pasta that we cooked and we're just going to basically, put it down into a dish.
You can add a bit of your cheese and the heat of the pasta and then the heat of the sauce that you're going to pour on top will actually melt your cheese for you.
And then, I'm just going to take our nice homemade tomato sauce and I'm going to pour it over here.
I can hear them coming for dinner already.
And that is our pasta casserole.
This is one of quickest cakes you can ever make.
And if you like marzipan or you like almonds, this is the cake of you.
I'm going to cut a little piece of butter, and just throw it into this pan because we're going to grease that pan later.
And then I'll drop the butter in there.
It's kind of softened butter.
And the recipe calls for a cup of sugar, but I like to add a little bit less, because I'm trying to cut down a bit on the sugar in my children's diet.
So I add about three-quarters of a cup of sugar.
Some vanilla essence.
I know they say you're supposed to cream the butter and the sugar together first, but I don't have time.
So I'm going to pop it all into one bowl.
Okay, so here we go, we're going to mix this all up.
Once that's all mixed together, I'm going to get my almond flour.
And I'm going to measure.
I, I don't really measure, usually.
I think approximations are a good thing.
This cake calls for two and a half cups of almond flour.
So this is about a half a cup.
The only other thing that you have to do is to grease your pan.
And I'd say grease it generously, because if you've gone to all the trouble to bake a cake, you want it to come out of your pan.
Those sprays, those non stick sprays like Pam, I think they're terrible and especially bad for our children's health.
Rather take a minute, it doesn't matter if your hand gets dirty, and grease the pan.
It's worth it.
That wasn't so bad to clean up.
In about 15 minutes you'll have a cake.
So, I've just come back from the Farmer's Market.
And I have to say, I think one of the most important things we can do for our children's health is to increase the amount of fruits and vegetables in their diet.
And, believe it or not, that begins with us.
If the children see us enjoying our fruits and vegetables, and saying, wow, I got the freshest head of cauliflower at the farmer's market today, then, they're much more likely to accept those kinds of foods.
Because the farther they travel, the more they lose the vitamin content in them.
So, I try and buy things that are grown in this area, that haven't been flown on an airplane, or stored in a storage fridge.
And then, I try and celebrate these vegetables with my children.
So, if I redefine what a treat is, if I say to them, hey, I found fresh artichokes at the market.
And they'll have a memory of that as being one of our family's treats.
So that's one thing we can do.
Another thing we can do, is we can actually take our children with us to the market.
If they go there and they see all of the vendors with their fresh English peas and their carrots.
And they get to kind of taste the foods.
Then they're going to be much more excited and much more willing to try those foods at home.
So when we look at different types of food and different levels of processing of foods, we can start on one hand looking at highly processed junk foods.
These are things like potato chips and you know, candy bars, and they would probably be the lowest nutritional content.
Those things also offer us substantially more nutritional value than processed junk food or processed canned food.
So, these are obviously unprocessed.
fresh, we're talking about fresh fruits and fresh vegetables.
And these guys really give our bodies the most nutritional value for, for weight or the most nutrient density, the highest nutrient density.
And this is one of the reasons why they're so profitable for processed food manufactuers to make and sell.
And then on the other end, if we look up at the top here we see that these foods are very high.
So, if at all possible, we should choose foods that spoil quickly.
Because that usually means that they're going to be better for us.
Pour some boiling water into a thermos, Just so that the inside of the thermos gets nice and hot.
And I'm just basically looking to see what there is from last night's supper.
So here's some nice pasta which we made with some, with a bit of a white sauce and some vegetables.
And while that's heating up, we'll make the side dishes.
Kids get hungry at school and you can really take advantage of that hunger by putting good things in their lunch.
They'll actually probably eat it, where they might not at home.
So, I'm just going to cut this carrot up into little sticks, like this.
Whatever vegetables you have in the fridge, you can just kind of chop up.
And just so they don't have to think in that moment, I'm going to strap on a recyclable fork so they can bring it back and we can wash it.
But putting in a whole orange is going to be difficult for them to peel.
If you make it easy for them to each, they're much more likely to eat it.
And then you put these little packages of love, in a nice container.
And what you can do to keep this dip cold.
And put the dressing right beside that, and it will keep it cold.
Children learn a lot from their parents.
They tend to pick up their parent's exercise habits.
They tend to copy their parent's food choices in the long run.
But they also learn a lot from us about how eating should happen.
Do we sit down together and eat from dishes?
There is a lot of evidence suggesting that children who sit down to eat with their families on a regular basis actually stay healthier.
Our eating behaviors teach our children more than just which foods are healthier for their bodies.
When we sit together, to share a meal, our children can learn valuable communication skills.
Throughout history, mealtimes have also been an important way for families to pass on traditions and stories from one generation to the next.
For older children, the dinner table can be a safe place to talk about anything that's worrying them, and to get advice from the people they trust most.
Besides all of this, dinner time can be so much fun.
If you want some great tips on how to make meal time special, you might want to have a look at Laurie David's book called The Family Dinner.
Firstly, try and have everything you need at the table ready at the start of the meal, so that no one has to get up for the water jug or the pepper mill.
For the first few nights, try thinking up an activity like a silly game or question to get the ball rolling.
Then, have a story ready about your own day.
Tell them something that happened to you, and how you reacted, and maybe ask them what they think you should have done.
Finally, if you have enough food to share, try inviting some friends to the meal.
Having friends of any age at the table helps make dinner fun and can teach your children that meals are a good time to relax and enjoy good food in good company.
It may not be realistic for some families to sit down to a meal every day.
But in general, the more often we can sit down with our children to eat, the better it will be for their health.
There is pretty good evidence that children who regularly eat with their families do better at school and have better health outcomes than those who don't.
And of course there are many ways for us to spend quality time with our children, but eating together can protect the whole family's health and add so much value to our lives.
Most parents that I meet have at some point or other, experienced a situation in which their child refuses to eat something that the parent wants the child to eat.
My children do this to me on a regular basis and that's probably why the term picky eater is used commonly especially here in the United States.
And there are a lot of theories about why children refuse certain foods.
Other people believe that some children have a heightened sensitivity to the flavors and textures of certain foods.
In general, eating should be stress free, whenever possible.
Firstly, the more children feel that they're involved in either choosing or helping to cook a meal, the more likely they'll be to eat it.
So if you can, take your children to a Farmer's Market or the vegetable section of a grocery store, and ask them what they feel like having for dinner that night.
When kids see adults coming together around healthy foods like they do at a market, they'll often be more willing to try new things.
Also, at places like the market, where most of the choices are healthy ones, you can't go wrong letting them have the power to make that decision.
Secondly, as much as possible, try and involve your children in the cooking process.
let little ones mix things in a bowl, or add fruit to make their own smoothie.
Older children can actually help prep vegetables or mash things like potatoes, or bananas, or avocados.
Even letting children assemble their own meal, letting them make their own yogurt parfait in the morning, for example, or make a fruit face with their berries.
This gives them a sense of control that can help them to be more adventurous eaters.
Another helpful step you can take, is to surround picky eaters with good role models as much as possible.
If children see us, their parents, or their brothers and sisters, or other children their age eating healthy foods, then they're going to be much more likely to try some too.
But in general mealtimes should be kept fun and light.
If you're worried about what your child is eating, try not to bring that worry to the table.
Kids love chicken nuggets.
So that's what we're going to do today.
We're going to make real chicken nuggets.
That's what they look like when they come from the butcher.
And what you have to do is cut them into approximately the size of a chicken nugget.
Because you don't want to leave chicken sitting out for a long time.
So, I'm going to use a gluten free flour, but you can just as easily use regular wheat flour.
That's going to be our step one.
And you can actually do this with fish, as well.
You don't need to use chicken.
Anything that you want breaded and crispy on the outside, this is a great pattern.
In the middle go the eggs.
It's not deep frying so we don't want it to be soaking in olive oil.
Okay, I think my oil is hot enough now, so I'm going to transfer my chicken nuggets onto this nice preheated pan.
The only other thing we have to do is to put some salt on this.
So I'm just going to take my salt shaker and add a bit of flavor.
And we'll do that on the other side as well.
If you see that there are bits of your pan that are getting dry, you can just drop a little bit more oil on there.
And then hopefully you'll get some nice golden brown nuggets that your kids will want to eat.
Okay, I can smell these guys cooking, so I'm going to start to flip them.
And you can see they've got a nice crispy shell on the outside.
And the thing is, if your going to serve this to your child for dinner, you probably give them 1 or 2, you don't want to give them a huge amount of meat.
And then we just let it cook on the other side until the chicken gets cooked all the way through.
Want chicken nuggets.
I like chicken nuggets.
It's delicious.
Children being children, they love their treats.
So what we're going to do today is make a healthy version of a children's treat.
We're going to make cupcakes.
So this is how you separate an egg.
And then you open it up, and you kind of scoot the yolk backwards and forwards until the white stuff has fallen into one bowl and the yolk can go in the other.
You just don't need it, and you're going to, probably put a little bit of icing on top, anyway.
I have to say, I never get these out.
Again, it's suppose to be about a teaspoon, but who really wants to get out their measuring spoons for this kind of thing?
And then I'm just going to cream the yolks and the sugar and the vanilla together.
And we're going to add a little bit of baking powder, just to make it rise, about a teaspoon should be enough.
And if it's a little bit thicker than this, it's fine, it'll still work.
And we're going to fold the whites into this part.
We're going to put our whites, plop them into there and this is called folding in.
And it makes a really nice, light cupcake.
And remember, we didn't put any butter into this.
We just put nice, wholesome farm eggs, a little bit of flour, and a little bit of sugar and some vanilla.
So it's a very easy recipe and it makes a nice birthday party cupcake, and what we're going to do now is scoop them into these cups.
My little boy with Celiac disease can't have any wheat.
I think the biggest thing about baking is that people think it's going to make a big mess and they think they're going to have to get out ten different measuring cups to do everying.
In general if you get the consistency right you can keep adding a bit of flour or a bit of milk, just correct as you go along.
And then you'll end up with something good.
And they're ready to go into the oven.
A good way to tell that they're done is that it starts to smell really good and you can stick a toothpick in the middle and if it comes out clean you know that they're done.
Okay, let's talk about the term organic.
I'm sure you've heard that term.
And let's see what that means and why it's better for our health, and the health of our planet, to buy organic foods whenever we can.
Now, sometimes you might see the word natural on foods that you buy in a supermarket.
And this term natural can actually be pretty misleading.
Because it's not very specific and they aren't many regulations around what can be called natural.
It's a term that's certified by the government, by the USDA, or the United States Department or Agriculture.
For fruits and vegetables organic means that the crops were, were grown without any synthetic pesticides or fertilizers and that they don't involve genetically modified organisms.
Pesticides and fertilizers are used to help us grow large amounts of food to feed lots of people, but in the way in which we're using them they're having serious environmental and health impacts.
Fertilizes and pesticides are made from fossil fuels, meaning that they release greenhouse gases into our environment.
Now when farmers apply too many pesticides, this can also be really harmful.
Because pesticides, in large doses, can lead to something called pesticide resistance.
Well, pesticides usually will kill off the majority of pests in any given population of pests.
But the few who are able to survive, if these guys continue to reproduce, then over many generations, the results will be, the emergence of something called superbugs.
And this can mean serious trouble for us.
Now because organic farming doesn't use any of these aggressive synthetic pesticides or fertilizers, we don't see the same kind of bad side effects.
Okay, so we've seen why organic is better for the environment, but what about Why it's better for people?
Firstly, organic farming methods protect the people who are working on the farms.
Farm workers are regularly exposed to pesticides.
And in the short term this can result in, toxicity or poisoning.
So organically-grown fruits and vegetables are free of these toxic pesticides.
Not only do they protect the farm workers, but we're also not at risk for consuming pesticide residues with the food that we eat.
You might have heard that phrase as well.
What does that mean and why is it something that we should be looking for if, if at all possible when we're shopping?
But basically, the closer you can get to your own kitchen garden, no matter how small that garden is, the better.
You can get local foods either at a farmer's market, some grocery stores will carry local produce and they'll label it and tell you where its grown.
And in contrast to that, when we buy, for example, fruit that's not in season in our part of the world, that fruit is often flown in from far away, and it brings with it a sort of a downside.
So let's talk now about why local food is better.
The money you spend on local food stays within your community, instead of going to support large corporations in other cities or states or even other countries.
Also, when we transport and store food for long periods of time the, the nutrient content, so the, the amount of vitamins in that food, especially when it's fresh produce, is reduced.
So the less transport and storage the better.
Many people also say that buying food at the farmer's market actually gives them produce that tastes better.
So a lot of people say that this farmer's market produce just tastes fresher and is more enjoyable to eat.
And we have to remember that buying local doesn't have to mean spending more.
When you buy local food that's in season, it's often the same price or cheaper than what you would pay at a grocery store.
So the take home message is really, we need to do the best we can with the resources that are available to us.
Whenever possible buy organic, if possible by locally grown or plant a small kitchen garden, even better.
And in general that will result in foods that are not only better for us but better for our planet as well.
You know it's hard to be a consumer these days because there are so many terms in the grocery store.
All natural, multi-grain, and some of these don't really mean much, but organic means something very specific.
It is a term that's defined and certified by the government through the U.S Department of Agriculture.
Now, the term organic doesn't always mean that the food is healthy, especially if the food is highly processed.
Just because a cookie is organic, it doesn't mean it's any better for us.
But, let's take a minute to look at what organic does mean.
For fruits and vegetables, organic means there are no synthetic pesticides or fertilizers, no genetically engineered crops and no sewage sludge used in the production.
Now, pesticides and fertilizers are used to help us to grow large amounts of food but they have serious environmental and health impacts.
Fertilizers and pesticides are made from fossil fuels and using them adds greenhouse gases to the environment and increases global warming.
And even though we think of extra nutrients as a good thing, overusing fertilizers pollutes our waterways, and harms fish and other marine life.
Overusing pesticides can also be harmful by producing super bugs or pests who can survive any amount of pesticide killer that you use.
For meat and milk, there's another reason to buy organic.
Because organic meat and milk, come from animals that didn't receive any unnecessary antibiotics or growth hormones.
The amount of antibiotics we use on livestock today, can create antibiotic-resistant bacteria that can make humans really sick in ways that we can't treat.
Growth hormones are allowed in the U.S, but are banned in the European Union, Canada and other countries.
Now, this is not meant to scare you away from fruits and vegetables.
It's just to say that if you can afford it and if you can find it, you may want to choose organic for any one of these reasons.
I'm Hannah Carmen, a graduate from a Master's Program in Earth Sciences at Stanford University.
So, I'm sure you've heard people say that locally grown food is better.
But why is that?
First, local foods are fresher because they take less time to get to you.
And because they've traveled less they contain more nutrients and people often find that they taste better.
Let's take a look at these two oranges.
They look the same, but one's from Chile and traveled 6,000 miles to get here.
Buying local foods doesn't have to mean that you spend more.
When you buy local foods in season it's often the same price or cheaper than the grocery store.
Seasonal foods are cheapest at the height of the season when the supply is large.
For me, the most important reason to buy locally is to support your local economy, especially at the farmer's market.
So it turns out that in the U.S., over 25% of the money we spend on groceries is at Walmart.
So if you spend a dollar on food at Walmart, the money goes to the store's overhead, it goes to shipping and packaging and marketing the food, it goes into the pockets of the billionaires who own Walmart.
A much smaller amount goes to the employees at Walmart and just a few cents of that dollar will go to the farmer who grew the food.
When you spend a dollar at the farmer's market, the majority of that dollar goes directly to the farmer.
In the food movement it can be easy to feel powerless, because at the root at most food issues are policies that lie in Washington.
But really, every time we spend a dollar on food, it's an opportunity to vote with our dollar.
So when you can, buy local more often.
It will be good for you, for your community and for your environment.
Many of us know that vegetables are important for our health.
And that we should try to kind of limit the amount of meat in our diets or the frequency with which we eat meat.
But it turns out that if we replace some of the meat in our diets with vegetables, that actually turns out to be better for the Earth as well.
Modern methods of producing meat actually hurt our environment.
Let's, let's take a look at beef, for example.
I don't know if they've ever heard the saying, don't poop where you eat, probably not.
But the point is that that manure actually fertilizes the grass to grow even more, and this is what we call a closed loop system.
These days we produce meat very differently.
The reason that we raise cattle in CAFO's and feed them on corn comes down to simple economics.
Corn is cheaper than grass.
Because the government incentivizes, or pays, farmers to grow lots of corn.
Because CAFOs are really tightly packed like, like slums, they can yield thousands more cows per acre than a pasture can.
And when cows eat corn instead of grass, they fatten up more quickly, which means that they can go to market more quickly as well.
But these cheaper prices don't take into account the enormous cost to the environment and to our health.
Sunlight is free, and it's free of greenhouse gases, but when we move to CAFOs where cows are eating corn, there are a lot of inputs besides sunlight.
When farmers grow corn they use fossil fuels.
And fossil fuels are used to make pesticides and fertilizers and to power the, the tractors and the machinery that harvest and transport the corn.
Now these fossil fuels are big contributors to global warming.
Also, huge amounts of manure collect around the CAFOs in enormous lagoons of waste, which harm the air and the water for miles around.
Unlike in the system where cow manure fertilizes the grass that it eats, this manure has no where to go, and it's produced in such enormous quantities that it's difficult to move anywhere else.
When cows live in such crowded conditions they're also much more likely to get diseases.
So farmers feed them antibiotics to make sure that they stay healthy.
80% of the antibiotics used in the United States go to this kind of commercial production of animals.
And it's really dangerous for our health, because it leads to antibiotic resistance bacteria.
So let's look at a chart that will kind of help us see the difference in greenhouse gas emissions of meat versus other things like fruits, vegetables, tofu, and beans.
So for a kilogram of beef, 27 kilograms of greenhouse gases are added to the environment.
Now, for a kilogram of lets say broccoli, or a kilogram of tofu, only about 2 kilograms of greenhouse gases are released into the environment.
Also different meats are relatively better for the environment.
For example, chicken is more energy efficient than beef and also because it has less saturated fat than beef it's probably better for your health as well.
So the message is limit red meat consumption, pick lean or energy efficient proteins like chicken or vegetable sources of protein more often, and, in general, choose vegetables more often.
Hi everyone.
I've been reading so much lately about the importance of gardening as we try and get our children excited about eating fruits and vegetables.
And I wanted to ask her, Rita, did you plant plants like this with your children when they were growing up?
And I also worked with lots of school children.
>> And many of the children that I worked with over the years, participated in eating their first salad.
Is it difficult to grow something like this?
It's very easy.
because that smells so good.
Okay.
And now we'll go to our seed packet and what I was mentioning about the seed packet is it will tell you the appropriate time of year.
Depends on where you live.
But we can grow this inside under bright, warm conditions in our homes on the window sill.
Okay.
So, the size of the seed determines planting depth.
Some plants don't even get covered at all.
So what I do is I usually take a little pinch of seeds.
So we'll just kind of sprinkle those with a little bit of distance between them.
And you know if you get too many you can hand the child the scissors after they germinate and they can come snip little micro basil and put it on their pasta.
And just lightly cover those seeds.
So I have a tag.
Now back to the seed packet.
It has information as to how long we should expect the seed to stay in the soil and then germinate.
What about watering?
Do we have to water it?
You could use just a simple spray bottle.
>> So after care of the plant is very important.
If you're a very busy person and you put this on your counter and the sun is shining in the window and you go away, what's going to happen?
The surface will dry out.
They're very close to the surface.
So for small, seeded plants, I recommend putting a little plastic wrap over the top.
Once you've got that done, you're going to check and make sure that it doesn't dry out.
And, in a week or so, you should see the little seed leaves come up.
The true leaves are just beginning to emerge down here in the middle.
It's not very big but if you even have a little bit of space or even some little planters by your sink just to have a few herbs growing it makes such a difference to your cooking.
Hm smells so good and the kids get so excited when they can actually grow something and take it inside and eat it.
So it is worthwhile even if you have just a little bit of space to plant a few seeds and water them.
Here's a big green one.
It's just about to get ripe.
This is going to be the winner this afternoon.
They're going to get very excited about that guy.
But I'm actually going to leave it on there for them to pick cause, it brings them so much more joy.
Okay, so we're going to make a little bit of nice fresh fish for the kids today.
So, one good way to get that fishy taste out, is to put a little bit of a marinade on top that has some nice flavors in it.
So, I'm going to use my children's scissors and they can actually do this part, they love it.
They're not here right now, or else.
I'd ask them to do it.
You don't want to feed them fish like salmon or halibut everyday of the week.
The tails of the fish have less bones so, a tail like this, I can't feel any bones in the fish.
You just don't want to be feeding really young children fish with bones in it.
Preparing fish is so easy.
People think it's complicated but it's actually one of the quickest things to make.
All you have to remember with fish, high temperature, short amount of time.
Put just a little bit of salt and pepper.
And then, look how easy this is, I'm going to mix it up, and slather it on.
Then, now it goes in the oven.
Depending on the size of your fish, it could be 15 to 20 minutes.
And probably, anywhere between 400 and 500 degrees is perfect for fish.
And what we're going to do, just to make sure that it's ready, we're going to take a knife and just kind of cut into it.
And you can see that that flakes apart nice and easily.
So, that means that the fish is cooked.
It's a favorite.
It's full of vegetables, just got a little bit of chicken.
And we're going to chop everything up.
Put it in a pot, you can't go wrong.
You don't have to put the same ingredients in your soup that I put in mine.
This is just a suggestion, but my kids like it and it's a good healthy meal.
Okay, so I start everything off with onions and garlic.
There is no right or wrong way to do this.
You just have to take a large onion and somehow get it into small pieces.
And now we're going to take a chunk of garlic and we're going to use the flat side of our blade to just give it a whack.
Your shell of your garlic cracks open and it makes it much more easy to get it off.
And I'll do two cloves for a whole pot of soup.
I'm just going to peel a couple of carrots.
Sometimes you can even give the kids a little plastic knife and ask them to help you chop it up.
If they get involved, they're much more likely to try the dish that you're making.
I don't like the idea of hiding vegetables from children because I think they're so beautiful.
Why not show them that they're eating cauliflower?
And I'm also going to add a little bit of broccoli.
Why not?
One principle that is so easy to remember is if you can try and get as many colors in your soups and salads and stir fry's as possible, you'll probably be covering all of the vitamin needs of your children because orange vegatables contain one kind of vitamin and green vegetables contain another kind.
So, if you cook like a rainbow, then your dishes that you make will contain all of the things that your children need.
And then the last thing I'm going to put in that bowl are some little zucchinis, baby zucchinis that I just got at the market.
And I'm not, I don't want to overcook these because then they get mushy.
Especially if you're chopping while your pot is on, you can actually throw the vegetables in and then get the soup prepared in about 15 minutes.
And now, the last thing we have to do, and I always leave this to last, is our chicken.
And that's just a food safety thing that my mom taught me.
She said never cut anything on a board that you've cut raw meat on.
So I bought some nice, fresh chicken thighs.
You actually don't need a lot of meat in any soup.
It's such a nice thing to just have a little bit of the meat flavor and have mostly vegetables.
And that should be enough meat.
In general, I think, our kids probably eat a bit too much protein these days.
So there's my chicken.
Now I'm going to wash my hands and we're going to head over to the pot.
So we're going to turn on our stove and wait for the pot to heat up.
I have my heat at about medium right now and I'll turn it down a little bit later, once the soup is boiling and just let it simmer.
This is the beginning of the flavor of your soup.
It won't taste like boiled vegetables.
It'll taste like something much better than that.
Then we're going to add our chicken.
Now is where our fresh thyme from the garden comes in.
Pull off some of the little tiny leaves and if little children are around their little fingers are great for pulling off these leaves.
It's the smell of cooking homemade soup in a house.
You don't have to add these spices but you can.
They add a little bit of flavor.
If you like chili powder, you can add just a bit of chili powder.
You can just play around with these different tastes and see which ones you like best.
Just a little safety thing that my mother taught to me .
She said if you have the young children around never leave the handle of you pot facing this way because a little person can come and reach it and pull it down on themselves.
She said always turn the pot handle away.
So I try and remember these little tips.
And then we're going to add all of our other vegetables, pour some broth over, and top it up with some water if we need to.
And if not, we fix it up.
If you don't want to use chicken broth, you could use one of these.
It's a bouillon cube and you could basically just unwrap it.
And now, we're just going to turn the heat up and wait for it to come to a boil.
And once it, it boils, we're just going to cover it, and turn the soup down and let it simmer for a while.
We are making steamed vegetables with white sauce.
So ideally when the vegetables are steamed.
Almost all of the water has actually evaporated.
Because, then you won't have lost many of those vitamins.
I'm just going to put a little bit of salt, and then I'm going to cover this.
If you have a six month old who's just getting their, their teeth, then you obviously have to cook it longer than if you have a two year who has a full set.
And they can really chew their carrots, even if they're not fully cooked.
And while that cooks, I am going to make a white sauce.
You just take a little bit of butter and let it melt.
Now, we're going to add the milk, for flavor I'm going to add a bit of salt to this, and a little bit of pepper.
Meanwhile, our vegetables are boiling nicely over here and about thirty seconds later, the sauce.
And we're going to add, a handful, of grated cheese.
Cheesy, yummy white sauce.
Home made, no added 1500 ingredients like you get in the store bought stuff.
I'm going to strain my vegetables now, so that, I can put it in one of my soups, because it has so many vitamins in it.
Food allergies in children have increased dramatically in recent years.
And even though children can have allergies to a wide variety of foods, there are eight foods that account for about 90% of all food allergic reactions in the United States.
Now, since 2004, companies are required to clearly label any of these big eight food allergens on their packaging.
Today, around 8% of children in the US have at least one food allergy.
That's almost 6 million children.
And often, the allergic reactions that these children have can be life threatening ones.
Anyone who spends time with the child has to know how to respond in case of an emergency and some children need to carry medication with them at all times.
But socially, food allergies can also be tricky, because a child who needs to bring her own food to a birthday party, or who can't share in a school treat can feel pretty left out at these events.
And sadly, there is a also the possibility that children with food allergies could be bullied because their restrictions make them different.
One way that parents of food-allergic children can help is to provide enough safe food for the allergic child to share with non-allergic friends.
For example, if you have a child with a gluten allergy as I do, and if you have the resources to do this, you might consider sending the child to a birthday party with some extra gluten free treats so that he can share.
You can also sometimes do this for school events where treats will be handed out and you know about it in advance.
If the gluten-free treats are good, and especially if they are homemade with love, your allergic child will feel more included in the fun.
Now, in order to make home into a worry-free zone, some families with allergic children try to keep the kitchen free of their child's allergen.
It's always important, of course, to read labels carefully at the supermarket and if someone brings a gift to your home that isn't safe for your allergic child, you might want to store it in a special place outside of the kitchen where it won't be eaten by accident.
Every family will find a different way to accomodate their child with a food allergy.
The key is to keep meals as stress-free as possible.
Like all children, our food allegic-children need to know that food is a wonderful part of life.
And, they just need to be a little bit more careful about the things that they're eating.
Let's talk about how our bodies understand taste and how we interpret the flavor of the foods we eat.
So, here is a diagram of one on my children.
So, nobody will get offended if my drawing skills aren't that great.
Since we're talking about taste, I'll draw in the part that most people most commonly associate with taste.
It's actually the strongest muscle in the human body.
I learned that playing Trivial Pursuit.
It helps to move food around in the mouth.
It also helps us to coordinate swallowing, by pushing down a flap here called the epiglottis, epiglottis, down over our windpipe which is also called a trachea.
And hopefully that way food will never go into the trachea.
Although it can on occasion and that usually makes us cough quite a bit to try and get it out.
But instead the food is supposed to go into this muscular tube behind the trachea called the esophagus.
Okay, now the oral cavity is roommates, let's say, with the nasal cavity.
And this is also why the food that enters our mouths also gets smelled while it's being tasted.
And all of this information is sent to our brains where it is integrated or decoded so that we suddenly become aware, aha, I am eating strawberry ice cream or some other recognizable flavor.
So this is how it works.
In the tongue, we have receptors that look like this.
They're basically cells that receive messages and send them to the brain.
So, here they are heading off to the brain in our zoomed in version.
And here they are heading off first to a part of the brain called the brain stem in our zoomed out picture.
And this is the brain stem, and this is a part that I'm just drawing in for completeness, called the cerebellum.
It doesn't have anything to do with taste directly, but it helps us get the fork into our mouth.
It has to do with coordination and, and balance.
So when a food approaches and then enters the mouth, information is carried to the smell and taste centers in the brain to give us more information about what we're eating.
When food enters this taste pore over here, the receptors fire.
And there are receptors for a bunch of different tastes.
There are receptors for sweet, sour, salt, bitter, and a fifth one called umami, which is sort of savory flavors.
And even that out tongues sense the fat content in foods, and also the temperature of foods and that is, contributes to what we perceive to be the flavor of that food.
So it gives us information about what we're eating and what we're tasting.
Our sense of smell is actually responsible for about 80% of what we taste in foods.
Well, there are also sensory cells at the top of the nasal cavity and these cells actually pass through a thin layer of bone.
And then they connect with other cells that transmit messages from those sensory cells to the brain.
And little odor particles will tickle these sensory cells and cause them to send those messages that then get transmitted to the brain.
Okay, now listen to this.
In college I had a friend who had been in a motorcycle accident.
He'd suffered a pretty serious concussion and he was lucky to be alive, but when he'd struck his head, these nerve cells had been sheared right across by the bone and this guy could not smell his food anymore.
So, he also couldn't distinguish between, let's say, the flavors of raspberry and strawberry.
Although he could still tell, because his taste receptors on his tongue were still intact.
So, why am I telling you this?
Why am I talking about taste in a class that has to do with nutrition?
Well firstly, I think it's really interesting.
But also taste provides us with information about what we're eating.
It, it gives us information about the nutritional content of the foods we're eating.
We instinctively are kind of hard wired to prefer foods that are high in sugar, salt, and fat because our bodies need those for survival.
Although we're kind of now learning that too much of a good thing can actually threaten our survival.
And we sort of have a library stored in our brains of favorite foods that might trigger memories through taste and smell.
For example, excessively bitter foods we will probably spit out because we associate excessive bitterness with poisons or toxins.
But also, when we're cooking healthy foods, we can use this knowledge to our advantage.
For example, if we can choose the freshest, the, the most locally grown, and, and seasonal vegetables, and other ingredients that we can afford, if we emphasize quality over quantity of ingredients, then it's more likely that our children will have a positive experience with regard to the taste and the flavors that they perceive in those foods.
Secondly when we flavor healthy foods with reasonable amounts of things that are sweet, a little bit of salt, perhaps something sour, maybe something bitter, umami if you like it, even a touch of fat like a little bit of butter on some, some steaming broccolli and even some, some spices that make something a little bit picante.
That can really add to the experience of those flavorful, healthy foods.
And finally, I think we have to not be afraid to experiment with fresh herbs and spices.
These things can really make the experience of the food much more pleasant.
And then our children will love to eat the healthy foods.
Unlike the processed food manufacturers, we have the best interests of the consumer at heart.
So if we use reasonable amounts of these sorts of flavorants, for lack of a better word, then we can really have a fine balance that will leave our children healthy and develop their taste for real whole foods.
I have a favorite salad dressing.
It's made with a little bit of vinegar or sometimes you can use lemon juice.
A little bit of oil.
I use olive oil usually and there's a little bit of my fat content.
Some salt, obviously salty.
And a little bit of pepper, which you could say would hit the pungency receptors, if they exist.
And then a bit of garlic for the umami flavor.
And a touch of honey to balance the sour out and add a little bit of sweetness.
If I put that dressing on basically anything colorful, any kind of colorful vegetable medley, it usually goes over well with the children.
So understanding how taste works can actually inform the way in which we cook.
Because,for example, fruits and vegetables don't need nutrition facts labels on them.
Fresh fruits and vegetables but they're very good for us.
So if we can minimize the number of items that we eat that have these labels, it's probably better for us.
Like two cereals or something like that then we might want to know how to look at this.
Let's look first at the first thing to start with look at is to look at the serving size.
This can be a bit misleading because sometimes there's more than one serving in a single container and it can be confusing.
So this will make it more clear if there's more than one serving per container, and everything underneath that is the amount per serving.
If you're looking at a chocolate bar that's got 400 calories in it.
That's probably too high for a small child given the fact that they only need about 1,400 cap, calories per day.
Okay, so then if we look on the right-hand side here we see something called percent daily values.
And there's a bunch of numbers, percentages.
And then it corresponds to a little note at the bottom that's starred that says that these values are based on a 2,000 calorie diet.
So yours may be different, and also your children's percent daily values may be different as well, if they're smaller.
Then if we look at dietary fiber, less than one gram is not that much so, for things like, see, your breakfast cereals you want to see something a bit higher than that.
Okay.
Okay, then below that is an item called total carbs.
So just to summarize, if we start here, we look at the serving size.
And make sure that we know how many servings are in the package we're eating, that can give us more information.
Then if we look at the calories per serving and just make sure that this isn't a ridiculously high number, that can be useful information.
If we move down and you look at the different kinds of fat in,in the packaged food.
And then also we want to definitely keep an eye on sodium.
We can think of sodium as salt basically because it's one of the the elements in salt and we should train, make sure we choose one that's lower.
Make sure we choose the item that has the lower salt if that's If that's an option.
And then finally we want to keep an eye on the sugars especially in processed foods where sugars tend to be really high.
We want to look at those and make sure that they are not ridiculously high.
We'd like to think that children, our most precious individuals, are in some ways protected by the society in which they live.
Most children are protected by their families.
Not all of them look like this family but in general the health of that family can have a very real affect on the health of the child.
Had enough education to help them understand what a balanced diet is when they're making decisions about what to feed their children.
That is going to have a positive health impact on these children.
And I'm just going to write the SES, Socio-Economic Status.
If we move out a layer and look at the community, we see that the health or the stability of the community has a very real effect on the child's health.
Are the streets safe to play in?
Are there safe ways for the family to get from A to B?
What sort of homes are there in this.
Are there good schools in the area?
Even to some extent what about fast food restaurants.
How many fast food restaurants are in this neighborhood and, and how many grocery stores for that matter.
And then decisions made at this level can also have very real effects on the health of the child.
Or on any individual for that matter who is living in the country.
If for example, a country is financially secure, it's more likely that the citizens of that country will be financially secure themselves.
The laws that a government passes around healthcare and access to that care will also affect the individual.
Is the country politically.
Stable in areas of the world where there's political instability, children are less likely to receive preventative medical services, like immunizations.
In the U.S, there have been big debates around, for example, gun laws.
Does one have a right to, to own a, a firearm.
Then that processed food is going to become part of our culture and the lifestyle choices.
Of a country, can effect the health of the individual living in that, in that part of the world.
What, what products are being marketed towards those target groups.
All of those are going to filter down, and effect the health of the child.
And then families can, can thrive and can raise healthy children.
Or if these protective layers fail our children they can be left at risk for poor health and developmental outcomes.
I also have a responsibility to be aware of what's happening in the world around me, and do what I can to change the world around me for the better.
And when that's all together in one pot it's easy, it's a complete meal and this is actually a really satisfying hearty meal for young children especially on a cold day when it's kind of rainy outside like it is today.
And for stew, they don't have to be finely chopped like they world be for tomato sauce or something like that.
You can just cut them in kind of rough chunks like this because mostly this is just going to add flavor to your stew.
So the next thing we have to do is get our garlic ready.
This is also just for flavor.
Wow, that was a strong onion.
It's kind of refreshing.
And I'm just going to put it in with the onions.
Now, the next thing that we're going to do is that we are going to season the meat.
And, I don't like to wash a lot of dishes, so I try and use the actual paper that the meat was wrapped in as much as possible.
And then the first thing I'm going to do is just put some salt on it.
So there's always a little bit of bitter.
The thing about this kind of cooking is that it doesn't matter what spices you use.
You can use any spices you like.
I'm going to put a bit of chili powder on.
It doesn't matter if it gets on the paper because you're going to use those spices when you toss the chunks of meat around in the leftover spices.
This is coriander, I love coriander, but if you don't like it, you don't have to use it.
Just choose spices that you like and be generous.
And the last thing we have to put on is just a little bit of corn starch.
You can use flour, but my four-year-old can't tolerate wheat, so I use corn starch, and I'm just going to dust a little bit of corn starch.
You think it's complicated to make a stew?
It is so easy.
Okay, so now I've got my big mess of spices and cornstarch and all of that stuff over this meat, and I'm just going to toss it.
Okay, so there is our meat, ready to be braised.
So I'm just going to cut big chunks like this and each child will get a chunk and eat adult and then I have a bowl full of these nice, baby potatoes.
They've been washed but you don't have to take the skin off of them or anything and we're almost done with our stew preparation.
It makes it so tender the kids love it.
Let's think.
It doesn't even matter if some seeds get in there because You're not going to be serving all of the sauce so the seeds will probably just stay at the bottom of your pot.
So you're just going to kind of glug in some juice.
I'm making a big pot of stew, so you might use less if you're making a smaller pot.
So if you're short on fluid at the end, you're going to top it up with chicken broth.
Then, I just bought a pasta sauce.
You can use any kind of pasta sauce and you're basically just going to pour.
Do I have pasta sauce on my face?
So I'm going to see what we have.
But, a little bit like that will just give it that little bit of bitter flavor as well.
Let it get nice and hot, and slide all of my beef that, has been covered in the spices and the, salt, and the pepper, and the cornstarch, and let it get nice and brown.
Now that our beef is starting to look nice and browned on all sides of the cubes, I'm going to add the onion and garlic to get a bit brown and to be exposed to that heat.
There's kind of like a thick paste that sticks to the bottom of your pot when you do this kind of braising.
And if you can scrape that up with your wooden spoon it gets into the sauce and gives it a really nice flavor.
It's kind of like a, a real bullion cube.
And you can see we've almost covered all of our meat and vegetables.
So that's going to get nice and tender in the oven, if we leave it there for a few hours.
Make sure everybody's nice and submerged.
Are you guys all in there?
Now I'm going to cover it and I'm going to put it in my preheated oven.
It's like lifting a small child.
One way to do vegetables is to roast them and it's so easy.
You just basically preheat your oven.
You cut up some vegetables and toss them with a little bit of olive oil and salt and pepper.
It's almost better than steaming them sometimes because all the sugar in the vegetables kind of condenses so they can get a more intense flavor.
Potatoes, I'm going to do separately, cause they're the slowest ones.
And you can even roast cauliflower.
Cauliflower can get a little bit watery if you over steam it so sometimes roasting it is a nice way of doing it.
And now, we're going to just take some olive oil and drizzle it all over these veggies.
And it's ready to go in the oven at about 350 degrees until it's cooked.
And basically, if you want them to cook faster, cut them into smaller cubes.
If you have a bit of time and you can cut them into wedges or bigger chunks.
And I like to add a little bit of rosemary, which smells so nice and just makes me feel like I'm somewhere in Greece or the Mediterranean.
And they'll basically kind of infuse the whole dish of potatoes with a nice rosemary flavor.
You could use dried rosemary if you, if you don't have fresh rosemary.
I've lined this pan with foil just so that it's easier to clean afterwards.
And that's going to go into the oven.
